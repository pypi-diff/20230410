# Comparing `tmp/mlrun-1.3.0rc9-py3-none-any.whl.zip` & `tmp/mlrun-1.3.1rc1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,374 +1,394 @@
-Zip file size: 1090382 bytes, number of entries: 372
--rw-r--r--  2.0 unx     8121 b- defN 23-Jan-18 11:42 mlrun/__init__.py
--rw-r--r--  2.0 unx    45801 b- defN 23-Jan-18 11:42 mlrun/__main__.py
--rw-r--r--  2.0 unx    22043 b- defN 23-Jan-18 11:42 mlrun/builder.py
--rw-r--r--  2.0 unx    48683 b- defN 23-Jan-18 11:42 mlrun/config.py
--rw-r--r--  2.0 unx     6505 b- defN 23-Jan-18 11:42 mlrun/errors.py
--rw-r--r--  2.0 unx    35473 b- defN 23-Jan-18 11:42 mlrun/execution.py
--rw-r--r--  2.0 unx    14557 b- defN 23-Jan-18 11:42 mlrun/features.py
--rw-r--r--  2.0 unx    30935 b- defN 23-Jan-18 11:42 mlrun/k8s_utils.py
--rw-r--r--  2.0 unx    27764 b- defN 23-Jan-18 11:42 mlrun/kfpops.py
--rw-r--r--  2.0 unx     8301 b- defN 23-Jan-18 11:42 mlrun/lists.py
--rw-r--r--  2.0 unx    44013 b- defN 23-Jan-18 11:42 mlrun/model.py
--rw-r--r--  2.0 unx    11828 b- defN 23-Jan-18 11:42 mlrun/render.py
--rw-r--r--  2.0 unx    78718 b- defN 23-Jan-18 11:42 mlrun/run.py
--rw-r--r--  2.0 unx     7579 b- defN 23-Jan-18 11:42 mlrun/secrets.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/__init__.py
--rw-r--r--  2.0 unx     2105 b- defN 23-Jan-18 11:42 mlrun/api/alembic.ini
--rw-r--r--  2.0 unx      685 b- defN 23-Jan-18 11:42 mlrun/api/constants.py
--rw-r--r--  2.0 unx    23530 b- defN 23-Jan-18 11:42 mlrun/api/initial_data.py
--rw-r--r--  2.0 unx    13806 b- defN 23-Jan-18 11:42 mlrun/api/main.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/api/__init__.py
--rw-r--r--  2.0 unx     4267 b- defN 23-Jan-18 11:42 mlrun/api/api/api.py
--rw-r--r--  2.0 unx     3646 b- defN 23-Jan-18 11:42 mlrun/api/api/deps.py
--rw-r--r--  2.0 unx    31272 b- defN 23-Jan-18 11:42 mlrun/api/api/utils.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/__init__.py
--rw-r--r--  2.0 unx     9458 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/artifacts.py
--rw-r--r--  2.0 unx     1190 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/auth.py
--rw-r--r--  2.0 unx     3588 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/background_tasks.py
--rw-r--r--  2.0 unx      859 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/client_spec.py
--rw-r--r--  2.0 unx     1160 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/clusterization_spec.py
--rw-r--r--  2.0 unx    28813 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/feature_store.py
--rw-r--r--  2.0 unx     6065 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/files.py
--rw-r--r--  2.0 unx     5549 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/frontend_spec.py
--rw-r--r--  2.0 unx    29653 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/functions.py
--rw-r--r--  2.0 unx    17927 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/grafana_proxy.py
--rw-r--r--  2.0 unx      979 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/healthz.py
--rw-r--r--  2.0 unx     2620 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/logs.py
--rw-r--r--  2.0 unx     8283 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/marketplace.py
--rw-r--r--  2.0 unx    15513 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/model_endpoints.py
--rw-r--r--  2.0 unx     3700 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/operations.py
--rw-r--r--  2.0 unx    10347 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/pipelines.py
--rw-r--r--  2.0 unx    11335 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/projects.py
--rw-r--r--  2.0 unx     8956 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/runs.py
--rw-r--r--  2.0 unx    12375 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/runtime_resources.py
--rw-r--r--  2.0 unx    10579 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/schedules.py
--rw-r--r--  2.0 unx     6057 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/secrets.py
--rw-r--r--  2.0 unx     4857 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/submit.py
--rw-r--r--  2.0 unx     4843 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/tags.py
--rw-r--r--  2.0 unx     1203 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/internal/__init__.py
--rw-r--r--  2.0 unx     1043 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/internal/config.py
--rw-r--r--  2.0 unx     1709 b- defN 23-Jan-18 11:42 mlrun/api/api/endpoints/internal/memory_reports.py
--rw-r--r--  2.0 unx     1296 b- defN 23-Jan-18 11:42 mlrun/api/crud/__init__.py
--rw-r--r--  2.0 unx     5433 b- defN 23-Jan-18 11:42 mlrun/api/crud/artifacts.py
--rw-r--r--  2.0 unx     5823 b- defN 23-Jan-18 11:42 mlrun/api/crud/client_spec.py
--rw-r--r--  2.0 unx     1049 b- defN 23-Jan-18 11:42 mlrun/api/crud/clusterization_spec.py
--rw-r--r--  2.0 unx    18449 b- defN 23-Jan-18 11:42 mlrun/api/crud/feature_store.py
--rw-r--r--  2.0 unx     2612 b- defN 23-Jan-18 11:42 mlrun/api/crud/functions.py
--rw-r--r--  2.0 unx     4429 b- defN 23-Jan-18 11:42 mlrun/api/crud/logs.py
--rw-r--r--  2.0 unx     8180 b- defN 23-Jan-18 11:42 mlrun/api/crud/marketplace.py
--rw-r--r--  2.0 unx    13968 b- defN 23-Jan-18 11:42 mlrun/api/crud/pipelines.py
--rw-r--r--  2.0 unx    12098 b- defN 23-Jan-18 11:42 mlrun/api/crud/projects.py
--rw-r--r--  2.0 unx     5787 b- defN 23-Jan-18 11:42 mlrun/api/crud/runs.py
--rw-r--r--  2.0 unx     5539 b- defN 23-Jan-18 11:42 mlrun/api/crud/runtime_resources.py
--rw-r--r--  2.0 unx    19885 b- defN 23-Jan-18 11:42 mlrun/api/crud/secrets.py
--rw-r--r--  2.0 unx     3265 b- defN 23-Jan-18 11:42 mlrun/api/crud/tags.py
--rw-r--r--  2.0 unx      701 b- defN 23-Jan-18 11:42 mlrun/api/crud/model_monitoring/__init__.py
--rw-r--r--  2.0 unx    36036 b- defN 23-Jan-18 11:42 mlrun/api/crud/model_monitoring/model_endpoint_store.py
--rw-r--r--  2.0 unx    32108 b- defN 23-Jan-18 11:42 mlrun/api/crud/model_monitoring/model_endpoints.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/db/__init__.py
--rw-r--r--  2.0 unx    12967 b- defN 23-Jan-18 11:42 mlrun/api/db/base.py
--rw-r--r--  2.0 unx      870 b- defN 23-Jan-18 11:42 mlrun/api/db/init_db.py
--rw-r--r--  2.0 unx     1226 b- defN 23-Jan-18 11:42 mlrun/api/db/session.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/db/filedb/__init__.py
--rw-r--r--  2.0 unx    13831 b- defN 23-Jan-18 11:42 mlrun/api/db/filedb/db.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/db/sqldb/__init__.py
--rw-r--r--  2.0 unx   133098 b- defN 23-Jan-18 11:42 mlrun/api/db/sqldb/db.py
--rw-r--r--  2.0 unx     2340 b- defN 23-Jan-18 11:42 mlrun/api/db/sqldb/helpers.py
--rw-r--r--  2.0 unx     2245 b- defN 23-Jan-18 11:42 mlrun/api/db/sqldb/session.py
--rw-r--r--  2.0 unx     1063 b- defN 23-Jan-18 11:42 mlrun/api/db/sqldb/models/__init__.py
--rw-r--r--  2.0 unx    18680 b- defN 23-Jan-18 11:42 mlrun/api/db/sqldb/models/models_mysql.py
--rw-r--r--  2.0 unx    17249 b- defN 23-Jan-18 11:42 mlrun/api/db/sqldb/models/models_sqlite.py
--rw-r--r--  2.0 unx     2906 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/env.py
--rw-r--r--  2.0 unx     4614 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/versions/32bae1b0e29c_increase_timestamp_fields_precision.py
--rw-r--r--  2.0 unx     1936 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/versions/4903aef6a91d_tag_foreign_key_and_cascades.py
--rw-r--r--  2.0 unx     1909 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/versions/5f1351c88a19_adding_background_tasks_table.py
--rw-r--r--  2.0 unx     1504 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/versions/9d16de5f03a7_adding_data_versions_table.py
--rw-r--r--  2.0 unx     1649 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/versions/b86f5b53f3d7_adding_name_and_updated_to_runs_table.py
--rw-r--r--  2.0 unx    24057 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/versions/c4af40b0bf61_init.py
--rw-r--r--  2.0 unx     1351 b- defN 23-Jan-18 11:42 mlrun/api/migrations_mysql/versions/ee041e8fdaa0_adding_next_run_time_column_to_schedule_.py
--rw-r--r--  2.0 unx     2906 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/env.py
--rw-r--r--  2.0 unx    11473 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/11f8dd2dc9fe_init.py
--rw-r--r--  2.0 unx     1348 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/1c954f8cb32d_schedule_last_run_uri.py
--rw-r--r--  2.0 unx     5180 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/2b6d23c715aa_adding_feature_sets.py
--rw-r--r--  2.0 unx     1388 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/6401142f2d7c_adding_next_run_time_column_to_schedule_.py
--rw-r--r--  2.0 unx     1767 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/64d90a1a69bc_adding_background_tasks_table.py
--rw-r--r--  2.0 unx     1259 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/863114f0c659_refactoring_feature_set.py
--rw-r--r--  2.0 unx     1482 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/accf9fc83d38_adding_data_versions_table.py
--rw-r--r--  2.0 unx     1892 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/b68e8e897a28_schedule_labels.py
--rw-r--r--  2.0 unx     1882 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/bcd0c1f9720c_adding_project_labels.py
--rw-r--r--  2.0 unx     1420 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/cf21882f938e_schedule_id.py
--rw-r--r--  2.0 unx     2034 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/d781f58f607f_tag_object_name_string.py
--rw-r--r--  2.0 unx     1828 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/deac06871ace_adding_marketplace_sources_table.py
--rw-r--r--  2.0 unx     1380 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/e1dd5983c06b_schedule_concurrency_limit.py
--rw-r--r--  2.0 unx     1831 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/e5594ed3ab53_adding_name_and_updated_to_runs_table.py
--rw-r--r--  2.0 unx     3936 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/f4249b4ba6fa_adding_feature_vectors.py
--rw-r--r--  2.0 unx     2588 b- defN 23-Jan-18 11:42 mlrun/api/migrations_sqlite/versions/f7b5a1a03629_adding_feature_labels.py
--rw-r--r--  2.0 unx     3976 b- defN 23-Jan-18 11:42 mlrun/api/schemas/__init__.py
--rw-r--r--  2.0 unx     2070 b- defN 23-Jan-18 11:42 mlrun/api/schemas/artifact.py
--rw-r--r--  2.0 unx     5311 b- defN 23-Jan-18 11:42 mlrun/api/schemas/auth.py
--rw-r--r--  2.0 unx     1563 b- defN 23-Jan-18 11:42 mlrun/api/schemas/background_task.py
--rw-r--r--  2.0 unx     2717 b- defN 23-Jan-18 11:42 mlrun/api/schemas/client_spec.py
--rw-r--r--  2.0 unx      898 b- defN 23-Jan-18 11:42 mlrun/api/schemas/clusterization_spec.py
--rw-r--r--  2.0 unx     5224 b- defN 23-Jan-18 11:42 mlrun/api/schemas/constants.py
--rw-r--r--  2.0 unx     3661 b- defN 23-Jan-18 11:42 mlrun/api/schemas/feature_store.py
--rw-r--r--  2.0 unx     2513 b- defN 23-Jan-18 11:42 mlrun/api/schemas/frontend_spec.py
--rw-r--r--  2.0 unx     3991 b- defN 23-Jan-18 11:42 mlrun/api/schemas/function.py
--rw-r--r--  2.0 unx      715 b- defN 23-Jan-18 11:42 mlrun/api/schemas/http.py
--rw-r--r--  2.0 unx     1405 b- defN 23-Jan-18 11:42 mlrun/api/schemas/k8s.py
--rw-r--r--  2.0 unx     4255 b- defN 23-Jan-18 11:42 mlrun/api/schemas/marketplace.py
--rw-r--r--  2.0 unx      920 b- defN 23-Jan-18 11:42 mlrun/api/schemas/memory_reports.py
--rw-r--r--  2.0 unx     4872 b- defN 23-Jan-18 11:42 mlrun/api/schemas/model_endpoints.py
--rw-r--r--  2.0 unx     1960 b- defN 23-Jan-18 11:42 mlrun/api/schemas/object.py
--rw-r--r--  2.0 unx     1194 b- defN 23-Jan-18 11:42 mlrun/api/schemas/pipeline.py
--rw-r--r--  2.0 unx     3909 b- defN 23-Jan-18 11:42 mlrun/api/schemas/project.py
--rw-r--r--  2.0 unx     1646 b- defN 23-Jan-18 11:42 mlrun/api/schemas/runtime_resource.py
--rw-r--r--  2.0 unx     3986 b- defN 23-Jan-18 11:42 mlrun/api/schemas/schedule.py
--rw-r--r--  2.0 unx     1484 b- defN 23-Jan-18 11:42 mlrun/api/schemas/secret.py
--rw-r--r--  2.0 unx      919 b- defN 23-Jan-18 11:42 mlrun/api/schemas/tag.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/__init__.py
--rw-r--r--  2.0 unx     1092 b- defN 23-Jan-18 11:42 mlrun/api/utils/asyncio.py
--rw-r--r--  2.0 unx     7302 b- defN 23-Jan-18 11:42 mlrun/api/utils/background_tasks.py
--rw-r--r--  2.0 unx     2413 b- defN 23-Jan-18 11:42 mlrun/api/utils/helpers.py
--rw-r--r--  2.0 unx     3728 b- defN 23-Jan-18 11:42 mlrun/api/utils/memory_reports.py
--rw-r--r--  2.0 unx     2599 b- defN 23-Jan-18 11:42 mlrun/api/utils/periodic.py
--rw-r--r--  2.0 unx    38870 b- defN 23-Jan-18 11:42 mlrun/api/utils/scheduler.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/auth/__init__.py
--rw-r--r--  2.0 unx    12249 b- defN 23-Jan-18 11:42 mlrun/api/utils/auth/verifier.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/auth/providers/__init__.py
--rw-r--r--  2.0 unx     1363 b- defN 23-Jan-18 11:42 mlrun/api/utils/auth/providers/base.py
--rw-r--r--  2.0 unx     1470 b- defN 23-Jan-18 11:42 mlrun/api/utils/auth/providers/nop.py
--rw-r--r--  2.0 unx    10471 b- defN 23-Jan-18 11:42 mlrun/api/utils/auth/providers/opa.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/clients/__init__.py
--rw-r--r--  2.0 unx    13014 b- defN 23-Jan-18 11:42 mlrun/api/utils/clients/chief.py
--rw-r--r--  2.0 unx    30137 b- defN 23-Jan-18 11:42 mlrun/api/utils/clients/iguazio.py
--rw-r--r--  2.0 unx     9841 b- defN 23-Jan-18 11:42 mlrun/api/utils/clients/nuclio.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/db/__init__.py
--rw-r--r--  2.0 unx     3305 b- defN 23-Jan-18 11:42 mlrun/api/utils/db/alembic.py
--rw-r--r--  2.0 unx     8100 b- defN 23-Jan-18 11:42 mlrun/api/utils/db/backup.py
--rw-r--r--  2.0 unx     3793 b- defN 23-Jan-18 11:42 mlrun/api/utils/db/mysql.py
--rw-r--r--  2.0 unx      992 b- defN 23-Jan-18 11:42 mlrun/api/utils/db/sql_collation.py
--rw-r--r--  2.0 unx     3855 b- defN 23-Jan-18 11:42 mlrun/api/utils/db/sqlite_migration.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/__init__.py
--rw-r--r--  2.0 unx    17315 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/follower.py
--rw-r--r--  2.0 unx    19424 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/leader.py
--rw-r--r--  2.0 unx     4936 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/member.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/remotes/__init__.py
--rw-r--r--  2.0 unx     2614 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/remotes/follower.py
--rw-r--r--  2.0 unx     2064 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/remotes/leader.py
--rw-r--r--  2.0 unx     4601 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/remotes/nop_follower.py
--rw-r--r--  2.0 unx     3801 b- defN 23-Jan-18 11:42 mlrun/api/utils/projects/remotes/nop_leader.py
--rw-r--r--  2.0 unx      571 b- defN 23-Jan-18 11:42 mlrun/api/utils/singletons/__init__.py
--rw-r--r--  2.0 unx     1439 b- defN 23-Jan-18 11:42 mlrun/api/utils/singletons/db.py
--rw-r--r--  2.0 unx      694 b- defN 23-Jan-18 11:42 mlrun/api/utils/singletons/k8s.py
--rw-r--r--  2.0 unx      840 b- defN 23-Jan-18 11:42 mlrun/api/utils/singletons/logs_dir.py
--rw-r--r--  2.0 unx     1279 b- defN 23-Jan-18 11:42 mlrun/api/utils/singletons/project_member.py
--rw-r--r--  2.0 unx     1063 b- defN 23-Jan-18 11:42 mlrun/api/utils/singletons/scheduler.py
--rw-r--r--  2.0 unx     1091 b- defN 23-Jan-18 11:42 mlrun/artifacts/__init__.py
--rw-r--r--  2.0 unx    46443 b- defN 23-Jan-18 11:42 mlrun/artifacts/base.py
--rw-r--r--  2.0 unx    24722 b- defN 23-Jan-18 11:42 mlrun/artifacts/dataset.py
--rw-r--r--  2.0 unx    12001 b- defN 23-Jan-18 11:42 mlrun/artifacts/manager.py
--rw-r--r--  2.0 unx    32043 b- defN 23-Jan-18 11:42 mlrun/artifacts/model.py
--rw-r--r--  2.0 unx    14636 b- defN 23-Jan-18 11:42 mlrun/artifacts/plots.py
--rw-r--r--  2.0 unx     1039 b- defN 23-Jan-18 11:42 mlrun/data_types/__init__.py
--rw-r--r--  2.0 unx     4541 b- defN 23-Jan-18 11:42 mlrun/data_types/data_types.py
--rw-r--r--  2.0 unx     5499 b- defN 23-Jan-18 11:42 mlrun/data_types/infer.py
--rw-r--r--  2.0 unx     8786 b- defN 23-Jan-18 11:42 mlrun/data_types/spark.py
--rw-r--r--  2.0 unx     3300 b- defN 23-Jan-18 11:42 mlrun/datastore/__init__.py
--rw-r--r--  2.0 unx     6946 b- defN 23-Jan-18 11:42 mlrun/datastore/azure_blob.py
--rw-r--r--  2.0 unx    16142 b- defN 23-Jan-18 11:42 mlrun/datastore/base.py
--rw-r--r--  2.0 unx     7961 b- defN 23-Jan-18 11:42 mlrun/datastore/datastore.py
--rw-r--r--  2.0 unx     3791 b- defN 23-Jan-18 11:42 mlrun/datastore/filestore.py
--rw-r--r--  2.0 unx     5114 b- defN 23-Jan-18 11:42 mlrun/datastore/google_cloud_storage.py
--rw-r--r--  2.0 unx     2627 b- defN 23-Jan-18 11:42 mlrun/datastore/inmem.py
--rw-r--r--  2.0 unx     4758 b- defN 23-Jan-18 11:42 mlrun/datastore/redis.py
--rw-r--r--  2.0 unx     7035 b- defN 23-Jan-18 11:42 mlrun/datastore/s3.py
--rw-r--r--  2.0 unx    29687 b- defN 23-Jan-18 11:42 mlrun/datastore/sources.py
--rw-r--r--  2.0 unx     6864 b- defN 23-Jan-18 11:42 mlrun/datastore/store_resources.py
--rw-r--r--  2.0 unx    52773 b- defN 23-Jan-18 11:42 mlrun/datastore/targets.py
--rw-r--r--  2.0 unx     1512 b- defN 23-Jan-18 11:42 mlrun/datastore/utils.py
--rw-r--r--  2.0 unx     8097 b- defN 23-Jan-18 11:42 mlrun/datastore/v3io.py
--rw-r--r--  2.0 unx     1343 b- defN 23-Jan-18 11:42 mlrun/datastore/wasbfs/__init__.py
--rw-r--r--  2.0 unx     6152 b- defN 23-Jan-18 11:42 mlrun/datastore/wasbfs/fs.py
--rw-r--r--  2.0 unx     2806 b- defN 23-Jan-18 11:42 mlrun/db/__init__.py
--rw-r--r--  2.0 unx    14722 b- defN 23-Jan-18 11:42 mlrun/db/base.py
--rw-r--r--  2.0 unx    28101 b- defN 23-Jan-18 11:42 mlrun/db/filedb.py
--rw-r--r--  2.0 unx   127412 b- defN 23-Jan-18 11:42 mlrun/db/httpdb.py
--rw-r--r--  2.0 unx    23676 b- defN 23-Jan-18 11:42 mlrun/db/sqldb.py
--rw-r--r--  2.0 unx     1501 b- defN 23-Jan-18 11:42 mlrun/feature_store/__init__.py
--rw-r--r--  2.0 unx    41126 b- defN 23-Jan-18 11:42 mlrun/feature_store/api.py
--rw-r--r--  2.0 unx    12754 b- defN 23-Jan-18 11:42 mlrun/feature_store/common.py
--rw-r--r--  2.0 unx    41889 b- defN 23-Jan-18 11:42 mlrun/feature_store/feature_set.py
--rw-r--r--  2.0 unx    21658 b- defN 23-Jan-18 11:42 mlrun/feature_store/feature_vector.py
--rw-r--r--  2.0 unx    11461 b- defN 23-Jan-18 11:42 mlrun/feature_store/ingestion.py
--rw-r--r--  2.0 unx    23658 b- defN 23-Jan-18 11:42 mlrun/feature_store/steps.py
--rw-r--r--  2.0 unx     1012 b- defN 23-Jan-18 11:42 mlrun/feature_store/retrieval/__init__.py
--rw-r--r--  2.0 unx     7588 b- defN 23-Jan-18 11:42 mlrun/feature_store/retrieval/base.py
--rw-r--r--  2.0 unx     4738 b- defN 23-Jan-18 11:42 mlrun/feature_store/retrieval/dask_merger.py
--rw-r--r--  2.0 unx     5437 b- defN 23-Jan-18 11:42 mlrun/feature_store/retrieval/job.py
--rw-r--r--  2.0 unx     4941 b- defN 23-Jan-18 11:42 mlrun/feature_store/retrieval/local_merger.py
--rw-r--r--  2.0 unx     3352 b- defN 23-Jan-18 11:42 mlrun/feature_store/retrieval/online.py
--rw-r--r--  2.0 unx     9726 b- defN 23-Jan-18 11:42 mlrun/feature_store/retrieval/spark_merger.py
--rw-r--r--  2.0 unx      743 b- defN 23-Jan-18 11:42 mlrun/frameworks/__init__.py
--rw-r--r--  2.0 unx    11404 b- defN 23-Jan-18 11:42 mlrun/frameworks/parallel_coordinates.py
--rw-r--r--  2.0 unx      962 b- defN 23-Jan-18 11:42 mlrun/frameworks/_common/__init__.py
--rw-r--r--  2.0 unx     8515 b- defN 23-Jan-18 11:42 mlrun/frameworks/_common/artifacts_library.py
--rw-r--r--  2.0 unx    21018 b- defN 23-Jan-18 11:42 mlrun/frameworks/_common/mlrun_interface.py
--rw-r--r--  2.0 unx    55376 b- defN 23-Jan-18 11:42 mlrun/frameworks/_common/model_handler.py
--rw-r--r--  2.0 unx     3469 b- defN 23-Jan-18 11:42 mlrun/frameworks/_common/plan.py
--rw-r--r--  2.0 unx     5757 b- defN 23-Jan-18 11:42 mlrun/frameworks/_common/producer.py
--rw-r--r--  2.0 unx     9209 b- defN 23-Jan-18 11:42 mlrun/frameworks/_common/utils.py
--rw-r--r--  2.0 unx      750 b- defN 23-Jan-18 11:42 mlrun/frameworks/_dl_common/__init__.py
--rw-r--r--  2.0 unx     1151 b- defN 23-Jan-18 11:42 mlrun/frameworks/_dl_common/model_handler.py
--rw-r--r--  2.0 unx      996 b- defN 23-Jan-18 11:42 mlrun/frameworks/_dl_common/utils.py
--rw-r--r--  2.0 unx      787 b- defN 23-Jan-18 11:42 mlrun/frameworks/_dl_common/loggers/__init__.py
--rw-r--r--  2.0 unx    11531 b- defN 23-Jan-18 11:42 mlrun/frameworks/_dl_common/loggers/logger.py
--rw-r--r--  2.0 unx    14777 b- defN 23-Jan-18 11:42 mlrun/frameworks/_dl_common/loggers/mlrun_logger.py
--rw-r--r--  2.0 unx    28414 b- defN 23-Jan-18 11:42 mlrun/frameworks/_dl_common/loggers/tensorboard_logger.py
--rw-r--r--  2.0 unx      956 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/__init__.py
--rw-r--r--  2.0 unx     3169 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/artifacts_library.py
--rw-r--r--  2.0 unx    16957 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/model_handler.py
--rw-r--r--  2.0 unx     1702 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/pkl_model_server.py
--rw-r--r--  2.0 unx     4881 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/plan.py
--rw-r--r--  2.0 unx     4061 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/producer.py
--rw-r--r--  2.0 unx    10490 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/utils.py
--rw-r--r--  2.0 unx      737 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/loggers/__init__.py
--rw-r--r--  2.0 unx     5684 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/loggers/logger.py
--rw-r--r--  2.0 unx     6453 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/loggers/mlrun_logger.py
--rw-r--r--  2.0 unx      922 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/plans/__init__.py
--rw-r--r--  2.0 unx     5212 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/plans/calibration_curve_plan.py
--rw-r--r--  2.0 unx     6078 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/plans/confusion_matrix_plan.py
--rw-r--r--  2.0 unx     6658 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/plans/dataset_plan.py
--rw-r--r--  2.0 unx     5318 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/plans/feature_importance_plan.py
--rw-r--r--  2.0 unx     6993 b- defN 23-Jan-18 11:42 mlrun/frameworks/_ml_common/plans/roc_curve_plan.py
--rw-r--r--  2.0 unx      706 b- defN 23-Jan-18 11:42 mlrun/frameworks/auto_mlrun/__init__.py
--rw-r--r--  2.0 unx    23796 b- defN 23-Jan-18 11:42 mlrun/frameworks/auto_mlrun/auto_mlrun.py
--rw-r--r--  2.0 unx      721 b- defN 23-Jan-18 11:42 mlrun/frameworks/huggingface/__init__.py
--rw-r--r--  2.0 unx     6083 b- defN 23-Jan-18 11:42 mlrun/frameworks/huggingface/model_server.py
--rw-r--r--  2.0 unx    15883 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/__init__.py
--rw-r--r--  2.0 unx    13891 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/model_handler.py
--rw-r--r--  2.0 unx     9189 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/model_server.py
--rw-r--r--  2.0 unx     8278 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/utils.py
--rw-r--r--  2.0 unx      857 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/callbacks/__init__.py
--rw-r--r--  2.0 unx     4081 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/callbacks/callback.py
--rw-r--r--  2.0 unx     5156 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/callbacks/logging_callback.py
--rw-r--r--  2.0 unx     4137 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/callbacks/mlrun_logging_callback.py
--rw-r--r--  2.0 unx      842 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/mlrun_interfaces/__init__.py
--rw-r--r--  2.0 unx     1624 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/mlrun_interfaces/booster_mlrun_interface.py
--rw-r--r--  2.0 unx    14256 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/mlrun_interfaces/mlrun_interface.py
--rw-r--r--  2.0 unx     1333 b- defN 23-Jan-18 11:42 mlrun/frameworks/lgbm/mlrun_interfaces/model_mlrun_interface.py
--rw-r--r--  2.0 unx      791 b- defN 23-Jan-18 11:42 mlrun/frameworks/onnx/__init__.py
--rw-r--r--  2.0 unx     6098 b- defN 23-Jan-18 11:42 mlrun/frameworks/onnx/dataset.py
--rw-r--r--  2.0 unx     2405 b- defN 23-Jan-18 11:42 mlrun/frameworks/onnx/mlrun_interface.py
--rw-r--r--  2.0 unx     6120 b- defN 23-Jan-18 11:42 mlrun/frameworks/onnx/model_handler.py
--rw-r--r--  2.0 unx     7061 b- defN 23-Jan-18 11:42 mlrun/frameworks/onnx/model_server.py
--rw-r--r--  2.0 unx    22056 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/__init__.py
--rw-r--r--  2.0 unx    27904 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/callbacks_handler.py
--rw-r--r--  2.0 unx    44639 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/mlrun_interface.py
--rw-r--r--  2.0 unx    22465 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/model_handler.py
--rw-r--r--  2.0 unx    10136 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/model_server.py
--rw-r--r--  2.0 unx     4515 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/utils.py
--rw-r--r--  2.0 unx      896 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/callbacks/__init__.py
--rw-r--r--  2.0 unx    11524 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/callbacks/callback.py
--rw-r--r--  2.0 unx    23166 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/callbacks/logging_callback.py
--rw-r--r--  2.0 unx     9310 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/callbacks/mlrun_logging_callback.py
--rw-r--r--  2.0 unx    26661 b- defN 23-Jan-18 11:42 mlrun/frameworks/pytorch/callbacks/tensorboard_logging_callback.py
--rw-r--r--  2.0 unx    10940 b- defN 23-Jan-18 11:42 mlrun/frameworks/sklearn/__init__.py
--rw-r--r--  2.0 unx     5852 b- defN 23-Jan-18 11:42 mlrun/frameworks/sklearn/estimator.py
--rw-r--r--  2.0 unx     7117 b- defN 23-Jan-18 11:42 mlrun/frameworks/sklearn/metric.py
--rw-r--r--  2.0 unx    12215 b- defN 23-Jan-18 11:42 mlrun/frameworks/sklearn/metrics_library.py
--rw-r--r--  2.0 unx    14126 b- defN 23-Jan-18 11:42 mlrun/frameworks/sklearn/mlrun_interface.py
--rw-r--r--  2.0 unx     4745 b- defN 23-Jan-18 11:42 mlrun/frameworks/sklearn/model_handler.py
--rw-r--r--  2.0 unx     1209 b- defN 23-Jan-18 11:42 mlrun/frameworks/sklearn/utils.py
--rw-r--r--  2.0 unx    10455 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/__init__.py
--rw-r--r--  2.0 unx    16627 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/mlrun_interface.py
--rw-r--r--  2.0 unx    28247 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/model_handler.py
--rw-r--r--  2.0 unx     9565 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/model_server.py
--rw-r--r--  2.0 unx     4284 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/utils.py
--rw-r--r--  2.0 unx      844 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/callbacks/__init__.py
--rw-r--r--  2.0 unx    21886 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/callbacks/logging_callback.py
--rw-r--r--  2.0 unx     8791 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/callbacks/mlrun_logging_callback.py
--rw-r--r--  2.0 unx    28728 b- defN 23-Jan-18 11:42 mlrun/frameworks/tf_keras/callbacks/tensorboard_logging_callback.py
--rw-r--r--  2.0 unx    10287 b- defN 23-Jan-18 11:42 mlrun/frameworks/xgboost/__init__.py
--rw-r--r--  2.0 unx      878 b- defN 23-Jan-18 11:42 mlrun/frameworks/xgboost/mlrun_interface.py
--rw-r--r--  2.0 unx    11617 b- defN 23-Jan-18 11:42 mlrun/frameworks/xgboost/model_handler.py
--rw-r--r--  2.0 unx     1069 b- defN 23-Jan-18 11:42 mlrun/frameworks/xgboost/utils.py
--rw-r--r--  2.0 unx      760 b- defN 23-Jan-18 11:42 mlrun/mlutils/__init__.py
--rw-r--r--  2.0 unx     4808 b- defN 23-Jan-18 11:42 mlrun/mlutils/data.py
--rw-r--r--  2.0 unx     2230 b- defN 23-Jan-18 11:42 mlrun/mlutils/models.py
--rw-r--r--  2.0 unx    28253 b- defN 23-Jan-18 11:42 mlrun/mlutils/plots.py
--rw-r--r--  2.0 unx     2142 b- defN 23-Jan-18 11:42 mlrun/model_monitoring/constants.py
--rw-r--r--  2.0 unx    23948 b- defN 23-Jan-18 11:42 mlrun/model_monitoring/features_drift_table.py
--rw-r--r--  2.0 unx     5939 b- defN 23-Jan-18 11:42 mlrun/model_monitoring/helpers.py
--rw-r--r--  2.0 unx    35538 b- defN 23-Jan-18 11:42 mlrun/model_monitoring/model_monitoring_batch.py
--rw-r--r--  2.0 unx    44033 b- defN 23-Jan-18 11:42 mlrun/model_monitoring/stream_processing_fs.py
--rw-r--r--  2.0 unx     2400 b- defN 23-Jan-18 11:42 mlrun/platforms/__init__.py
--rw-r--r--  2.0 unx    24642 b- defN 23-Jan-18 11:42 mlrun/platforms/iguazio.py
--rw-r--r--  2.0 unx    11852 b- defN 23-Jan-18 11:42 mlrun/platforms/other.py
--rw-r--r--  2.0 unx     1153 b- defN 23-Jan-18 11:42 mlrun/projects/__init__.py
--rw-r--r--  2.0 unx    15873 b- defN 23-Jan-18 11:42 mlrun/projects/operations.py
--rw-r--r--  2.0 unx    37274 b- defN 23-Jan-18 11:42 mlrun/projects/pipelines.py
--rw-r--r--  2.0 unx   117036 b- defN 23-Jan-18 11:42 mlrun/projects/project.py
--rw-r--r--  2.0 unx     6595 b- defN 23-Jan-18 11:42 mlrun/runtimes/__init__.py
--rw-r--r--  2.0 unx    96046 b- defN 23-Jan-18 11:42 mlrun/runtimes/base.py
--rw-r--r--  2.0 unx     6689 b- defN 23-Jan-18 11:42 mlrun/runtimes/constants.py
--rw-r--r--  2.0 unx    29821 b- defN 23-Jan-18 11:42 mlrun/runtimes/daskjob.py
--rw-r--r--  2.0 unx     9190 b- defN 23-Jan-18 11:42 mlrun/runtimes/funcdoc.py
--rw-r--r--  2.0 unx    60304 b- defN 23-Jan-18 11:42 mlrun/runtimes/function.py
--rw-r--r--  2.0 unx     4911 b- defN 23-Jan-18 11:42 mlrun/runtimes/function_reference.py
--rw-r--r--  2.0 unx     6530 b- defN 23-Jan-18 11:42 mlrun/runtimes/generators.py
--rw-r--r--  2.0 unx    15672 b- defN 23-Jan-18 11:42 mlrun/runtimes/kubejob.py
--rw-r--r--  2.0 unx    17083 b- defN 23-Jan-18 11:42 mlrun/runtimes/local.py
--rw-r--r--  2.0 unx     2885 b- defN 23-Jan-18 11:42 mlrun/runtimes/nuclio.py
--rw-r--r--  2.0 unx    59226 b- defN 23-Jan-18 11:42 mlrun/runtimes/pod.py
--rw-r--r--  2.0 unx     7472 b- defN 23-Jan-18 11:42 mlrun/runtimes/remotesparkjob.py
--rw-r--r--  2.0 unx    29227 b- defN 23-Jan-18 11:42 mlrun/runtimes/serving.py
--rw-r--r--  2.0 unx    21026 b- defN 23-Jan-18 11:42 mlrun/runtimes/utils.py
--rw-r--r--  2.0 unx      790 b- defN 23-Jan-18 11:42 mlrun/runtimes/mpijob/__init__.py
--rw-r--r--  2.0 unx    15538 b- defN 23-Jan-18 11:42 mlrun/runtimes/mpijob/abstract.py
--rw-r--r--  2.0 unx    12833 b- defN 23-Jan-18 11:42 mlrun/runtimes/mpijob/v1.py
--rw-r--r--  2.0 unx     7537 b- defN 23-Jan-18 11:42 mlrun/runtimes/mpijob/v1alpha1.py
--rw-r--r--  2.0 unx      788 b- defN 23-Jan-18 11:42 mlrun/runtimes/sparkjob/__init__.py
--rw-r--r--  2.0 unx    33761 b- defN 23-Jan-18 11:42 mlrun/runtimes/sparkjob/abstract.py
--rw-r--r--  2.0 unx     2033 b- defN 23-Jan-18 11:42 mlrun/runtimes/sparkjob/spark2job.py
--rw-r--r--  2.0 unx    28644 b- defN 23-Jan-18 11:42 mlrun/runtimes/sparkjob/spark3job.py
--rw-r--r--  2.0 unx     1050 b- defN 23-Jan-18 11:42 mlrun/serving/__init__.py
--rw-r--r--  2.0 unx     6116 b- defN 23-Jan-18 11:42 mlrun/serving/merger.py
--rw-r--r--  2.0 unx    18038 b- defN 23-Jan-18 11:42 mlrun/serving/remote.py
--rw-r--r--  2.0 unx    54988 b- defN 23-Jan-18 11:42 mlrun/serving/routers.py
--rw-r--r--  2.0 unx    18686 b- defN 23-Jan-18 11:42 mlrun/serving/server.py
--rw-r--r--  2.0 unx      836 b- defN 23-Jan-18 11:42 mlrun/serving/serving_wrapper.py
--rw-r--r--  2.0 unx    47891 b- defN 23-Jan-18 11:42 mlrun/serving/states.py
--rw-r--r--  2.0 unx     3468 b- defN 23-Jan-18 11:42 mlrun/serving/utils.py
--rw-r--r--  2.0 unx    11814 b- defN 23-Jan-18 11:42 mlrun/serving/v1_serving.py
--rw-r--r--  2.0 unx    21336 b- defN 23-Jan-18 11:42 mlrun/serving/v2_serving.py
--rw-r--r--  2.0 unx      855 b- defN 23-Jan-18 11:42 mlrun/utils/__init__.py
--rw-r--r--  2.0 unx    10397 b- defN 23-Jan-18 11:42 mlrun/utils/async_http.py
--rw-r--r--  2.0 unx     3456 b- defN 23-Jan-18 11:42 mlrun/utils/azure_vault.py
--rw-r--r--  2.0 unx     6186 b- defN 23-Jan-18 11:42 mlrun/utils/clones.py
--rw-r--r--  2.0 unx    35912 b- defN 23-Jan-18 11:42 mlrun/utils/helpers.py
--rw-r--r--  2.0 unx     6061 b- defN 23-Jan-18 11:42 mlrun/utils/http.py
--rw-r--r--  2.0 unx     5324 b- defN 23-Jan-18 11:42 mlrun/utils/logger.py
--rw-r--r--  2.0 unx     7097 b- defN 23-Jan-18 11:42 mlrun/utils/model_monitoring.py
--rw-r--r--  2.0 unx     3923 b- defN 23-Jan-18 11:42 mlrun/utils/regex.py
--rw-r--r--  2.0 unx      883 b- defN 23-Jan-18 11:42 mlrun/utils/singleton.py
--rw-r--r--  2.0 unx     1319 b- defN 23-Jan-18 11:42 mlrun/utils/v3io_clients.py
--rw-r--r--  2.0 unx     9957 b- defN 23-Jan-18 11:42 mlrun/utils/vault.py
--rw-r--r--  2.0 unx      990 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/__init__.py
--rw-r--r--  2.0 unx     7093 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/notification_pusher.py
--rw-r--r--  2.0 unx     1833 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/notification/__init__.py
--rw-r--r--  2.0 unx     2067 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/notification/base.py
--rw-r--r--  2.0 unx     1901 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/notification/console.py
--rw-r--r--  2.0 unx     4510 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/notification/git.py
--rw-r--r--  2.0 unx     1951 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/notification/ipython.py
--rw-r--r--  2.0 unx     3650 b- defN 23-Jan-18 11:42 mlrun/utils/notifications/notification/slack.py
--rw-r--r--  2.0 unx      614 b- defN 23-Jan-18 11:42 mlrun/utils/version/__init__.py
--rw-r--r--  2.0 unx       88 b- defN 23-Jan-18 11:42 mlrun/utils/version/version.json
--rw-r--r--  2.0 unx     1469 b- defN 23-Jan-18 11:42 mlrun/utils/version/version.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Jan-18 11:42 mlrun-1.3.0rc9.dist-info/LICENSE
--rw-r--r--  2.0 unx    16288 b- defN 23-Jan-18 11:42 mlrun-1.3.0rc9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jan-18 11:42 mlrun-1.3.0rc9.dist-info/WHEEL
--rw-r--r--  2.0 unx       47 b- defN 23-Jan-18 11:42 mlrun-1.3.0rc9.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        6 b- defN 23-Jan-18 11:42 mlrun-1.3.0rc9.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    34699 b- defN 23-Jan-18 11:42 mlrun-1.3.0rc9.dist-info/RECORD
-372 files, 4132270 bytes uncompressed, 1035118 bytes compressed:  75.0%
+Zip file size: 1154739 bytes, number of entries: 392
+-rw-r--r--  2.0 unx     8727 b- defN 23-Apr-10 11:28 mlrun/__init__.py
+-rw-r--r--  2.0 unx    47778 b- defN 23-Apr-10 11:28 mlrun/__main__.py
+-rw-r--r--  2.0 unx    23554 b- defN 23-Apr-10 11:28 mlrun/builder.py
+-rw-r--r--  2.0 unx    49829 b- defN 23-Apr-10 11:28 mlrun/config.py
+-rw-r--r--  2.0 unx     6587 b- defN 23-Apr-10 11:28 mlrun/errors.py
+-rw-r--r--  2.0 unx    38928 b- defN 23-Apr-10 11:28 mlrun/execution.py
+-rw-r--r--  2.0 unx    15531 b- defN 23-Apr-10 11:28 mlrun/features.py
+-rw-r--r--  2.0 unx    31384 b- defN 23-Apr-10 11:28 mlrun/k8s_utils.py
+-rw-r--r--  2.0 unx    29645 b- defN 23-Apr-10 11:28 mlrun/kfpops.py
+-rw-r--r--  2.0 unx     8360 b- defN 23-Apr-10 11:28 mlrun/lists.py
+-rw-r--r--  2.0 unx    52194 b- defN 23-Apr-10 11:28 mlrun/model.py
+-rw-r--r--  2.0 unx    11828 b- defN 23-Apr-10 11:28 mlrun/render.py
+-rw-r--r--  2.0 unx    64321 b- defN 23-Apr-10 11:28 mlrun/run.py
+-rw-r--r--  2.0 unx     7731 b- defN 23-Apr-10 11:28 mlrun/secrets.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/__init__.py
+-rw-r--r--  2.0 unx     2105 b- defN 23-Apr-10 11:28 mlrun/api/alembic.ini
+-rw-r--r--  2.0 unx      685 b- defN 23-Apr-10 11:28 mlrun/api/constants.py
+-rw-r--r--  2.0 unx    23530 b- defN 23-Apr-10 11:28 mlrun/api/initial_data.py
+-rw-r--r--  2.0 unx    24019 b- defN 23-Apr-10 11:28 mlrun/api/main.py
+-rw-r--r--  2.0 unx     5235 b- defN 23-Apr-10 11:28 mlrun/api/middlewares.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/api/__init__.py
+-rw-r--r--  2.0 unx     4267 b- defN 23-Apr-10 11:28 mlrun/api/api/api.py
+-rw-r--r--  2.0 unx     3143 b- defN 23-Apr-10 11:28 mlrun/api/api/deps.py
+-rw-r--r--  2.0 unx    32788 b- defN 23-Apr-10 11:28 mlrun/api/api/utils.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/__init__.py
+-rw-r--r--  2.0 unx     9458 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/artifacts.py
+-rw-r--r--  2.0 unx     1190 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/auth.py
+-rw-r--r--  2.0 unx     3588 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/background_tasks.py
+-rw-r--r--  2.0 unx     1202 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/client_spec.py
+-rw-r--r--  2.0 unx     1160 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/clusterization_spec.py
+-rw-r--r--  2.0 unx    28813 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/feature_store.py
+-rw-r--r--  2.0 unx     6065 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/files.py
+-rw-r--r--  2.0 unx     5690 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/frontend_spec.py
+-rw-r--r--  2.0 unx    33894 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/functions.py
+-rw-r--r--  2.0 unx     5798 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/grafana_proxy.py
+-rw-r--r--  2.0 unx      979 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/healthz.py
+-rw-r--r--  2.0 unx     2429 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/logs.py
+-rw-r--r--  2.0 unx     8283 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/marketplace.py
+-rw-r--r--  2.0 unx    15724 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/model_endpoints.py
+-rw-r--r--  2.0 unx     3700 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/operations.py
+-rw-r--r--  2.0 unx     9099 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/pipelines.py
+-rw-r--r--  2.0 unx    11392 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/projects.py
+-rw-r--r--  2.0 unx     8956 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/runs.py
+-rw-r--r--  2.0 unx     8988 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/runtime_resources.py
+-rw-r--r--  2.0 unx    10579 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/schedules.py
+-rw-r--r--  2.0 unx     6057 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/secrets.py
+-rw-r--r--  2.0 unx     5265 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/submit.py
+-rw-r--r--  2.0 unx     4843 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/tags.py
+-rw-r--r--  2.0 unx     1203 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/internal/__init__.py
+-rw-r--r--  2.0 unx     1043 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/internal/config.py
+-rw-r--r--  2.0 unx     1709 b- defN 23-Apr-10 11:28 mlrun/api/api/endpoints/internal/memory_reports.py
+-rw-r--r--  2.0 unx     1184 b- defN 23-Apr-10 11:28 mlrun/api/crud/__init__.py
+-rw-r--r--  2.0 unx     5433 b- defN 23-Apr-10 11:28 mlrun/api/crud/artifacts.py
+-rw-r--r--  2.0 unx     7341 b- defN 23-Apr-10 11:28 mlrun/api/crud/client_spec.py
+-rw-r--r--  2.0 unx     1049 b- defN 23-Apr-10 11:28 mlrun/api/crud/clusterization_spec.py
+-rw-r--r--  2.0 unx    18449 b- defN 23-Apr-10 11:28 mlrun/api/crud/feature_store.py
+-rw-r--r--  2.0 unx     3550 b- defN 23-Apr-10 11:28 mlrun/api/crud/functions.py
+-rw-r--r--  2.0 unx     9578 b- defN 23-Apr-10 11:28 mlrun/api/crud/logs.py
+-rw-r--r--  2.0 unx     8180 b- defN 23-Apr-10 11:28 mlrun/api/crud/marketplace.py
+-rw-r--r--  2.0 unx    13982 b- defN 23-Apr-10 11:28 mlrun/api/crud/pipelines.py
+-rw-r--r--  2.0 unx    13326 b- defN 23-Apr-10 11:28 mlrun/api/crud/projects.py
+-rw-r--r--  2.0 unx     5931 b- defN 23-Apr-10 11:28 mlrun/api/crud/runs.py
+-rw-r--r--  2.0 unx     5539 b- defN 23-Apr-10 11:28 mlrun/api/crud/runtime_resources.py
+-rw-r--r--  2.0 unx    19885 b- defN 23-Apr-10 11:28 mlrun/api/crud/secrets.py
+-rw-r--r--  2.0 unx     3265 b- defN 23-Apr-10 11:28 mlrun/api/crud/tags.py
+-rw-r--r--  2.0 unx      722 b- defN 23-Apr-10 11:28 mlrun/api/crud/model_monitoring/__init__.py
+-rw-r--r--  2.0 unx    14943 b- defN 23-Apr-10 11:28 mlrun/api/crud/model_monitoring/grafana.py
+-rw-r--r--  2.0 unx    40998 b- defN 23-Apr-10 11:28 mlrun/api/crud/model_monitoring/model_endpoints.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/db/__init__.py
+-rw-r--r--  2.0 unx    13684 b- defN 23-Apr-10 11:28 mlrun/api/db/base.py
+-rw-r--r--  2.0 unx      870 b- defN 23-Apr-10 11:28 mlrun/api/db/init_db.py
+-rw-r--r--  2.0 unx     1226 b- defN 23-Apr-10 11:28 mlrun/api/db/session.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/db/filedb/__init__.py
+-rw-r--r--  2.0 unx    14555 b- defN 23-Apr-10 11:28 mlrun/api/db/filedb/db.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/db/sqldb/__init__.py
+-rw-r--r--  2.0 unx   136433 b- defN 23-Apr-10 11:28 mlrun/api/db/sqldb/db.py
+-rw-r--r--  2.0 unx     2340 b- defN 23-Apr-10 11:28 mlrun/api/db/sqldb/helpers.py
+-rw-r--r--  2.0 unx     2542 b- defN 23-Apr-10 11:28 mlrun/api/db/sqldb/session.py
+-rw-r--r--  2.0 unx     1063 b- defN 23-Apr-10 11:28 mlrun/api/db/sqldb/models/__init__.py
+-rw-r--r--  2.0 unx    18687 b- defN 23-Apr-10 11:28 mlrun/api/db/sqldb/models/models_mysql.py
+-rw-r--r--  2.0 unx    16908 b- defN 23-Apr-10 11:28 mlrun/api/db/sqldb/models/models_sqlite.py
+-rw-r--r--  2.0 unx     2906 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/env.py
+-rw-r--r--  2.0 unx     4614 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/32bae1b0e29c_increase_timestamp_fields_precision.py
+-rw-r--r--  2.0 unx     1936 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/4903aef6a91d_tag_foreign_key_and_cascades.py
+-rw-r--r--  2.0 unx     1909 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/5f1351c88a19_adding_background_tasks_table.py
+-rw-r--r--  2.0 unx     1415 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/88e656800d6a_add_requested_logs_column_and_index_to_.py
+-rw-r--r--  2.0 unx     1504 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/9d16de5f03a7_adding_data_versions_table.py
+-rw-r--r--  2.0 unx     1649 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/b86f5b53f3d7_adding_name_and_updated_to_runs_table.py
+-rw-r--r--  2.0 unx    24057 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/c4af40b0bf61_init.py
+-rw-r--r--  2.0 unx     1351 b- defN 23-Apr-10 11:28 mlrun/api/migrations_mysql/versions/ee041e8fdaa0_adding_next_run_time_column_to_schedule_.py
+-rw-r--r--  2.0 unx     2906 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/env.py
+-rw-r--r--  2.0 unx    11473 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/11f8dd2dc9fe_init.py
+-rw-r--r--  2.0 unx     1348 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/1c954f8cb32d_schedule_last_run_uri.py
+-rw-r--r--  2.0 unx     5180 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/2b6d23c715aa_adding_feature_sets.py
+-rw-r--r--  2.0 unx     1388 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/6401142f2d7c_adding_next_run_time_column_to_schedule_.py
+-rw-r--r--  2.0 unx     1767 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/64d90a1a69bc_adding_background_tasks_table.py
+-rw-r--r--  2.0 unx     1360 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/803438ecd005_add_requested_logs_column_to_runs.py
+-rw-r--r--  2.0 unx     1259 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/863114f0c659_refactoring_feature_set.py
+-rw-r--r--  2.0 unx     1482 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/accf9fc83d38_adding_data_versions_table.py
+-rw-r--r--  2.0 unx     1892 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/b68e8e897a28_schedule_labels.py
+-rw-r--r--  2.0 unx     1882 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/bcd0c1f9720c_adding_project_labels.py
+-rw-r--r--  2.0 unx     1420 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/cf21882f938e_schedule_id.py
+-rw-r--r--  2.0 unx     2034 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/d781f58f607f_tag_object_name_string.py
+-rw-r--r--  2.0 unx     1828 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/deac06871ace_adding_marketplace_sources_table.py
+-rw-r--r--  2.0 unx     1380 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/e1dd5983c06b_schedule_concurrency_limit.py
+-rw-r--r--  2.0 unx     1831 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/e5594ed3ab53_adding_name_and_updated_to_runs_table.py
+-rw-r--r--  2.0 unx     3936 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/f4249b4ba6fa_adding_feature_vectors.py
+-rw-r--r--  2.0 unx     2588 b- defN 23-Apr-10 11:28 mlrun/api/migrations_sqlite/versions/f7b5a1a03629_adding_feature_labels.py
+-rw-r--r--  2.0 unx     3962 b- defN 23-Apr-10 11:28 mlrun/api/schemas/__init__.py
+-rw-r--r--  2.0 unx     2070 b- defN 23-Apr-10 11:28 mlrun/api/schemas/artifact.py
+-rw-r--r--  2.0 unx     5311 b- defN 23-Apr-10 11:28 mlrun/api/schemas/auth.py
+-rw-r--r--  2.0 unx     1563 b- defN 23-Apr-10 11:28 mlrun/api/schemas/background_task.py
+-rw-r--r--  2.0 unx     2751 b- defN 23-Apr-10 11:28 mlrun/api/schemas/client_spec.py
+-rw-r--r--  2.0 unx      898 b- defN 23-Apr-10 11:28 mlrun/api/schemas/clusterization_spec.py
+-rw-r--r--  2.0 unx     6278 b- defN 23-Apr-10 11:28 mlrun/api/schemas/constants.py
+-rw-r--r--  2.0 unx     3671 b- defN 23-Apr-10 11:28 mlrun/api/schemas/feature_store.py
+-rw-r--r--  2.0 unx     2571 b- defN 23-Apr-10 11:28 mlrun/api/schemas/frontend_spec.py
+-rw-r--r--  2.0 unx     3991 b- defN 23-Apr-10 11:28 mlrun/api/schemas/function.py
+-rw-r--r--  2.0 unx      715 b- defN 23-Apr-10 11:28 mlrun/api/schemas/http.py
+-rw-r--r--  2.0 unx     1405 b- defN 23-Apr-10 11:28 mlrun/api/schemas/k8s.py
+-rw-r--r--  2.0 unx     4258 b- defN 23-Apr-10 11:28 mlrun/api/schemas/marketplace.py
+-rw-r--r--  2.0 unx      920 b- defN 23-Apr-10 11:28 mlrun/api/schemas/memory_reports.py
+-rw-r--r--  2.0 unx    12343 b- defN 23-Apr-10 11:28 mlrun/api/schemas/model_endpoints.py
+-rw-r--r--  2.0 unx     1965 b- defN 23-Apr-10 11:28 mlrun/api/schemas/object.py
+-rw-r--r--  2.0 unx     1194 b- defN 23-Apr-10 11:28 mlrun/api/schemas/pipeline.py
+-rw-r--r--  2.0 unx     3935 b- defN 23-Apr-10 11:28 mlrun/api/schemas/project.py
+-rw-r--r--  2.0 unx     1646 b- defN 23-Apr-10 11:28 mlrun/api/schemas/runtime_resource.py
+-rw-r--r--  2.0 unx     4192 b- defN 23-Apr-10 11:28 mlrun/api/schemas/schedule.py
+-rw-r--r--  2.0 unx     1494 b- defN 23-Apr-10 11:28 mlrun/api/schemas/secret.py
+-rw-r--r--  2.0 unx      919 b- defN 23-Apr-10 11:28 mlrun/api/schemas/tag.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/__init__.py
+-rw-r--r--  2.0 unx     1092 b- defN 23-Apr-10 11:28 mlrun/api/utils/asyncio.py
+-rw-r--r--  2.0 unx     7302 b- defN 23-Apr-10 11:28 mlrun/api/utils/background_tasks.py
+-rw-r--r--  2.0 unx     2413 b- defN 23-Apr-10 11:28 mlrun/api/utils/helpers.py
+-rw-r--r--  2.0 unx     3728 b- defN 23-Apr-10 11:28 mlrun/api/utils/memory_reports.py
+-rw-r--r--  2.0 unx     2599 b- defN 23-Apr-10 11:28 mlrun/api/utils/periodic.py
+-rw-r--r--  2.0 unx    38822 b- defN 23-Apr-10 11:28 mlrun/api/utils/scheduler.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/auth/__init__.py
+-rw-r--r--  2.0 unx    12249 b- defN 23-Apr-10 11:28 mlrun/api/utils/auth/verifier.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/auth/providers/__init__.py
+-rw-r--r--  2.0 unx     1363 b- defN 23-Apr-10 11:28 mlrun/api/utils/auth/providers/base.py
+-rw-r--r--  2.0 unx     1470 b- defN 23-Apr-10 11:28 mlrun/api/utils/auth/providers/nop.py
+-rw-r--r--  2.0 unx    10835 b- defN 23-Apr-10 11:28 mlrun/api/utils/auth/providers/opa.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/clients/__init__.py
+-rw-r--r--  2.0 unx    13232 b- defN 23-Apr-10 11:28 mlrun/api/utils/clients/chief.py
+-rw-r--r--  2.0 unx    30488 b- defN 23-Apr-10 11:28 mlrun/api/utils/clients/iguazio.py
+-rw-r--r--  2.0 unx    10775 b- defN 23-Apr-10 11:28 mlrun/api/utils/clients/log_collector.py
+-rw-r--r--  2.0 unx     9841 b- defN 23-Apr-10 11:28 mlrun/api/utils/clients/nuclio.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/clients/protocols/__init__.py
+-rw-r--r--  2.0 unx     2564 b- defN 23-Apr-10 11:28 mlrun/api/utils/clients/protocols/grpc.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/db/__init__.py
+-rw-r--r--  2.0 unx     3305 b- defN 23-Apr-10 11:28 mlrun/api/utils/db/alembic.py
+-rw-r--r--  2.0 unx     8214 b- defN 23-Apr-10 11:28 mlrun/api/utils/db/backup.py
+-rw-r--r--  2.0 unx     3795 b- defN 23-Apr-10 11:28 mlrun/api/utils/db/mysql.py
+-rw-r--r--  2.0 unx      992 b- defN 23-Apr-10 11:28 mlrun/api/utils/db/sql_collation.py
+-rw-r--r--  2.0 unx     3855 b- defN 23-Apr-10 11:28 mlrun/api/utils/db/sqlite_migration.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/__init__.py
+-rw-r--r--  2.0 unx    17315 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/follower.py
+-rw-r--r--  2.0 unx    19424 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/leader.py
+-rw-r--r--  2.0 unx     7040 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/member.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/remotes/__init__.py
+-rw-r--r--  2.0 unx     2614 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/remotes/follower.py
+-rw-r--r--  2.0 unx     2064 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/remotes/leader.py
+-rw-r--r--  2.0 unx     4601 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/remotes/nop_follower.py
+-rw-r--r--  2.0 unx     3801 b- defN 23-Apr-10 11:28 mlrun/api/utils/projects/remotes/nop_leader.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-10 11:28 mlrun/api/utils/singletons/__init__.py
+-rw-r--r--  2.0 unx     1439 b- defN 23-Apr-10 11:28 mlrun/api/utils/singletons/db.py
+-rw-r--r--  2.0 unx      694 b- defN 23-Apr-10 11:28 mlrun/api/utils/singletons/k8s.py
+-rw-r--r--  2.0 unx      840 b- defN 23-Apr-10 11:28 mlrun/api/utils/singletons/logs_dir.py
+-rw-r--r--  2.0 unx     1279 b- defN 23-Apr-10 11:28 mlrun/api/utils/singletons/project_member.py
+-rw-r--r--  2.0 unx     1063 b- defN 23-Apr-10 11:28 mlrun/api/utils/singletons/scheduler.py
+-rw-r--r--  2.0 unx     1091 b- defN 23-Apr-10 11:28 mlrun/artifacts/__init__.py
+-rw-r--r--  2.0 unx    30849 b- defN 23-Apr-10 11:28 mlrun/artifacts/base.py
+-rw-r--r--  2.0 unx    20366 b- defN 23-Apr-10 11:28 mlrun/artifacts/dataset.py
+-rw-r--r--  2.0 unx    12110 b- defN 23-Apr-10 11:28 mlrun/artifacts/manager.py
+-rw-r--r--  2.0 unx    23673 b- defN 23-Apr-10 11:28 mlrun/artifacts/model.py
+-rw-r--r--  2.0 unx    15383 b- defN 23-Apr-10 11:28 mlrun/artifacts/plots.py
+-rw-r--r--  2.0 unx     1087 b- defN 23-Apr-10 11:28 mlrun/data_types/__init__.py
+-rw-r--r--  2.0 unx     4647 b- defN 23-Apr-10 11:28 mlrun/data_types/data_types.py
+-rw-r--r--  2.0 unx     5813 b- defN 23-Apr-10 11:28 mlrun/data_types/infer.py
+-rw-r--r--  2.0 unx     9118 b- defN 23-Apr-10 11:28 mlrun/data_types/spark.py
+-rw-r--r--  2.0 unx     3300 b- defN 23-Apr-10 11:28 mlrun/datastore/__init__.py
+-rw-r--r--  2.0 unx     6946 b- defN 23-Apr-10 11:28 mlrun/datastore/azure_blob.py
+-rw-r--r--  2.0 unx    17304 b- defN 23-Apr-10 11:28 mlrun/datastore/base.py
+-rw-r--r--  2.0 unx     7995 b- defN 23-Apr-10 11:28 mlrun/datastore/datastore.py
+-rw-r--r--  2.0 unx     3791 b- defN 23-Apr-10 11:28 mlrun/datastore/filestore.py
+-rw-r--r--  2.0 unx     5114 b- defN 23-Apr-10 11:28 mlrun/datastore/google_cloud_storage.py
+-rw-r--r--  2.0 unx     2627 b- defN 23-Apr-10 11:28 mlrun/datastore/inmem.py
+-rw-r--r--  2.0 unx     4873 b- defN 23-Apr-10 11:28 mlrun/datastore/redis.py
+-rw-r--r--  2.0 unx     7035 b- defN 23-Apr-10 11:28 mlrun/datastore/s3.py
+-rw-r--r--  2.0 unx    34025 b- defN 23-Apr-10 11:28 mlrun/datastore/sources.py
+-rw-r--r--  2.0 unx     6864 b- defN 23-Apr-10 11:28 mlrun/datastore/store_resources.py
+-rw-r--r--  2.0 unx    61928 b- defN 23-Apr-10 11:28 mlrun/datastore/targets.py
+-rw-r--r--  2.0 unx     1660 b- defN 23-Apr-10 11:28 mlrun/datastore/utils.py
+-rw-r--r--  2.0 unx     8097 b- defN 23-Apr-10 11:28 mlrun/datastore/v3io.py
+-rw-r--r--  2.0 unx     1343 b- defN 23-Apr-10 11:28 mlrun/datastore/wasbfs/__init__.py
+-rw-r--r--  2.0 unx     6152 b- defN 23-Apr-10 11:28 mlrun/datastore/wasbfs/fs.py
+-rw-r--r--  2.0 unx     2810 b- defN 23-Apr-10 11:28 mlrun/db/__init__.py
+-rw-r--r--  2.0 unx    14796 b- defN 23-Apr-10 11:28 mlrun/db/base.py
+-rw-r--r--  2.0 unx    28129 b- defN 23-Apr-10 11:28 mlrun/db/filedb.py
+-rw-r--r--  2.0 unx   128262 b- defN 23-Apr-10 11:28 mlrun/db/httpdb.py
+-rw-r--r--  2.0 unx    24292 b- defN 23-Apr-10 11:28 mlrun/db/sqldb.py
+-rw-r--r--  2.0 unx     1501 b- defN 23-Apr-10 11:28 mlrun/feature_store/__init__.py
+-rw-r--r--  2.0 unx    42928 b- defN 23-Apr-10 11:28 mlrun/feature_store/api.py
+-rw-r--r--  2.0 unx    12807 b- defN 23-Apr-10 11:28 mlrun/feature_store/common.py
+-rw-r--r--  2.0 unx    46903 b- defN 23-Apr-10 11:28 mlrun/feature_store/feature_set.py
+-rw-r--r--  2.0 unx    21937 b- defN 23-Apr-10 11:28 mlrun/feature_store/feature_vector.py
+-rw-r--r--  2.0 unx    11813 b- defN 23-Apr-10 11:28 mlrun/feature_store/ingestion.py
+-rw-r--r--  2.0 unx    23868 b- defN 23-Apr-10 11:28 mlrun/feature_store/steps.py
+-rw-r--r--  2.0 unx     1232 b- defN 23-Apr-10 11:28 mlrun/feature_store/retrieval/__init__.py
+-rw-r--r--  2.0 unx    25911 b- defN 23-Apr-10 11:28 mlrun/feature_store/retrieval/base.py
+-rw-r--r--  2.0 unx     4261 b- defN 23-Apr-10 11:28 mlrun/feature_store/retrieval/dask_merger.py
+-rw-r--r--  2.0 unx     7106 b- defN 23-Apr-10 11:28 mlrun/feature_store/retrieval/job.py
+-rw-r--r--  2.0 unx     4765 b- defN 23-Apr-10 11:28 mlrun/feature_store/retrieval/local_merger.py
+-rw-r--r--  2.0 unx     3352 b- defN 23-Apr-10 11:28 mlrun/feature_store/retrieval/online.py
+-rw-r--r--  2.0 unx     9661 b- defN 23-Apr-10 11:28 mlrun/feature_store/retrieval/spark_merger.py
+-rw-r--r--  2.0 unx      743 b- defN 23-Apr-10 11:28 mlrun/frameworks/__init__.py
+-rw-r--r--  2.0 unx    11466 b- defN 23-Apr-10 11:28 mlrun/frameworks/parallel_coordinates.py
+-rw-r--r--  2.0 unx      962 b- defN 23-Apr-10 11:28 mlrun/frameworks/_common/__init__.py
+-rw-r--r--  2.0 unx     8515 b- defN 23-Apr-10 11:28 mlrun/frameworks/_common/artifacts_library.py
+-rw-r--r--  2.0 unx    21018 b- defN 23-Apr-10 11:28 mlrun/frameworks/_common/mlrun_interface.py
+-rw-r--r--  2.0 unx    55376 b- defN 23-Apr-10 11:28 mlrun/frameworks/_common/model_handler.py
+-rw-r--r--  2.0 unx     3469 b- defN 23-Apr-10 11:28 mlrun/frameworks/_common/plan.py
+-rw-r--r--  2.0 unx     5757 b- defN 23-Apr-10 11:28 mlrun/frameworks/_common/producer.py
+-rw-r--r--  2.0 unx     9209 b- defN 23-Apr-10 11:28 mlrun/frameworks/_common/utils.py
+-rw-r--r--  2.0 unx      750 b- defN 23-Apr-10 11:28 mlrun/frameworks/_dl_common/__init__.py
+-rw-r--r--  2.0 unx     1151 b- defN 23-Apr-10 11:28 mlrun/frameworks/_dl_common/model_handler.py
+-rw-r--r--  2.0 unx      996 b- defN 23-Apr-10 11:28 mlrun/frameworks/_dl_common/utils.py
+-rw-r--r--  2.0 unx      787 b- defN 23-Apr-10 11:28 mlrun/frameworks/_dl_common/loggers/__init__.py
+-rw-r--r--  2.0 unx    11531 b- defN 23-Apr-10 11:28 mlrun/frameworks/_dl_common/loggers/logger.py
+-rw-r--r--  2.0 unx    14777 b- defN 23-Apr-10 11:28 mlrun/frameworks/_dl_common/loggers/mlrun_logger.py
+-rw-r--r--  2.0 unx    28414 b- defN 23-Apr-10 11:28 mlrun/frameworks/_dl_common/loggers/tensorboard_logger.py
+-rw-r--r--  2.0 unx      956 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/__init__.py
+-rw-r--r--  2.0 unx     3169 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/artifacts_library.py
+-rw-r--r--  2.0 unx    16957 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/model_handler.py
+-rw-r--r--  2.0 unx     2368 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/pkl_model_server.py
+-rw-r--r--  2.0 unx     4881 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/plan.py
+-rw-r--r--  2.0 unx     4061 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/producer.py
+-rw-r--r--  2.0 unx    10490 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/utils.py
+-rw-r--r--  2.0 unx      737 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/loggers/__init__.py
+-rw-r--r--  2.0 unx     5684 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/loggers/logger.py
+-rw-r--r--  2.0 unx     6453 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/loggers/mlrun_logger.py
+-rw-r--r--  2.0 unx      922 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/plans/__init__.py
+-rw-r--r--  2.0 unx     5212 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/plans/calibration_curve_plan.py
+-rw-r--r--  2.0 unx     6078 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/plans/confusion_matrix_plan.py
+-rw-r--r--  2.0 unx     6658 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/plans/dataset_plan.py
+-rw-r--r--  2.0 unx     5318 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/plans/feature_importance_plan.py
+-rw-r--r--  2.0 unx     6993 b- defN 23-Apr-10 11:28 mlrun/frameworks/_ml_common/plans/roc_curve_plan.py
+-rw-r--r--  2.0 unx      706 b- defN 23-Apr-10 11:28 mlrun/frameworks/auto_mlrun/__init__.py
+-rw-r--r--  2.0 unx    23796 b- defN 23-Apr-10 11:28 mlrun/frameworks/auto_mlrun/auto_mlrun.py
+-rw-r--r--  2.0 unx      721 b- defN 23-Apr-10 11:28 mlrun/frameworks/huggingface/__init__.py
+-rw-r--r--  2.0 unx     6083 b- defN 23-Apr-10 11:28 mlrun/frameworks/huggingface/model_server.py
+-rw-r--r--  2.0 unx    15883 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/__init__.py
+-rw-r--r--  2.0 unx    13891 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/model_handler.py
+-rw-r--r--  2.0 unx     9189 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/model_server.py
+-rw-r--r--  2.0 unx     8278 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/utils.py
+-rw-r--r--  2.0 unx      857 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/callbacks/__init__.py
+-rw-r--r--  2.0 unx     4081 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/callbacks/callback.py
+-rw-r--r--  2.0 unx     5156 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/callbacks/logging_callback.py
+-rw-r--r--  2.0 unx     4137 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/callbacks/mlrun_logging_callback.py
+-rw-r--r--  2.0 unx      842 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/mlrun_interfaces/__init__.py
+-rw-r--r--  2.0 unx     1624 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/mlrun_interfaces/booster_mlrun_interface.py
+-rw-r--r--  2.0 unx    14256 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/mlrun_interfaces/mlrun_interface.py
+-rw-r--r--  2.0 unx     1333 b- defN 23-Apr-10 11:28 mlrun/frameworks/lgbm/mlrun_interfaces/model_mlrun_interface.py
+-rw-r--r--  2.0 unx      791 b- defN 23-Apr-10 11:28 mlrun/frameworks/onnx/__init__.py
+-rw-r--r--  2.0 unx     6098 b- defN 23-Apr-10 11:28 mlrun/frameworks/onnx/dataset.py
+-rw-r--r--  2.0 unx     2405 b- defN 23-Apr-10 11:28 mlrun/frameworks/onnx/mlrun_interface.py
+-rw-r--r--  2.0 unx     6203 b- defN 23-Apr-10 11:28 mlrun/frameworks/onnx/model_handler.py
+-rw-r--r--  2.0 unx     7061 b- defN 23-Apr-10 11:28 mlrun/frameworks/onnx/model_server.py
+-rw-r--r--  2.0 unx    22056 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/__init__.py
+-rw-r--r--  2.0 unx    27904 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/callbacks_handler.py
+-rw-r--r--  2.0 unx    44639 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/mlrun_interface.py
+-rw-r--r--  2.0 unx    22465 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/model_handler.py
+-rw-r--r--  2.0 unx    10136 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/model_server.py
+-rw-r--r--  2.0 unx     4515 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/utils.py
+-rw-r--r--  2.0 unx      896 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/callbacks/__init__.py
+-rw-r--r--  2.0 unx    11524 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/callbacks/callback.py
+-rw-r--r--  2.0 unx    23166 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/callbacks/logging_callback.py
+-rw-r--r--  2.0 unx     9310 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/callbacks/mlrun_logging_callback.py
+-rw-r--r--  2.0 unx    26661 b- defN 23-Apr-10 11:28 mlrun/frameworks/pytorch/callbacks/tensorboard_logging_callback.py
+-rw-r--r--  2.0 unx    10892 b- defN 23-Apr-10 11:28 mlrun/frameworks/sklearn/__init__.py
+-rw-r--r--  2.0 unx     5852 b- defN 23-Apr-10 11:28 mlrun/frameworks/sklearn/estimator.py
+-rw-r--r--  2.0 unx     7117 b- defN 23-Apr-10 11:28 mlrun/frameworks/sklearn/metric.py
+-rw-r--r--  2.0 unx    12215 b- defN 23-Apr-10 11:28 mlrun/frameworks/sklearn/metrics_library.py
+-rw-r--r--  2.0 unx    14126 b- defN 23-Apr-10 11:28 mlrun/frameworks/sklearn/mlrun_interface.py
+-rw-r--r--  2.0 unx     4745 b- defN 23-Apr-10 11:28 mlrun/frameworks/sklearn/model_handler.py
+-rw-r--r--  2.0 unx     1209 b- defN 23-Apr-10 11:28 mlrun/frameworks/sklearn/utils.py
+-rw-r--r--  2.0 unx    10455 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/__init__.py
+-rw-r--r--  2.0 unx    16627 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/mlrun_interface.py
+-rw-r--r--  2.0 unx    28247 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/model_handler.py
+-rw-r--r--  2.0 unx     9565 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/model_server.py
+-rw-r--r--  2.0 unx     4284 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/utils.py
+-rw-r--r--  2.0 unx      844 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/callbacks/__init__.py
+-rw-r--r--  2.0 unx    21886 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/callbacks/logging_callback.py
+-rw-r--r--  2.0 unx     8791 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/callbacks/mlrun_logging_callback.py
+-rw-r--r--  2.0 unx    28728 b- defN 23-Apr-10 11:28 mlrun/frameworks/tf_keras/callbacks/tensorboard_logging_callback.py
+-rw-r--r--  2.0 unx    10287 b- defN 23-Apr-10 11:28 mlrun/frameworks/xgboost/__init__.py
+-rw-r--r--  2.0 unx      878 b- defN 23-Apr-10 11:28 mlrun/frameworks/xgboost/mlrun_interface.py
+-rw-r--r--  2.0 unx    11617 b- defN 23-Apr-10 11:28 mlrun/frameworks/xgboost/model_handler.py
+-rw-r--r--  2.0 unx     1069 b- defN 23-Apr-10 11:28 mlrun/frameworks/xgboost/utils.py
+-rw-r--r--  2.0 unx      760 b- defN 23-Apr-10 11:28 mlrun/mlutils/__init__.py
+-rw-r--r--  2.0 unx     5325 b- defN 23-Apr-10 11:28 mlrun/mlutils/data.py
+-rw-r--r--  2.0 unx     2598 b- defN 23-Apr-10 11:28 mlrun/mlutils/models.py
+-rw-r--r--  2.0 unx    30120 b- defN 23-Apr-10 11:28 mlrun/mlutils/plots.py
+-rw-r--r--  2.0 unx     1307 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/__init__.py
+-rw-r--r--  2.0 unx     2962 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/common.py
+-rw-r--r--  2.0 unx     3117 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/constants.py
+-rw-r--r--  2.0 unx    23948 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/features_drift_table.py
+-rw-r--r--  2.0 unx     5935 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/helpers.py
+-rw-r--r--  2.0 unx     5176 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/model_endpoint.py
+-rw-r--r--  2.0 unx    36191 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/model_monitoring_batch.py
+-rw-r--r--  2.0 unx    43025 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stream_processing_fs.py
+-rw-r--r--  2.0 unx     4240 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/__init__.py
+-rw-r--r--  2.0 unx    16926 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/kv_model_endpoint_store.py
+-rw-r--r--  2.0 unx     5695 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/model_endpoint_store.py
+-rw-r--r--  2.0 unx    15700 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/sql_model_endpoint_store.py
+-rw-r--r--  2.0 unx      884 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/models/__init__.py
+-rw-r--r--  2.0 unx      655 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/models/base.py
+-rw-r--r--  2.0 unx     3744 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/models/mysql.py
+-rw-r--r--  2.0 unx     3661 b- defN 23-Apr-10 11:28 mlrun/model_monitoring/stores/models/sqlite.py
+-rw-r--r--  2.0 unx     2400 b- defN 23-Apr-10 11:28 mlrun/platforms/__init__.py
+-rw-r--r--  2.0 unx    22976 b- defN 23-Apr-10 11:28 mlrun/platforms/iguazio.py
+-rw-r--r--  2.0 unx    11852 b- defN 23-Apr-10 11:28 mlrun/platforms/other.py
+-rw-r--r--  2.0 unx     1153 b- defN 23-Apr-10 11:28 mlrun/projects/__init__.py
+-rw-r--r--  2.0 unx    17302 b- defN 23-Apr-10 11:28 mlrun/projects/operations.py
+-rw-r--r--  2.0 unx    37882 b- defN 23-Apr-10 11:28 mlrun/projects/pipelines.py
+-rw-r--r--  2.0 unx   103212 b- defN 23-Apr-10 11:28 mlrun/projects/project.py
+-rw-r--r--  2.0 unx     8973 b- defN 23-Apr-10 11:28 mlrun/runtimes/__init__.py
+-rw-r--r--  2.0 unx   107571 b- defN 23-Apr-10 11:28 mlrun/runtimes/base.py
+-rw-r--r--  2.0 unx     6689 b- defN 23-Apr-10 11:28 mlrun/runtimes/constants.py
+-rw-r--r--  2.0 unx    30403 b- defN 23-Apr-10 11:28 mlrun/runtimes/daskjob.py
+-rw-r--r--  2.0 unx     9190 b- defN 23-Apr-10 11:28 mlrun/runtimes/funcdoc.py
+-rw-r--r--  2.0 unx    69047 b- defN 23-Apr-10 11:28 mlrun/runtimes/function.py
+-rw-r--r--  2.0 unx     4911 b- defN 23-Apr-10 11:28 mlrun/runtimes/function_reference.py
+-rw-r--r--  2.0 unx     6530 b- defN 23-Apr-10 11:28 mlrun/runtimes/generators.py
+-rw-r--r--  2.0 unx    17034 b- defN 23-Apr-10 11:28 mlrun/runtimes/kubejob.py
+-rw-r--r--  2.0 unx    17858 b- defN 23-Apr-10 11:28 mlrun/runtimes/local.py
+-rw-r--r--  2.0 unx     2885 b- defN 23-Apr-10 11:28 mlrun/runtimes/nuclio.py
+-rw-r--r--  2.0 unx    60648 b- defN 23-Apr-10 11:28 mlrun/runtimes/pod.py
+-rw-r--r--  2.0 unx     7695 b- defN 23-Apr-10 11:28 mlrun/runtimes/remotesparkjob.py
+-rw-r--r--  2.0 unx    29852 b- defN 23-Apr-10 11:28 mlrun/runtimes/serving.py
+-rw-r--r--  2.0 unx    21249 b- defN 23-Apr-10 11:28 mlrun/runtimes/utils.py
+-rw-r--r--  2.0 unx      790 b- defN 23-Apr-10 11:28 mlrun/runtimes/mpijob/__init__.py
+-rw-r--r--  2.0 unx    14782 b- defN 23-Apr-10 11:28 mlrun/runtimes/mpijob/abstract.py
+-rw-r--r--  2.0 unx    13845 b- defN 23-Apr-10 11:28 mlrun/runtimes/mpijob/v1.py
+-rw-r--r--  2.0 unx     8460 b- defN 23-Apr-10 11:28 mlrun/runtimes/mpijob/v1alpha1.py
+-rw-r--r--  2.0 unx      673 b- defN 23-Apr-10 11:28 mlrun/runtimes/package/__init__.py
+-rw-r--r--  2.0 unx    27044 b- defN 23-Apr-10 11:28 mlrun/runtimes/package/context_handler.py
+-rw-r--r--  2.0 unx      788 b- defN 23-Apr-10 11:28 mlrun/runtimes/sparkjob/__init__.py
+-rw-r--r--  2.0 unx    35976 b- defN 23-Apr-10 11:28 mlrun/runtimes/sparkjob/abstract.py
+-rw-r--r--  2.0 unx     2033 b- defN 23-Apr-10 11:28 mlrun/runtimes/sparkjob/spark2job.py
+-rw-r--r--  2.0 unx    28722 b- defN 23-Apr-10 11:28 mlrun/runtimes/sparkjob/spark3job.py
+-rw-r--r--  2.0 unx     1050 b- defN 23-Apr-10 11:28 mlrun/serving/__init__.py
+-rw-r--r--  2.0 unx     6116 b- defN 23-Apr-10 11:28 mlrun/serving/merger.py
+-rw-r--r--  2.0 unx    18038 b- defN 23-Apr-10 11:28 mlrun/serving/remote.py
+-rw-r--r--  2.0 unx    55244 b- defN 23-Apr-10 11:28 mlrun/serving/routers.py
+-rw-r--r--  2.0 unx    19005 b- defN 23-Apr-10 11:28 mlrun/serving/server.py
+-rw-r--r--  2.0 unx      836 b- defN 23-Apr-10 11:28 mlrun/serving/serving_wrapper.py
+-rw-r--r--  2.0 unx    48391 b- defN 23-Apr-10 11:28 mlrun/serving/states.py
+-rw-r--r--  2.0 unx     3468 b- defN 23-Apr-10 11:28 mlrun/serving/utils.py
+-rw-r--r--  2.0 unx    11814 b- defN 23-Apr-10 11:28 mlrun/serving/v1_serving.py
+-rw-r--r--  2.0 unx    21441 b- defN 23-Apr-10 11:28 mlrun/serving/v2_serving.py
+-rw-r--r--  2.0 unx      855 b- defN 23-Apr-10 11:28 mlrun/utils/__init__.py
+-rw-r--r--  2.0 unx    10397 b- defN 23-Apr-10 11:28 mlrun/utils/async_http.py
+-rw-r--r--  2.0 unx     3456 b- defN 23-Apr-10 11:28 mlrun/utils/azure_vault.py
+-rw-r--r--  2.0 unx     6245 b- defN 23-Apr-10 11:28 mlrun/utils/clones.py
+-rw-r--r--  2.0 unx     1662 b- defN 23-Apr-10 11:28 mlrun/utils/db.py
+-rw-r--r--  2.0 unx    41426 b- defN 23-Apr-10 11:28 mlrun/utils/helpers.py
+-rw-r--r--  2.0 unx     7093 b- defN 23-Apr-10 11:28 mlrun/utils/http.py
+-rw-r--r--  2.0 unx     5637 b- defN 23-Apr-10 11:28 mlrun/utils/logger.py
+-rw-r--r--  2.0 unx     7875 b- defN 23-Apr-10 11:28 mlrun/utils/model_monitoring.py
+-rw-r--r--  2.0 unx     3954 b- defN 23-Apr-10 11:28 mlrun/utils/regex.py
+-rw-r--r--  2.0 unx      883 b- defN 23-Apr-10 11:28 mlrun/utils/singleton.py
+-rw-r--r--  2.0 unx     1319 b- defN 23-Apr-10 11:28 mlrun/utils/v3io_clients.py
+-rw-r--r--  2.0 unx     9957 b- defN 23-Apr-10 11:28 mlrun/utils/vault.py
+-rw-r--r--  2.0 unx      990 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/__init__.py
+-rw-r--r--  2.0 unx     7093 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/notification_pusher.py
+-rw-r--r--  2.0 unx     1833 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/notification/__init__.py
+-rw-r--r--  2.0 unx     2067 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/notification/base.py
+-rw-r--r--  2.0 unx     1901 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/notification/console.py
+-rw-r--r--  2.0 unx     4510 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/notification/git.py
+-rw-r--r--  2.0 unx     1951 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/notification/ipython.py
+-rw-r--r--  2.0 unx     3650 b- defN 23-Apr-10 11:28 mlrun/utils/notifications/notification/slack.py
+-rw-r--r--  2.0 unx      614 b- defN 23-Apr-10 11:28 mlrun/utils/version/__init__.py
+-rw-r--r--  2.0 unx       88 b- defN 23-Apr-10 11:28 mlrun/utils/version/version.json
+-rw-r--r--  2.0 unx     1970 b- defN 23-Apr-10 11:28 mlrun/utils/version/version.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-Apr-10 11:28 mlrun-1.3.1rc1.dist-info/LICENSE
+-rw-r--r--  2.0 unx    16975 b- defN 23-Apr-10 11:28 mlrun-1.3.1rc1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-10 11:28 mlrun-1.3.1rc1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       47 b- defN 23-Apr-10 11:28 mlrun-1.3.1rc1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        6 b- defN 23-Apr-10 11:28 mlrun-1.3.1rc1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    36742 b- defN 23-Apr-10 11:28 mlrun-1.3.1rc1.dist-info/RECORD
+392 files, 4314881 bytes uncompressed, 1096151 bytes compressed:  74.6%
```

## zipnote {}

```diff
@@ -51,14 +51,17 @@
 
 Filename: mlrun/api/initial_data.py
 Comment: 
 
 Filename: mlrun/api/main.py
 Comment: 
 
+Filename: mlrun/api/middlewares.py
+Comment: 
+
 Filename: mlrun/api/api/__init__.py
 Comment: 
 
 Filename: mlrun/api/api/api.py
 Comment: 
 
 Filename: mlrun/api/api/deps.py
@@ -189,15 +192,15 @@
 
 Filename: mlrun/api/crud/tags.py
 Comment: 
 
 Filename: mlrun/api/crud/model_monitoring/__init__.py
 Comment: 
 
-Filename: mlrun/api/crud/model_monitoring/model_endpoint_store.py
+Filename: mlrun/api/crud/model_monitoring/grafana.py
 Comment: 
 
 Filename: mlrun/api/crud/model_monitoring/model_endpoints.py
 Comment: 
 
 Filename: mlrun/api/db/__init__.py
 Comment: 
@@ -246,14 +249,17 @@
 
 Filename: mlrun/api/migrations_mysql/versions/4903aef6a91d_tag_foreign_key_and_cascades.py
 Comment: 
 
 Filename: mlrun/api/migrations_mysql/versions/5f1351c88a19_adding_background_tasks_table.py
 Comment: 
 
+Filename: mlrun/api/migrations_mysql/versions/88e656800d6a_add_requested_logs_column_and_index_to_.py
+Comment: 
+
 Filename: mlrun/api/migrations_mysql/versions/9d16de5f03a7_adding_data_versions_table.py
 Comment: 
 
 Filename: mlrun/api/migrations_mysql/versions/b86f5b53f3d7_adding_name_and_updated_to_runs_table.py
 Comment: 
 
 Filename: mlrun/api/migrations_mysql/versions/c4af40b0bf61_init.py
@@ -276,14 +282,17 @@
 
 Filename: mlrun/api/migrations_sqlite/versions/6401142f2d7c_adding_next_run_time_column_to_schedule_.py
 Comment: 
 
 Filename: mlrun/api/migrations_sqlite/versions/64d90a1a69bc_adding_background_tasks_table.py
 Comment: 
 
+Filename: mlrun/api/migrations_sqlite/versions/803438ecd005_add_requested_logs_column_to_runs.py
+Comment: 
+
 Filename: mlrun/api/migrations_sqlite/versions/863114f0c659_refactoring_feature_set.py
 Comment: 
 
 Filename: mlrun/api/migrations_sqlite/versions/accf9fc83d38_adding_data_versions_table.py
 Comment: 
 
 Filename: mlrun/api/migrations_sqlite/versions/b68e8e897a28_schedule_labels.py
@@ -423,17 +432,26 @@
 
 Filename: mlrun/api/utils/clients/chief.py
 Comment: 
 
 Filename: mlrun/api/utils/clients/iguazio.py
 Comment: 
 
+Filename: mlrun/api/utils/clients/log_collector.py
+Comment: 
+
 Filename: mlrun/api/utils/clients/nuclio.py
 Comment: 
 
+Filename: mlrun/api/utils/clients/protocols/__init__.py
+Comment: 
+
+Filename: mlrun/api/utils/clients/protocols/grpc.py
+Comment: 
+
 Filename: mlrun/api/utils/db/__init__.py
 Comment: 
 
 Filename: mlrun/api/utils/db/alembic.py
 Comment: 
 
 Filename: mlrun/api/utils/db/backup.py
@@ -888,29 +906,62 @@
 
 Filename: mlrun/mlutils/models.py
 Comment: 
 
 Filename: mlrun/mlutils/plots.py
 Comment: 
 
+Filename: mlrun/model_monitoring/__init__.py
+Comment: 
+
+Filename: mlrun/model_monitoring/common.py
+Comment: 
+
 Filename: mlrun/model_monitoring/constants.py
 Comment: 
 
 Filename: mlrun/model_monitoring/features_drift_table.py
 Comment: 
 
 Filename: mlrun/model_monitoring/helpers.py
 Comment: 
 
+Filename: mlrun/model_monitoring/model_endpoint.py
+Comment: 
+
 Filename: mlrun/model_monitoring/model_monitoring_batch.py
 Comment: 
 
 Filename: mlrun/model_monitoring/stream_processing_fs.py
 Comment: 
 
+Filename: mlrun/model_monitoring/stores/__init__.py
+Comment: 
+
+Filename: mlrun/model_monitoring/stores/kv_model_endpoint_store.py
+Comment: 
+
+Filename: mlrun/model_monitoring/stores/model_endpoint_store.py
+Comment: 
+
+Filename: mlrun/model_monitoring/stores/sql_model_endpoint_store.py
+Comment: 
+
+Filename: mlrun/model_monitoring/stores/models/__init__.py
+Comment: 
+
+Filename: mlrun/model_monitoring/stores/models/base.py
+Comment: 
+
+Filename: mlrun/model_monitoring/stores/models/mysql.py
+Comment: 
+
+Filename: mlrun/model_monitoring/stores/models/sqlite.py
+Comment: 
+
 Filename: mlrun/platforms/__init__.py
 Comment: 
 
 Filename: mlrun/platforms/iguazio.py
 Comment: 
 
 Filename: mlrun/platforms/other.py
@@ -981,14 +1032,20 @@
 
 Filename: mlrun/runtimes/mpijob/v1.py
 Comment: 
 
 Filename: mlrun/runtimes/mpijob/v1alpha1.py
 Comment: 
 
+Filename: mlrun/runtimes/package/__init__.py
+Comment: 
+
+Filename: mlrun/runtimes/package/context_handler.py
+Comment: 
+
 Filename: mlrun/runtimes/sparkjob/__init__.py
 Comment: 
 
 Filename: mlrun/runtimes/sparkjob/abstract.py
 Comment: 
 
 Filename: mlrun/runtimes/sparkjob/spark2job.py
@@ -1035,14 +1092,17 @@
 
 Filename: mlrun/utils/azure_vault.py
 Comment: 
 
 Filename: mlrun/utils/clones.py
 Comment: 
 
+Filename: mlrun/utils/db.py
+Comment: 
+
 Filename: mlrun/utils/helpers.py
 Comment: 
 
 Filename: mlrun/utils/http.py
 Comment: 
 
 Filename: mlrun/utils/logger.py
@@ -1092,26 +1152,26 @@
 
 Filename: mlrun/utils/version/version.json
 Comment: 
 
 Filename: mlrun/utils/version/version.py
 Comment: 
 
-Filename: mlrun-1.3.0rc9.dist-info/LICENSE
+Filename: mlrun-1.3.1rc1.dist-info/LICENSE
 Comment: 
 
-Filename: mlrun-1.3.0rc9.dist-info/METADATA
+Filename: mlrun-1.3.1rc1.dist-info/METADATA
 Comment: 
 
-Filename: mlrun-1.3.0rc9.dist-info/WHEEL
+Filename: mlrun-1.3.1rc1.dist-info/WHEEL
 Comment: 
 
-Filename: mlrun-1.3.0rc9.dist-info/entry_points.txt
+Filename: mlrun-1.3.1rc1.dist-info/entry_points.txt
 Comment: 
 
-Filename: mlrun-1.3.0rc9.dist-info/top_level.txt
+Filename: mlrun-1.3.1rc1.dist-info/top_level.txt
 Comment: 
 
-Filename: mlrun-1.3.0rc9.dist-info/RECORD
+Filename: mlrun-1.3.1rc1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mlrun/__init__.py

```diff
@@ -20,25 +20,25 @@
     "code_to_function",
     "import_function",
     "handler",
     "ArtifactType",
     "get_secret_or_env",
 ]
 
-import json
+import warnings
 from os import environ, path
 
 import dotenv
 
 from .config import config as mlconf
 from .datastore import DataItem, store_manager
 from .db import get_run_db
 from .errors import MLRunInvalidArgumentError, MLRunNotFoundError
 from .execution import MLClientCtx
-from .model import NewTask, RunObject, RunTemplate, new_task
+from .model import RunObject, RunTemplate, new_task
 from .platforms import (
     VolumeMount,
     auto_mount,
     mount_v3io,
     mount_v3io_extended,
     mount_v3io_legacy,
     v3io_cred,
@@ -51,29 +51,29 @@
     load_project,
     new_project,
     pipeline_context,
     run_function,
 )
 from .projects.project import _add_username_to_project_name_if_needed
 from .run import (
-    ArtifactType,
+    _run_pipeline,
     code_to_function,
     function_to_module,
     get_dataitem,
     get_object,
     get_or_create_ctx,
     get_pipeline,
     handler,
     import_function,
     new_function,
     run_local,
     run_pipeline,
     wait_for_pipeline_completion,
 )
-from .runtimes import new_model_server
+from .runtimes import ArtifactType, new_model_server
 from .secrets import get_secret_or_env
 from .utils.version import Version
 
 __version__ = Version().get()["version"]
 
 
 def get_version():
@@ -112,25 +112,35 @@
         project_name, artifact_path = set_environment(project='my-project')
         set_environment("http://localhost:8080", artifact_path="./")
         set_environment(env_file="mlrun.env")
         set_environment("<remote-service-url>", access_key="xyz", username="joe")
 
     :param api_path:       location/url of mlrun api service
     :param artifact_path:  path/url for storing experiment artifacts
-    :param project:        default project name
+    :param project:        default project name (deprecated in 1.3.0 and will be removed in 1.5.0) - use project
+                           APIs such as `get_or_create_project`, `load_project` to configure the active project
     :param access_key:     set the remote cluster access key (V3IO_ACCESS_KEY)
     :param user_project:   add the current user name to the provided project name (making it unique per user)
+                           (deprecated in 1.3.0 and will be removed in 1.5.0)
     :param username:       name of the user to authenticate
     :param env_file:       path/url to .env file (holding MLRun config and other env vars), see: set_env_from_file()
     :param mock_functions: set to True to create local/mock functions instead of real containers,
                            set to "auto" to auto determine based on the presence of k8s/Nuclio
     :returns:
         default project name
         actual artifact path/url, can be used to create subpaths per task or group of artifacts
     """
+    if user_project or project:
+        warnings.warn(
+            "'user_project' and 'project' are deprecated in 1.3.0, and will be removed in 1.5.0, use project "
+            "APIs such as 'get_or_create_project', 'load_project' to configure the active project.",
+            # TODO: Remove in 1.5.0
+            FutureWarning,
+        )
+
     if env_file:
         set_env_from_file(env_file)
 
     # set before the dbpath (so it will re-connect with the new credentials)
     if access_key:
         environ["V3IO_ACCESS_KEY"] = access_key
     if username:
```

## mlrun/__main__.py

```diff
@@ -13,14 +13,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import json
 import pathlib
 import socket
 import traceback
+import warnings
 from ast import literal_eval
 from base64 import b64decode, b64encode
 from os import environ, path, remove
 from pprint import pprint
 from subprocess import Popen
 from sys import executable
 from urllib.parse import urlparse
@@ -179,14 +180,19 @@
 )
 @click.argument("run_args", nargs=-1, type=click.UNPROCESSED)
 @click.option(
     "--ensure-project",
     is_flag=True,
     help="ensure the project exists, if not, create project",
 )
+@click.option(
+    "--returns",
+    multiple=True,
+    help="Logging configurations for the handler's returning values",
+)
 def run(
     url,
     param,
     inputs,
     outputs,
     in_path,
     out_path,
@@ -221,14 +227,15 @@
     watch,
     verbose,
     scrape_metrics,
     env_file,
     auto_build,
     run_args,
     ensure_project,
+    returns,
 ):
     """Execute a task and inject parameters."""
 
     if env_file:
         mlrun.set_env_from_file(env_file)
 
     out_path = out_path or environ.get("MLRUN_ARTIFACT_PATH")
@@ -368,14 +375,17 @@
     if hyper_param_options:
         runobj.spec.hyper_param_options = py_eval(hyper_param_options)
     set_item(runobj.spec.hyper_param_options, param_file, "param_file")
     set_item(runobj.spec.hyper_param_options, hyper_param_strategy, "strategy")
     set_item(runobj.spec.hyper_param_options, selector, "selector")
 
     set_item(runobj.spec, inputs, run_keys.inputs, list2dict(inputs))
+    set_item(
+        runobj.spec, returns, run_keys.returns, [py_eval(value) for value in returns]
+    )
     set_item(runobj.spec, in_path, run_keys.input_path)
     set_item(runobj.spec, out_path, run_keys.output_path)
     set_item(runobj.spec, outputs, run_keys.outputs, list(outputs))
     set_item(
         runobj.spec, secrets, run_keys.secrets, line2keylist(secrets, "kind", "source")
     )
     set_item(runobj.spec, verbose, "verbose")
@@ -580,15 +590,20 @@
 @click.option("--source", "-s", default="", help="location/url of the source")
 @click.option(
     "--func-url",
     "-f",
     default="",
     help="path/url of function yaml or function " "yaml or db://<project>/<name>[:tag]",
 )
-@click.option("--dashboard", "-d", default="", help="nuclio dashboard url")
+@click.option(
+    "--dashboard",
+    "-d",
+    default="",
+    help="Deprecated. Keep empty to allow auto-detect by MLRun API",
+)
 @click.option("--project", "-p", default="", help="project name")
 @click.option("--model", "-m", multiple=True, help="model name and path (name=path)")
 @click.option("--kind", "-k", default=None, help="runtime sub kind")
 @click.option("--tag", default="", help="version tag")
 @click.option("--env", "-e", multiple=True, help="environment variables")
 @click.option("--verbose", is_flag=True, help="verbose log")
 @click.option(
@@ -660,14 +675,22 @@
 
     function.spec.source = source
     if env:
         for k, v in list2dict(env).items():
             function.set_env(k, v)
     function.verbose = verbose
 
+    if dashboard:
+        warnings.warn(
+            "'--dashboard' is deprecated in 1.3.0, and will be removed in 1.5.0, "
+            "Keep '--dashboard' value empty to allow auto-detection by MLRun API.",
+            # TODO: Remove in 1.5.0
+            FutureWarning,
+        )
+
     try:
         addr = function.deploy(dashboard=dashboard, project=project, tag=tag)
     except Exception as err:
         print(f"deploy error: {err_to_str(err)}")
         exit(1)
 
     print(f"function deployed, address={addr}")
@@ -706,15 +729,15 @@
 @click.option("--project", "-p", help="project name")
 @click.option("--tag", "-t", default="", help="artifact/function tag")
 @click.option("--db", help="db path/url")
 @click.argument("extra_args", nargs=-1, type=click.UNPROCESSED)
 def get(kind, name, selector, namespace, uid, project, tag, db, extra_args):
     """List/get one or more object per kind/class.
 
-    KIND - resource type to list/get: run | runtime | artifact | function
+    KIND - resource type to list/get: run | runtime | workflow | artifact | function
     NAME - optional, resource name or category
     """
 
     if db:
         mlconf.dbpath = db
     if not project:
         print("warning, project parameter was not specified using default !")
@@ -779,17 +802,46 @@
                 get_in(f, "kind", ""),
                 get_in(f, "status.state", ""),
                 f"{name}:{tag}",
                 get_in(f, "metadata.hash", ""),
             ]
             lines.append(line)
         print(tabulate(lines, headers=headers))
+
+    elif kind.startswith("workflow"):
+        run_db = get_run_db()
+        if project == "*":
+            print("warning, reading workflows for all projects may take a long time !")
+            pipelines = run_db.list_pipelines(project=project, page_size=200)
+            pipe_runs = pipelines.runs
+            while pipelines.next_page_token is not None:
+                pipelines = run_db.list_pipelines(
+                    project=project, page_token=pipelines.next_page_token
+                )
+                pipe_runs.extend(pipelines.runs)
+        else:
+            pipelines = run_db.list_pipelines(project=project)
+            pipe_runs = pipelines.runs
+
+        lines = []
+        headers = ["project", "name", "status", "created at", "finished at"]
+        for pipe_run in pipe_runs:
+            line = [
+                pipe_run["project"],
+                pipe_run["name"],
+                pipe_run["status"],
+                pipe_run["created_at"],
+                pipe_run["finished_at"],
+            ]
+            lines.append(line)
+        print(tabulate(lines, headers=headers))
+
     else:
         print(
-            "currently only get runs | runtimes | artifacts | func [name] | runtime are supported"
+            "currently only get runs | runtimes | workflows | artifacts  | func [name] | runtime are supported"
         )
 
 
 @main.command()
 @click.option("--port", "-p", help="port to listen on", type=int)
 @click.option("--dirpath", "-d", help="database directory (dirpath)")
 @click.option("--dsn", "-s", help="database dsn, e.g. sqlite:///db/mlrun.db")
@@ -964,37 +1016,40 @@
     type=int,
     default=None,
     help="timeout in seconds to wait for pipeline completion (used when watch=True)",
 )
 @click.option(
     "--env-file", default="", help="path to .env file to load config/variables from"
 )
+# TODO: Remove --ensure-project in 1.5.0
 @click.option(
     "--ensure-project",
     is_flag=True,
     help="ensure the project exists, if not, create project",
 )
 @click.option(
+    "--save/--no-save",
+    default=True,
+    help="create and save the project if not exist",
+)
+@click.option(
     "--schedule",
     type=str,
     default=None,
     help="To create a schedule define a standard crontab expression string."
     "for help see: "
     "https://apscheduler.readthedocs.io/en/3.x/modules/triggers/cron.html#module-apscheduler.triggers.cron."
     "For using the pre-defined workflow's schedule, set --schedule 'true'",
 )
-# TODO: Remove in 1.6.0 --overwrite-schedule and -os, keep --override-workflow and -ow
+# TODO: Remove in 1.5.0
 @click.option(
-    "--override-workflow",
     "--overwrite-schedule",
-    "-ow",
     "-os",
-    "override_workflow",
     is_flag=True,
-    help="Override a schedule when submitting a new one with the same name.",
+    help="Overwrite a schedule when submitting a new one with the same name.",
 )
 @click.option(
     "--save-secrets",
     is_flag=True,
     help="Store the project secrets as k8s secrets",
 )
 def project(
@@ -1018,27 +1073,33 @@
     handler,
     engine,
     local,
     env_file,
     timeout,
     ensure_project,
     schedule,
-    override_workflow,
+    overwrite_schedule,
     save_secrets,
+    save,
 ):
     """load and/or run a project"""
     if env_file:
         mlrun.set_env_from_file(env_file)
 
+    if ensure_project:
+        warnings.warn(
+            "'ensure_project' is deprecated and will be removed in 1.5.0, use 'save' (True by default) instead. ",
+            # TODO: Remove this in 1.5.0
+            FutureWarning,
+        )
+
     if db:
         mlconf.dbpath = db
 
-    proj = load_project(
-        context, url, name, init_git=init_git, clone=clone, save=ensure_project
-    )
+    proj = load_project(context, url, name, init_git=init_git, clone=clone, save=save)
     url_str = " from " + url if url else ""
     print(f"Loading project {proj.name}{url_str} into {context}:\n")
 
     if is_relative_path(artifact_path):
         artifact_path = path.abspath(artifact_path)
     if param:
         proj.spec.params = fill_params(param, proj.spec.params)
@@ -1102,15 +1163,15 @@
                 watch=watch,
                 dirty=dirty,
                 workflow_handler=handler,
                 engine=engine,
                 local=local,
                 schedule=schedule,
                 timeout=timeout,
-                override=override_workflow,
+                overwrite=overwrite_schedule,
             )
 
         except Exception as exc:
             print(traceback.format_exc())
             message = f"failed to run pipeline, {err_to_str(exc)}"
             proj.notifiers.push(message, "error")
             exit(1)
```

## mlrun/builder.py

```diff
@@ -7,16 +7,17 @@
 #   http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
+import os.path
 import pathlib
+import re
 import tarfile
 import tempfile
 from base64 import b64decode, b64encode
 from os import path
 from urllib.parse import urlparse
 
 from kubernetes import client
@@ -50,28 +51,28 @@
         dock += f"ARG PIP_CERT={config.httpdb.builder.pip_ca_path}\n"
 
     build_args = config.get_build_args()
     for build_arg_key, build_arg_value in build_args.items():
         dock += f"ARG {build_arg_key}={build_arg_value}\n"
 
     if source:
-        dock += f"RUN mkdir -p {workdir}\n"
         dock += f"WORKDIR {workdir}\n"
         # 'ADD' command does not extract zip files - add extraction stage to the dockerfile
         if source.endswith(".zip"):
+            source_dir = os.path.join(workdir, "source")
             stage1 = f"""
             FROM {base_image} AS extractor
             RUN apt-get update -qqy && apt install --assume-yes unzip
-            RUN mkdir -p /source
-            COPY {source} /source
-            RUN cd /source && unzip {source} && rm {source}
+            RUN mkdir -p {source_dir}
+            COPY {source} {source_dir}
+            RUN cd {source_dir} && unzip {source} && rm {source}
             """
             dock = stage1 + "\n" + dock
 
-            dock += f"COPY --from=extractor /source/ {workdir}\n"
+            dock += f"COPY --from=extractor {source_dir}/ {workdir}\n"
         else:
             dock += f"ADD {source} {workdir}\n"
 
         if user_unix_id is not None and enriched_group_id is not None:
             dock += f"RUN chown -R {user_unix_id}:{enriched_group_id} {workdir}\n"
 
         dock += f"ENV PYTHONPATH {workdir}\n"
@@ -323,20 +324,25 @@
         requirements_path = "requirements.txt"
         if source:
             raise ValueError("requirements list only works with inline code")
     else:
         requirements_list = None
         requirements_path = requirements
 
+    commands = commands or []
     if with_mlrun:
-        commands = commands or []
+        # mlrun prerequisite - upgrade pip
+        upgrade_pip_command = resolve_upgrade_pip_command(commands)
+        if upgrade_pip_command:
+            commands.append(upgrade_pip_command)
+
         mlrun_command = resolve_mlrun_install_command(
-            mlrun_version_specifier, client_version
+            mlrun_version_specifier, client_version, commands
         )
-        if mlrun_command not in commands:
+        if mlrun_command:
             commands.append(mlrun_command)
 
     if not inline_code and not source and not commands:
         logger.info("skipping build, nothing to add")
         return "skipped"
 
     context = "/context"
@@ -386,22 +392,37 @@
     ):
         from mlrun.api.api.utils import ensure_function_security_context
 
         ensure_function_security_context(runtime, auth_info)
         user_unix_id = runtime.spec.security_context.run_as_user
         enriched_group_id = runtime.spec.security_context.run_as_group
 
+    if source_to_copy and (
+        not runtime.spec.clone_target_dir
+        or not os.path.isabs(runtime.spec.clone_target_dir)
+    ):
+        # use a temp dir for permissions and set it as the workdir
+        tmpdir = tempfile.mkdtemp()
+        relative_workdir = runtime.spec.clone_target_dir or ""
+        if relative_workdir.startswith("./"):
+            # TODO: use 'removeprefix' when we drop python 3.7 support
+            # relative_workdir.removeprefix("./")
+            relative_workdir = relative_workdir[2:]
+
+        runtime.spec.clone_target_dir = path.join(tmpdir, "mlrun", relative_workdir)
+
     dock = make_dockerfile(
         base_image,
         commands,
         source=source_to_copy,
         requirements=requirements_path,
         extra=extra,
         user_unix_id=user_unix_id,
         enriched_group_id=enriched_group_id,
+        workdir=runtime.spec.clone_target_dir,
     )
 
     kpod = make_kaniko_pod(
         project,
         context,
         image_target,
         dockertext=dock,
@@ -443,15 +464,23 @@
         "affinity",
         "tolerations",
         "priority_class_name",
         "service_account",
     ]
 
 
-def resolve_mlrun_install_command(mlrun_version_specifier=None, client_version=None):
+def resolve_mlrun_install_command(
+    mlrun_version_specifier=None, client_version=None, commands=None
+):
+    commands = commands or []
+    install_mlrun_regex = re.compile(r".*pip install .*mlrun.*")
+    for command in commands:
+        if install_mlrun_regex.match(command):
+            return None
+
     unstable_versions = ["unstable", "0.0.0+unstable"]
     unstable_mlrun_version_specifier = (
         f"{config.package_path}[complete] @ git+"
         f"https://github.com/mlrun/mlrun@development"
     )
     if not mlrun_version_specifier:
         if config.httpdb.builder.mlrun_version_specifier:
@@ -468,23 +497,34 @@
         else:
             mlrun_version_specifier = (
                 f"{config.package_path}[complete]=={config.version}"
             )
     return f'python -m pip install "{mlrun_version_specifier}"'
 
 
+def resolve_upgrade_pip_command(commands=None):
+    commands = commands or []
+    pip_upgrade_regex = re.compile(r".*pip install --upgrade .*pip.*")
+    for command in commands:
+        if pip_upgrade_regex.match(command):
+            return None
+
+    return f"python -m pip install --upgrade pip{config.httpdb.builder.pip_version}"
+
+
 def build_runtime(
     auth_info: mlrun.api.schemas.AuthInfo,
     runtime,
     with_mlrun=True,
     mlrun_version_specifier=None,
     skip_deployed=False,
     interactive=False,
     builder_env=None,
     client_version=None,
+    client_python_version=None,
 ):
     build = runtime.spec.build
     namespace = runtime.metadata.namespace
     project = runtime.metadata.project
     if skip_deployed and runtime.is_deployed():
         runtime.status.state = mlrun.api.schemas.FunctionState.ready
         return True
@@ -529,14 +569,15 @@
     name = normalize_name(f"mlrun-build-{runtime.metadata.name}")
     base_image: str = (
         build.base_image or runtime.spec.image or config.default_base_image
     )
     enriched_base_image = enrich_image_url(
         base_image,
         client_version,
+        client_python_version,
     )
 
     status = build_image(
         auth_info,
         project,
         image_target=build.image,
         base_image=enriched_base_image,
```

## mlrun/config.py

```diff
@@ -40,38 +40,38 @@
 import mlrun.errors
 from mlrun.errors import err_to_str
 
 env_prefix = "MLRUN_"
 env_file_key = f"{env_prefix}CONFIG_FILE"
 _load_lock = Lock()
 _none_type = type(None)
-default_env_file = "~/.mlrun.env"
+default_env_file = os.getenv("MLRUN_DEFAULT_ENV_FILE", "~/.mlrun.env")
 
 default_config = {
     "namespace": "",  # default kubernetes namespace
     "dbpath": "",  # db/api url
     # url to nuclio dashboard api (can be with user & token, e.g. https://username:password@dashboard-url.com)
     "nuclio_dashboard_url": "",
     "nuclio_version": "",
-    "default_nuclio_runtime": "python:3.7",
+    "default_nuclio_runtime": "python:3.9",
     "nest_asyncio_enabled": "",  # enable import of nest_asyncio for corner cases with old jupyter, set "1"
     "ui_url": "",  # remote/external mlrun UI url (for hyperlinks) (This is deprecated in favor of the ui block)
     "remote_host": "",
     "api_base_version": "v1",
     "version": "",  # will be set to current version
     "images_tag": "",  # tag to use with mlrun images e.g. mlrun/mlrun (defaults to version)
     "images_registry": "",  # registry to use with mlrun images e.g. quay.io/ (defaults to empty, for dockerhub)
     # comma separated list of images that are in the specified images_registry, and therefore will be enriched with this
     # registry when used. default to mlrun/* which means any image which is of the mlrun repository (mlrun/mlrun,
     # mlrun/ml-base, etc...)
     "images_to_enrich_registry": "^mlrun/*",
     "kfp_url": "",
     "kfp_ttl": "14400",  # KFP ttl in sec, after that completed PODs will be deleted
-    "kfp_image": "",  # image to use for KFP runner (defaults to mlrun/mlrun)
-    "dask_kfp_image": "",  # image to use for dask KFP runner (defaults to mlrun/ml-base)
+    "kfp_image": "mlrun/mlrun",  # image to use for KFP runner (defaults to mlrun/mlrun)
+    "dask_kfp_image": "mlrun/ml-base",  # image to use for dask KFP runner (defaults to mlrun/ml-base)
     "igz_version": "",  # the version of the iguazio system the API is running on
     "iguazio_api_url": "",  # the url to iguazio api
     "spark_app_image": "",  # image to use for spark operator app runtime
     "spark_app_image_tag": "",  # image tag to use for spark operator app runtime
     "spark_history_server_path": "",  # spark logs directory for spark history server
     "spark_operator_version": "spark-3",  # the version of the spark operator in use
     "builder_alpine_image": "alpine:3.13.1",  # builder alpine image (as kaniko's initContainer)
@@ -90,15 +90,15 @@
     "runtimes_cleanup_interval": "300",
     # runs monitoring interval in seconds
     "runs_monitoring_interval": "30",
     # runs monitoring debouncing interval in seconds for run with non-terminal state without corresponding k8s resource
     # by default the interval will be - (runs_monitoring_interval * 2 ), if set will override the default
     "runs_monitoring_missing_runtime_resources_debouncing_interval": None,
     # the grace period (in seconds) that will be given to runtime resources (after they're in terminal state)
-    # before deleting them
+    # before deleting them (4 hours)
     "runtime_resources_deletion_grace_period": "14400",
     "scrape_metrics": True,
     # sets the background color that is used in printed tables in jupyter
     "background_color": "#4EC64B",
     "artifact_path": "",  # default artifacts path/url
     # Add {{workflow.uid}} to artifact_path unless user specified a path manually
     "enrich_artifact_path_with_workflow_id": True,
@@ -113,14 +113,17 @@
     # FIXME: Adding these defaults here so we won't need to patch the "installing component" (provazio-controller) to
     #  configure this values on field systems, for newer system this will be configured correctly
     "v3io_api": "http://v3io-webapi:8081",
     "redis": {
         "url": "",
         "type": "standalone",  # deprecated.
     },
+    "sql": {
+        "url": "",
+    },
     "v3io_framesd": "http://framesd:8080",
     "datastore": {"async_source_mode": "disabled"},
     # default node selector to be applied to all functions - json string base64 encoded format
     "default_function_node_selector": "e30=",
     # default priority class to be applied to functions running on k8s cluster
     "default_function_priority_class_name": "",
     # valid options for priority classes - separated by a comma
@@ -268,27 +271,38 @@
             #  ---------------------------------------------------------------------
             # Note: adding a mode requires special handling on
             # - mlrun.runtimes.constants.NuclioIngressAddTemplatedIngressModes
             # - mlrun.runtimes.function.enrich_function_with_ingress
             "add_templated_ingress_host_mode": "never",
         },
         "logs": {
+            "decode": {
+                # Replace with a replacement marker. Uses � (U+FFFD, the official REPLACEMENT CHARACTER).
+                # see https://docs.python.org/3/library/codecs.html#error-handlers for more info and options
+                "errors": "replace",
+            },
             "pipelines": {
                 # pull state mode was introduced to have a way to pull the state of a run which was spawned by a
                 # pipeline step instead of pulling the state by getting the run logs
                 "pull_state": {
                     # enabled - pull state of a run every "pull_state_interval" seconds and pull logs every
                     # "pull_logs_interval" seconds
                     # disabled - pull logs every "pull_logs_default_interval" seconds
                     "mode": "disabled",
                     # those params are used when mode is enabled
                     "pull_logs_interval": 30,  # seconds
                     "pull_state_interval": 5,  # seconds
                 },
             },
+            "nuclio": {
+                # setting interval to a higher interval than regular jobs / build, because pulling the retrieved logs
+                # from nuclio for the deploy status doesn't include the actual live "builder" container logs, but
+                # rather a high level status
+                "pull_deploy_status_default_interval": 10  # seconds
+            },
             # this is the default interval period for pulling logs, if not specified different timeout interval
             "pull_logs_default_interval": 3,  # seconds
             "pull_logs_backoff_no_logs_default_interval": 10,  # seconds
         },
         "authorization": {
             "mode": "none",  # one of none, opa
             "opa": {
@@ -350,29 +364,31 @@
             "build_args": "",
             "pip_ca_secret_name": "",
             "pip_ca_secret_key": "",
             "pip_ca_path": "/etc/ssl/certs/mlrun/pip-ca-certificates.crt",
             # template for the prefix that the function target image will be enforced to have (as long as it's targeted
             # to be in the configured registry). Supported template values are: {project} {name}
             "function_target_image_name_prefix_template": "func-{project}-{name}",
+            "pip_version": "~=23.0",
         },
         "v3io_api": "",
         "v3io_framesd": "",
     },
     "model_endpoint_monitoring": {
         "serving_stream_args": {"shard_count": 1, "retention_period_hours": 24},
         "drift_thresholds": {"default": {"possible_drift": 0.5, "drift_detected": 0.7}},
         "store_prefixes": {
             "default": "v3io:///users/pipelines/{project}/model-endpoints/{kind}",
             "user_space": "v3io:///projects/{project}/model-endpoints/{kind}",
         },
         "batch_processing_function_branch": "master",
         "parquet_batching_max_events": 10000,
         # See mlrun.api.schemas.ModelEndpointStoreType for available options
-        "store_type": "kv",
+        "store_type": "v3io-nosql",
+        "endpoint_store_connection": "",
     },
     "secret_stores": {
         "vault": {
             # URLs to access Vault. For example, in a local env (Minikube on Mac) these would be:
             # http://docker.for.mac.localhost:8200
             "url": "",
             "remote_url": "",
@@ -391,14 +407,15 @@
         "kubernetes": {
             # When this is True (the default), all project secrets will be automatically added to each job,
             # unless user asks for a specific list of secrets.
             "auto_add_project_secrets": True,
             "project_secret_name": "mlrun-project-secrets-{project}",
             "auth_secret_name": "mlrun-auth-secrets.{hashed_access_key}",
             "env_variable_prefix": "MLRUN_K8S_SECRET__",
+            "global_function_env_secret_name": None,
         },
     },
     "feature_store": {
         "data_prefixes": {
             "default": "v3io:///projects/{project}/FeatureStore/{name}/{kind}",
             "nosql": "v3io:///projects/{project}/FeatureStore/{name}/{kind}",
             "redisnosql": "redis:///projects/{project}/FeatureStore/{name}/{kind}",
@@ -460,14 +477,41 @@
         # which returns the version from the version.json file
         "release": "",
     },
     "debug": {
         "expose_internal_api_endpoints": False,
     },
     "default_workflow_runner_name": "workflow-runner-{}",
+    "log_collector": {
+        "address": "localhost:8282",
+        # log collection mode can be one of: "sidecar", "legacy", "best-effort"
+        # "sidecar" - use the sidecar to collect logs
+        # "legacy" - use the legacy log collection method (logs are collected straight from the pod)
+        # "best-effort" - use the sidecar, but if for some reason it's not available use the legacy method
+        # note that this mode also effects the log querying method as well, meaning if the mode is "best-effort"
+        # the log query will try to use the sidecar first and if it's not available it will use the legacy method
+        # TODO: once this is changed to "sidecar" by default, also change in common_fixtures.py
+        "mode": "legacy",
+        # interval for collecting and sending runs which require their logs to be collected
+        "periodic_start_log_interval": 10,
+        "verbose": True,
+        # the number of workers which will be used to trigger the start log collection
+        "concurrent_start_logs_workers": 15,
+        # the time in hours in which to start log collection from.
+        # after upgrade, we might have runs which completed in the mean time or still in non-terminal state and
+        # we want to collect their logs in the new log collection method (sidecar)
+        # default is 4 hours = 4*60*60 = 14400 seconds
+        "api_downtime_grace_period": 14400,
+        "get_logs": {
+            # the number of retries to get logs from the log collector
+            "max_retries": 3,
+        },
+        # interval for stopping log collection for runs which are in a terminal state
+        "stop_logs_interval": 3600,
+    },
 }
 
 _is_running_as_api = None
 
 
 def is_running_as_api():
     # MLRUN_IS_API_SERVER is set when running the api server which is being done through the CLI command mlrun db
@@ -808,48 +852,14 @@
     @property
     def version(self):
         # importing here to avoid circular dependency
         from mlrun.utils.version import Version
 
         return Version().get()["version"]
 
-    @property
-    def kfp_image(self):
-        """
-        When this configuration is not set we want to set it to mlrun/mlrun, but we need to use the enrich_image method.
-        The problem is that the mlrun.utils.helpers module is importing the config (this) module, so we must import the
-        module inside this function (and not on initialization), and then calculate this property value here.
-        """
-        if not self._kfp_image:
-            # importing here to avoid circular dependency
-            import mlrun.utils.helpers
-
-            return mlrun.utils.helpers.enrich_image_url("mlrun/mlrun")
-        return self._kfp_image
-
-    @kfp_image.setter
-    def kfp_image(self, value):
-        self._kfp_image = value
-
-    @property
-    def dask_kfp_image(self):
-        """
-        See kfp_image property docstring for why we're defining this property
-        """
-        if not self._dask_kfp_image:
-            # importing here to avoid circular dependency
-            import mlrun.utils.helpers
-
-            return mlrun.utils.helpers.enrich_image_url("mlrun/ml-base")
-        return self._dask_kfp_image
-
-    @dask_kfp_image.setter
-    def dask_kfp_image(self, value):
-        self._dask_kfp_image = value
-
     @staticmethod
     def resolve_ui_url():
         # ui_url is deprecated in favor of the ui.url (we created the ui block)
         # since the config class is used in a "recursive" way, we can't use property like we used in other places
         # since the property will need to be url, which exists in other structs as well
         return config.ui.url or config.ui_url
 
@@ -896,19 +906,19 @@
     @iguazio_api_url.setter
     def iguazio_api_url(self, value):
         self._iguazio_api_url = value
 
     def is_api_running_on_k8s(self):
         # determine if the API service is attached to K8s cluster
         # when there is a cluster the .namespace is set
-        return True if mlrun.mlconf.namespace else False
+        return bool(mlrun.mlconf.namespace)
 
     def is_nuclio_detected(self):
         # determine is Nuclio service is detected, when the nuclio_version is not set
-        return True if mlrun.mlconf.nuclio_version else False
+        return bool(mlrun.mlconf.nuclio_version)
 
     def use_nuclio_mock(self, force_mock=None):
         # determine if to use Nuclio mock service
         mock_nuclio = mlrun.mlconf.mock_nuclio_deployment
         if mock_nuclio and mock_nuclio == "auto":
             mock_nuclio = not mlrun.mlconf.is_nuclio_detected()
         return True if mock_nuclio and force_mock is None else force_mock
@@ -963,18 +973,14 @@
     data = read_env(env)
     if data:
         config.update(data, skip_errors=skip_errors)
 
     # HACK to enable config property to both have dynamic default and to use the value from dict/env like other
     # configurations - we just need a key in the dict that is different than the property name, so simply adding prefix
     # underscore
-    config._cfg["_kfp_image"] = config._cfg["kfp_image"]
-    del config._cfg["kfp_image"]
-    config._cfg["_dask_kfp_image"] = config._cfg["dask_kfp_image"]
-    del config._cfg["dask_kfp_image"]
     config._cfg["_iguazio_api_url"] = config._cfg["iguazio_api_url"]
     del config._cfg["iguazio_api_url"]
 
     _validate_config(config)
 
 
 def _validate_config(config):
```

## mlrun/errors.py

```diff
@@ -125,15 +125,18 @@
     if isinstance(err, str):
         return err
 
     errors = []
     error_strings = []
     while err and err not in errors:
         errors.append(err)
-        error_strings.append(str(err))
+        err_msg = str(err)
+        if not err_msg:
+            err_msg = repr(err)
+        error_strings.append(err_msg)
         err = err.__cause__
 
     return ", caused by: ".join(error_strings)
 
 
 # Specific Errors
 class MLRunUnauthorizedError(MLRunHTTPStatusError):
```

## mlrun/execution.py

```diff
@@ -15,24 +15,25 @@
 import os
 import uuid
 from copy import deepcopy
 from datetime import datetime
 from typing import List, Union
 
 import numpy as np
+import yaml
+from dateutil import parser
 
 import mlrun
 from mlrun.artifacts import ModelArtifact
 from mlrun.datastore.store_resources import get_store_resource
 from mlrun.errors import MLRunInvalidArgumentError
 
 from .artifacts import DatasetArtifact
 from .artifacts.manager import ArtifactManager, extend_artifact_path
 from .datastore import store_manager
-from .db import get_run_db
 from .features import Feature
 from .model import HyperParamOptions
 from .secrets import SecretsStore
 from .utils import (
     dict_to_json,
     dict_to_yaml,
     get_in,
@@ -89,14 +90,16 @@
         self._hyper_param_options = HyperParamOptions()
         self._in_path = ""
         self.artifact_path = ""
         self._inputs = {}
         self._outputs = []
 
         self._results = {}
+        # tracks the execution state, completion of runs is not decided by the execution
+        # as there may be multiple executions for a single run (e.g mpi)
         self._state = "created"
         self._error = None
         self._commit = ""
         self._host = None
         self._start_time = now_date()
         self._last_update = now_date()
         self._iteration_results = None
@@ -109,15 +112,15 @@
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, exc_traceback):
         if exc_value:
             self.set_state(error=exc_value, commit=False)
-        self.commit()
+        self.commit(completed=True)
 
     def get_child_context(self, with_parent_params=False, **params):
         """get child context (iteration)
 
         allow sub experiments (epochs, hyper-param, ..) under a parent
         will create a new iteration, log_xx will update the child only
         use commit_children() to save all the children and specify the best run
@@ -224,15 +227,15 @@
 
     def set_logger_stream(self, stream):
         self._logger.replace_handler_stream("default", stream)
 
     def _init_dbs(self, rundb):
         if rundb:
             if isinstance(rundb, str):
-                self._rundb = get_run_db(rundb, secrets=self._secrets_manager)
+                self._rundb = mlrun.db.get_run_db(rundb, secrets=self._secrets_manager)
             else:
                 self._rundb = rundb
         else:
             self._rundb = mlrun.get_run_db()
         self._data_stores = store_manager.set(self._secrets_manager, db=self._rundb)
         self._artifacts_manager = ArtifactManager(db=self._rundb)
 
@@ -255,15 +258,15 @@
         attrs: dict,
         rundb="",
         autocommit=False,
         tmp="",
         host=None,
         log_stream=None,
         is_api=False,
-        update_db=True,
+        store_run=True,
     ):
         """create execution context from dict"""
 
         self = cls(autocommit=autocommit, tmp=tmp, log_stream=log_stream)
 
         meta = attrs.get("metadata")
         if meta:
@@ -308,18 +311,19 @@
                         self._set_input(k, v)
 
         if host and not is_api:
             self.set_label("host", host)
 
         start = get_in(attrs, "status.start_time")
         if start:
+            start = parser.parse(start) if isinstance(start, str) else start
             self._start_time = start
         self._state = "running"
-        if update_db:
-            self._update_db(commit=True)
+        if store_run:
+            self.store_run()
         return self
 
     @property
     def uid(self):
         """Unique run id"""
         if self._iteration:
             return f"{self._uid}-{self._iteration}"
@@ -327,14 +331,19 @@
 
     @property
     def tag(self):
         """run tag (uid or workflow id if exists)"""
         return self._labels.get("workflow") or self._uid
 
     @property
+    def state(self):
+        """execution state"""
+        return self._state
+
+    @property
     def iteration(self):
         """child iteration index, for hyper parameters"""
         return self._iteration
 
     @property
     def project(self):
         """project name, runs can be categorized by projects"""
@@ -441,15 +450,15 @@
         example::
 
             p1 = context.get_param("p1", 0)
         """
         if key not in self._parameters:
             self._parameters[key] = default
             if default:
-                self._update_db()
+                self._update_run()
             return default
         return self._parameters[key]
 
     def _load_project_object(self):
         if not self._project_object:
             if not self._project:
                 self.logger.warning("get_project_param called without a project name")
@@ -516,15 +525,15 @@
             context.log_result('accuracy', 0.85)
 
         :param key:    result key
         :param value:  result value
         :param commit: commit (write to DB now vs wait for the end of the run)
         """
         self._results[str(key)] = _cast_result(value)
-        self._update_db(commit=commit)
+        self._update_run(commit=commit)
 
     def log_results(self, results: dict, commit=False):
         """log a set of scalar result values
 
         example::
 
             context.log_results({'accuracy': 0.85, 'loss': 0.2})
@@ -535,15 +544,15 @@
         if not isinstance(results, dict):
             raise MLRunInvalidArgumentError(
                 "(multiple) results must be in the form of dict"
             )
 
         for p in results.keys():
             self._results[str(p)] = _cast_result(results[p])
-        self._update_db(commit=commit)
+        self._update_run(commit=commit)
 
     def log_iteration_results(self, best, summary: list, task: dict, commit=False):
         """Reserved for internal use"""
 
         if best:
             self._results["best_iteration"] = best
             for k, v in get_in(task, ["status", "results"], {}).items():
@@ -562,15 +571,15 @@
                     link_iteration=best,
                     db_key=artifact["spec"]["db_key"],
                 )
 
         if summary is not None:
             self._iteration_results = summary
         if commit:
-            self._update_db(commit=True)
+            self._update_run(commit=True)
 
     def log_metric(self, key: str, value, timestamp=None, labels=None):
         """TBD, log a real-time time-series metric"""
         labels = {} if labels is None else labels
         if not timestamp:
             timestamp = datetime.now()
         if self._rundb:
@@ -644,15 +653,15 @@
             viewer=viewer,
             upload=upload,
             labels=labels,
             db_key=db_key,
             format=format,
             **kwargs,
         )
-        self._update_db()
+        self._update_run()
         return item
 
     def log_dataset(
         self,
         key,
         df,
         tag="",
@@ -723,15 +732,15 @@
             artifact_path=extend_artifact_path(artifact_path, self.artifact_path),
             target_path=target_path,
             tag=tag,
             upload=upload,
             db_key=db_key,
             labels=labels,
         )
-        self._update_db()
+        self._update_run()
         return item
 
     def log_model(
         self,
         key,
         body=None,
         framework="",
@@ -825,66 +834,79 @@
             model,
             artifact_path=extend_artifact_path(artifact_path, self.artifact_path),
             tag=tag,
             upload=upload,
             db_key=db_key,
             labels=labels,
         )
-        self._update_db()
+        self._update_run()
         return item
 
     def get_cached_artifact(self, key):
         """return an logged artifact from cache (for potential updates)"""
         return self._artifacts_manager.artifacts[key]
 
     def update_artifact(self, artifact_object):
         """update an artifact object in the cache and the DB"""
         self._artifacts_manager.update_artifact(self, artifact_object)
 
-    def commit(self, message: str = "", completed=True):
+    def commit(self, message: str = "", completed=False):
         """save run state and optionally add a commit message
 
         :param message:   commit message to save in the run
         :param completed: mark run as completed
         """
-        completed = completed and self._state == "running"
+        # changing state to completed is allowed only when the execution is in running state
+        if self._state != "running":
+            completed = False
+
         if message:
             self._annotations["message"] = message
         if completed:
             self._state = "completed"
 
         if self._parent:
             self._parent.update_child_iterations()
             self._parent._last_update = now_date()
-            self._parent._update_db(commit=True, message=message)
+            self._parent._update_run(commit=True, message=message)
 
         if self._children:
             self.update_child_iterations(commit_children=True, completed=completed)
         self._last_update = now_date()
-        self._update_db(commit=True, message=message)
+        self._update_run(commit=True, message=message)
         if completed and not self.iteration:
             mlrun.runtimes.utils.global_context.set(None)
 
-    def set_state(self, state: str = None, error: str = None, commit=True):
-        """modify and store the run state or mark an error
-
-        :param state:   set run state
-        :param error:   error message (if exist will set the state to error)
-        :param commit:  will immediately update the state in the DB
+    def set_state(self, execution_state: str = None, error: str = None, commit=True):
+        """
+        Modify and store the execution state or mark an error and update the run state accordingly.
+        This method allows to set the run state to 'completed' in the DB which is discouraged.
+        Completion of runs should be decided externally to the execution context.
+
+        :param execution_state:     set execution state
+        :param error:               error message (if exist will set the state to error)
+        :param commit:              will immediately update the state in the DB
         """
+        # TODO: The execution context should not set the run state to completed.
+        #  Create a separate state for the execution in the run object.
+
         updates = {"status.last_update": now_date().isoformat()}
 
-        if error:
+        if error is not None:
             self._state = "error"
             self._error = str(error)
             updates["status.state"] = "error"
             updates["status.error"] = error
-        elif state and state != self._state and self._state != "error":
-            self._state = state
-            updates["status.state"] = state
+        elif (
+            execution_state
+            and execution_state != self._state
+            and self._state != "error"
+        ):
+            self._state = execution_state
+            updates["status.state"] = execution_state
         self._last_update = now_date()
 
         if self._rundb and commit:
             self._rundb.update_run(
                 updates, self._uid, self.project, iter=self._iteration
             )
 
@@ -896,17 +918,17 @@
             self._rundb.update_run(
                 updates, self._uid, self.project, iter=self._iteration
             )
 
     def to_dict(self):
         """convert the run context to a dictionary"""
 
-        def set_if_valid(struct, key, val):
+        def set_if_not_none(_struct, key, val):
             if val:
-                struct[key] = val
+                _struct[key] = val
 
         struct = {
             "kind": "run",
             "metadata": {
                 "name": self.name,
                 "uid": self._uid,
                 "iteration": self._iteration,
@@ -920,57 +942,126 @@
                 "parameters": self._parameters,
                 "handler": self._handler,
                 "outputs": self._outputs,
                 run_keys.output_path: self.artifact_path,
                 run_keys.inputs: {k: v.artifact_url for k, v in self._inputs.items()},
             },
             "status": {
-                "state": self._state,
                 "results": self._results,
                 "start_time": to_date_str(self._start_time),
                 "last_update": to_date_str(self._last_update),
             },
         }
 
+        # completion of runs is not decided by the execution as there may be
+        # multiple executions for a single run (e.g. mpi)
+        if self._state != "completed":
+            struct["status"]["state"] = self._state
+
         if not self._iteration:
             struct["spec"]["hyperparams"] = self._hyperparams
             struct["spec"]["hyper_param_options"] = self._hyper_param_options.to_dict()
 
-        set_if_valid(struct["status"], "error", self._error)
-        set_if_valid(struct["status"], "commit", self._commit)
+        set_if_not_none(struct["status"], "error", self._error)
+        set_if_not_none(struct["status"], "commit", self._commit)
+        set_if_not_none(struct["status"], "iterations", self._iteration_results)
 
-        if self._iteration_results:
-            struct["status"]["iterations"] = self._iteration_results
         struct["status"][run_keys.artifacts] = self._artifacts_manager.artifact_list()
         self._data_stores.to_dict(struct["spec"])
         return struct
 
+    def _get_updates(self):
+        def set_if_not_none(_struct, key, val):
+            if val:
+                _struct[key] = val
+
+        struct = {
+            "metadata.labels": self._labels,
+            "metadata.annotations": self._annotations,
+            "spec.parameters": self._parameters,
+            "spec.outputs": self._outputs,
+            "spec.inputs": {k: v.artifact_url for k, v in self._inputs.items()},
+            "status.results": self._results,
+            "status.start_time": to_date_str(self._start_time),
+            "status.last_update": to_date_str(self._last_update),
+        }
+
+        # completion of runs is not decided by the execution as there may be
+        # multiple executions for a single run (e.g. mpi)
+        if self._state != "completed":
+            struct["status.state"] = self._state
+
+        set_if_not_none(struct, "status.error", self._error)
+        set_if_not_none(struct, "status.commit", self._commit)
+        set_if_not_none(struct, "status.iterations", self._iteration_results)
+
+        struct[f"status.{run_keys.artifacts}"] = self._artifacts_manager.artifact_list()
+        return struct
+
     def to_yaml(self):
         """convert the run context to a yaml buffer"""
         return dict_to_yaml(self.to_dict())
 
     def to_json(self):
         """convert the run context to a json buffer"""
         return dict_to_json(self.to_dict())
 
-    def _update_db(self, commit=False, message=""):
-        self.last_update = now_date()
-        if self._tmpfile:
-            data = self.to_json()
-            with open(self._tmpfile, "w") as fp:
-                fp.write(data)
-                fp.close()
+    def store_run(self):
+        """
+        store the run object in the DB - removes missing fields
+        use _update_run for coherent updates
+        """
+        self._write_tmpfile()
+        if self._rundb:
+            self._rundb.store_run(
+                self.to_dict(), self._uid, self.project, iter=self._iteration
+            )
 
+    def _update_run(self, commit=False, message=""):
+        """
+        update the required fields in the run object (using mlrun.utils.helpers.update_in)
+        instead of overwriting existing
+        """
+        self._merge_tmpfile()
         if commit or self._autocommit:
             self._commit = message
             if self._rundb:
-                self._rundb.store_run(
-                    self.to_dict(), self._uid, self.project, iter=self._iteration
+                self._rundb.update_run(
+                    self._get_updates(), self._uid, self.project, iter=self._iteration
                 )
 
+    def _merge_tmpfile(self):
+        if not self._tmpfile:
+            return
+
+        loaded_run = self._read_tmpfile()
+        dict_run = self.to_dict()
+        if loaded_run:
+            for key, val in dict_run.items():
+                update_in(loaded_run, key, val)
+        else:
+            loaded_run = dict_run
+
+        self._write_tmpfile(json=dict_to_json(loaded_run))
+
+    def _read_tmpfile(self):
+        if self._tmpfile:
+            with open(self._tmpfile) as fp:
+                return yaml.safe_load(fp)
+
+        return None
+
+    def _write_tmpfile(self, json=None):
+        self.last_update = now_date()
+        if self._tmpfile:
+            data = json or self.to_json()
+            with open(self._tmpfile, "w") as fp:
+                fp.write(data)
+                fp.close()
+
 
 def _cast_result(value):
     if isinstance(value, (int, str, float)):
         return value
     if isinstance(value, list):
         return [_cast_result(v) for v in value]
     if isinstance(value, dict):
```

## mlrun/features.py

```diff
@@ -10,18 +10,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import math
 import re
-from typing import Dict, List, Optional
+from typing import Dict, List, Optional, Union
 
-from .data_types import ValueType
-from .errors import err_to_str
+from .data_types import ValueType, python_type_to_value_type
+from .errors import MLRunRuntimeError, err_to_str
 from .model import ModelObj
 
 
 def _limited_string(value: str, max_size: int = 40):
     """
     Provide limited string size, typically for reporting original value
     in case of error (and for better identification of error location
@@ -33,35 +33,40 @@
         else value[:max_size] + "..."
     )
 
 
 class Entity(ModelObj):
     """data entity (index)"""
 
+    kind = "entity"
+
     def __init__(
         self,
         name: str = None,
-        value_type: ValueType = None,
+        value_type: Union[ValueType, str] = None,
         description: str = None,
         labels: Optional[Dict[str, str]] = None,
     ):
         """data entity (index key)
 
         :param name:        entity name
-        :param value_type:  type of the entity, e.g. ValueType.STRING, ValueType.INT
+        :param value_type:  type of the entity, e.g. ValueType.STRING, ValueType.INT (default ValueType.STRING)
         :param description: test description of the entity
         :param labels:      a set of key/value labels (tags)
         """
         self.name = name
         self.description = description
-        self.value_type = value_type
+        self.value_type = ValueType(value_type) if value_type else None
         if name and not value_type:
             self.value_type = ValueType.STRING
         self.labels = labels or {}
 
+    def __eq__(self, other):
+        return self.name == other.name
+
 
 class Feature(ModelObj):
     """data feature"""
 
     _dict_fields = [
         "name",
         "description",
@@ -72,39 +77,43 @@
         "aggregate",
         "validator",
         "origin",
     ]
 
     def __init__(
         self,
-        value_type: str = None,
+        value_type: Union[ValueType, str] = None,
         dims: List[int] = None,
         description: str = None,
         aggregate: bool = None,
         name: str = None,
         validator=None,
         default: str = None,
         labels: Dict[str, str] = None,
     ):
         """data feature
 
         Features can be specified manually or inferred automatically (during ingest/preview)
 
         :param value_type:  type of the feature. Use the ValueType constants library e.g. ValueType.STRING,
-                            ValueType.INT
+                            ValueType.INT (default ValueType.STRING)
         :param dims:        list of dimensions for vectors/tensors, e.g. [2, 2]
         :param description: text description of the feature
         :param aggregate:   is it an aggregated value
         :param name:        name of the feature
         :param validator:   feature validation policy
         :param default:     default value
         :param labels:      a set of key/value labels (tags)
         """
         self.name = name or ""
-        self.value_type = value_type
+        self.value_type = (
+            python_type_to_value_type(value_type)
+            if value_type is not None
+            else ValueType.STRING
+        )
         self.dims = dims
         self.description = description
         self.default = default
         self.labels = labels or {}
         self.aggregate = aggregate
         self.origin = None  # used to link the feature to the feature set origin (inside vector.status)
         self._validator = validator
@@ -406,15 +415,15 @@
 
         :param check_type:  check feature type e.g. True, False
         :param severity:    severity name e.g. info, warning, etc.
         :param regex:       regular expression for validation
         """
         super().__init__(check_type, severity)
         self.regex = regex
-        self.regex_compile = re.compile(self.regex)
+        self.regex_compile = re.compile(self.regex) if self.regex else None
 
     def check(self, value):
         ok, args = super().check(value)
         if ok:
             try:
                 if self.regex is not None:
                     if not re.fullmatch(self.regex_compile, value):
@@ -429,14 +438,28 @@
             except Exception as err:
                 return (
                     False,
                     {"message": err_to_str(err), "type": self.kind},
                 )
         return ok, args
 
+    @classmethod
+    def from_dict(cls, struct=None, fields=None, deprecated_fields: dict = None):
+        new_obj = super(RegexValidator, cls).from_dict(
+            struct=struct, fields=fields, deprecated_fields=deprecated_fields
+        )
+        if hasattr(new_obj, "regex"):
+            new_obj.regex_compile = re.compile(new_obj.regex) if new_obj.regex else None
+        else:
+            raise MLRunRuntimeError(
+                f"Object with type {type(new_obj)} "
+                f"have to contain `regex` attribute"
+            )
+        return new_obj
+
 
 validator_kinds = {
     "": Validator,
     "minmax": MinMaxValidator,
     "minmaxlen": MinMaxLenValidator,
     "regex": RegexValidator,
 }
```

## mlrun/k8s_utils.py

```diff
@@ -539,14 +539,17 @@
             self.v1api.delete_namespaced_secret(secret_name, namespace)
         else:
             k8s_secret.data = secret_data
             self.v1api.replace_namespaced_secret(secret_name, namespace, k8s_secret)
 
     def _get_project_secrets_raw_data(self, project, namespace=""):
         secret_name = self.get_project_secret_name(project)
+        return self._get_secret_raw_data(secret_name, namespace)
+
+    def _get_secret_raw_data(self, secret_name, namespace=""):
         namespace = self.resolve_namespace(namespace)
 
         try:
             k8s_secret = self.v1api.read_namespaced_secret(secret_name, namespace)
         except ApiException:
             return None
 
@@ -561,27 +564,33 @@
         if filter_internal:
             secret_keys = list(
                 filter(lambda key: not key.startswith("mlrun."), secret_keys)
             )
         return secret_keys
 
     def get_project_secret_data(self, project, secret_keys=None, namespace=""):
-        results = {}
         secrets_data = self._get_project_secrets_raw_data(project, namespace)
+        return self._decode_secret_data(secrets_data, secret_keys)
+
+    def get_secret_data(self, secret_name, namespace=""):
+        secrets_data = self._get_secret_raw_data(secret_name, namespace)
+        return self._decode_secret_data(secrets_data)
+
+    def _decode_secret_data(self, secrets_data, secret_keys=None):
+        results = {}
         if not secrets_data:
             return results
 
         # If not asking for specific keys, return all
         secret_keys = secret_keys or secrets_data.keys()
 
         for key in secret_keys:
             encoded_value = secrets_data.get(key)
             if encoded_value:
                 results[key] = base64.b64decode(secrets_data[key]).decode("utf-8")
-
         return results
 
 
 class BasePod:
     def __init__(
         self,
         task_name="",
```

## mlrun/kfpops.py

```diff
@@ -7,51 +7,54 @@
 #   http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
 import getpass
 import json
 import os
 import os.path
 from copy import deepcopy
+from typing import Dict, List, Union
 
 from kfp import dsl
 from kubernetes import client as k8s_client
 
 import mlrun
 from mlrun.errors import err_to_str
 
 from .config import config
 from .db import get_or_set_dburl, get_run_db
-from .model import HyperParamOptions
+from .model import HyperParamOptions, RunSpec
 from .utils import (
     dict_to_yaml,
     gen_md_table,
     get_artifact_target,
     get_in,
     get_workflow_url,
     is_ipython,
     is_legacy_artifact,
     logger,
     run_keys,
+    version,
 )
 
 # default KFP artifacts and output (ui metadata, metrics etc.)
 # directories to /tmp to allow running with security context
 KFPMETA_DIR = os.environ.get("KFPMETA_OUT_DIR", "/tmp")
 KFP_ARTIFACTS_DIR = os.environ.get("KFP_ARTIFACTS_DIR", "/tmp")
 
 project_annotation = "mlrun/project"
 run_annotation = "mlrun/pipeline-step-type"
 function_annotation = "mlrun/function-uri"
 
+dsl.ContainerOp._DISABLE_REUSABLE_COMPONENT_WARNING = True
+
 
 class PipelineRunType:
     run = "run"
     build = "build"
     deploy = "deploy"
 
 
@@ -189,14 +192,16 @@
     rundb: str = "",
     mode: str = "",
     handler: str = "",
     more_args: list = None,
     hyper_param_options=None,
     verbose=None,
     scrape_metrics=False,
+    returns: List[Union[str, Dict[str, str]]] = None,
+    auto_build: bool = False,
 ):
     """mlrun KubeFlow pipelines operator, use to form pipeline steps
 
     when using kubeflow pipelines, each step is wrapped in an mlrun_op
     one step can pass state and data to the next step, see example below.
 
     :param name:    name used for the step
@@ -227,14 +232,26 @@
     :param out_path: default output path/url (prefix) for artifacts
     :param rundb:    path for rundb (or use 'MLRUN_DBPATH' env instead)
     :param mode:     run mode, e.g. 'pass' for using the command without mlrun wrapper
     :param handler   code entry-point/handler name
     :param job_image name of the image user for the job
     :param verbose:  add verbose prints/logs
     :param scrape_metrics:  whether to add the `mlrun/scrape-metrics` label to this run's resources
+    :param returns: List of configurations for how to log the returning values from the handler's run (as artifacts or
+                    results). The list's length must be equal to the amount of returning objects. A configuration may be
+                    given as:
+
+                    * A string of the key to use to log the returning value as result or as an artifact. To specify
+                      The artifact type, it is possible to pass a string in the following structure:
+                      "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no artifact
+                      type is specified, the object's default artifact type will be used.
+                    * A dictionary of configurations to use when logging. Further info per object type and artifact
+                      type can be given there. The artifact key must appear in the dictionary as "key": "the_key".
+    :param auto_build: when set to True and the function require build it will be built on the first
+                       function run, use only if you dont plan on changing the build config between runs
 
     :returns: KFP step operation
 
     Example:
     from kfp import dsl
     from mlrun import mlrun_op
     from mlrun.platforms import mount_v3io
@@ -271,14 +288,15 @@
     """
     secrets = [] if secrets is None else secrets
     params = {} if params is None else params
     hyperparams = {} if hyperparams is None else hyperparams
     if hyper_param_options and isinstance(hyper_param_options, dict):
         hyper_param_options = HyperParamOptions.from_dict(hyper_param_options)
     inputs = {} if inputs is None else inputs
+    returns = [] if returns is None else returns
     outputs = [] if outputs is None else outputs
     labels = {} if labels is None else labels
 
     rundb = rundb or get_or_set_dburl()
     cmd = [
         "python",
         "-m",
@@ -323,23 +341,26 @@
             or runobj.spec.hyper_param_options.param_file
         )
         hyper_param_options = hyper_param_options or runobj.spec.hyper_param_options
         selector = (
             selector or runobj.spec.selector or runobj.spec.hyper_param_options.selector
         )
         inputs = inputs or runobj.spec.inputs
+        returns = returns or runobj.spec.returns
         outputs = outputs or runobj.spec.outputs
         in_path = in_path or runobj.spec.input_path
         out_path = out_path or runobj.spec.output_path
         secrets = secrets or runobj.spec.secret_sources
         project = project or runobj.metadata.project
         labels = runobj.metadata.labels or labels
         verbose = verbose or runobj.spec.verbose
         scrape_metrics = scrape_metrics or runobj.spec.scrape_metrics
 
+    outputs = RunSpec.join_outputs_and_returns(outputs=outputs, returns=returns)
+
     if not name:
         if not function_name:
             raise ValueError("name or function object must be specified")
         name = function_name
         if handler:
             short_name = handler
             for separator in ["#", "::", "."]:
@@ -352,14 +373,15 @@
         outputs.append("iteration_results")
     if "run_id" not in outputs:
         outputs.append("run_id")
 
     params = params or {}
     hyperparams = hyperparams or {}
     inputs = inputs or {}
+    returns = returns or []
     secrets = secrets or []
 
     if "V3IO_USERNAME" in os.environ and "v3io_user" not in labels:
         labels["v3io_user"] = os.environ.get("V3IO_USERNAME")
     if "owner" not in labels:
         labels["owner"] = os.environ.get("V3IO_USERNAME") or getpass.getuser()
 
@@ -371,14 +393,19 @@
         cmd += ["-s", f"{secret['kind']}={secret['source']}"]
     for param, val in params.items():
         cmd += ["-p", f"{param}={val}"]
     for xpram, val in hyperparams.items():
         cmd += ["-x", f"{xpram}={val}"]
     for input_param, val in inputs.items():
         cmd += ["-i", f"{input_param}={val}"]
+    for log_hint in returns:
+        cmd += [
+            "--returns",
+            json.dumps(log_hint) if isinstance(log_hint, dict) else log_hint,
+        ]
     for label, val in labels.items():
         cmd += ["--label", f"{label}={val}"]
     for output in outputs:
         cmd += ["-o", str(output)]
         file_outputs[
             output.replace(".", "_")
         ] = f"/tmp/{output}"  # not using path.join to avoid windows "\"
@@ -402,24 +429,30 @@
         cmd += ["--image", job_image]
     if mode:
         cmd += ["--mode", mode]
     if verbose:
         cmd += ["--verbose"]
     if scrape_metrics:
         cmd += ["--scrape-metrics"]
+    if auto_build:
+        cmd += ["--auto-build"]
     if more_args:
         cmd += more_args
 
     registry = get_default_reg()
     if image and image.startswith("."):
         if registry:
             image = f"{registry}/{image[1:]}"
         else:
             raise ValueError("local image registry env not found")
 
+    image = mlrun.utils.enrich_image_url(
+        image, mlrun.get_version(), str(version.Version().get_python_version())
+    )
+
     cop = dsl.ContainerOp(
         name=name,
         image=image,
         command=cmd + [command],
         file_outputs=file_outputs,
         output_artifact_paths={
             "mlpipeline-ui-metadata": KFPMETA_DIR + "/mlpipeline-ui-metadata.json",
```

## mlrun/lists.py

```diff
@@ -211,16 +211,18 @@
     def to_objects(self) -> List[Artifact]:
         """return as a list of artifact objects"""
         return [dict_to_artifact(artifact) for artifact in self]
 
     def objects(self) -> List[Artifact]:
         """return as a list of artifact objects"""
         warnings.warn(
-            "This is replaced with .to_objects(), and will be deprecated in 1.1.x",
-            PendingDeprecationWarning,
+            "'objects' is deprecated in 1.3.0 and will be removed in 1.5.0. "
+            "Use 'to_objects' instead.",
+            # TODO: remove in 1.5.0
+            FutureWarning,
         )
         return [dict_to_artifact(artifact) for artifact in self]
 
     def dataitems(self) -> List["mlrun.DataItem"]:
         """return as a list of DataItem objects"""
         dataitems = []
         for item in self:
```

## mlrun/model.py

```diff
@@ -12,20 +12,19 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import inspect
 import pathlib
 import re
 import time
-import warnings
 from collections import OrderedDict
 from copy import deepcopy
 from datetime import datetime
 from os import environ
-from typing import Dict, List, Optional, Tuple, Union
+from typing import Any, Dict, List, Optional, Tuple, Union
 
 import mlrun
 
 from .utils import (
     dict_to_json,
     dict_to_yaml,
     get_artifact_target,
@@ -165,15 +164,20 @@
         if children is None:
             return cls(classes_map, default_kind)
         if not isinstance(children, dict):
             raise ValueError("children must be a dict")
 
         new_obj = cls(classes_map, default_kind)
         for name, child in children.items():
-            child_obj = new_obj._get_child_object(child, name)
+            obj_name = name
+            if hasattr(child, "name") and child.name is not None:
+                obj_name = child.name
+            elif isinstance(child, dict) and "name" in child:
+                obj_name = child["name"]
+            child_obj = new_obj._get_child_object(child, obj_name)
             new_obj._children[name] = child_obj
 
         return new_obj
 
     def _get_child_object(self, child, name):
         if hasattr(child, "kind") and child.kind in self._classes_map.keys():
             child.name = name
@@ -272,15 +276,15 @@
 
 class Credentials(ModelObj):
     generate_access_key = "$generate"
     secret_reference_prefix = "$ref:"
 
     def __init__(
         self,
-        access_key=None,
+        access_key: str = None,
     ):
         self.access_key = access_key
 
 
 class BaseMetadata(ModelObj):
     def __init__(
         self,
@@ -482,20 +486,35 @@
         secret_sources=None,
         data_stores=None,
         strategy=None,
         verbose=None,
         scrape_metrics=None,
         hyper_param_options=None,
         allow_empty_resources=None,
+        inputs_type_hints=None,
+        returns=None,
     ):
+        # A dictionary of parsing configurations that will be read from the inputs the user set. The keys are the inputs
+        # keys (parameter names) and the values are the type hint given in the input keys after the colon.
+        # Notice: We set it first as empty dictionary as setting the inputs will set it as well in case the type hints
+        # were passed in the input keys.
+        self._inputs_type_hints = {}
 
         self._hyper_param_options = None
-        self._inputs = inputs
-        self._outputs = outputs
 
+        # Initialize the inputs and returns properties first and then use their setter methods:
+        self._inputs = None
+        self.inputs = inputs
+        if inputs_type_hints:
+            # Override the empty dictionary only if the user passed the parameter:
+            self._inputs_type_hints = inputs_type_hints
+        self._returns = None
+        self.returns = returns
+
+        self._outputs = outputs
         self.hyper_param_options = hyper_param_options
         self.parameters = parameters or {}
         self.hyperparams = hyperparams or {}
         self.param_file = param_file
         self.strategy = strategy
         self.selector = selector
         self.handler = handler
@@ -515,37 +534,124 @@
         return struct
 
     def is_hyper_job(self):
         param_file = self.param_file or self.hyper_param_options.param_file
         return param_file or self.hyperparams
 
     @property
-    def inputs(self):
+    def inputs(self) -> Dict[str, str]:
+        """
+        Get the inputs dictionary. A dictionary of parameter names as keys and paths as values.
+
+        :return: The inputs dictionary.
+        """
         return self._inputs
 
     @inputs.setter
-    def inputs(self, inputs):
+    def inputs(self, inputs: Dict[str, str]):
+        """
+        Set the given inputs in the spec. Inputs can include a type hint string in their keys following a colon, meaning
+        following this structure: "<input key : type hint>".
+
+        :exmaple:
+
+        >>> run_spec.inputs = {
+        ...     "my_input": "...",
+        ...     "my_hinted_input : pandas.DataFrame": "..."
+        ... }
+
+        :param inputs: The inputs to set.
+        """
+        # Check if None, then set and return:
+        if inputs is None:
+            self._inputs = None
+            return
+
+        # Verify it's a dictionary:
         self._inputs = self._verify_dict(inputs, "inputs")
 
     @property
+    def inputs_type_hints(self) -> Dict[str, str]:
+        """
+        Get the input type hints. A dictionary of parameter names as keys and their type hints as values.
+
+        :return: The input type hints dictionary.
+        """
+        return self._inputs_type_hints
+
+    @inputs_type_hints.setter
+    def inputs_type_hints(self, inputs_type_hints: Dict[str, str]):
+        """
+        Set the inputs type hints to parse during a run.
+
+        :param inputs_type_hints: The type hints to set.
+        """
+        # Verify the given value is a dictionary or None:
+        self._inputs_type_hints = self._verify_dict(
+            inputs_type_hints, "inputs_type_hints"
+        )
+
+    @property
+    def returns(self):
+        """
+        Get the returns list. A list of log hints for returning values.
+
+        :return: The returns list.
+        """
+        return self._returns
+
+    @returns.setter
+    def returns(self, returns: List[Union[str, Dict[str, str]]]):
+        """
+        Set the returns list to log the returning values at the end of a run.
+
+        :param returns: The return list to set.
+
+        :raise MLRunInvalidArgumentError: In case one of the values in the list is invalid.
+        """
+        if returns is None:
+            self._returns = None
+            return
+        self._verify_list(returns, "returns")
+
+        # Validate:
+        for log_hint in returns:
+            mlrun.run._parse_log_hint(log_hint=log_hint)
+
+        # Store the results:
+        self._returns = returns
+
+    @property
     def hyper_param_options(self) -> HyperParamOptions:
         return self._hyper_param_options
 
     @hyper_param_options.setter
     def hyper_param_options(self, hyper_param_options):
         self._hyper_param_options = self._verify_dict(
             hyper_param_options, "hyper_param_options", HyperParamOptions
         )
 
     @property
-    def outputs(self):
-        return self._outputs
+    def outputs(self) -> List[str]:
+        """
+        Get the expected outputs. The list is constructed from keys of both the `outputs` and `returns` properties.
+
+        :return: The expected outputs list.
+        """
+        return self.join_outputs_and_returns(
+            outputs=self._outputs, returns=self.returns
+        )
 
     @outputs.setter
     def outputs(self, outputs):
+        """
+        Set the expected outputs list.
+
+        :param outputs: A list of expected output keys.
+        """
         self._verify_list(outputs, "outputs")
         self._outputs = outputs
 
     @property
     def secret_sources(self):
         return self._secret_sources
 
@@ -568,14 +674,108 @@
         if self.handler:
             if inspect.isfunction(self.handler):
                 return self.handler.__name__
             else:
                 return str(self.handler)
         return ""
 
+    def extract_type_hints_from_inputs(self):
+        """
+        This method extracts the type hints from the inputs keys in the input dictionary.
+
+        As a result, after the method ran the inputs dictionary - a dictionary of parameter names as keys and paths as
+        values, will be cleared from type hints and the extracted type hints will be saved in the spec's inputs type
+        hints dictionary - a dictionary of parameter names as keys and their type hints as values. If a parameter is
+        not in the type hints dictionary, its type hint will be `mlrun.DataItem` by default.
+        """
+        # Validate there are inputs to read:
+        if self.inputs is None:
+            return
+
+        # Prepare dictionaries to hold the cleared inputs and type hints:
+        cleared_inputs = {}
+        extracted_inputs_type_hints = {}
+
+        # Clear the inputs from parsing configurations:
+        for input_key, input_value in self.inputs.items():
+            # Look for type hinted in input key:
+            if ":" in input_key:
+                # Separate the user input by colon:
+                input_key, input_type = RunSpec._separate_type_hint_from_input_key(
+                    input_key=input_key
+                )
+                # Collect the type hint:
+                extracted_inputs_type_hints[input_key] = input_type
+            # Collect the cleared input key:
+            cleared_inputs[input_key] = input_value
+
+        # Set the now configuration free inputs and extracted type hints:
+        self.inputs = cleared_inputs
+        self.inputs_type_hints = extracted_inputs_type_hints
+
+    @staticmethod
+    def join_outputs_and_returns(
+        outputs: List[str], returns: List[Union[str, Dict[str, str]]]
+    ) -> List[str]:
+        """
+        Get the outputs set in the spec. The outputs are constructed from both the 'outputs' and 'returns' properties
+        that were set by the user.
+
+        :param outputs: A spec outputs property - list of output keys.
+        :param returns: A spec returns property - list of key and configuration of how to log returning values.
+
+        :return: The joined 'outputs' and 'returns' list.
+        """
+        # Collect the 'returns' property keys:
+        cleared_returns = []
+        if returns:
+            for return_value in returns:
+                # Check if the return entry is a configuration dictionary or a key-type structure string (otherwise its
+                # just a key string):
+                if isinstance(return_value, dict):
+                    # Set it to the artifact key:
+                    return_value = return_value["key"]
+                elif ":" in return_value:
+                    # Take only the key name (returns values pattern is validated when set in the spec):
+                    return_value = return_value.replace(" ", "").split(":")[0]
+                # Collect it:
+                cleared_returns.append(return_value)
+
+        # Use `set` join to combine the two lists without duplicates:
+        outputs = list(set(outputs if outputs else []) | set(cleared_returns))
+
+        return outputs
+
+    @staticmethod
+    def _separate_type_hint_from_input_key(input_key: str) -> Tuple[str, str]:
+        """
+        An input key in the `inputs` dictionary parameter of a task (or `Runtime.run` method) or the docs setting of a
+        `Runtime` handler can be provided with a colon to specify its type hint in the following structure:
+        "<parameter_key> : <type_hint>".
+
+        This method parses the provided value by the user.
+
+        :param input_key: A string entry in the inputs dictionary keys.
+
+        :return: The value as key and type hint tuple.
+
+        :raise MLRunInvalidArgumentError: If an incorrect pattern was provided.
+        """
+        # Validate correct pattern:
+        if input_key.count(":") > 1:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                f"Incorrect input pattern. Inputs keys can have only a single ':' in them to specify the desired type "
+                f"the input will be parsed as. Given: {input_key}."
+            )
+
+        # Split into key and type:
+        value_key, value_type = input_key.replace(" ", "").split(":")
+
+        return value_key, value_type
+
 
 class RunStatus(ModelObj):
     """Run status"""
 
     def __init__(
         self,
         state=None,
@@ -585,26 +785,28 @@
         status_text=None,
         results=None,
         artifacts=None,
         start_time=None,
         last_update=None,
         iterations=None,
         ui_url=None,
+        reason: str = None,
     ):
         self.state = state or "created"
         self.status_text = status_text
         self.error = error
         self.host = host
         self.commit = commit
         self.results = results
         self.artifacts = artifacts
         self.start_time = start_time
         self.last_update = last_update
         self.iterations = iterations
         self.ui_url = ui_url
+        self.reason = reason
 
 
 class RunTemplate(ModelObj):
     """Run template"""
 
     def __init__(self, spec: RunSpec = None, metadata: RunMetadata = None):
         self._spec = None
@@ -873,14 +1075,15 @@
             return None
 
         new_offset = 0
         if db.kind == "http":
             state, new_offset = db.watch_log(
                 self.metadata.uid, self.metadata.project, watch=watch, offset=offset
             )
+        # not expected to reach this else, as FileDB is not supported any more and because we don't watch logs on API
         else:
             state, text = db.get_log(
                 self.metadata.uid, self.metadata.project, offset=offset
             )
             if text:
                 print(text.decode())
 
@@ -998,57 +1201,14 @@
         self.name = name
         self.doc = doc
         self.parameters = [] if parameters is None else parameters
         self.outputs = [] if outputs is None else outputs
         self.lineno = lineno
 
 
-# TODO: remove in 0.9.0
-def NewTask(
-    name=None,
-    project=None,
-    handler=None,
-    params=None,
-    hyper_params=None,
-    param_file=None,
-    selector=None,
-    strategy=None,
-    inputs=None,
-    outputs=None,
-    in_path=None,
-    out_path=None,
-    artifact_path=None,
-    secrets=None,
-    base=None,
-):
-    """Creates a new task - see new_task"""
-    warnings.warn(
-        "NewTask will be deprecated in 0.7.0, and will be removed in 0.9.0, use new_task instead",
-        # TODO: In 0.7.0 and replace NewTask to new_task in examples & demos
-        PendingDeprecationWarning,
-    )
-    return new_task(
-        name,
-        project,
-        handler,
-        params,
-        hyper_params,
-        param_file,
-        selector,
-        strategy,
-        inputs,
-        outputs,
-        in_path,
-        out_path,
-        artifact_path,
-        secrets,
-        base,
-    )
-
-
 def new_task(
     name=None,
     project=None,
     handler=None,
     params=None,
     hyper_params=None,
     param_file=None,
@@ -1057,14 +1217,15 @@
     inputs=None,
     outputs=None,
     in_path=None,
     out_path=None,
     artifact_path=None,
     secrets=None,
     base=None,
+    returns=None,
 ) -> RunTemplate:
     """Creates a new task
 
     :param name:            task name
     :param project:         task project
     :param handler:         code entry-point/handler name
     :param params:          input parameters (dict)
@@ -1081,25 +1242,37 @@
                             omitted the path will be the out_path/key)
     :param in_path:         default input path/url (prefix) for inputs
     :param out_path:        default output path/url (prefix) for artifacts
     :param artifact_path:   default artifact output path
     :param secrets:         extra secrets specs, will be injected into the runtime
                             e.g. ['file=<filename>', 'env=ENV_KEY1,ENV_KEY2']
     :param base:            task instance to use as a base instead of a fresh new task instance
+    :param returns:         List of log hints - configurations for how to log the returning values from the handler's
+                            run (as artifacts or results). The list's length must be equal to the amount of returning
+                            objects. A log hint may be given as:
+
+                            * A string of the key to use to log the returning value as result or as an artifact. To
+                              specify The artifact type, it is possible to pass a string in the following structure:
+                              "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no
+                              artifact type is specified, the object's default artifact type will be used.
+                            * A dictionary of configurations to use when logging. Further info per object type and
+                              artifact type can be given there. The artifact key must appear in the dictionary as
+                              "key": "the_key".
     """
 
     if base:
         run = deepcopy(base)
     else:
         run = RunTemplate()
     run.metadata.name = name or run.metadata.name
     run.metadata.project = project or run.metadata.project
     run.spec.handler = handler or run.spec.handler
     run.spec.parameters = params or run.spec.parameters
     run.spec.inputs = inputs or run.spec.inputs
+    run.spec.returns = returns or run.spec.returns
     run.spec.outputs = outputs or run.spec.outputs or []
     run.spec.input_path = in_path or run.spec.input_path
     run.spec.output_path = artifact_path or out_path or run.spec.output_path
     run.spec.secret_sources = secrets or run.spec.secret_sources or []
 
     run.spec.hyperparams = hyper_params or run.spec.hyperparams
     run.spec.hyper_param_options = hyper_param_options or run.spec.hyper_param_options
@@ -1184,29 +1357,29 @@
         "time_field",
         "schedule",
         "online",
         "workers",
         "max_age",
         "start_time",
         "end_time",
+        "credentials_prefix",
     ]
     kind = None
 
     def __init__(
         self,
         name: str = None,
         path: str = None,
         attributes: Dict[str, str] = None,
         key_field: str = None,
         time_field: str = None,
         schedule: str = None,
         start_time: Optional[Union[datetime, str]] = None,
         end_time: Optional[Union[datetime, str]] = None,
     ):
-
         self.name = name
         self.path = str(path) if path is not None else None
         self.attributes = attributes or {}
         self.schedule = schedule
         self.key_field = key_field
         self.time_field = time_field
         self.start_time = start_time
@@ -1234,22 +1407,21 @@
         "key_bucketing_number",
         "partition_cols",
         "time_partitioning_granularity",
         "max_events",
         "flush_after_seconds",
         "storage_options",
         "run_id",
+        "schema",
+        "credentials_prefix",
     ]
 
-    # TODO - remove once "after_state" is fully deprecated
     @classmethod
     def from_dict(cls, struct=None, fields=None):
-        return super().from_dict(
-            struct, fields=fields, deprecated_fields={"after_state": "after_step"}
-        )
+        return super().from_dict(struct, fields=fields)
 
     def get_path(self):
         if self.path:
             is_single_file = hasattr(self, "is_single_file") and self.is_single_file()
             return TargetPathObject(self.path, self.run_id, is_single_file)
         else:
             return None
@@ -1263,39 +1435,34 @@
         after_step=None,
         partitioned: bool = False,
         key_bucketing_number: Optional[int] = None,
         partition_cols: Optional[List[str]] = None,
         time_partitioning_granularity: Optional[str] = None,
         max_events: Optional[int] = None,
         flush_after_seconds: Optional[int] = None,
-        after_state=None,
         storage_options: Dict[str, str] = None,
+        schema: Dict[str, Any] = None,
+        credentials_prefix=None,
     ):
-        if after_state:
-            warnings.warn(
-                "The after_state parameter is deprecated. Use after_step instead",
-                # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-                PendingDeprecationWarning,
-            )
-            after_step = after_step or after_state
-
         self.name = name
         self.kind: str = kind
         self.path = path
         self.after_step = after_step
         self.attributes = attributes or {}
         self.last_written = None
         self.partitioned = partitioned
         self.key_bucketing_number = key_bucketing_number
         self.partition_cols = partition_cols
         self.time_partitioning_granularity = time_partitioning_granularity
         self.max_events = max_events
         self.flush_after_seconds = flush_after_seconds
         self.storage_options = storage_options
         self.run_id = None
+        self.schema = schema
+        self.credentials_prefix = credentials_prefix
 
 
 class FeatureSetProducer(ModelObj):
     """information about the task/job which produced the feature set data"""
 
     def __init__(self, kind=None, name=None, uri=None, owner=None, sources=None):
         self.kind = kind
@@ -1319,14 +1486,15 @@
         "size",
         "last_written",
         "run_id",
         "partitioned",
         "key_bucketing_number",
         "partition_cols",
         "time_partitioning_granularity",
+        "credentials_prefix",
     ]
 
     def __init__(
         self,
         kind: str = None,
         name: str = "",
         path=None,
```

## mlrun/run.py

```diff
@@ -8,46 +8,45 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import functools
+import importlib
 import importlib.util as imputil
 import inspect
 import json
 import os
 import pathlib
-import shutil
+import re
 import socket
 import tempfile
 import time
 import uuid
+import warnings
 from base64 import b64decode
 from collections import OrderedDict
 from copy import deepcopy
-from enum import Enum
 from os import environ, makedirs, path
 from pathlib import Path
-from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union
+from typing import Callable, Dict, List, Optional, Tuple, Type, Union
 
-import cloudpickle
-import numpy as np
-import pandas as pd
+import nuclio
 import yaml
+from deprecated import deprecated
 from kfp import Client
-from nuclio import build_file, utils
 
 import mlrun.api.schemas
 import mlrun.errors
 import mlrun.utils.helpers
 from mlrun.kfpops import format_summary_from_kfp_run, show_kfp_run
 
 from .config import config as mlconf
-from .datastore import DataItem, store_manager
+from .datastore import store_manager
 from .db import get_or_set_dburl, get_run_db
 from .execution import MLClientCtx
 from .model import BaseMetadata, RunObject, RunTemplate
 from .runtimes import (
     DaskCluster,
     HandlerRuntime,
     KubejobRuntime,
@@ -59,21 +58,22 @@
     RuntimeKinds,
     ServingRuntime,
     Spark2Runtime,
     Spark3Runtime,
     get_runtime_class,
 )
 from .runtimes.funcdoc import update_function_entry_points
+from .runtimes.package.context_handler import ArtifactType, ContextHandler
 from .runtimes.serving import serving_subkind
 from .runtimes.utils import add_code_metadata, global_context
 from .utils import (
     extend_hub_uri_if_needed,
     get_in,
     logger,
-    new_pipe_meta,
+    new_pipe_metadata,
     parse_versioned_object_uri,
     retry_until_successful,
     run_keys,
     update_in,
 )
 
 
@@ -123,14 +123,15 @@
     secrets=None,
     handler=None,
     params: dict = None,
     inputs: dict = None,
     artifact_path: str = "",
     mode: str = None,
     allow_empty_resources=None,
+    returns: list = None,
 ):
     """Run a task on function/code (.py, .ipynb or .yaml) locally,
 
     example::
 
         # define a task
         task = new_task(params={'p1': 8}, out_path=out_path)
@@ -148,21 +149,33 @@
     :param workdir:  working dir to exec in
     :param project:  function project (none for 'default')
     :param tag:      function version tag (none for 'latest')
     :param secrets:  secrets dict if the function source is remote (s3, v3io, ..)
 
     :param handler:  pointer or name of a function handler
     :param params:   input parameters (dict)
-    :param inputs:   input objects (dict of key: path)
+    :param inputs:   Input objects to pass to the handler. Type hints can be given so the input will be parsed
+                     during runtime from `mlrun.DataItem` to the given type hint. The type hint can be given
+                     in the key field of the dictionary after a colon, e.g: "<key> : <type_hint>".
     :param artifact_path: default artifact output path
     :param mode:    Runtime mode for more details head to `mlrun.new_function`
     :param allow_empty_resources:   Allow passing non materialized set/vector as input to jobs
                                     (allows to have function which don't depend on having targets,
                                     e.g a function which accepts a feature vector uri and generate
                                      the offline vector e.g. parquet_ for it if it doesn't exist)
+    :param returns:  List of configurations for how to log the returning values from the handler's run (as artifacts or
+                     results). The list's length must be equal to the amount of returning objects. A configuration may
+                     be given as:
+
+                     * A string of the key to use to log the returning value as result or as an artifact. To specify
+                       The artifact type, it is possible to pass a string in the following structure:
+                       "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no artifact
+                       type is specified, the object's default artifact type will be used.
+                     * A dictionary of configurations to use when logging. Further info per object type and artifact
+                       type can be given there. The artifact key must appear in the dictionary as "key": "the_key".
 
     :return: run object
     """
 
     function_name = name
     if command and isinstance(command, str):
         sp = command.split()
@@ -197,14 +210,15 @@
         fn.spec.build = runtime.spec.build
     return fn.run(
         task,
         name=name,
         handler=handler,
         params=params,
         inputs=inputs,
+        returns=returns,
         artifact_path=artifact_path,
     )
 
 
 def function_to_module(code="", workdir=None, secrets=None, silent=False):
     """Load code, notebook or mlrun function as .py module
     this function can import a local/remote py file or notebook
@@ -469,15 +483,15 @@
     function = new_function(runtime=runtime)
     project = project or mlrun.mlconf.default_project
     # When we're importing from the hub we want to assign to a target project, otherwise any store on it will
     # simply default to the default project
     if project and is_hub_uri:
         function.metadata.project = project
     if new_name:
-        function.metadata.name = new_name
+        function.metadata.name = mlrun.utils.helpers.normalize_name(new_name)
     return function
 
 
 def import_function_to_dict(url, secrets=None):
     """Load function spec from local/remote YAML file"""
     obj = get_object(url, secrets)
     runtime = yaml.load(obj, Loader=yaml.FullLoader)
@@ -600,15 +614,15 @@
     if not name:
         if command and kind not in [RuntimeKinds.remote]:
             name, _ = path.splitext(path.basename(command))
         else:
             name = "mlrun-" + uuid.uuid4().hex[0:6]
 
     # make sure function name is valid
-    name = utils.normalize_name(name)
+    name = mlrun.utils.helpers.normalize_name(name)
 
     runner.metadata.name = name
     runner.metadata.project = (
         runner.metadata.project or project or mlconf.default_project
     )
     if tag:
         runner.metadata.tag = tag
@@ -820,29 +834,29 @@
             "a valid code file must be specified "
             "when not using the embed_code option"
         )
 
     is_nuclio, subkind = resolve_nuclio_subkind(kind)
     code_origin = add_name(add_code_metadata(filename), name)
 
-    name, spec, code = build_file(
+    name, spec, code = nuclio.build_file(
         filename,
         name=name,
         handler=handler or "handler",
         kind=subkind,
         ignored_tags=ignored_tags,
     )
     spec_kind = get_in(spec, "kind", "")
     if not kind and spec_kind not in ["", "Function"]:
         kind = spec_kind.lower()
 
         # if its a nuclio subkind, redo nb parsing
         is_nuclio, subkind = resolve_nuclio_subkind(kind)
         if is_nuclio:
-            name, spec, code = build_file(
+            name, spec, code = nuclio.build_file(
                 filename,
                 name=name,
                 handler=handler or "handler",
                 kind=subkind,
                 ignored_tags=ignored_tags,
             )
 
@@ -882,15 +896,15 @@
     if kind is None or kind in ["", "Function"]:
         raise ValueError("please specify the function kind")
     elif kind in RuntimeKinds.all():
         r = get_runtime_class(kind)()
     else:
         raise ValueError(f"unsupported runtime ({kind})")
 
-    name, spec, code = build_file(filename, name=name, ignored_tags=ignored_tags)
+    name, spec, code = nuclio.build_file(filename, name=name, ignored_tags=ignored_tags)
 
     if not name:
         raise ValueError("name must be specified")
     h = get_in(spec, "spec.handler", "").split(":")
     r.handler = h[0] if len(h) <= 1 else h[1]
     r.metadata = get_in(spec, "spec.metadata")
     r.metadata.name = name
@@ -910,45 +924,65 @@
 
     if with_doc:
         update_function_entry_points(r, code)
     r.spec.default_handler = handler
     return r
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'run_pipeline' will be removed in 1.5.0, use 'project.run' instead",
+    category=FutureWarning,
+)
 def run_pipeline(
     pipeline,
     arguments=None,
     project=None,
     experiment=None,
     run=None,
     namespace=None,
     artifact_path=None,
     ops=None,
     url=None,
+    # TODO: deprecated, remove in 1.5.0
     ttl=None,
     remote: bool = True,
+    cleanup_ttl=None,
 ):
-    """remote KubeFlow pipeline execution
+    """
+    remote KubeFlow pipeline execution
 
     Submit a workflow task to KFP via mlrun API service
 
     :param pipeline:   KFP pipeline function or path to .yaml/.zip pipeline file
     :param arguments:  pipeline arguments
     :param project:    name of project
     :param experiment: experiment name
     :param run:        optional, run name
     :param namespace:  Kubernetes namespace (if not using default)
     :param url:        optional, url to mlrun API service
     :param artifact_path:  target location/url for mlrun artifacts
     :param ops:        additional operators (.apply() to all pipeline functions)
-    :param ttl:        pipeline ttl in secs (after that the pods will be removed)
-    :param remote:     read kfp data from mlrun service (default=True)
+    :param ttl:        pipeline cleanup ttl in secs (time to wait after workflow completion, at which point the
+                       workflow and all its resources are deleted) (deprecated, use cleanup_ttl instead)
+    :param remote:     read kfp data from mlrun service (default=True). Run pipeline from local kfp data (remote=False)
+      is deprecated. Should not be used
+    :param cleanup_ttl:
+                       pipeline cleanup ttl in secs (time to wait after workflow completion, at which point the
+                       workflow and all its resources are deleted)
 
     :returns: kubeflow pipeline id
     """
+    if ttl:
+        warnings.warn(
+            "'ttl' is deprecated, use 'cleanup_ttl' instead. "
+            "This will be removed in 1.5.0",
+            # TODO: Remove this in 1.5.0
+            FutureWarning,
+        )
 
     artifact_path = artifact_path or mlconf.artifact_path
     project = project or mlconf.default_project
     artifact_path = mlrun.utils.helpers.fill_artifact_path_template(
         artifact_path, project or mlconf.default_project
     )
     if artifact_path and "{{run.uid}}" in artifact_path:
@@ -956,51 +990,118 @@
     if not artifact_path:
         raise ValueError("artifact path was not specified")
 
     namespace = namespace or mlconf.namespace
     arguments = arguments or {}
 
     if remote or url:
-        mldb = mlrun.db.get_run_db(url)
-        if mldb.kind != "http":
-            raise ValueError(
-                "run pipeline require access to remote api-service"
-                ", please set the dbpath url"
-            )
-        id = mldb.submit_pipeline(
-            project,
-            pipeline,
-            arguments,
+        from .projects.pipelines import WorkflowSpec, pipeline_context
+
+        clear_pipeline_context = False
+        # if pipeline_context.workflow isn't set it means the `run_pipeline` method was called directly
+        # so to make sure the pipeline and functions inside are being run in the KFP pipeline we set the pipeline
+        # context with KFP engine
+        if not pipeline_context.workflow:
+            workflow_spec = WorkflowSpec(engine="kfp")
+            pipeline_context.set(pipeline_context.project, workflow=workflow_spec)
+            clear_pipeline_context = True
+
+        pipeline_run_id = _run_pipeline(
+            pipeline=pipeline,
+            arguments=arguments,
+            project=project,
             experiment=experiment,
             run=run,
             namespace=namespace,
-            ops=ops,
             artifact_path=artifact_path,
+            ops=ops,
+            url=url,
+            cleanup_ttl=cleanup_ttl or ttl,
         )
 
+        if clear_pipeline_context:
+            pipeline_context.clear()
+
+    # this shouldn't be used, keeping for backwards compatibility until the entire method is deprecated
     else:
         client = Client(namespace=namespace)
         if isinstance(pipeline, str):
             experiment = client.create_experiment(name=experiment)
             run_result = client.run_pipeline(
                 experiment.id, run, pipeline, params=arguments
             )
         else:
-            conf = new_pipe_meta(artifact_path, ttl, ops)
+            conf = new_pipe_metadata(
+                artifact_path=artifact_path, cleanup_ttl=ttl, op_transformers=ops
+            )
             run_result = client.create_run_from_pipeline_func(
                 pipeline,
                 arguments,
                 run_name=run,
                 experiment_name=experiment,
                 pipeline_conf=conf,
             )
 
-        id = run_result.run_id
-    logger.info(f"Pipeline run id={id}, check UI for progress")
-    return id
+        pipeline_run_id = run_result.run_id
+        logger.info(f"Pipeline run id={id}, check UI for progress")
+
+    return pipeline_run_id
+
+
+def _run_pipeline(
+    pipeline,
+    arguments=None,
+    project=None,
+    experiment=None,
+    run=None,
+    namespace=None,
+    artifact_path=None,
+    ops=None,
+    url=None,
+    cleanup_ttl=None,
+):
+    """remote KubeFlow pipeline execution
+
+    Submit a workflow task to KFP via mlrun API service
+
+    :param pipeline:   KFP pipeline function or path to .yaml/.zip pipeline file
+    :param arguments:  pipeline arguments
+    :param project:    name of project
+    :param experiment: experiment name
+    :param run:        optional, run name
+    :param namespace:  Kubernetes namespace (if not using default)
+    :param url:        optional, url to mlrun API service
+    :param artifact_path:  target location/url for mlrun artifacts
+    :param ops:        additional operators (.apply() to all pipeline functions)
+    :param cleanup_ttl:
+                       pipeline cleanup ttl in secs (time to wait after workflow completion, at which point the
+                       workflow and all its resources are deleted)
+
+    :returns: kubeflow pipeline id
+    """
+    mldb = mlrun.db.get_run_db(url)
+    if mldb.kind != "http":
+        raise ValueError(
+            "run pipeline require access to remote api-service"
+            ", please set the dbpath url"
+        )
+
+    pipeline_run_id = mldb.submit_pipeline(
+        project,
+        pipeline,
+        arguments,
+        experiment=experiment,
+        run=run,
+        namespace=namespace,
+        ops=ops,
+        artifact_path=artifact_path,
+        cleanup_ttl=cleanup_ttl,
+    )
+    logger.info(f"Pipeline run id={pipeline_run_id}, check UI for progress")
+    return pipeline_run_id
 
 
 def wait_for_pipeline_completion(
     run_id,
     timeout=60 * 60,
     expected_statuses: List[str] = None,
     namespace=None,
@@ -1236,766 +1337,209 @@
                 "some runs did not reach terminal state on time"
             )
         runs = running
 
     return completed
 
 
-class ArtifactType(Enum):
-    """
-    Possible artifact types to log using the MLRun `context` decorator.
-    """
-
-    # Types:
-    DATASET = "dataset"
-    DIRECTORY = "directory"
-    FILE = "file"
-    OBJECT = "object"
-    PLOT = "plot"
-    RESULT = "result"
-
-    # Constants:
-    DEFAULT = RESULT
-
-
-# Instruction types:
-LogInstructionType = Union[
-    Tuple[str, ArtifactType],
-    Tuple[str, str],
-    Tuple[str, ArtifactType, Dict[str, Any]],
-    Tuple[str, str, Dict[str, Any]],
-    str,
-    None,
-]
-ParseInstructionType = Dict[str, Type]
-
-
-class InputsParser:
-    """
-    A static class to hold all the common parsing functions - functions for parsing MLRun DataItem to the user desired
-    type.
+def _parse_type_hint(type_hint: Union[Type, str]) -> Type:
     """
+    Parse a given type hint from string to its actual hinted type class object. The string must be one of the following:
 
-    @staticmethod
-    def parse_pandas_dataframe(data_item: DataItem) -> pd.DataFrame:
-        """
-        Parse an MLRun `DataItem` to a `pandas.DataFrame`.
-
-        :param data_item: The `DataItem` to parse.
-
-        :returns: The `DataItem` as a `pandas.DataFrame`.
-        """
-        return data_item.as_df()
+    * Python builtin type - one of ``tuple``, ``list``, ``set``, ``dict`` and ``bytearray``.
+    * Full module import path. An alias is not allowed (if ``import pandas as pd`` is used, the type hint cannot be
+      ``pd.DataFrame`` but ``pandas.DataFrame``).
 
-    @staticmethod
-    def parse_numpy_array(data_item: DataItem) -> np.ndarray:
-        """
-        Parse an MLRun `DataItem` to a `numpy.ndarray`.
-
-        :param data_item: The `DataItem` to parse.
-
-        :returns: The `DataItem` as a `numpy.ndarray`.
-        """
-        return data_item.as_df().to_numpy()
+    The type class on its own (like `DataFrame`) cannot be used as the scope of the decorator is not the same as the
+    handler itself, hence modules and objects that were imported in the handler's scope are not available. This is the
+    same reason import aliases cannot be used as well.
 
-    @staticmethod
-    def parse_dict(data_item: DataItem) -> dict:
-        """
-        Parse an MLRun `DataItem` to a `dict`.
-
-        :param data_item: The `DataItem` to parse.
-
-        :returns: The `DataItem` as a `dict`.
-        """
-        return data_item.as_df().to_dict()
+    If the provided type hint is not a string, it will simply be returned as is.
 
-    @staticmethod
-    def parse_list(data_item: DataItem) -> list:
-        """
-        Parse an MLRun `DataItem` to a `list`.
-
-        :param data_item: The `DataItem` to parse.
-
-        :returns: The `DataItem` as a `list`.
-        """
-        return data_item.as_df().to_numpy().tolist()
+    **Notice**: This method should only run on client side as it dependent on user requirements.
 
-    @staticmethod
-    def parse_object(data_item: DataItem) -> object:
-        """
-        Parse an MLRun `DataItem` to its unpickled object. The pickle file will be downloaded to a local temp
-        directory and then loaded.
-
-        :param data_item: The `DataItem` to parse.
-
-        :returns: The `DataItem` as the original object that was pickled once it was logged.
-        """
-        object_file = data_item.local()
-        with open(object_file, "rb") as pickle_file:
-            obj = cloudpickle.load(pickle_file)
-        return obj
+    :param type_hint: The type hint to parse.
 
+    :return: The hinted type.
 
-class OutputsLogger:
-    """
-    A static class to hold all the common logging functions - functions for logging different objects by artifact type
-    to MLRun.
+    :raise MLRunInvalidArgumentError: In case the type hint is not following the 2 options mentioned above.
     """
+    if not isinstance(type_hint, str):
+        return type_hint
 
-    @staticmethod
-    def log_dataset(
-        ctx: MLClientCtx,
-        obj: Union[pd.DataFrame, np.ndarray, pd.Series, dict, list],
-        key: str,
-        logging_kwargs: dict,
-    ):
-        """
-        Log an object as a dataset. The dataset wil lbe cast to a `pandas.DataFrame`. Supporting casting from
-        `pandas.Series`, `numpy.ndarray`, `dict` and `list`.
-
-        :param ctx:            The MLRun context to log with.
-        :param obj:            The data to log.
-        :param key:            The key of the artifact.
-        :param logging_kwargs: Additional keyword arguments to pass to the `context.log_dataset`
-
-        :raise MLRunInvalidArgumentError: If the type is not supported for being cast to `pandas.DataFrame`.
-        """
-        # Check for the object type:
-        if not isinstance(obj, pd.DataFrame):
-            if isinstance(obj, (np.ndarray, pd.Series, dict, list)):
-                obj = pd.DataFrame(obj)
-            else:
-                raise mlrun.errors.MLRunInvalidArgumentError(
-                    f"The value requested to be logged as a dataset artifact is of type '{type(obj)}' and it "
-                    f"cannot be logged as a dataset. Please parse it in your code into one `numpy.ndarray`, "
-                    f"`pandas.DataFrame`, `pandas.Series`, `dict`, `list` before returning it so we can log it."
-                )
-
-        # Log the DataFrame object as a dataset:
-        ctx.log_dataset(**logging_kwargs, key=key, df=obj)
+    # TODO: Remove once Packager is implemented (it will support typing hints)
+    # If a typing hint is provided, we return a dummy Union type so the parser will skip the data item:
+    if type_hint.startswith("typing."):
+        return Union[int, str]
 
-    @staticmethod
-    def log_directory(
-        ctx: MLClientCtx,
-        obj: Union[str, Path],
-        key: str,
-        logging_kwargs: dict,
+    # Validate the type hint is a valid module path:
+    if not bool(
+        re.fullmatch(r"([a-zA-Z_][a-zA-Z0-9_]*\.)*[a-zA-Z_][a-zA-Z0-9_]*", type_hint)
     ):
-        """
-        Log a directory as a zip file. The zip file will be created at the current working directory. Once logged,
-        it will be deleted.
-
-        :param ctx:            The MLRun context to log with.
-        :param obj:            The directory to zip path.
-        :param key:            The key of the artifact.
-        :param logging_kwargs: Additional keyword arguments to pass to the `context.log_artifact` method.
-
-        :raises MLRunInvalidArgumentError: In case the given path is not of a directory or do not exist.
-        """
-        # In case it is a `pathlib` path, parse to str:
-        obj = str(obj)
-
-        # Verify the path is of an existing directory:
-        if not os.path.isdir(obj):
-            raise mlrun.errors.MLRunInvalidArgumentError(
-                f"The given path is not a directory: '{obj}'"
-            )
-        if not os.path.exists(obj):
-            raise mlrun.errors.MLRunInvalidArgumentError(
-                f"The given directory path do not exist: '{obj}'"
-            )
-
-        # Zip the directory:
-        directory_zip_path = shutil.make_archive(
-            base_name=key,
-            format="zip",
-            root_dir=os.path.abspath(obj),
+        raise mlrun.errors.MLRunInvalidArgumentError(
+            f"Invalid type hint. An input type hint must be a valid python class name or its module import path. For "
+            f"example: 'list', 'pandas.DataFrame', 'numpy.ndarray', 'sklearn.linear_model.LinearRegression'. Type hint "
+            f"given: '{type_hint}'."
         )
 
-        # Log the zip file:
-        ctx.log_artifact(**logging_kwargs, item=key, local_path=directory_zip_path)
-
-        # Delete the zip file:
-        os.remove(directory_zip_path)
-
-    @staticmethod
-    def log_file(
-        ctx: MLClientCtx,
-        obj: Union[str, Path],
-        key: str,
-        logging_kwargs: dict,
-    ):
-        """
-        Log a file to MLRun.
-
-        :param ctx:            The MLRun context to log with.
-        :param obj:            The path of the file to log.
-        :param key:            The key of the artifact.
-        :param logging_kwargs: Additional keyword arguments to pass to the `context.log_artifact` method.
-
-        :raises MLRunInvalidArgumentError: In case the given path is not of a file or do not exist.
-        """
-        # In case it is a `pathlib` path, parse to str:
-        obj = str(obj)
-
-        # Verify the path is of an existing directory:
-        if not os.path.isfile(obj):
-            raise mlrun.errors.MLRunInvalidArgumentError(
-                f"The given path is not a file: '{obj}'"
-            )
-        if not os.path.exists(obj):
-            raise mlrun.errors.MLRunInvalidArgumentError(
-                f"The given directory path do not exist: '{obj}'"
-            )
-
-        # Log the zip file:
-        ctx.log_artifact(**logging_kwargs, item=key, local_path=os.path.abspath(obj))
-
-    @staticmethod
-    def log_object(ctx: MLClientCtx, obj, key: str, logging_kwargs: dict):
-        """
-        Log an object as a pickle.
-
-        :param ctx:            The MLRun context to log with.
-        :param obj:            The object to log.
-        :param key:            The key of the artifact.
-        :param logging_kwargs: Additional keyword arguments to pass to the `context.log_artifact` method.
-        """
-        ctx.log_artifact(
-            **logging_kwargs,
-            item=key,
-            body=obj if isinstance(obj, (bytes, bytearray)) else cloudpickle.dumps(obj),
-            format="pkl",
+    # Look for a builtin type (rest of the builtin types like `int`, `str`, `float` should be treated as results, hence
+    # not given as an input to an MLRun function, but as a parameter):
+    builtin_types = {
+        tuple.__name__: tuple,
+        list.__name__: list,
+        set.__name__: set,
+        dict.__name__: dict,
+        bytearray.__name__: bytearray,
+    }
+    if type_hint in builtin_types:
+        return builtin_types[type_hint]
+
+    # If it's not a builtin, its should have a full module path:
+    if "." not in type_hint:
+        raise mlrun.errors.MLRunInvalidArgumentError(
+            f"MLRun tried to get the type hint '{type_hint}' but it can't as it is not a valid builtin Python type "
+            f"(one of {', '.join(list(builtin_types.keys()))}). Pay attention using only the type as string is not "
+            f"allowed as the handler's scope is different then MLRun's. To properly give a type hint, please specify "
+            f"the full module path. For example: do not use `DataFrame`, use `pandas.DataFrame`."
         )
 
-    @staticmethod
-    def log_plot(ctx: MLClientCtx, obj, key: str, logging_kwargs: dict):
-        """
-        Log an object as a plot. Currently, supporting plots produced by one the following modules: `matplotlib`,
-        `seaborn`, `plotly` and `bokeh`.
-
-        :param ctx:            The MLRun context to log with.
-        :param obj:            The plot to log.
-        :param key:            The key of the artifact.
-        :param logging_kwargs: Additional keyword arguments to pass to the `context.log_artifact`.
-
-        :raise MLRunInvalidArgumentError: If the object type is not supported (meaning the plot was not produced by
-                                          one of the supported modules).
-        """
-        # Create the plot artifact according to the module produced the object:
-        artifact = None
-
-        # `matplotlib` and `seaborn`:
-        try:
-            import matplotlib.pyplot as plt
-
-            from mlrun.artifacts import PlotArtifact
-
-            # Get the figure:
-            figure = None
-            if isinstance(obj, plt.Figure):
-                figure = obj
-            elif isinstance(obj, plt.Axes):
-                if hasattr(obj, "get_figure"):
-                    figure = obj.get_figure()
-                elif hasattr(obj, "figure"):
-                    figure = obj.figure
-                elif hasattr(obj, "fig"):
-                    figure = obj.fig
-
-            # Create the artifact:
-            if figure is not None:
-                artifact = PlotArtifact(key=key, body=figure)
-        except ModuleNotFoundError:
-            pass
-
-        # `plotly`:
-        if artifact is None:
-            try:
-                import plotly
-
-                from mlrun.artifacts import PlotlyArtifact
-
-                if isinstance(obj, plotly.graph_objs.Figure):
-                    artifact = PlotlyArtifact(key=key, figure=obj)
-            except ModuleNotFoundError:
-                pass
-
-        # `bokeh`:
-        if artifact is None:
-            try:
-                import bokeh.plotting as bokeh_plt
-
-                from mlrun.artifacts import BokehArtifact
-
-                if isinstance(obj, bokeh_plt.Figure):
-                    artifact = BokehArtifact(key=key, figure=obj)
-            except ModuleNotFoundError:
-                pass
-            except ImportError:
-                logger.warn(
-                    "Bokeh installation is ignored. If needed, "
-                    "make sure you have the required version with `pip install mlrun[bokeh]`"
-                )
-
-        # Log the artifact:
-        if artifact is None:
-            raise mlrun.errors.MLRunInvalidArgumentError(
-                f"The given plot is of type `{type(obj)}`. We currently support logging plots produced by one of "
-                f"the following modules: `matplotlib`, `seaborn`, `plotly` and `bokeh`. You may try to save the "
-                f"plot to file and log it as a file instead."
-            )
-        ctx.log_artifact(**logging_kwargs, item=artifact)
-
-    @staticmethod
-    def log_result(
-        ctx: MLClientCtx,
-        obj: Union[int, float, str, list, tuple, dict, np.ndarray],
-        key: str,
-        logging_kwargs: dict,
-    ):
-        """
-        Log an object as a result. The objects value will be cast to a serializable version of itself. Supporting:
-        int, float, str, list, tuple, dict, numpy.ndarray
-
-        :param ctx:            The MLRun context to log with.
-        :param obj:            The value to log.
-        :param key:            The key of the artifact.
-        :param logging_kwargs: Additional keyword arguments to pass to the `context.log_result` method.
-        """
-        ctx.log_result(**logging_kwargs, key=key, value=obj)
-
-
-class ContextHandler:
-    """
-    Private class for handling an MLRun context of a function that is wrapped in MLRun's `handler` decorator.
-
-    The context handler have 3 duties:
-      1. Check if the user used MLRun to run the wrapped function and if so, get the MLRun context.
-      2. Parse the user's inputs (MLRun `DataItem`) to the function.
-      3. Log the function's outputs to MLRun.
-
-    The context handler use dictionaries to map objects to their logging / parsing function. The maps can be edited
-    using the relevant `update_X` class method. If needed to add additional artifacts types, the `ArtifactType` class
-    can be inherited and replaced as well using the `update_artifact_type_class` class method.
-    """
-
-    # The artifact type enum class to use:
-    _ARTIFACT_TYPE_CLASS = ArtifactType
-    # The map to use to get default artifact types of objects:
-    _DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP = None
-    # The map to use for logging an object by its type:
-    _OUTPUTS_LOGGING_MAP = None
-    # The map to use for parsing an object by its type:
-    _INPUTS_PARSING_MAP = None
-
-    @classmethod
-    def update_artifact_type_class(cls, artifact_type_class: Type[ArtifactType]):
-        """
-        Update the artifact type enum class that the handler will use to specify new artifact types to log and parse.
-
-        :param artifact_type_class: An enum inheriting from the `ArtifactType` enum.
-        """
-        cls._ARTIFACT_TYPE_CLASS = artifact_type_class
-
-    @classmethod
-    def update_default_objects_artifact_types_map(
-        cls, updates: Dict[type, ArtifactType]
-    ):
-        """
-        Enrich the default objects artifact types map with new objects types to support.
-
-        :param updates: New objects types to artifact types to support.
-        """
-        if cls._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP is None:
-            cls._init_default_objects_artifact_types_map()
-        cls._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP.update(updates)
-
-    @classmethod
-    def update_outputs_logging_map(
-        cls,
-        updates: Dict[ArtifactType, Callable[[MLClientCtx, Any, str, dict], None]],
-    ):
-        """
-        Enrich the outputs logging map with new artifact types to support. The outputs logging map is a dictionary of
-        artifact type enum as key, and a function that will handle the given output. The function must accept 4 keyword
-        arguments
-
-        * ctx: `mlrun.MLClientCtx` - The MLRun context to log with.
-        * obj: `Any` - The value / object to log.
-        * key: `str` - The key of the artifact.
-        * logging_kwargs: `dict` - Keyword arguments the user can pass in the instructions tuple.
-
-        :param updates: New artifact types to support - a dictionary of artifact type enum as key, and a function that
-                        will handle the given output to update the current map.
-        """
-        if cls._OUTPUTS_LOGGING_MAP is None:
-            cls._init_outputs_logging_map()
-        cls._OUTPUTS_LOGGING_MAP.update(updates)
-
-    @classmethod
-    def update_inputs_parsing_map(cls, updates: Dict[type, Callable[[DataItem], Any]]):
-        """
-        Enrich the inputs parsing map with new objects to support. The inputs parsing map is a dictionary of object
-        types as key, and a function that will handle the given input. The function must accept 1 keyword argument
-        (data_item: `mlrun.DataItem`) and return the relevant parsed object.
-
-        :param updates: New object types to support - a dictionary of artifact type enum as key, and a function that
-                        will handle the given input to update the current map.
-        """
-        if cls._INPUTS_PARSING_MAP is None:
-            cls._init_inputs_parsing_map()
-        cls._INPUTS_PARSING_MAP.update(updates)
-
-    def __init__(self):
-        """
-        Initialize a context handler.
-        """
-        # Initialize the maps:
-        if self._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP is None:
-            self._init_default_objects_artifact_types_map()
-        if self._OUTPUTS_LOGGING_MAP is None:
-            self._init_outputs_logging_map()
-        if self._INPUTS_PARSING_MAP is None:
-            self._init_inputs_parsing_map()
-
-        # Set up a variable to hold the context:
-        self._context: MLClientCtx = None
-
-    def look_for_context(self, args: tuple, kwargs: dict):
-        """
-        Look for an MLRun context (`mlrun.MLClientCtx`). The handler will look for a context in the given order:
-          1. The given arguments.
-          2. The given keyword arguments.
-          3. If an MLRun RunTime was used the context will be located via the `mlrun.get_or_create_ctx` method.
-
-        :param args:   The arguments tuple passed to the function.
-        :param kwargs: The keyword arguments dictionary passed to the function.
-        """
-        # Search in the given arguments:
-        for argument in args:
-            if isinstance(argument, MLClientCtx):
-                self._context = argument
-                return
-
-        # Search in the given keyword arguments:
-        for argument_name, argument_value in kwargs.items():
-            if isinstance(argument_value, MLClientCtx):
-                self._context = argument_value
-                return
-
-        # Search if the function was triggered from an MLRun RunTime object by looking at the call stack:
-        # Index 0: the current frame.
-        # Index 1: the decorator's frame.
-        # Index 2-...: If it is from mlrun.runtimes we can be sure it ran via MLRun, otherwise not.
-        for callstack_frame in inspect.getouterframes(inspect.currentframe()):
-            if os.path.join("mlrun", "runtimes", "") in callstack_frame.filename:
-                self._context = mlrun.get_or_create_ctx("context")
-                break
-
-    def is_context_available(self) -> bool:
-        """
-        Check if a context was found by the method `look_for_context`.
-
-        :returns: True if a context was found and False otherwise.
-        """
-        return self._context is not None
-
-    def parse_inputs(
-        self, args: tuple, kwargs: dict, expected_arguments_types: OrderedDict
-    ) -> tuple:
-        """
-        Parse the given arguments and keyword arguments data items to the expected types.
-
-        :param args:                     The arguments tuple passed to the function.
-        :param kwargs:                   The keyword arguments dictionary passed to the function.
-        :param expected_arguments_types: An ordered dictionary of the expected types of arguments.
-
-        :returns: The parsed args (kwargs are parsed inplace).
-        """
-        # Parse the arguments:
-        parsed_args = []
-        expected_arguments_keys = list(expected_arguments_types.keys())
-        for i, argument in enumerate(args):
-            if (
-                isinstance(argument, mlrun.DataItem)
-                and expected_arguments_types[expected_arguments_keys[i]]
-                != inspect._empty
-            ):
-                parsed_args.append(
-                    self._parse_input(
-                        data_item=argument,
-                        expected_type=expected_arguments_types[
-                            expected_arguments_keys[i]
-                        ],
-                    )
-                )
-                continue
-            parsed_args.append(argument)
-        parsed_args = tuple(parsed_args)  # `args` is expected to be a tuple.
-
-        # Parse the keyword arguments:
-        for key in kwargs.keys():
-            if isinstance(kwargs[key], mlrun.DataItem) and expected_arguments_types[
-                key
-            ] not in [
-                inspect._empty,
-                mlrun.DataItem,
-            ]:
-                kwargs[key] = self._parse_input(
-                    data_item=kwargs[key], expected_type=expected_arguments_types[key]
+    # Import the module to receive the hinted type:
+    try:
+        # Get the module path and the type class (If we'll wish to support inner classes, the `rsplit` won't work):
+        module_path, type_hint = type_hint.rsplit(".", 1)
+        # Replace alias if needed (alias assumed to be imported already, hence we look in globals):
+        # For example:
+        # If in handler scope there was `import A.B.C as abc` and user gave a type hint "abc.Something" then:
+        # `module_path[0]` will be equal to "abc". Then, because it is an alias, it will appear in the globals, so we'll
+        # replace the alias with the full module name in order to import the module.
+        module_path = module_path.split(".")
+        if module_path[0] in globals():
+            module_path[0] = globals()[module_path[0]].__name__
+        module_path = ".".join(module_path)
+        # Import the module:
+        module = importlib.import_module(module_path)
+        # Get the class type from the module:
+        type_hint = getattr(module, type_hint)
+    except ModuleNotFoundError as module_not_found_error:
+        # May be raised from `importlib.import_module` in case the module does not exist.
+        raise mlrun.errors.MLRunInvalidArgumentError(
+            f"MLRun tried to get the type hint '{type_hint}' but the module '{module_path}' cannot be imported. "
+            f"Keep in mind that using alias in the module path (meaning: import module as alias) is not allowed. "
+            f"If the module path is correct, please make sure the module package is installed in the python "
+            f"interpreter."
+        ) from module_not_found_error
+    except AttributeError as attribute_error:
+        # May be raised from `getattr(module, type_hint)` in case the class type cannot be imported directly from the
+        # imported module.
+        raise mlrun.errors.MLRunInvalidArgumentError(
+            f"MLRun tried to get the type hint '{type_hint}' from the module '{module.__name__}' but it seems it "
+            f"doesn't exist. Make sure the class can be imported from the module with the exact module path you "
+            f"passed. Notice inner classes (a class inside of a class) are not supported."
+        ) from attribute_error
+
+    return type_hint
+
+
+def _parse_log_hint(
+    log_hint: Union[Dict[str, str], str, None]
+) -> Union[Dict[str, str], None]:
+    """
+    Parse a given log hint from string to a logging configuration dictionary. The string will be read as the artifact
+    key ('key' in the dictionary) and if the string have a single colon, the following structure is assumed:
+    "<artifact_key> : <artifact_type>". The artifact type must be on of the values of `ArtifactType`'s enum.
+
+    If a logging configuration dictionary is received, it will be validated to have a key field and valid artifact type
+    value.
+
+    None will be returned as None.
+
+    :param log_hint: The log hint to parse.
+
+    :return: The hinted logging configuration.
+
+    :raise MLRunInvalidArgumentError: In case the log hint is not following the string structure, the artifact type is
+                                      not valid or the dictionary is missing the key field.
+    """
+    # Check for None value:
+    if log_hint is None:
+        return None
+
+    # If the log hint was provided as a string, construct a dictionary out of it:
+    if isinstance(log_hint, str):
+        # Check if only key is given:
+        if ":" not in log_hint:
+            log_hint = {"key": log_hint}
+        # Check for valid "<key> : <artifact type>" pattern:
+        else:
+            if log_hint.count(":") > 1:
+                raise mlrun.errors.MLRunInvalidArgumentError(
+                    f"Incorrect log hint pattern. Output keys can have only a single ':' in them to specify the "
+                    f"desired artifact type the returned value will be logged as: '<artifact_key> : <artifact_type>', "
+                    f"but given: {log_hint}"
                 )
+            # Split into key and type:
+            key, artifact_type = log_hint.replace(" ", "").split(":")
+            log_hint = {"key": key, "artifact_type": artifact_type}
+
+    # TODO: Replace with constants keys once mlrun.package is implemented.
+    # Validate the log hint dictionary has the mandatory key:
+    if "key" not in log_hint:
+        raise mlrun.errors.MLRunInvalidArgumentError(
+            f"An output log hint dictionary must include the 'key' - the artifact key (it's name). The following "
+            f"log hint is missing the key: {log_hint}."
+        )
 
-        return parsed_args
-
-    def log_outputs(
-        self,
-        outputs: list,
-        logging_instructions: List[LogInstructionType],
-    ):
-        """
-        Log the given outputs as artifacts with the stored context.
-
-        :param outputs:              List of outputs to log.
-        :param logging_instructions: List of logging instructions to use.
-        """
-        for obj, instructions in zip(outputs, logging_instructions):
-            # Check if needed to log (not None):
-            if instructions is None:
-                continue
-            # Parse the instructions:
-            artifact_type = self._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP.get(
-                type(obj), self._ARTIFACT_TYPE_CLASS.DEFAULT
-            ).value
-            key = None
-            logging_kwargs = {}
-            if isinstance(instructions, str):
-                # A string with a template of "{key}" or "{key}: {artifact_type}":
-                if ":" in instructions:
-                    key, artifact_type = instructions.split(":", 1)
-                    # Remove spaces after ':':
-                    artifact_type = artifact_type.lstrip(" ")
-                else:
-                    key = instructions
-            elif isinstance(instructions, tuple):
-                # A tuple of [0] - key, [1] - artifact type, [2] - context log kwargs:
-                key = instructions[0]
-                artifact_type = instructions[1]
-                if len(instructions) > 2:
-                    logging_kwargs = instructions[2]
-            # Check if the object to log is None (None values are only logged if the artifact type is Result):
-            if obj is None and artifact_type != ArtifactType.RESULT.value:
-                continue
-            # Log:
-            self._log_output(
-                obj=obj,
-                artifact_type=artifact_type,
-                key=key,
-                logging_kwargs=logging_kwargs,
-            )
-
-    def set_labels(self, labels: Dict[str, str]):
-        """
-        Set the given labels with the stored context.
-
-        :param labels: The labels to set.
-        """
-        for key, value in labels.items():
-            self._context.set_label(key=key, value=value)
-
-    @classmethod
-    def _init_default_objects_artifact_types_map(cls):
-        """
-        Initialize the default objects artifact types map with the basic classes supported by MLRun. In addition, it
-        will try to support further common packages that are not required in MLRun.
-        """
-        # Initialize the map with the default classes:
-        cls._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP = {
-            pd.DataFrame: ArtifactType.DATASET,
-            pd.Series: ArtifactType.DATASET,
-            np.ndarray: ArtifactType.DATASET,
-            dict: ArtifactType.RESULT,
-            list: ArtifactType.RESULT,
-            tuple: ArtifactType.RESULT,
-            str: ArtifactType.RESULT,
-            int: ArtifactType.RESULT,
-            float: ArtifactType.RESULT,
-            bytes: ArtifactType.OBJECT,
-            bytearray: ArtifactType.OBJECT,
-        }
-
-        # Try to enrich it with further classes according ot the user's environment:
-        try:
-            import matplotlib.pyplot as plt
-
-            cls._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP[plt.Figure] = ArtifactType.PLOT
-            cls._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP[plt.Axes] = ArtifactType.PLOT
-        except ModuleNotFoundError:
-            pass
-        try:
-            import plotly
-
-            cls._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP[
-                plotly.graph_objs.Figure
-            ] = ArtifactType.PLOT
-        except ModuleNotFoundError:
-            pass
-        try:
-            import bokeh.plotting as bokeh_plt
-
-            cls._DEFAULT_OBJECTS_ARTIFACT_TYPES_MAP[
-                bokeh_plt.Figure
-            ] = ArtifactType.PLOT
-        except ModuleNotFoundError:
-            pass
-        except ImportError:
-            logger.warn(
-                "Bokeh installation is ignored. If needed, "
-                "make sure you have the required version with `pip install mlrun[bokeh]`"
-            )
-
-    @classmethod
-    def _init_outputs_logging_map(cls):
-        """
-        Initialize the outputs logging map for the basic artifact types supported by MLRun.
-        """
-        cls._OUTPUTS_LOGGING_MAP = {
-            ArtifactType.DATASET: OutputsLogger.log_dataset,
-            ArtifactType.DIRECTORY: OutputsLogger.log_directory,
-            ArtifactType.FILE: OutputsLogger.log_file,
-            ArtifactType.OBJECT: OutputsLogger.log_object,
-            ArtifactType.PLOT: OutputsLogger.log_plot,
-            ArtifactType.RESULT: OutputsLogger.log_result,
-        }
-
-    @classmethod
-    def _init_inputs_parsing_map(cls):
-        """
-        Initialize the inputs parsing map with the basic classes supported by MLRun.
-        """
-        cls._INPUTS_PARSING_MAP = {
-            pd.DataFrame: InputsParser.parse_pandas_dataframe,
-            np.ndarray: InputsParser.parse_numpy_array,
-            dict: InputsParser.parse_dict,
-            list: InputsParser.parse_list,
-            object: InputsParser.parse_object,
-        }
-
-    def _parse_input(self, data_item: DataItem, expected_type: type) -> Any:
-        """
-        Parse the given data frame to the expected type. By default, it will be parsed to an object (will be treated as
-        a pickle).
-
-        :param data_item:     The data item to parse.
-        :param expected_type: THe expected type to parse to.
-
-        :returns: The parsed data item.
-
-        :raises MLRunRuntimeError: If an error was raised during the parsing function.
-        """
-        try:
-            return self._INPUTS_PARSING_MAP.get(
-                expected_type, self._INPUTS_PARSING_MAP[object]
-            )(data_item=data_item)
-        except Exception as exception:
-            raise mlrun.errors.MLRunRuntimeError(
-                f"MLRun tried to parse a `DataItem` of type '{expected_type}' but failed. Be sure the item was "
-                f"logged correctly - as the type you are trying to parse it back to. In general, python objects should "
-                f"be logged as pickles."
-            ) from exception
-
-    def _log_output(
-        self,
-        obj,
-        artifact_type: Union[ArtifactType, str],
-        key: str,
-        logging_kwargs: Dict[str, Any],
-    ):
-        """
-        Log the given object to MLRun as the given artifact type with the provided key. The key can be part of a
-        logging keyword arguments to pass to the relevant context logging function.
-
-        :param obj:           The object to log.
-        :param artifact_type: The artifact type to log the object as.
-        :param key:           The key (name) of the artifact or a logging kwargs to use when logging the artifact.
-
-        :raises MLRunInvalidArgumentError: If a key was provided in the logging kwargs.
-        :raises MLRunRuntimeError:         If an error was raised during the logging function.
-        """
-        # Get the artifact type (will also verify the artifact type is valid):
-        artifact_type = self._ARTIFACT_TYPE_CLASS(artifact_type)
-
-        # Check if 'key' or 'item' were given the logging kwargs:
-        if "key" in logging_kwargs or "item" in logging_kwargs:
+    # Validate the artifact type is valid:
+    if "artifact_type" in log_hint:
+        valid_artifact_types = [t.value for t in ArtifactType.__members__.values()]
+        if log_hint["artifact_type"] not in valid_artifact_types:
             raise mlrun.errors.MLRunInvalidArgumentError(
-                "When passing logging keyword arguments, both 'key' and 'item' (according to the context method) "
-                "cannot be added to the dictionary as the key is given on its own."
+                f"The following artifact type '{log_hint['artifact_type']}' is not a valid `ArtifactType`. "
+                f"Please select one of the following: {','.join(valid_artifact_types)}"
             )
 
-        # Use the logging map to log the object:
-        try:
-            self._OUTPUTS_LOGGING_MAP[artifact_type](
-                ctx=self._context,
-                obj=obj,
-                key=key,
-                logging_kwargs=logging_kwargs,
-            )
-        except Exception as exception:
-            raise mlrun.errors.MLRunRuntimeError(
-                f"MLRun tried to log '{key}' as '{artifact_type.value}' but failed. If you didn't provide the artifact "
-                f"type and the default one does not fit, try to select the correct type from the enum `ArtifactType`."
-            ) from exception
+    return log_hint
 
 
 def handler(
     labels: Dict[str, str] = None,
-    outputs: List[LogInstructionType] = None,
-    inputs: Union[bool, ParseInstructionType] = True,
+    outputs: List[Union[str, Dict[str, str]]] = None,
+    inputs: Union[bool, Dict[str, Union[str, Type]]] = True,
 ):
     """
     MLRun's handler is a decorator to wrap a function and enable setting labels, automatic `mlrun.DataItem` parsing and
     outputs logging.
 
     :param labels:  Labels to add to the run. Expecting a dictionary with the labels names as keys. Default: None.
     :param outputs: Logging configurations for the function's returned values. Expecting a list of tuples and None
                     values:
 
                     * str - A string in the format of '{key}:{artifact_type}'. If a string was given without ':' it will
-                            indicate the key and the artifact type will be according to the returned value
-                            type.
-                    * tuple - A tuple of:
-
-                      * [0]: str - The key (name) of the artifact to use for the logged output.
-                      * [1]: Union[`ArtifactType`, str] = "result" - An `ArtifactType` enum or an equivalent
-                        string, that indicates how to log the returned value. The artifact types can be one of:
-
-                        * DATASET = "dataset"
-                        * DIRECTORY = "directory"
-                        * FILE = "file"
-                        * OBJECT = "object"
-                        * PLOT = "plot"
-                        * RESULT = "result".
-
-                      * [2]: Optional[Dict[str, Any]] - A keyword arguments dictionary with the properties to pass to
-                        the relevant logging function (one of `context.log_artifact`, `context.log_result`,
-                        `context.log_dataset`).
+                      indicate the key and the artifact type will be according to the returned value type. The artifact
+                      types can be one of: "dataset", "directory", "file", "object", "plot" and "result".
+
+                    * Dict[str, str] - A dictionary of logging configuration. the key 'key' is mandatory for the logged
+                      artifact key.
 
                     * None - Do not log the output.
 
                     The list length must be equal to the total amount of returned values from the function. Default is
                     None - meaning no outputs will be logged.
 
     :param inputs: Parsing configurations for the arguments passed as inputs via the `run` method of an MLRun function.
                    Can be passed as a boolean value or a dictionary:
 
                    * True - Parse all found inputs to the assigned type hint in the function's signature. If there is no
-                            type hint assigned, the value will remain an `mlrun.DataItem`.
+                     type hint assigned, the value will remain an `mlrun.DataItem`.
                    * False - Do not parse inputs, leaving the inputs as `mlrun.DataItem`.
-                   * Dict[str, Type] - A dictionary with argument name as key and the expected type to parse the
-                                       `mlrun.DataItem` to.
+                   * Dict[str, Union[Type, str]] - A dictionary with argument name as key and the expected type to parse
+                     the `mlrun.DataItem` to. The expected type can be a string as well, idicating the full module path.
+
+                   **Notice**: Type hints from the `typing` module (e.g. `typing.Optional`, `typing.Union`,
+                   `typing.List` etc.) are currently not supported but will be in the future.
 
                    Default: True.
 
     Example::
 
             import mlrun
 
@@ -2017,52 +1561,62 @@
 
     def decorator(func: Callable):
         def wrapper(*args: tuple, **kwargs: dict):
             nonlocal labels
             nonlocal outputs
             nonlocal inputs
 
-            # Set default `inputs` - inspect the full signature and add the user's input on top of it::
-            func_signature = inspect.signature(func)
+            # Set default `inputs` - inspect the full signature and add the user's input on top of it:
             if inputs:
+                # Get the available parameters type hints from the function's signature:
+                func_signature = inspect.signature(func)
                 parameters = OrderedDict(
                     {
                         parameter.name: parameter.annotation
                         for parameter in func_signature.parameters.values()
                     }
                 )
+                # If user input is given, add it on top of the collected defaults (from signature), strings type hints
+                # will be parsed to their actual types:
                 if isinstance(inputs, dict):
-                    parameters.update(**inputs)
+                    parameters.update(
+                        {
+                            parameter_name: _parse_type_hint(type_hint=type_hint)
+                            for parameter_name, type_hint in inputs.items()
+                        }
+                    )
                 inputs = parameters
 
             # Create a context handler and look for a context:
             context_handler = ContextHandler()
             context_handler.look_for_context(args=args, kwargs=kwargs)
 
             # If an MLRun context is found, parse arguments pre-run (kwargs are parsed inplace):
             if context_handler.is_context_available() and inputs:
                 args = context_handler.parse_inputs(
-                    args=args, kwargs=kwargs, expected_arguments_types=inputs
+                    args=args, kwargs=kwargs, type_hints=inputs
                 )
 
             # Call the original function and get the returning values:
             func_outputs = func(*args, **kwargs)
 
             # If an MLRun context is found, set the given labels and log the returning values to MLRun via the context:
             if context_handler.is_context_available():
                 if labels:
                     context_handler.set_labels(labels=labels)
                 if outputs:
                     context_handler.log_outputs(
                         outputs=func_outputs
                         if isinstance(func_outputs, tuple)
                         else [func_outputs],
-                        logging_instructions=outputs,
+                        log_hints=[
+                            _parse_log_hint(log_hint=log_hint) for log_hint in outputs
+                        ],
                     )
-                return  # Do not return any values as the function ran via MLRun.
+                    return  # Do not return any values as the returning values were logged to MLRun.
             return func_outputs
 
         # Make sure to pass the wrapped function's signature (argument list, type hints and doc strings) to the wrapper:
         wrapper = functools.wraps(func)(wrapper)
 
         return wrapper
```

## mlrun/secrets.py

```diff
@@ -149,14 +149,15 @@
         return None
 
 
 def get_secret_or_env(
     key: str,
     secret_provider: Union[Dict, SecretsStore, Callable, None] = None,
     default: Optional[str] = None,
+    prefix: Optional[str] = None,
 ) -> str:
     """Retrieve value of a secret, either from a user-provided secret store, or from environment variables.
     The function will retrieve a secret value, attempting to find it according to the following order:
 
     1. If `secret_provider` was provided, will attempt to retrieve the secret from it
     2. If an MLRun `SecretsStore` was provided, query it for the secret key
     3. An environment variable with the same key
@@ -175,16 +176,19 @@
 
         secret = get_secret_or_env("KEY1", secret_provider=my_secret_provider, default="TOO-MANY-SECRETS")
 
     :param key: Secret key to look for
     :param secret_provider: Dictionary, callable or `SecretsStore` to extract the secret value from. If using a
         callable, it must use the signature `callable(key:str)`
     :param default: Default value to return if secret was not available through any other means
+    :param prefix: When passed, the prefix is added to the secret key.
     :return: The secret value if found in any of the sources, or `default` if provided.
     """
+    if prefix:
+        key = f"{prefix}_{key}"
 
     value = None
     if secret_provider:
         if isinstance(secret_provider, (Dict, SecretsStore)):
             value = secret_provider.get(key)
         else:
             value = secret_provider(key)
```

## mlrun/api/main.py

```diff
@@ -10,32 +10,35 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import asyncio
 import concurrent.futures
-import time
+import datetime
 import traceback
-import uuid
+import typing
 
 import fastapi
 import fastapi.concurrency
+import sqlalchemy.orm
 import uvicorn
-import uvicorn.protocols.utils
 from fastapi.exception_handlers import http_exception_handler
 
 import mlrun.api.schemas
 import mlrun.api.utils.clients.chief
+import mlrun.api.utils.clients.log_collector
 import mlrun.errors
+import mlrun.lists
 import mlrun.utils
 import mlrun.utils.version
 from mlrun.api.api.api import api_router
 from mlrun.api.db.session import close_session, create_session
 from mlrun.api.initial_data import init_data
+from mlrun.api.middlewares import init_middlewares
 from mlrun.api.utils.periodic import (
     cancel_all_periodic_functions,
     cancel_periodic_function,
     run_function_periodically,
 )
 from mlrun.api.utils.singletons.db import get_db, initialize_db
 from mlrun.api.utils.singletons.logs_dir import initialize_logs_dir
@@ -43,15 +46,15 @@
     get_project_member,
     initialize_project_member,
 )
 from mlrun.api.utils.singletons.scheduler import get_scheduler, initialize_scheduler
 from mlrun.config import config
 from mlrun.errors import err_to_str
 from mlrun.k8s_utils import get_k8s_helper
-from mlrun.runtimes import RuntimeKinds, get_runtime_handler
+from mlrun.runtimes import RuntimeClassMode, RuntimeKinds, get_runtime_handler
 from mlrun.utils import logger
 
 API_PREFIX = "/api"
 BASE_VERSIONED_API_PREFIX = f"{API_PREFIX}/v1"
 
 
 app = fastapi.FastAPI(
@@ -64,29 +67,29 @@
     docs_url=f"{BASE_VERSIONED_API_PREFIX}/docs",
     redoc_url=f"{BASE_VERSIONED_API_PREFIX}/redoc",
     default_response_class=fastapi.responses.ORJSONResponse,
 )
 app.include_router(api_router, prefix=BASE_VERSIONED_API_PREFIX)
 # This is for backward compatibility, that is why we still leave it here but not include it in the schema
 # so new users won't use the old un-versioned api
-# TODO: remove when 0.9.x versions are no longer relevant
+# TODO: remove in 1.4.0
 app.include_router(api_router, prefix=API_PREFIX, include_in_schema=False)
 
+init_middlewares(app)
+
 
 @app.exception_handler(Exception)
 async def generic_error_handler(request: fastapi.Request, exc: Exception):
     error_message = repr(exc)
     return await fastapi.exception_handlers.http_exception_handler(
         # we have no specific knowledge on what was the exception and what status code fits so we simply use 500
         # This handler is mainly to put the error message in the right place in the body so the client will be able to
         # show it
-        # TODO: 0.6.6 is the last version expecting the error details to be under reason, when it's no longer a relevant
-        #  version can be changed to detail=error_message
         request,
-        fastapi.HTTPException(status_code=500, detail={"reason": error_message}),
+        fastapi.HTTPException(status_code=500, detail=error_message),
     )
 
 
 @app.exception_handler(mlrun.errors.MLRunHTTPStatusError)
 async def http_status_error_handler(
     request: fastapi.Request, exc: mlrun.errors.MLRunHTTPStatusError
 ):
@@ -94,89 +97,20 @@
     error_message = repr(exc)
     logger.warning(
         "Request handling returned error status",
         error_message=error_message,
         status_code=status_code,
         traceback=traceback.format_exc(),
     )
-    # TODO: 0.6.6 is the last version expecting the error details to be under reason, when it's no longer a relevant
-    #  version can be changed to detail=error_message
     return await http_exception_handler(
         request,
-        fastapi.HTTPException(
-            status_code=status_code, detail={"reason": error_message}
-        ),
+        fastapi.HTTPException(status_code=status_code, detail=error_message),
     )
 
 
-def get_client_address(scope):
-    # uvicorn expects this to be a tuple while starlette test client sets it to be a list
-    if isinstance(scope.get("client"), list):
-        scope["client"] = tuple(scope.get("client"))
-    return uvicorn.protocols.utils.get_client_addr(scope)
-
-
-@app.middleware("http")
-async def log_request_response(request: fastapi.Request, call_next):
-    request_id = str(uuid.uuid4())
-    silent_logging_paths = [
-        "healthz",
-    ]
-    path_with_query_string = uvicorn.protocols.utils.get_path_with_query_string(
-        request.scope
-    )
-    start_time = time.perf_counter_ns()
-    if not any(
-        silent_logging_path in path_with_query_string
-        for silent_logging_path in silent_logging_paths
-    ):
-        logger.debug(
-            "Received request",
-            headers=request.headers,
-            method=request.method,
-            client_address=get_client_address(request.scope),
-            http_version=request.scope["http_version"],
-            request_id=request_id,
-            uri=path_with_query_string,
-        )
-    try:
-        response = await call_next(request)
-    except Exception as exc:
-        logger.warning(
-            "Request handling failed. Sending response",
-            # User middleware (like this one) runs after the exception handling middleware, the only thing running after
-            # it is starletter's ServerErrorMiddleware which is responsible for catching any un-handled exception
-            # and transforming it to 500 response. therefore we can statically assign status code to 500
-            status_code=500,
-            request_id=request_id,
-            uri=path_with_query_string,
-            method=request.method,
-            exc=exc,
-            traceback=traceback.format_exc(),
-        )
-        raise
-    else:
-        # convert from nanoseconds to milliseconds
-        elapsed_time_in_ms = (time.perf_counter_ns() - start_time) / 1000 / 1000
-        if not any(
-            silent_logging_path in path_with_query_string
-            for silent_logging_path in silent_logging_paths
-        ):
-            logger.debug(
-                "Sending response",
-                status_code=response.status_code,
-                request_id=request_id,
-                elapsed_time=elapsed_time_in_ms,
-                uri=path_with_query_string,
-                method=request.method,
-                headers=response.headers,
-            )
-        return response
-
-
 @app.on_event("startup")
 async def startup_event():
     logger.info(
         "configuration dump",
         dumped_config=config.dump_yaml(),
         version=mlrun.utils.version.Version().get(),
     )
@@ -222,14 +156,233 @@
 
     # maintenance periodic functions should only run on the chief instance
     if config.httpdb.clusterization.role == mlrun.api.schemas.ClusterizationRole.chief:
         # runs cleanup/monitoring is not needed if we're not inside kubernetes cluster
         if get_k8s_helper(silent=True).is_running_inside_kubernetes_cluster():
             _start_periodic_cleanup()
             _start_periodic_runs_monitoring()
+            await _start_logs_collection()
+            await _start_periodic_stop_logs()
+
+
+async def _start_logs_collection():
+    if config.log_collector.mode == mlrun.api.schemas.LogsCollectorMode.legacy:
+        logger.info(
+            "Using legacy logs collection method, skipping logs collection periodic function",
+            mode=config.log_collector.mode,
+        )
+        return
+    logger.info(
+        "Starting logs collection periodic function",
+        mode=config.log_collector.mode,
+        interval=config.log_collector.periodic_start_log_interval,
+    )
+    start_logs_limit = asyncio.Semaphore(
+        config.log_collector.concurrent_start_logs_workers
+    )
+
+    await _verify_log_collection_started_on_startup(start_logs_limit)
+
+    run_function_periodically(
+        interval=int(config.log_collector.periodic_start_log_interval),
+        name=_initiate_logs_collection.__name__,
+        replace=False,
+        function=_initiate_logs_collection,
+        start_logs_limit=start_logs_limit,
+    )
+
+
+async def _verify_log_collection_started_on_startup(
+    start_logs_limit: asyncio.Semaphore,
+):
+    """
+    Verifies that log collection was started on startup for all runs which might have started before the API
+    initialization or after upgrade.
+    In that case we want to make sure that all runs which are in non-terminal state will have their logs collected
+    with the new log collection method and runs which might have reached terminal state while the API was down will
+    have their logs collected as well.
+    :param start_logs_limit: Semaphore which limits the number of concurrent log collection tasks
+    """
+    db_session = await fastapi.concurrency.run_in_threadpool(create_session)
+    logger.debug(
+        "Getting all runs which are in non terminal state and require logs collection"
+    )
+    runs = await fastapi.concurrency.run_in_threadpool(
+        get_db().list_distinct_runs_uids,
+        db_session,
+        requested_logs_modes=[None, False],
+        only_uids=False,
+        states=mlrun.runtimes.constants.RunStates.non_terminal_states(),
+    )
+    logger.debug(
+        "Getting all runs which might have reached terminal state while the API was down",
+        api_downtime_grace_period=config.log_collector.api_downtime_grace_period,
+    )
+    runs.extend(
+        await fastapi.concurrency.run_in_threadpool(
+            get_db().list_distinct_runs_uids,
+            db_session,
+            requested_logs_modes=[None, False],
+            only_uids=False,
+            # We take the minimum between the api_downtime_grace_period and the runtime_resources_deletion_grace_period
+            # because we want to make sure that we don't miss any runs which might have reached terminal state while the
+            # API was down, and their runtime resources are not deleted
+            last_update_time_from=datetime.datetime.now(datetime.timezone.utc)
+            - datetime.timedelta(
+                seconds=min(
+                    int(config.log_collector.api_downtime_grace_period),
+                    int(config.runtime_resources_deletion_grace_period),
+                )
+            ),
+            states=mlrun.runtimes.constants.RunStates.terminal_states(),
+        )
+    )
+    if runs:
+        logger.debug(
+            "Found runs which require logs collection",
+            runs_uids=[run.get("metadata", {}).get("uid", None) for run in runs],
+        )
+
+        # we're using best_effort=True so the api will mark the runs as requested logs collection even in cases
+        # where the log collection failed (e.g. when the pod is not found for runs that might have reached terminal
+        # state while the API was down)
+        await _start_log_and_update_runs(
+            start_logs_limit, db_session, runs, best_effort=True
+        )
+
+
+async def _initiate_logs_collection(start_logs_limit: asyncio.Semaphore):
+    """
+    This function is responsible for initiating the logs collection process. It will get a list of all runs which are
+    in a state which requires logs collection and will initiate the logs collection process for each of them.
+    :param start_logs_limit: a semaphore which limits the number of concurrent logs collection processes
+    """
+    db_session = await fastapi.concurrency.run_in_threadpool(create_session)
+    try:
+        # list all the runs in the system which we didn't request logs collection for yet
+        runs = await fastapi.concurrency.run_in_threadpool(
+            get_db().list_distinct_runs_uids,
+            db_session,
+            requested_logs_modes=[False],
+            only_uids=False,
+        )
+        if runs:
+            logger.debug(
+                "Found runs which require logs collection",
+                runs_uids=[run.get("metadata", {}).get("uid", None) for run in runs],
+            )
+            await _start_log_and_update_runs(start_logs_limit, db_session, runs)
+
+    finally:
+        await fastapi.concurrency.run_in_threadpool(close_session, db_session)
+
+
+async def _start_log_and_update_runs(
+    start_logs_limit: asyncio.Semaphore,
+    db_session: sqlalchemy.orm.Session,
+    runs: list,
+    best_effort: bool = False,
+):
+    if not runs:
+        return
+
+    # each result contains either run_uid or None
+    # if it's None it means something went wrong, and we should skip it
+    # if it's run_uid it means we requested logs collection for it and we should update it's requested_logs field
+    results = await asyncio.gather(
+        *[
+            _start_log_for_run(
+                run, start_logs_limit, raise_on_error=False, best_effort=best_effort
+            )
+            for run in runs
+        ]
+    )
+    runs_to_update_requested_logs = [result for result in results if result]
+
+    # distinct the runs uids
+    runs_to_update_requested_logs = list(set(runs_to_update_requested_logs))
+
+    if len(runs_to_update_requested_logs) > 0:
+        logger.debug(
+            "Updating runs to indicate that we requested logs collection for them",
+            runs_uids=runs_to_update_requested_logs,
+        )
+        # update the runs to indicate that we have requested log collection for them
+        await fastapi.concurrency.run_in_threadpool(
+            get_db().update_runs_requested_logs,
+            db_session,
+            uids=runs_to_update_requested_logs,
+        )
+
+
+async def _start_log_for_run(
+    run: dict,
+    start_logs_limit: asyncio.Semaphore = None,
+    raise_on_error: bool = True,
+    best_effort: bool = False,
+) -> typing.Optional[typing.Union[str, None]]:
+    """
+    Starts log collection for a specific run
+    :param run: run object
+    :param start_logs_limit: semaphore to limit the number of concurrent log collection requests
+    :param raise_on_error: if True, will raise an exception if something went wrong, otherwise will return None and
+    log the error
+    :return: the run_uid of the run if log collection was started, None otherwise
+    """
+    # using semaphore to limit the number of concurrent log collection requests
+    # this is to prevent opening too many connections to many connections
+    async with start_logs_limit:
+        logs_collector_client = (
+            mlrun.api.utils.clients.log_collector.LogCollectorClient()
+        )
+        run_kind = run.get("metadata", {}).get("labels", {}).get("kind", None)
+        project_name = run.get("metadata", {}).get("project", None)
+        run_uid = run.get("metadata", {}).get("uid", None)
+
+        # information for why runtime isn't log collectable is inside the method
+        if not mlrun.runtimes.RuntimeKinds.is_log_collectable_runtime(run_kind):
+            # we mark the run as requested logs collection so we won't iterate over it again
+            return run_uid
+        try:
+            runtime_handler: mlrun.runtimes.BaseRuntimeHandler = (
+                await fastapi.concurrency.run_in_threadpool(
+                    get_runtime_handler, run_kind
+                )
+            )
+            object_id = runtime_handler.resolve_object_id(run)
+            label_selector = runtime_handler.resolve_label_selector(
+                project=project_name,
+                object_id=object_id,
+                class_mode=RuntimeClassMode.run,
+                # when collecting logs for runtimes we only collect for the main runtime resource, as there could be
+                # runtimes that the user will create with hundreds of resources (e.g mpi job can have multiple workers
+                # which aren't really important for log collection
+                with_main_runtime_resource_label_selector=True,
+            )
+            success, _ = await logs_collector_client.start_logs(
+                run_uid=run_uid,
+                selector=label_selector,
+                project=project_name,
+                best_effort=best_effort,
+                raise_on_error=True,
+            )
+            if success:
+                # update the run to mark that we requested logs collection for it
+                return run_uid
+
+        except Exception as exc:
+            if raise_on_error:
+                raise exc
+
+            logger.warning(
+                "Failed to start logs for run",
+                run_uid=run_uid,
+                exc=mlrun.errors.err_to_str(exc),
+            )
+            return None
 
 
 def _start_periodic_cleanup():
     interval = int(config.runtimes_cleanup_interval)
     if interval > 0:
         logger.info("Starting periodic runtimes cleanup", interval=interval)
         run_function_periodically(
@@ -242,14 +395,59 @@
     if interval > 0:
         logger.info("Starting periodic runs monitoring", interval=interval)
         run_function_periodically(
             interval, _monitor_runs.__name__, False, _monitor_runs
         )
 
 
+async def _start_periodic_stop_logs():
+    if config.log_collector.mode == mlrun.api.schemas.LogsCollectorMode.legacy:
+        logger.info(
+            "Using legacy logs collection method, skipping stop logs periodic function",
+            mode=config.log_collector.mode,
+        )
+        return
+
+    await _verify_log_collection_stopped_on_startup()
+
+    interval = int(config.log_collector.stop_logs_interval)
+    if interval > 0:
+        logger.info("Starting periodic stop logs", interval=interval)
+        run_function_periodically(interval, _stop_logs.__name__, False, _stop_logs)
+
+
+async def _verify_log_collection_stopped_on_startup():
+    """
+    Pulls runs from DB that are in terminal state and have logs requested, and call stop logs for them.
+    This is done so that the log collector won't keep trying to collect logs for runs that are already
+    in terminal state.
+    """
+    logger.debug(
+        "Getting all runs which have reached terminal state and have logs requested",
+    )
+    db_session = await fastapi.concurrency.run_in_threadpool(create_session)
+    try:
+        runs = await fastapi.concurrency.run_in_threadpool(
+            get_db().list_distinct_runs_uids,
+            db_session,
+            requested_logs_modes=[True],
+            only_uids=False,
+            states=mlrun.runtimes.constants.RunStates.terminal_states(),
+        )
+
+        if len(runs) > 0:
+            logger.debug(
+                "Stopping logs for runs which reached terminal state before startup",
+                runs_count=len(runs),
+            )
+            await _stop_logs_for_runs(runs)
+    finally:
+        await fastapi.concurrency.run_in_threadpool(close_session, db_session)
+
+
 def _start_chief_clusterization_spec_sync_loop():
     interval = int(config.httpdb.clusterization.worker.sync_with_chief.interval)
     if interval > 0:
         logger.info("Starting chief clusterization spec sync loop", interval=interval)
         run_function_periodically(
             interval,
             _synchronize_with_chief_clusterization_spec.__name__,
@@ -343,14 +541,65 @@
                     exc=err_to_str(exc),
                     kind=kind,
                 )
     finally:
         close_session(db_session)
 
 
+async def _stop_logs():
+    """
+    Stop logs for runs that are in terminal state and last updated in the previous interval
+    """
+    logger.debug(
+        "Getting all runs which reached terminal state in the previous interval and have logs requested",
+        interval_seconds=int(config.log_collector.stop_logs_interval),
+    )
+    db_session = await fastapi.concurrency.run_in_threadpool(create_session)
+    try:
+        runs = await fastapi.concurrency.run_in_threadpool(
+            get_db().list_distinct_runs_uids,
+            db_session,
+            requested_logs_modes=[True],
+            only_uids=False,
+            states=mlrun.runtimes.constants.RunStates.terminal_states(),
+            last_update_time_from=datetime.datetime.now(datetime.timezone.utc)
+            - datetime.timedelta(seconds=1.5 * config.log_collector.stop_logs_interval),
+        )
+
+        if len(runs) > 0:
+            logger.debug(
+                "Stopping logs for runs which reached terminal state in the previous interval",
+                runs_count=len(runs),
+            )
+            await _stop_logs_for_runs(runs)
+    finally:
+        await fastapi.concurrency.run_in_threadpool(close_session, db_session)
+
+
+async def _stop_logs_for_runs(runs: list):
+    project_to_run_uids = {}
+    for run in runs:
+        project_name = run.get("metadata", {}).get("project", None)
+        run_uid = run.get("metadata", {}).get("uid", None)
+        project_to_run_uids.setdefault(project_name, []).append(run_uid)
+
+    for project_name, run_uids in project_to_run_uids.items():
+        try:
+            await mlrun.api.utils.clients.log_collector.LogCollectorClient().stop_logs(
+                project_name, run_uids
+            )
+        except Exception as exc:
+            logger.warning(
+                "Failed stopping logs for runs. Ignoring",
+                exc=err_to_str(exc),
+                project=project_name,
+                run_uids=run_uids,
+            )
+
+
 def main():
     if config.httpdb.clusterization.role == mlrun.api.schemas.ClusterizationRole.chief:
         init_data()
     elif (
         config.httpdb.clusterization.worker.sync_with_chief.mode
         == mlrun.api.schemas.WaitForChiefToReachOnlineStateFeatureFlag.enabled
         and config.httpdb.clusterization.role
```

## mlrun/api/api/deps.py

```diff
@@ -66,28 +66,15 @@
             "background-tasks",
             "client-spec",
             "migrations",
             "clusterization-spec",
             "memory-reports",
         ]
         if not any(enabled_endpoint in path for enabled_endpoint in enabled_endpoints):
-            message = (
-                "API is waiting for migrations to be triggered. Send POST request to /api/operations/migrations to"
-                " trigger it"
-            )
-            if (
-                mlrun.mlconf.httpdb.state
-                == mlrun.api.schemas.APIStates.migrations_in_progress
-            ):
-                message = "Migrations are in progress"
-            elif (
-                mlrun.mlconf.httpdb.state
-                == mlrun.api.schemas.APIStates.migrations_failed
-            ):
-                message = "Migrations failed, API can't be started"
+            message = mlrun.api.schemas.APIStates.description(mlrun.mlconf.httpdb.state)
             raise mlrun.errors.MLRunPreconditionFailedError(message)
 
 
 def expose_internal_endpoints(request: Request):
     if not mlrun.mlconf.debug.expose_internal_api_endpoints:
         path_with_query_string = uvicorn.protocols.utils.get_path_with_query_string(
             request.scope
```

## mlrun/api/api/utils.py

```diff
@@ -45,17 +45,15 @@
 from mlrun.run import import_function, new_function
 from mlrun.runtimes.utils import enrich_function_from_dict
 from mlrun.utils import get_in, logger, parse_versioned_object_uri
 
 
 def log_and_raise(status=HTTPStatus.BAD_REQUEST.value, **kw):
     logger.error(str(kw))
-    # TODO: 0.6.6 is the last version expecting the error details to be under reason, when it's no longer a relevant
-    #  version can be changed to details=kw
-    raise HTTPException(status_code=status, detail={"reason": kw})
+    raise HTTPException(status_code=status, detail=kw)
 
 
 def log_path(project, uid) -> Path:
     return project_logs_path(project) / uid
 
 
 def project_logs_path(project) -> Path:
@@ -96,27 +94,34 @@
                 path_from_volume = path_from_volume[1:]
             path = str(Path(real_path) / Path(path_from_volume))
     if schema:
         schema_prefix = schema + "://"
         if not path.startswith(schema_prefix):
             path = f"{schema_prefix}{path}"
 
-    # Check if path is allowed - v3io:// is always allowed, and also the real_path parameter if specified.
-    # We never allow local files in the allowed paths list. Allowed paths must contain a schema (://)
+    allowed_paths_list = get_allowed_path_prefixes_list()
+    if not any(path.startswith(allowed_path) for allowed_path in allowed_paths_list):
+        raise mlrun.errors.MLRunAccessDeniedError("Unauthorized path")
+    return path
+
+
+def get_allowed_path_prefixes_list() -> typing.List[str]:
+    """
+    Get list of allowed paths - v3io:// is always allowed, and also the real_path parameter if specified.
+    We never allow local files in the allowed paths list. Allowed paths must contain a schema (://).
+    """
+    real_path = config.httpdb.real_path
     allowed_file_paths = config.httpdb.allowed_file_paths or ""
     allowed_paths_list = [
         path.strip() for path in allowed_file_paths.split(",") if "://" in path
     ]
     if real_path:
         allowed_paths_list.append(real_path)
     allowed_paths_list.append("v3io://")
-
-    if not any(path.startswith(allowed_path) for allowed_path in allowed_paths_list):
-        raise mlrun.errors.MLRunAccessDeniedError("Unauthorized path")
-    return path
+    return allowed_paths_list
 
 
 def get_secrets(auth_info: mlrun.api.schemas.AuthInfo):
     return {
         "V3IO_ACCESS_KEY": auth_info.data_session,
     }
 
@@ -227,14 +232,23 @@
     if mask_sensitive_data:
         mask_function_sensitive_data(function, auth_info)
 
     if ensure_security_context:
         ensure_function_security_context(function, auth_info)
 
 
+def ensure_function_auth_and_sensitive_data_is_masked(
+    function,
+    auth_info: mlrun.api.schemas.AuthInfo,
+    allow_empty_access_key: bool = False,
+):
+    ensure_function_has_auth_set(function, auth_info, allow_empty_access_key)
+    mask_function_sensitive_data(function, auth_info)
+
+
 def mask_function_sensitive_data(function, auth_info: mlrun.api.schemas.AuthInfo):
     if not mlrun.runtimes.RuntimeKinds.is_local_runtime(function.kind):
         _mask_v3io_access_key_env_var(function, auth_info)
         _mask_v3io_volume_credentials(function)
 
 
 def _mask_v3io_volume_credentials(function: mlrun.runtimes.pod.KubeResource):
@@ -415,15 +429,24 @@
             "access_key"
         )
         function.set_env_from_secret(
             "V3IO_ACCESS_KEY", secret_name, access_key_secret_key
         )
 
 
-def ensure_function_has_auth_set(function, auth_info: mlrun.api.schemas.AuthInfo):
+def ensure_function_has_auth_set(
+    function: mlrun.runtimes.BaseRuntime,
+    auth_info: mlrun.api.schemas.AuthInfo,
+    allow_empty_access_key: bool = False,
+):
+    """
+    :param function:    Function object.
+    :param auth_info:   The auth info of the request.
+    :param allow_empty_access_key: Whether to raise an error if access key wasn't set or requested to get generated
+    """
     if (
         not mlrun.runtimes.RuntimeKinds.is_local_runtime(function.kind)
         and mlrun.api.utils.auth.verifier.AuthVerifier().is_jobs_auth_required()
     ):
         function: mlrun.runtimes.pod.KubeResource
         if (
             function.metadata.credentials.access_key
@@ -436,18 +459,25 @@
                 # created an access key with control and data session plane, so enriching auth_info with those planes
                 auth_info.planes = [
                     mlrun.api.utils.clients.iguazio.SessionPlanes.control,
                     mlrun.api.utils.clients.iguazio.SessionPlanes.data,
                 ]
 
             function.metadata.credentials.access_key = auth_info.access_key
+
         if not function.metadata.credentials.access_key:
+            if allow_empty_access_key:
+                # skip further enrichment as we allow empty access key
+                return
+
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "Function access key must be set (function.metadata.credentials.access_key)"
             )
+
+        # after access key was passed or enriched with the condition above, we mask it with creating auth secret
         if not function.metadata.credentials.access_key.startswith(
             mlrun.model.Credentials.secret_reference_prefix
         ):
             if not auth_info.username:
                 raise mlrun.errors.MLRunInvalidArgumentError(
                     "Username is missing from auth info"
                 )
@@ -672,39 +702,55 @@
             mlrun.runtimes.RuntimeKinds.is_local_runtime(fn.kind)
             and not mlrun.mlconf.httpdb.jobs.allow_local_run
         ):
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "Local runtimes can not be run through API (not locally)"
             )
         run_db = get_run_db_instance(db_session)
-        fn.set_db_connection(run_db, True)
+        fn.set_db_connection(run_db)
         logger.info("Submitting run", function=fn.to_dict(), task=task)
-        # fn.spec.rundb = "http://mlrun-api:8080"
         schedule = data.get("schedule")
         if schedule:
             cron_trigger = schedule
             if isinstance(cron_trigger, dict):
                 cron_trigger = schemas.ScheduleCronTrigger(**cron_trigger)
             schedule_labels = task["metadata"].get("labels")
-            get_scheduler().create_schedule(
-                db_session,
-                auth_info,
-                task["metadata"]["project"],
-                task["metadata"]["name"],
-                schemas.ScheduleKinds.job,
-                data,
-                cron_trigger,
-                schedule_labels,
-            )
+            created = False
+
+            try:
+                get_scheduler().update_schedule(
+                    db_session,
+                    auth_info,
+                    task["metadata"]["project"],
+                    task["metadata"]["name"],
+                    data,
+                    cron_trigger,
+                    schedule_labels,
+                )
+            except mlrun.errors.MLRunNotFoundError:
+                logger.debug("No existing schedule found, creating a new one")
+                get_scheduler().create_schedule(
+                    db_session,
+                    auth_info,
+                    task["metadata"]["project"],
+                    task["metadata"]["name"],
+                    schemas.ScheduleKinds.job,
+                    data,
+                    cron_trigger,
+                    schedule_labels,
+                )
+                created = True
             project = task["metadata"]["project"]
 
             response = {
                 "schedule": schedule,
                 "project": task["metadata"]["project"],
                 "name": task["metadata"]["name"],
+                # indicate whether it was created or modified
+                "action": "created" if created else "modified",
             }
         else:
             # When processing a hyper-param run, secrets may be needed to access the parameters file (which is accessed
             # locally from the mlrun service pod) - include project secrets and the caller's access key
             param_file_secrets = (
                 mlrun.api.crud.Secrets()
                 .list_project_secrets(
```

## mlrun/api/api/endpoints/client_spec.py

```diff
@@ -8,23 +8,32 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from fastapi import APIRouter
+import typing
+
+from fastapi import APIRouter, Header
 
 import mlrun.api.crud
 import mlrun.api.schemas
 
 router = APIRouter()
 
 
 @router.get(
     "/client-spec",
     response_model=mlrun.api.schemas.ClientSpec,
 )
-def get_client_spec():
-
-    # TODO: cache me
-    return mlrun.api.crud.ClientSpec().get_client_spec()
+def get_client_spec(
+    client_version: typing.Optional[str] = Header(
+        None, alias=mlrun.api.schemas.HeaderNames.client_version
+    ),
+    client_python_version: typing.Optional[str] = Header(
+        None, alias=mlrun.api.schemas.HeaderNames.python_version
+    ),
+):
+    return mlrun.api.crud.ClientSpec().get_client_spec(
+        client_version=client_version, client_python_version=client_python_version
+    )
```

## mlrun/api/api/endpoints/frontend_spec.py

```diff
@@ -20,14 +20,15 @@
 import mlrun.api.api.deps
 import mlrun.api.schemas
 import mlrun.api.utils.clients.iguazio
 import mlrun.builder
 import mlrun.runtimes
 import mlrun.runtimes.utils
 import mlrun.utils.helpers
+from mlrun.api.api.utils import get_allowed_path_prefixes_list
 from mlrun.config import config
 from mlrun.platforms import is_iguazio_session_cookie
 
 router = fastapi.APIRouter()
 
 
 @router.get(
@@ -78,14 +79,15 @@
         function_deployment_mlrun_command=mlrun.builder.resolve_mlrun_install_command(),
         auto_mount_type=config.storage.auto_mount_type,
         auto_mount_params=config.get_storage_auto_mount_params(),
         default_artifact_path=config.artifact_path,
         default_function_pod_resources=mlrun.mlconf.default_function_pod_resources.to_dict(),
         default_function_preemption_mode=mlrun.mlconf.function_defaults.preemption_mode,
         feature_store_data_prefixes=config.feature_store.data_prefixes.to_dict(),
+        allowed_artifact_path_prefixes_list=get_allowed_path_prefixes_list(),
         # ce_mode is deprecated, we will use the full ce config instead and ce_mode will be removed in 1.6.0
         ce_mode=config.ce.mode,
         ce=config.ce.to_dict(),
     )
 
 
 def _resolve_jobs_dashboard_url(session: str) -> typing.Optional[str]:
```

## mlrun/api/api/endpoints/functions.py

```diff
@@ -36,14 +36,15 @@
 import mlrun.api.crud
 import mlrun.api.db.session
 import mlrun.api.schemas
 import mlrun.api.utils.auth.verifier
 import mlrun.api.utils.background_tasks
 import mlrun.api.utils.clients.chief
 import mlrun.api.utils.singletons.project_member
+import mlrun.model_monitoring.constants
 from mlrun.api.api import deps
 from mlrun.api.api.utils import get_run_db_instance, log_and_raise, log_path
 from mlrun.api.crud.secrets import Secrets, SecretsClientType
 from mlrun.api.schemas import SecretProviderName, SecretsData
 from mlrun.api.utils.singletons.k8s import get_k8s
 from mlrun.builder import build_runtime
 from mlrun.config import config
@@ -92,14 +93,15 @@
         mlrun.api.crud.Functions().store_function,
         db_session,
         data,
         name,
         project,
         tag=tag,
         versioned=versioned,
+        auth_info=auth_info,
     )
     return {
         "hash_key": hash_key,
     }
 
 
 @router.get("/func/{project}/{name}")
@@ -155,31 +157,33 @@
 
 @router.get("/funcs")
 async def list_functions(
     project: str = None,
     name: str = None,
     tag: str = None,
     labels: List[str] = Query([], alias="label"),
+    hash_key: str = None,
     auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
     if project is None:
         project = config.default_project
     await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_permissions(
         project,
         mlrun.api.schemas.AuthorizationAction.read,
         auth_info,
     )
     functions = await run_in_threadpool(
         mlrun.api.crud.Functions().list_functions,
-        db_session,
-        project,
-        name,
-        tag,
-        labels,
+        db_session=db_session,
+        project=project,
+        name=name,
+        tag=tag,
+        labels=labels,
+        hash_key=hash_key,
     )
     functions = await mlrun.api.utils.auth.verifier.AuthVerifier().filter_project_resources_by_permissions(
         mlrun.api.schemas.AuthorizationResourceTypes.function,
         functions,
         lambda function: (
             function.get("metadata", {}).get("project", mlrun.mlconf.default_project),
             function["metadata"]["name"],
@@ -196,14 +200,17 @@
 async def build_function(
     request: Request,
     auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
     client_version: Optional[str] = Header(
         None, alias=mlrun.api.schemas.HeaderNames.client_version
     ),
+    client_python_version: Optional[str] = Header(
+        None, alias=mlrun.api.schemas.HeaderNames.python_version
+    ),
 ):
     data = None
     try:
         data = await request.json()
     except ValueError:
         log_and_raise(HTTPStatus.BAD_REQUEST.value, reason="bad JSON body")
 
@@ -256,14 +263,15 @@
         auth_info,
         function,
         with_mlrun,
         skip_deployed,
         mlrun_version_specifier,
         data.get("builder_env"),
         client_version,
+        client_python_version,
     )
     return {
         "data": fn.to_dict(),
         "ready": ready,
     }
 
 
@@ -273,14 +281,17 @@
     request: Request,
     background_tasks: BackgroundTasks,
     auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
     client_version: Optional[str] = Header(
         None, alias=mlrun.api.schemas.HeaderNames.client_version
     ),
+    client_python_version: Optional[str] = Header(
+        None, alias=mlrun.api.schemas.HeaderNames.python_version
+    ),
 ):
     # TODO: ensure project here !!! for background task
     data = None
     try:
         data = await request.json()
     except ValueError:
         log_and_raise(HTTPStatus.BAD_REQUEST.value, reason="bad JSON body")
@@ -304,14 +315,15 @@
         background_tasks,
         _start_function,
         background_timeout,
         # args for _start_function
         function,
         auth_info,
         client_version,
+        client_python_version,
     )
 
     return background_task
 
 
 @router.post("/status/function")
 @router.post("/status/function/")
@@ -402,15 +414,21 @@
 ):
     # job deploy status
     state = get_in(fn, "status.state", "")
     pod = get_in(fn, "status.build_pod", "")
     image = get_in(fn, "spec.build.image", "")
     out = b""
     if not pod:
-        if state == "ready":
+        if state == mlrun.api.schemas.FunctionState.ready:
+            # when the function has been built we set the created image into the `spec.image` for reference see at the
+            # end of the function where we resolve if the status is ready and then set the spec.build.image to
+            # spec.image
+            # TODO: spec shouldn't hold backend enriched attributes, but rather in the status block
+            #   therefore need set it as a new attribute in status.image which will ease our resolution
+            #   of whether it is a user defined image or MLRun enriched one.
             image = image or get_in(fn, "spec.image")
         return Response(
             content=out,
             media_type="text/plain",
             headers={
                 "function_status": state,
                 "function_image": image,
@@ -418,14 +436,24 @@
             },
         )
 
     # read from log file
     terminal_states = ["failed", "error", "ready"]
     log_file = log_path(project, f"build_{name}__{tag or 'latest'}")
     if state in terminal_states and log_file.exists():
+
+        if state == mlrun.api.schemas.FunctionState.ready:
+            # when the function has been built we set the created image into the `spec.image` for reference see at the
+            # end of the function where we resolve if the status is ready and then set the spec.build.image to
+            # spec.image
+            # TODO: spec shouldn't hold backend enriched attributes, but rather in the status block
+            #   therefore need set it as a new attribute in status.image which will ease our resolution
+            #   of whether it is a user defined image or MLRun enriched one.
+            image = image or get_in(fn, "spec.image")
+
         with log_file.open("rb") as fp:
             fp.seek(offset)
             out = fp.read()
         return Response(
             content=out,
             media_type="text/plain",
             headers={
@@ -487,15 +515,15 @@
 
 
 def _handle_nuclio_deploy_status(
     db_session, auth_info, fn, name, project, tag, last_log_timestamp, verbose
 ):
     (
         state,
-        address,
+        _,
         nuclio_name,
         last_log_timestamp,
         text,
         status,
     ) = get_nuclio_deploy_status(
         name,
         project,
@@ -518,34 +546,43 @@
     # and hence, for BC it would be filled with the external invocation url first item
     # or completely empty.
     address = external_invocation_urls[0] if external_invocation_urls else ""
 
     # the built and pushed image name used to run the nuclio function container
     container_image = status.get("containerImage", "")
 
-    update_in(fn, "status.nuclio_name", nuclio_name)
-    update_in(fn, "status.internal_invocation_urls", internal_invocation_urls)
-    update_in(fn, "status.external_invocation_urls", external_invocation_urls)
-    update_in(fn, "status.state", state)
-    update_in(fn, "status.address", address)
-    update_in(fn, "status.container_image", container_image)
+    # we don't want to store the function on all requests to get the deploy status, therefore we verify
+    # that changes were actually made and if that's the case then we store the function
+    if _is_nuclio_deploy_status_changed(
+        previous_status=fn.get("status", {}),
+        new_status=status,
+        new_state=state,
+        new_nuclio_name=nuclio_name,
+    ):
+        update_in(fn, "status.nuclio_name", nuclio_name)
+        update_in(fn, "status.internal_invocation_urls", internal_invocation_urls)
+        update_in(fn, "status.external_invocation_urls", external_invocation_urls)
+        update_in(fn, "status.state", state)
+        update_in(fn, "status.address", address)
+        update_in(fn, "status.container_image", container_image)
+
+        versioned = False
+        if state == "ready":
+            # Versioned means the version will be saved in the DB forever, we don't want to spam
+            # the DB with intermediate or unusable versions, only successfully deployed versions
+            versioned = True
+        mlrun.api.crud.Functions().store_function(
+            db_session,
+            fn,
+            name,
+            project,
+            tag,
+            versioned=versioned,
+        )
 
-    versioned = False
-    if state == "ready":
-        # Versioned means the version will be saved in the DB forever, we don't want to spam
-        # the DB with intermediate or unusable versions, only successfully deployed versions
-        versioned = True
-    mlrun.api.crud.Functions().store_function(
-        db_session,
-        fn,
-        name,
-        project,
-        tag,
-        versioned=versioned,
-    )
     return Response(
         content=text,
         media_type="text/plain",
         headers={
             "x-mlrun-function-status": state,
             "x-mlrun-last-timestamp": str(last_log_timestamp),
             "x-mlrun-address": address,
@@ -562,14 +599,15 @@
     auth_info: mlrun.api.schemas.AuthInfo,
     function,
     with_mlrun=True,
     skip_deployed=False,
     mlrun_version_specifier=None,
     builder_env=None,
     client_version=None,
+    client_python_version=None,
 ):
     fn = None
     ready = None
     try:
         fn = new_function(runtime=function)
     except Exception as err:
         logger.error(traceback.format_exc())
@@ -594,39 +632,54 @@
                     if fn.spec.track_models:
                         logger.info("Tracking enabled, initializing model monitoring")
                         _init_serving_function_stream_args(fn=fn)
                         # get model monitoring access key
                         model_monitoring_access_key = _process_model_monitoring_secret(
                             db_session,
                             fn.metadata.project,
-                            "MODEL_MONITORING_ACCESS_KEY",
+                            mlrun.model_monitoring.constants.ProjectSecretKeys.ACCESS_KEY,
                         )
+
                         # initialize model monitoring stream
                         _create_model_monitoring_stream(project=fn.metadata.project)
 
+                        if fn.spec.tracking_policy:
+                            # convert to `TrackingPolicy` object as `fn.spec.tracking_policy` is provided as a dict
+                            fn.spec.tracking_policy = (
+                                mlrun.utils.model_monitoring.TrackingPolicy.from_dict(
+                                    fn.spec.tracking_policy
+                                )
+                            )
+                        else:
+                            # initialize tracking policy with default values
+                            fn.spec.tracking_policy = (
+                                mlrun.utils.model_monitoring.TrackingPolicy()
+                            )
+
                         # deploy both model monitoring stream and model monitoring batch job
                         mlrun.api.crud.ModelEndpoints().deploy_monitoring_functions(
                             project=fn.metadata.project,
-                            model_monitoring_access_key=model_monitoring_access_key,
                             db_session=db_session,
                             auth_info=auth_info,
                             tracking_policy=fn.spec.tracking_policy,
+                            model_monitoring_access_key=model_monitoring_access_key,
                         )
                 except Exception as exc:
                     logger.warning(
                         "Failed deploying model monitoring infrastructure for the project",
                         project=fn.metadata.project,
                         exc=exc,
                         traceback=traceback.format_exc(),
                     )
 
             deploy_nuclio_function(
                 fn,
                 auth_info=auth_info,
                 client_version=client_version,
+                client_python_version=client_python_version,
                 builder_env=builder_env,
             )
             # deploy only start the process, the get status API is used to check readiness
             ready = False
         else:
             log_file = log_path(
                 fn.metadata.project,
@@ -640,14 +693,15 @@
                 auth_info,
                 fn,
                 with_mlrun,
                 mlrun_version_specifier,
                 skip_deployed,
                 builder_env=builder_env,
                 client_version=client_version,
+                client_python_version=client_python_version,
             )
         fn.save(versioned=True)
         logger.info("Fn:\n %s", fn.to_yaml())
     except Exception as err:
         logger.error(traceback.format_exc())
         log_and_raise(
             HTTPStatus.BAD_REQUEST.value,
@@ -674,15 +728,18 @@
             reason=f"runtime error: function {url} not found",
         )
 
     return new_function(runtime=runtime)
 
 
 def _start_function(
-    function, auth_info: mlrun.api.schemas.AuthInfo, client_version: str = None
+    function,
+    auth_info: mlrun.api.schemas.AuthInfo,
+    client_version: str = None,
+    client_python_version: str = None,
 ):
     db_session = mlrun.api.db.session.create_session()
     try:
         resource = runtime_resources_map.get(function.kind)
         if "start" not in resource:
             log_and_raise(
                 HTTPStatus.BAD_REQUEST.value,
@@ -693,15 +750,19 @@
             function.set_db_connection(run_db)
             mlrun.api.api.utils.apply_enrichment_and_validation_on_function(
                 function,
                 auth_info,
             )
 
             #  resp = resource["start"](fn)  # TODO: handle resp?
-            resource["start"](function, client_version=client_version)
+            resource["start"](
+                function,
+                client_version=client_version,
+                client_python_version=client_python_version,
+            )
             function.save(versioned=False)
             logger.info("Fn:\n %s", function.to_yaml())
         except Exception as err:
             logger.error(traceback.format_exc())
             log_and_raise(
                 HTTPStatus.BAD_REQUEST.value,
                 reason=f"runtime error: {err_to_str(err)}",
@@ -860,7 +921,30 @@
     if user_provided_key:
         logger.info(
             "Deleting user-provided access-key - replaced with an internal secret"
         )
         Secrets().delete_project_secret(project_name, provider, secret_key)
 
     return secret_value
+
+
+def _is_nuclio_deploy_status_changed(
+    previous_status: dict, new_status: dict, new_state: str, new_nuclio_name: str = None
+) -> bool:
+    # get relevant fields from the new status
+    new_container_image = new_status.get("containerImage", "")
+    new_internal_invocation_urls = new_status.get("internalInvocationUrls", [])
+    new_external_invocation_urls = new_status.get("externalInvocationUrls", [])
+    address = new_external_invocation_urls[0] if new_external_invocation_urls else ""
+
+    # Determine if any of the relevant fields have changed
+    has_changed = (
+        previous_status.get("nuclio_name", "") != new_nuclio_name
+        or previous_status.get("state") != new_state
+        or previous_status.get("container_image", "") != new_container_image
+        or previous_status.get("internal_invocation_urls", [])
+        != new_internal_invocation_urls
+        or previous_status.get("external_invocation_urls", [])
+        != new_external_invocation_urls
+        or previous_status.get("address", "") != address
+    )
+    return has_changed
```

## mlrun/api/api/endpoints/grafana_proxy.py

```diff
@@ -9,500 +9,137 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import asyncio
-import json
+import warnings
 from http import HTTPStatus
-from typing import Any, Dict, List, Optional, Set, Union
+from typing import List, Union
 
-import numpy as np
-import pandas as pd
 from fastapi import APIRouter, Depends, Request, Response
 from fastapi.concurrency import run_in_threadpool
 from sqlalchemy.orm import Session
 
 import mlrun.api.crud
+import mlrun.api.crud.model_monitoring.grafana
 import mlrun.api.schemas
 import mlrun.api.utils.auth.verifier
+import mlrun.model_monitoring
 from mlrun.api.api import deps
-from mlrun.api.schemas import (
-    GrafanaColumn,
-    GrafanaDataPoint,
-    GrafanaNumberColumn,
-    GrafanaTable,
-    GrafanaTimeSeriesTarget,
-    ProjectsFormat,
-)
-from mlrun.api.utils.singletons.project_member import get_project_member
-from mlrun.errors import MLRunBadRequestError
-from mlrun.utils import config, logger
-from mlrun.utils.model_monitoring import parse_model_endpoint_store_prefix
-from mlrun.utils.v3io_clients import get_frames_client
+from mlrun.api.schemas import GrafanaTable, GrafanaTimeSeriesTarget
 
 router = APIRouter()
 
+NAME_TO_SEARCH_FUNCTION_DICTIONARY = {
+    "list_projects": mlrun.api.crud.model_monitoring.grafana.grafana_list_projects,
+}
+NAME_TO_QUERY_FUNCTION_DICTIONARY = {
+    "list_endpoints": mlrun.api.crud.model_monitoring.grafana.grafana_list_endpoints,
+    "individual_feature_analysis": mlrun.api.crud.model_monitoring.grafana.grafana_individual_feature_analysis,
+    "overall_feature_analysis": mlrun.api.crud.model_monitoring.grafana.grafana_overall_feature_analysis,
+    "incoming_features": mlrun.api.crud.model_monitoring.grafana.grafana_incoming_features,
+}
+
+SUPPORTED_QUERY_FUNCTIONS = set(NAME_TO_QUERY_FUNCTION_DICTIONARY.keys())
+SUPPORTED_SEARCH_FUNCTIONS = set(NAME_TO_SEARCH_FUNCTION_DICTIONARY)
+
 
 @router.get("/grafana-proxy/model-endpoints", status_code=HTTPStatus.OK.value)
 def grafana_proxy_model_endpoints_check_connection(
     auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
 ):
     """
     Root of grafana proxy for the model-endpoints API, used for validating the model-endpoints data source
     connectivity.
     """
     mlrun.api.crud.ModelEndpoints().get_access_key(auth_info)
     return Response(status_code=HTTPStatus.OK.value)
 
 
-@router.post(
-    "/grafana-proxy/model-endpoints/query",
-    response_model=List[Union[GrafanaTable, GrafanaTimeSeriesTarget]],
-)
-async def grafana_proxy_model_endpoints_query(
-    request: Request,
-    auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
-) -> List[Union[GrafanaTable, GrafanaTimeSeriesTarget]]:
-    """
-    Query route for model-endpoints grafana proxy API, used for creating an interface between grafana queries and
-    model-endpoints logic.
-
-    This implementation requires passing target_endpoint query parameter in order to dispatch different
-    model-endpoint monitoring functions.
-    """
-    body = await request.json()
-    query_parameters = _parse_query_parameters(body)
-    _validate_query_parameters(query_parameters, SUPPORTED_QUERY_FUNCTIONS)
-    query_parameters = _drop_grafana_escape_chars(query_parameters)
-
-    # At this point everything is validated and we can access everything that is needed without performing all previous
-    # checks again.
-    target_endpoint = query_parameters["target_endpoint"]
-    function = NAME_TO_QUERY_FUNCTION_DICTIONARY[target_endpoint]
-    if asyncio.iscoroutinefunction(function):
-        return await function(body, query_parameters, auth_info)
-    result = await run_in_threadpool(function, body, query_parameters, auth_info)
-    return result
-
-
 @router.post("/grafana-proxy/model-endpoints/search", response_model=List[str])
 async def grafana_proxy_model_endpoints_search(
     request: Request,
     auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ) -> List[str]:
     """
     Search route for model-endpoints grafana proxy API, used for creating an interface between grafana queries and
     model-endpoints logic.
 
     This implementation requires passing target_endpoint query parameter in order to dispatch different
     model-endpoint monitoring functions.
+
+    :param request:    An api request with the required target and parameters.
+    :param auth_info:  The auth info of the request.
+    :param db_session: A session that manages the current dialog with the database.
+
+    :return: List of results. e.g. list of available project names.
     """
     mlrun.api.crud.ModelEndpoints().get_access_key(auth_info)
     body = await request.json()
-    query_parameters = _parse_search_parameters(body)
-
-    _validate_query_parameters(query_parameters, SUPPORTED_SEARCH_FUNCTIONS)
+    query_parameters = mlrun.api.crud.model_monitoring.grafana.parse_search_parameters(
+        body
+    )
+    mlrun.api.crud.model_monitoring.grafana.validate_query_parameters(
+        query_parameters, SUPPORTED_SEARCH_FUNCTIONS
+    )
 
     # At this point everything is validated and we can access everything that is needed without performing all previous
     # checks again.
     target_endpoint = query_parameters["target_endpoint"]
     function = NAME_TO_SEARCH_FUNCTION_DICTIONARY[target_endpoint]
-    if asyncio.iscoroutinefunction(function):
-        return await function(db_session, auth_info)
-    result = await run_in_threadpool(function, db_session, auth_info)
-    return result
-
-
-def grafana_list_projects(
-    db_session: Session, auth_info: mlrun.api.schemas.AuthInfo
-) -> List[str]:
-    projects_output = get_project_member().list_projects(
-        db_session, format_=ProjectsFormat.name_only, leader_session=auth_info.session
-    )
-    return projects_output.projects
-
-
-async def grafana_list_endpoints(
-    body: Dict[str, Any],
-    query_parameters: Dict[str, str],
-    auth_info: mlrun.api.schemas.AuthInfo,
-) -> List[GrafanaTable]:
-    project = query_parameters.get("project")
-
-    # Filters
-    model = query_parameters.get("model", None)
-    function = query_parameters.get("function", None)
-    labels = query_parameters.get("labels", "")
-    labels = labels.split(",") if labels else []
-
-    # Metrics to include
-    metrics = query_parameters.get("metrics", "")
-    metrics = metrics.split(",") if metrics else []
-
-    # Time range for metrics
-    start = body.get("rangeRaw", {}).get("start", "now-1h")
-    end = body.get("rangeRaw", {}).get("end", "now")
-
-    if project:
-        await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_permissions(
-            project,
-            mlrun.api.schemas.AuthorizationAction.read,
-            auth_info,
-        )
-    endpoint_list = await run_in_threadpool(
-        mlrun.api.crud.ModelEndpoints().list_model_endpoints,
-        auth_info=auth_info,
-        project=project,
-        model=model,
-        function=function,
-        labels=labels,
-        metrics=metrics,
-        start=start,
-        end=end,
-    )
-    allowed_endpoints = await mlrun.api.utils.auth.verifier.AuthVerifier().filter_project_resources_by_permissions(
-        mlrun.api.schemas.AuthorizationResourceTypes.model_endpoint,
-        endpoint_list.endpoints,
-        lambda _endpoint: (
-            _endpoint.metadata.project,
-            _endpoint.metadata.uid,
-        ),
-        auth_info,
-    )
-    endpoint_list.endpoints = allowed_endpoints
-
-    columns = [
-        GrafanaColumn(text="endpoint_id", type="string"),
-        GrafanaColumn(text="endpoint_function", type="string"),
-        GrafanaColumn(text="endpoint_model", type="string"),
-        GrafanaColumn(text="endpoint_model_class", type="string"),
-        GrafanaColumn(text="first_request", type="time"),
-        GrafanaColumn(text="last_request", type="time"),
-        GrafanaColumn(text="accuracy", type="number"),
-        GrafanaColumn(text="error_count", type="number"),
-        GrafanaColumn(text="drift_status", type="number"),
-    ]
-
-    metric_columns = []
-
-    found_metrics = set()
-    for endpoint in endpoint_list.endpoints:
-        if endpoint.status.metrics is not None:
-            for key in endpoint.status.metrics.keys():
-                if key not in found_metrics:
-                    found_metrics.add(key)
-                    metric_columns.append(GrafanaColumn(text=key, type="number"))
-
-    columns = columns + metric_columns
-    table = GrafanaTable(columns=columns)
-
-    for endpoint in endpoint_list.endpoints:
-        row = [
-            endpoint.metadata.uid,
-            endpoint.spec.function_uri,
-            endpoint.spec.model,
-            endpoint.spec.model_class,
-            endpoint.status.first_request,
-            endpoint.status.last_request,
-            endpoint.status.accuracy,
-            endpoint.status.error_count,
-            endpoint.status.drift_status,
-        ]
-
-        if endpoint.status.metrics is not None and metric_columns:
-            for metric_column in metric_columns:
-                row.append(endpoint.status.metrics[metric_column.text])
-
-        table.add_row(*row)
-
-    return [table]
-
-
-async def grafana_individual_feature_analysis(
-    body: Dict[str, Any],
-    query_parameters: Dict[str, str],
-    auth_info: mlrun.api.schemas.AuthInfo,
-):
-    endpoint_id = query_parameters.get("endpoint_id")
-    project = query_parameters.get("project")
-    await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_resource_permissions(
-        mlrun.api.schemas.AuthorizationResourceTypes.model_endpoint,
-        project,
-        endpoint_id,
-        mlrun.api.schemas.AuthorizationAction.read,
-        auth_info,
-    )
-
-    endpoint = await run_in_threadpool(
-        mlrun.api.crud.ModelEndpoints().get_model_endpoint,
-        auth_info=auth_info,
-        project=project,
-        endpoint_id=endpoint_id,
-        feature_analysis=True,
-    )
-
-    # Load JSON data from KV, make sure not to fail if a field is missing
-    feature_stats = endpoint.status.feature_stats or {}
-    current_stats = endpoint.status.current_stats or {}
-    drift_measures = endpoint.status.drift_measures or {}
-
-    table = GrafanaTable(
-        columns=[
-            GrafanaColumn(text="feature_name", type="string"),
-            GrafanaColumn(text="actual_min", type="number"),
-            GrafanaColumn(text="actual_mean", type="number"),
-            GrafanaColumn(text="actual_max", type="number"),
-            GrafanaColumn(text="expected_min", type="number"),
-            GrafanaColumn(text="expected_mean", type="number"),
-            GrafanaColumn(text="expected_max", type="number"),
-            GrafanaColumn(text="tvd", type="number"),
-            GrafanaColumn(text="hellinger", type="number"),
-            GrafanaColumn(text="kld", type="number"),
-        ]
-    )
 
-    for feature, base_stat in feature_stats.items():
-        current_stat = current_stats.get(feature, {})
-        drift_measure = drift_measures.get(feature, {})
-
-        table.add_row(
-            feature,
-            current_stat.get("min"),
-            current_stat.get("mean"),
-            current_stat.get("max"),
-            base_stat.get("min"),
-            base_stat.get("mean"),
-            base_stat.get("max"),
-            drift_measure.get("tvd"),
-            drift_measure.get("hellinger"),
-            drift_measure.get("kld"),
+    if asyncio.iscoroutinefunction(function):
+        result = await function(db_session, auth_info, query_parameters)
+    else:
+        result = await run_in_threadpool(
+            function, db_session, auth_info, query_parameters
         )
+    return result
 
-    return [table]
 
+@router.post(
+    "/grafana-proxy/model-endpoints/query",
+    response_model=List[Union[GrafanaTable, GrafanaTimeSeriesTarget]],
+)
+async def grafana_proxy_model_endpoints_query(
+    request: Request,
+    auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
+) -> List[Union[GrafanaTable, GrafanaTimeSeriesTarget]]:
+    """
+    Query route for model-endpoints grafana proxy API, used for creating an interface between grafana queries and
+    model-endpoints logic.
 
-async def grafana_overall_feature_analysis(
-    body: Dict[str, Any],
-    query_parameters: Dict[str, str],
-    auth_info: mlrun.api.schemas.AuthInfo,
-):
-    endpoint_id = query_parameters.get("endpoint_id")
-    project = query_parameters.get("project")
-    await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_resource_permissions(
-        mlrun.api.schemas.AuthorizationResourceTypes.model_endpoint,
-        project,
-        endpoint_id,
-        mlrun.api.schemas.AuthorizationAction.read,
-        auth_info,
-    )
-    endpoint = await run_in_threadpool(
-        mlrun.api.crud.ModelEndpoints().get_model_endpoint,
-        auth_info=auth_info,
-        project=project,
-        endpoint_id=endpoint_id,
-        feature_analysis=True,
-    )
+    This implementation requires passing target_endpoint query parameter in order to dispatch different
+    model-endpoint monitoring functions.
+    """
 
-    table = GrafanaTable(
-        columns=[
-            GrafanaNumberColumn(text="tvd_sum"),
-            GrafanaNumberColumn(text="tvd_mean"),
-            GrafanaNumberColumn(text="hellinger_sum"),
-            GrafanaNumberColumn(text="hellinger_mean"),
-            GrafanaNumberColumn(text="kld_sum"),
-            GrafanaNumberColumn(text="kld_mean"),
-        ]
+    warnings.warn(
+        "This api is deprecated in 1.3.1 and will be removed in 1.5.0. "
+        "Please update grafana model monitoring dashboards that use a different data source",
+        # TODO: remove in 1.5.0
+        FutureWarning,
     )
 
-    if endpoint.status.drift_measures:
-        table.add_row(
-            endpoint.status.drift_measures.get("tvd_sum"),
-            endpoint.status.drift_measures.get("tvd_mean"),
-            endpoint.status.drift_measures.get("hellinger_sum"),
-            endpoint.status.drift_measures.get("hellinger_mean"),
-            endpoint.status.drift_measures.get("kld_sum"),
-            endpoint.status.drift_measures.get("kld_mean"),
-        )
-
-    return [table]
-
-
-async def grafana_incoming_features(
-    body: Dict[str, Any],
-    query_parameters: Dict[str, str],
-    auth_info: mlrun.api.schemas.AuthInfo,
-):
-    endpoint_id = query_parameters.get("endpoint_id")
-    project = query_parameters.get("project")
-    start = body.get("rangeRaw", {}).get("from", "now-1h")
-    end = body.get("rangeRaw", {}).get("to", "now")
-
-    await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_resource_permissions(
-        mlrun.api.schemas.AuthorizationResourceTypes.model_endpoint,
-        project,
-        endpoint_id,
-        mlrun.api.schemas.AuthorizationAction.read,
-        auth_info,
+    body = await request.json()
+    query_parameters = mlrun.api.crud.model_monitoring.grafana.parse_query_parameters(
+        body
     )
-
-    endpoint = await run_in_threadpool(
-        mlrun.api.crud.ModelEndpoints().get_model_endpoint,
-        auth_info=auth_info,
-        project=project,
-        endpoint_id=endpoint_id,
+    mlrun.api.crud.model_monitoring.grafana.validate_query_parameters(
+        query_parameters, SUPPORTED_QUERY_FUNCTIONS
     )
-
-    time_series = []
-
-    feature_names = endpoint.spec.feature_names
-
-    if not feature_names:
-        logger.warn(
-            "'feature_names' is either missing or not initialized in endpoint record",
-            endpoint_id=endpoint.metadata.uid,
+    query_parameters = (
+        mlrun.api.crud.model_monitoring.grafana.drop_grafana_escape_chars(
+            query_parameters
         )
-        return time_series
-
-    path = config.model_endpoint_monitoring.store_prefixes.default.format(
-        project=project, kind=mlrun.api.schemas.ModelMonitoringStoreKinds.EVENTS
-    )
-    _, container, path = parse_model_endpoint_store_prefix(path)
-
-    client = get_frames_client(
-        token=auth_info.data_session,
-        address=config.v3io_framesd,
-        container=container,
-    )
-
-    data: pd.DataFrame = await run_in_threadpool(
-        client.read,
-        backend="tsdb",
-        table=path,
-        columns=feature_names,
-        filter=f"endpoint_id=='{endpoint_id}'",
-        start=start,
-        end=end,
     )
 
-    data.drop(["endpoint_id"], axis=1, inplace=True, errors="ignore")
-    data.index = data.index.astype(np.int64) // 10**6
-
-    for feature, indexed_values in data.to_dict().items():
-        target = GrafanaTimeSeriesTarget(target=feature)
-        for index, value in indexed_values.items():
-            data_point = GrafanaDataPoint(value=float(value), timestamp=index)
-            target.add_data_point(data_point)
-        time_series.append(target)
-
-    return time_series
-
-
-def _parse_query_parameters(request_body: Dict[str, Any]) -> Dict[str, str]:
-    """
-    This function searches for the target field in Grafana's SimpleJson json. Once located, the target string is
-    parsed by splitting on semi-colons (;). Each part in the resulting list is then split by an equal sign (=) to be
-    read as key-value pairs.
-    """
-
-    # Try to get the target
-    targets = request_body.get("targets", [])
-
-    if len(targets) > 1:
-        logger.warn(
-            f"The 'targets' list contains more then one element ({len(targets)}), all targets except the first one are "
-            f"ignored."
-        )
-
-    target_obj = targets[0] if targets else {}
-    target_query = target_obj.get("target") if target_obj else ""
-
-    if not target_query:
-        raise MLRunBadRequestError(f"Target missing in request body:\n {request_body}")
-
-    parameters = _parse_parameters(target_query)
-
-    return parameters
-
-
-def _parse_search_parameters(request_body: Dict[str, Any]) -> Dict[str, str]:
-    """
-    This function searches for the target field in Grafana's SimpleJson json. Once located, the target string is
-    parsed by splitting on semi-colons (;). Each part in the resulting list is then split by an equal sign (=) to be
-    read as key-value pairs.
-    """
-
-    # Try to get the target
-    target = request_body.get("target")
-
-    if not target:
-        raise MLRunBadRequestError(f"Target missing in request body:\n {request_body}")
-
-    parameters = _parse_parameters(target)
-
-    return parameters
-
-
-def _parse_parameters(target_query):
-    parameters = {}
-    for query in filter(lambda q: q, target_query.split(";")):
-        query_parts = query.split("=")
-        if len(query_parts) < 2:
-            raise MLRunBadRequestError(
-                f"Query must contain both query key and query value. Expected query_key=query_value, found {query} "
-                f"instead."
-            )
-        parameters[query_parts[0]] = query_parts[1]
-    return parameters
-
-
-def _drop_grafana_escape_chars(query_parameters: Dict[str, str]):
-    query_parameters = dict(query_parameters)
-    endpoint_id = query_parameters.get("endpoint_id")
-    if endpoint_id is not None:
-        query_parameters["endpoint_id"] = endpoint_id.replace("\\", "")
-    return query_parameters
-
-
-def _validate_query_parameters(
-    query_parameters: Dict[str, str], supported_endpoints: Optional[Set[str]] = None
-):
-    """Validates the parameters sent via Grafana's SimpleJson query"""
-    if "target_endpoint" not in query_parameters:
-        raise MLRunBadRequestError(
-            f"Expected 'target_endpoint' field in query, found {query_parameters} instead"
-        )
-
-    if (
-        supported_endpoints is not None
-        and query_parameters["target_endpoint"] not in supported_endpoints
-    ):
-        raise MLRunBadRequestError(
-            f"{query_parameters['target_endpoint']} unsupported in query parameters: {query_parameters}. "
-            f"Currently supports: {','.join(supported_endpoints)}"
-        )
-
-
-def _json_loads_or_default(string: Optional[str], default: Any):
-    if string is None:
-        return default
-    obj = json.loads(string)
-    if not obj:
-        return default
-    return obj
-
-
-NAME_TO_QUERY_FUNCTION_DICTIONARY = {
-    "list_endpoints": grafana_list_endpoints,
-    "individual_feature_analysis": grafana_individual_feature_analysis,
-    "overall_feature_analysis": grafana_overall_feature_analysis,
-    "incoming_features": grafana_incoming_features,
-}
-
-NAME_TO_SEARCH_FUNCTION_DICTIONARY = {
-    "list_projects": grafana_list_projects,
-}
-
-SUPPORTED_QUERY_FUNCTIONS = set(NAME_TO_QUERY_FUNCTION_DICTIONARY.keys())
-SUPPORTED_SEARCH_FUNCTIONS = set(NAME_TO_SEARCH_FUNCTION_DICTIONARY)
+    # At this point everything is validated and we can access everything that is needed without performing all previous
+    # checks again.
+    target_endpoint = query_parameters["target_endpoint"]
+    function = NAME_TO_QUERY_FUNCTION_DICTIONARY[target_endpoint]
+    if asyncio.iscoroutinefunction(function):
+        return await function(body, query_parameters, auth_info)
+    result = await run_in_threadpool(function, body, query_parameters, auth_info)
+    return result
```

## mlrun/api/api/endpoints/logs.py

```diff
@@ -68,18 +68,18 @@
     await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_resource_permissions(
         mlrun.api.schemas.AuthorizationResourceTypes.log,
         project,
         uid,
         mlrun.api.schemas.AuthorizationAction.read,
         auth_info,
     )
-    run_state, log = await run_in_threadpool(
-        mlrun.api.crud.Logs().get_logs, db_session, project, uid, size, offset
+    run_state, log_stream = await mlrun.api.crud.Logs().get_logs(
+        db_session, project, uid, size, offset
     )
     headers = {
         "x-mlrun-run-state": run_state,
-        # pod_status was changed x-mlrun-run-state in 0.5.3, keeping it here for backwards compatibility (so <0.5.3
-        # clients will work with the API)
-        # TODO: remove this in 0.7.0
-        "pod_status": run_state,
     }
-    return fastapi.Response(content=log, media_type="text/plain", headers=headers)
+    return fastapi.responses.StreamingResponse(
+        log_stream,
+        media_type="text/plain",
+        headers=headers,
+    )
```

## mlrun/api/api/endpoints/model_endpoints.py

```diff
@@ -29,35 +29,35 @@
 from mlrun.errors import MLRunConflictError
 
 router = APIRouter()
 
 
 @router.put(
     "/projects/{project}/model-endpoints/{endpoint_id}",
-    status_code=HTTPStatus.NO_CONTENT.value,
+    response_model=mlrun.api.schemas.ModelEndpoint,
 )
 async def create_or_patch(
     project: str,
     endpoint_id: str,
     model_endpoint: mlrun.api.schemas.ModelEndpoint,
     auth_info: mlrun.api.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
     ),
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
-):
+) -> mlrun.api.schemas.ModelEndpoint:
     """
-    Either create or updates the record of a given ModelEndpoint object.
+    Either create or update the record of a given `ModelEndpoint` object.
     Leaving here for backwards compatibility.
     """
 
     warnings.warn(
         "This PUT call is deprecated, please use POST for create or PATCH for update"
         "This will be removed in 1.5.0",
         # TODO: Remove this API in 1.5.0
-        PendingDeprecationWarning,
+        FutureWarning,
     )
 
     await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_resource_permissions(
         mlrun.api.schemas.AuthorizationResourceTypes.model_endpoint,
         project,
         endpoint_id,
         mlrun.api.schemas.AuthorizationAction.store,
@@ -72,15 +72,15 @@
     if endpoint_id != model_endpoint.metadata.uid:
         raise MLRunConflictError(
             f"Mismatch between endpoint_id {endpoint_id} and ModelEndpoint.metadata.uid {model_endpoint.metadata.uid}."
             f"\nMake sure the supplied function_uri, and model are configured as intended"
         )
     # Since the endpoint records are created automatically, at point of serving function deployment, we need to use
     # V3IO_ACCESS_KEY here
-    await run_in_threadpool(
+    return await run_in_threadpool(
         mlrun.api.crud.ModelEndpoints().create_or_patch,
         db_session=db_session,
         access_key=os.environ.get("V3IO_ACCESS_KEY"),
         model_endpoint=model_endpoint,
         auth_info=auth_info,
     )
 
@@ -95,26 +95,27 @@
     model_endpoint: mlrun.api.schemas.ModelEndpoint,
     auth_info: mlrun.api.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
     ),
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
 ) -> mlrun.api.schemas.ModelEndpoint:
     """
-    Create a DB record of a given ModelEndpoint object.
+    Create a DB record of a given `ModelEndpoint` object.
 
     :param project:         The name of the project.
     :param endpoint_id:     The unique id of the model endpoint.
     :param model_endpoint:  Model endpoint object to record in DB.
     :param auth_info:       The auth info of the request.
     :param db_session:      A session that manages the current dialog with the database. When creating a new model
                             endpoint id record, we need to use the db session for getting information from an existing
                             model artifact and also for storing the new model monitoring feature set.
 
     :return: A Model endpoint object.
     """
+
     await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_resource_permissions(
         resource_type=mlrun.api.schemas.AuthorizationResourceTypes.model_endpoint,
         project_name=project,
         resource_name=endpoint_id,
         action=mlrun.api.schemas.AuthorizationAction.store,
         auth_info=auth_info,
     )
@@ -145,22 +146,21 @@
     endpoint_id: str,
     attributes: str = None,
     auth_info: mlrun.api.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
     ),
 ) -> mlrun.api.schemas.ModelEndpoint:
     """
-    Update a DB record of a given ModelEndpoint object.
+    Update a DB record of a given `ModelEndpoint` object.
 
     :param project:       The name of the project.
     :param endpoint_id:   The unique id of the model endpoint.
     :param attributes:    Attributes that will be updated. The input is provided in a json structure that will be
                           converted into a dictionary before applying the patch process. Note that the keys of
-                          dictionary should exist in the DB target. More details about the model endpoint available
-                          attributes can be found under :py:class:`~mlrun.api.schemas.ModelEndpoint`.
+                          the dictionary should exist in the DB target.
 
                           example::
 
                           attributes = {"drift_status": "POSSIBLE_DRIFT", "state": "new_state"}
 
     :param auth_info:     The auth info of the request.
 
@@ -241,15 +241,15 @@
     ),
 ) -> mlrun.api.schemas.ModelEndpointList:
     """
     Returns a list of endpoints of type 'ModelEndpoint', supports filtering by model, function, tag,
     labels or top level. By default, when no filters are applied, all available endpoints for the given project will be
     listed.
 
-    If uids are passed: will return ModelEndpointList of endpoints with uid in uids
+    If uids are passed: will return `ModelEndpointList` of endpoints with uid in uids
     Labels can be used to filter on the existence of a label:
     api/projects/{project}/model-endpoints/?label=mylabel
 
     Or on the value of a given label:
     api/projects/{project}/model-endpoints/?label=mylabel=1
 
     Multiple labels can be queried in a single request by either using "&" separator:
@@ -260,29 +260,29 @@
     Top level: if true will return only routers and endpoint that are NOT children of any router
 
     :param auth_info: The auth info of the request.
     :param project:   The name of the project.
     :param model:     The name of the model to filter by.
     :param function:  The name of the function to filter by.
     :param labels:    A list of labels to filter by. Label filters work by either filtering a specific value of a label
-                      (i.e. list("key==value")) or by looking for the existence of a given key (i.e. "key").
-    :param metrics:   A list of metrics to return for each endpoint. There are pre-defined metrics for model endpoints
-                      such as predictions_per_second and latency_avg_5m but also custom metrics defined by the user.
-                      Please note that these metrics are stored in the time series DB and the results will be appeared
-                      under model_endpoint.spec.metrics of each endpoint.
+                      (i.e. list("key=value")) or by looking for the existence of a given key (i.e. "key").
+    :param metrics:   A list of real-time metrics to return for each endpoint. There are pre-defined real-time metrics
+                      for model endpoints such as predictions_per_second and latency_avg_5m but also custom metrics
+                      defined by the user. Please note that these metrics are stored in the time series DB and the
+                      results will be appeared under model_endpoint.spec.metrics of each endpoint.
     :param start:     The start time of the metrics. Can be represented by a string containing an RFC 3339
                       time, a Unix timestamp in milliseconds, a relative time (`'now'` or `'now-[0-9]+[mhd]'`, where
                       `m` = minutes, `h` = hours, and `'d'` = days), or 0 for the earliest time.
     :param end:       The end time of the metrics. Can be represented by a string containing an RFC 3339
                       time, a Unix timestamp in milliseconds, a relative time (`'now'` or `'now-[0-9]+[mhd]'`, where
                       `m` = minutes, `h` = hours, and `'d'` = days), or 0 for the earliest time.
     :param top_level: If True will return only routers and endpoint that are NOT children of any router.
-    :param uids:      Will return ModelEndpointList of endpoints with uid in uids.
+    :param uids:      Will return `ModelEndpointList` of endpoints with uid in uids.
 
-    :return: An object of ModelEndpointList which is literally a list of model endpoints along with some metadata. To
+    :return: An object of `ModelEndpointList` which is literally a list of model endpoints along with some metadata. To
              get a standard list of model endpoints use ModelEndpointList.endpoints.
     """
 
     await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_permissions(
         project_name=project,
         action=mlrun.api.schemas.AuthorizationAction.read,
         auth_info=auth_info,
@@ -329,31 +329,35 @@
     auth_info: mlrun.api.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
     ),
 ) -> mlrun.api.schemas.ModelEndpoint:
     """Get a single model endpoint object. You can apply different time series metrics that will be added to the
        result.
 
-    :param project:          The name of the project.
-    :param endpoint_id:      The unique id of the model endpoint.
-    :param start:            The start time of the metrics. Can be represented by a string containing an RFC 3339
-                             time, a Unix timestamp in milliseconds, a relative time (`'now'` or `'now-[0-9]+[mhd]'`,
-                             where `m` = minutes, `h` = hours, and `'d'` = days), or 0 for the earliest time.
-    :param end:              The end time of the metrics. Can be represented by a string containing an RFC 3339
-                             time, a Unix timestamp in milliseconds, a relative time (`'now'` or `'now-[0-9]+[mhd]'`,
-                             where `m` = minutes, `h` = hours, and `'d'` = days), or 0 for the earliest time.
-    :param metrics:          A list of metrics to return for the model endpoint. There are pre-defined metrics for model
-                             endpoints such as predictions_per_second and latency_avg_5m but also custom metrics
-                             defined by the user. Please note that these metrics are stored in the time series DB and
-                             the results will be appeared under model_endpoint.spec.metrics.
-    :param feature_analysis: When True, the base feature statistics and current feature statistics will be added to
-                             the output of the resulting object.
-    :param auth_info:        The auth info of the request.
 
-    :return: A ModelEndpoint object.
+    :param project:                    The name of the project
+    :param endpoint_id:                The unique id of the model endpoint.
+    :param start:                      The start time of the metrics. Can be represented by a string containing an
+                                       RFC 3339 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
+                                       `'now-[0-9]+[mhd]'`, where `m` = minutes, `h` = hours, and `'d'` = days), or
+                                       0 for the earliest time.
+    :param end:                        The end time of the metrics. Can be represented by a string containing an
+                                       RFC 3339 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
+                                       `'now-[0-9]+[mhd]'`, where `m` = minutes, `h` = hours, and `'d'` = days), or
+                                       0 for the earliest time.
+    :param metrics:                    A list of real-time metrics to return for the model endpoint. There are
+                                       pre-defined real-time metrics for model endpoints such as predictions_per_second
+                                       and latency_avg_5m but also custom metrics defined by the user. Please note that
+                                       these metrics are stored in the time series DB and the results will be
+                                       appeared under model_endpoint.spec.metrics.
+    :param feature_analysis:           When True, the base feature statistics and current feature statistics will
+                                       be added to the output of the resulting object.
+    :param auth_info:                  The auth info of the request
+
+    :return:  A `ModelEndpoint` object.
     """
     await mlrun.api.utils.auth.verifier.AuthVerifier().query_project_resource_permissions(
         mlrun.api.schemas.AuthorizationResourceTypes.model_endpoint,
         project,
         endpoint_id,
         mlrun.api.schemas.AuthorizationAction.read,
         auth_info,
```

## mlrun/api/api/endpoints/pipelines.py

```diff
@@ -95,38 +95,14 @@
     return mlrun.api.schemas.PipelinesOutput(
         runs=allowed_runs,
         total_size=total_size or 0,
         next_page_token=next_page_token or None,
     )
 
 
-@router.post("/submit_pipeline")
-@router.post("/submit_pipeline/")
-# TODO: remove when 0.6.6 is no longer relevant
-async def submit_pipeline_legacy(
-    request: Request,
-    namespace: str = None,
-    experiment_name: str = Query("Default", alias="experiment"),
-    run_name: str = Query("", alias="run"),
-    auth_info: mlrun.api.schemas.AuthInfo = Depends(
-        mlrun.api.api.deps.authenticate_request
-    ),
-):
-    if namespace is None:
-        namespace = config.namespace
-    response = await _create_pipeline(
-        auth_info,
-        request,
-        namespace,
-        experiment_name,
-        run_name,
-    )
-    return response
-
-
 @router.post("/projects/{project}/pipelines")
 async def create_pipeline(
     project: str,
     request: Request,
     namespace: str = None,
     experiment_name: str = Query("Default", alias="experiment"),
     run_name: str = Query("", alias="run"),
@@ -181,16 +157,15 @@
             project,
             "",
             mlrun.api.schemas.AuthorizationAction.create,
             auth_info,
         )
 
     arguments = {}
-    # TODO: stop reading "pipeline-arguments" header when 0.6.6 is no longer relevant
-    arguments_data = request.headers.get("pipeline-arguments") or request.headers.get(
+    arguments_data = request.headers.get(
         mlrun.api.schemas.HeaderNames.pipeline_arguments
     )
     if arguments_data:
         arguments = ast.literal_eval(arguments_data)
 
     run = await run_in_threadpool(
         mlrun.api.crud.Pipelines().create_pipeline,
@@ -219,28 +194,14 @@
         return None
     workflow_manifest = yaml.load(data, Loader=yaml.FullLoader)
     return mlrun.api.crud.Pipelines().resolve_project_from_workflow_manifest(
         workflow_manifest
     )
 
 
-@router.get("/pipelines/{run_id}")
-@router.get("/pipelines/{run_id}/")
-# TODO: remove when 0.6.6 is no longer relevant
-async def get_pipeline_legacy(
-    run_id: str,
-    namespace: str = Query(config.namespace),
-    auth_info: mlrun.api.schemas.AuthInfo = Depends(
-        mlrun.api.api.deps.authenticate_request
-    ),
-    db_session: Session = Depends(deps.get_db_session),
-):
-    return await _get_pipeline_without_project(db_session, auth_info, run_id, namespace)
-
-
 @router.get("/projects/{project}/pipelines/{run_id}")
 async def get_pipeline(
     run_id: str,
     project: str,
     namespace: str = Query(config.namespace),
     format_: mlrun.api.schemas.PipelinesFormat = Query(
         mlrun.api.schemas.PipelinesFormat.summary, alias="format"
```

## mlrun/api/api/endpoints/projects.py

```diff
@@ -201,14 +201,15 @@
         deletion_strategy,
         auth_info.projects_role,
         auth_info,
         wait_for_completion=wait_for_completion,
     )
     if is_running_in_background:
         return fastapi.Response(status_code=http.HTTPStatus.ACCEPTED.value)
+    await get_project_member().post_delete_project(name)
     return fastapi.Response(status_code=http.HTTPStatus.NO_CONTENT.value)
 
 
 @router.get("/projects", response_model=mlrun.api.schemas.ProjectsOutput)
 async def list_projects(
     format_: mlrun.api.schemas.ProjectsFormat = fastapi.Query(
         mlrun.api.schemas.ProjectsFormat.full, alias="format"
```

## mlrun/api/api/endpoints/runtime_resources.py

```diff
@@ -25,25 +25,14 @@
 import mlrun.api.crud
 import mlrun.api.schemas
 import mlrun.api.utils.auth.verifier
 
 router = fastapi.APIRouter()
 
 
-@router.get("/runtimes", response_model=mlrun.api.schemas.RuntimeResourcesOutput)
-# TODO: remove when 0.6.6 is no longer relevant
-async def list_runtime_resources_legacy(
-    label_selector: str = None,
-    auth_info: mlrun.api.schemas.AuthInfo = fastapi.Depends(
-        mlrun.api.api.deps.authenticate_request
-    ),
-):
-    await _list_runtime_resources("*", auth_info, label_selector)
-
-
 @router.get(
     "/projects/{project}/runtime-resources",
     response_model=typing.Union[
         mlrun.api.schemas.RuntimeResourcesOutput,
         mlrun.api.schemas.GroupedByJobRuntimeResourcesOutput,
         mlrun.api.schemas.GroupedByProjectRuntimeResourcesOutput,
     ],
@@ -61,34 +50,14 @@
     ),
 ):
     return await _list_runtime_resources(
         project, auth_info, label_selector, group_by, kind, object_id
     )
 
 
-@router.get("/runtimes/{kind}", response_model=mlrun.api.schemas.KindRuntimeResources)
-# TODO: remove when 0.6.6 is no longer relevant
-async def list_runtime_resources_by_kind_legacy(
-    kind: str,
-    label_selector: str = None,
-    auth_info: mlrun.api.schemas.AuthInfo = fastapi.Depends(
-        mlrun.api.api.deps.authenticate_request
-    ),
-):
-    runtime_resources_output = await _list_runtime_resources(
-        "*", auth_info, label_selector, kind_filter=kind
-    )
-    if runtime_resources_output:
-        return runtime_resources_output[0]
-    else:
-        return mlrun.api.schemas.KindRuntimeResources(
-            kind=kind, resources=mlrun.api.schemas.RuntimeResources()
-        )
-
-
 @router.delete(
     "/projects/{project}/runtime-resources",
     response_model=mlrun.api.schemas.GroupedByProjectRuntimeResourcesOutput,
 )
 async def delete_runtime_resources(
     project: str,
     label_selector: typing.Optional[str] = fastapi.Query(None, alias="label-selector"),
@@ -113,94 +82,14 @@
         kind,
         object_id,
         force,
         grace_period,
     )
 
 
-@router.delete("/runtimes", status_code=http.HTTPStatus.NO_CONTENT.value)
-# TODO: remove when 0.6.6 is no longer relevant
-async def delete_runtimes_legacy(
-    label_selector: str = None,
-    force: bool = False,
-    grace_period: int = mlrun.mlconf.runtime_resources_deletion_grace_period,
-    auth_info: mlrun.api.schemas.AuthInfo = fastapi.Depends(
-        mlrun.api.api.deps.authenticate_request
-    ),
-    db_session: sqlalchemy.orm.Session = fastapi.Depends(
-        mlrun.api.api.deps.get_db_session
-    ),
-):
-    return await _delete_runtime_resources(
-        db_session,
-        auth_info,
-        "*",
-        label_selector,
-        force=force,
-        grace_period=grace_period,
-        return_body=False,
-    )
-
-
-@router.delete("/runtimes/{kind}", status_code=http.HTTPStatus.NO_CONTENT.value)
-# TODO: remove when 0.6.6 is no longer relevant
-async def delete_runtime_legacy(
-    kind: str,
-    label_selector: str = None,
-    force: bool = False,
-    grace_period: int = mlrun.mlconf.runtime_resources_deletion_grace_period,
-    auth_info: mlrun.api.schemas.AuthInfo = fastapi.Depends(
-        mlrun.api.api.deps.authenticate_request
-    ),
-    db_session: sqlalchemy.orm.Session = fastapi.Depends(
-        mlrun.api.api.deps.get_db_session
-    ),
-):
-    return await _delete_runtime_resources(
-        db_session,
-        auth_info,
-        "*",
-        label_selector,
-        kind,
-        force=force,
-        grace_period=grace_period,
-        return_body=False,
-    )
-
-
-@router.delete(
-    "/runtimes/{kind}/{object_id}", status_code=http.HTTPStatus.NO_CONTENT.value
-)
-# TODO: remove when 0.6.6 is no longer relevant
-async def delete_runtime_object_legacy(
-    kind: str,
-    object_id: str,
-    label_selector: str = None,
-    force: bool = False,
-    grace_period: int = mlrun.mlconf.runtime_resources_deletion_grace_period,
-    auth_info: mlrun.api.schemas.AuthInfo = fastapi.Depends(
-        mlrun.api.api.deps.authenticate_request
-    ),
-    db_session: sqlalchemy.orm.Session = fastapi.Depends(
-        mlrun.api.api.deps.get_db_session
-    ),
-):
-    return await _delete_runtime_resources(
-        db_session,
-        auth_info,
-        "*",
-        label_selector,
-        kind,
-        object_id,
-        force,
-        grace_period,
-        return_body=False,
-    )
-
-
 async def _delete_runtime_resources(
     db_session: sqlalchemy.orm.Session,
     auth_info: mlrun.api.schemas.AuthInfo,
     project: str,
     label_selector: typing.Optional[str] = None,
     kind: typing.Optional[str] = None,
     object_id: typing.Optional[str] = None,
```

## mlrun/api/api/endpoints/submit.py

```diff
@@ -39,14 +39,17 @@
     request: Request,
     username: Optional[str] = Header(None, alias="x-remote-user"),
     auth_info: mlrun.api.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
     client_version: Optional[str] = Header(
         None, alias=mlrun.api.schemas.HeaderNames.client_version
     ),
+    client_python_version: Optional[str] = Header(
+        None, alias=mlrun.api.schemas.HeaderNames.python_version
+    ),
 ):
     data = None
     try:
         data = await request.json()
     except ValueError:
         mlrun.api.api.utils.log_and_raise(
             HTTPStatus.BAD_REQUEST.value, reason="bad JSON body"
@@ -114,13 +117,19 @@
             # TODO: remove this duplication
             labels.setdefault("v3io_user", username)
             labels.setdefault("owner", username)
 
     client_version = client_version or data["task"]["metadata"].get("labels", {}).get(
         "mlrun/client_version"
     )
+    client_python_version = client_python_version or data["task"]["metadata"].get(
+        "labels", {}
+    ).get("mlrun/client_python_version")
     if client_version is not None:
         data["task"]["metadata"].setdefault("labels", {}).update(
             {"mlrun/client_version": client_version}
         )
-    logger.info("Submitting run", data=data)
+    if client_python_version is not None:
+        data["task"]["metadata"].setdefault("labels", {}).update(
+            {"mlrun/client_python_version": client_python_version}
+        )
     return await mlrun.api.api.utils.submit_run(db_session, auth_info, data)
```

## mlrun/api/crud/__init__.py

```diff
@@ -8,21 +8,23 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from .artifacts import Artifacts  # noqa: F401
-from .client_spec import ClientSpec  # noqa: F401
-from .clusterization_spec import ClusterizationSpec  # noqa: F401
-from .feature_store import FeatureStore  # noqa: F401
-from .functions import Functions  # noqa: F401
-from .logs import Logs  # noqa: F401
-from .marketplace import Marketplace  # noqa: F401
-from .model_monitoring import ModelEndpoints, ModelEndpointStoreType  # noqa: F401
-from .pipelines import Pipelines  # noqa: F401
-from .projects import Projects  # noqa: F401
-from .runs import Runs  # noqa: F401
-from .runtime_resources import RuntimeResources  # noqa: F401
-from .secrets import Secrets, SecretsClientType  # noqa: F401
-from .tags import Tags  # noqa: F401
+# flake8: noqa: F401  - this is until we take care of the F401 violations with respect to __all__ & sphinx
+
+from .artifacts import Artifacts
+from .client_spec import ClientSpec
+from .clusterization_spec import ClusterizationSpec
+from .feature_store import FeatureStore
+from .functions import Functions
+from .logs import Logs
+from .marketplace import Marketplace
+from .model_monitoring import ModelEndpoints
+from .pipelines import Pipelines
+from .projects import Projects
+from .runs import Runs
+from .runtime_resources import RuntimeResources
+from .secrets import Secrets, SecretsClientType
+from .tags import Tags
```

## mlrun/api/crud/client_spec.py

```diff
@@ -17,37 +17,44 @@
 from mlrun.config import Config, config, default_config
 from mlrun.runtimes.utils import resolve_mpijob_crd_version, resolve_nuclio_version
 
 
 class ClientSpec(
     metaclass=mlrun.utils.singleton.Singleton,
 ):
-    def get_client_spec(self):
+    def get_client_spec(
+        self, client_version: str = None, client_python_version: str = None
+    ):
         mpijob_crd_version = resolve_mpijob_crd_version(api_context=True)
         return mlrun.api.schemas.ClientSpec(
             version=config.version,
             namespace=config.namespace,
             docker_registry=config.httpdb.builder.docker_registry,
             remote_host=config.remote_host,
             mpijob_crd_version=mpijob_crd_version,
             ui_url=config.resolve_ui_url(),
             artifact_path=config.artifact_path,
             spark_app_image=config.spark_app_image,
             spark_app_image_tag=config.spark_app_image_tag,
             spark_history_server_path=config.spark_history_server_path,
-            kfp_image=config.kfp_image,
+            kfp_image=self._resolve_image_by_client_versions(
+                config.kfp_image, client_version, client_python_version
+            ),
             kfp_url=config.resolve_kfp_url(),
-            dask_kfp_image=config.dask_kfp_image,
+            dask_kfp_image=self._resolve_image_by_client_versions(
+                config.dask_kfp_image, client_version, client_python_version
+            ),
             api_url=config.httpdb.api_url,
             nuclio_version=resolve_nuclio_version(),
             spark_operator_version=config.spark_operator_version,
             calculate_artifact_hash=config.artifacts.calculate_hash,
             generate_artifact_target_path_from_artifact_hash=config.artifacts.generate_target_path_from_artifact_hash,
             redis_url=config.redis.url,
             redis_type=config.redis.type,
+            sql_url=config.sql.url,
             # These don't have a default value, but we don't send them if they are not set to allow the client to know
             # when to use server value and when to use client value (server only if set). Since their default value is
             # empty and not set is also empty we can use the same _get_config_value_if_not_default
             default_function_priority_class_name=self._get_config_value_if_not_default(
                 "default_function_priority_class_name"
             ),
             valid_function_priority_class_names=self._get_config_value_if_not_default(
@@ -93,14 +100,37 @@
             logs=self._get_config_value_if_not_default("httpdb.logs"),
             feature_store_data_prefixes=self._get_config_value_if_not_default(
                 "feature_store.data_prefixes"
             ),
         )
 
     @staticmethod
+    def _resolve_image_by_client_versions(
+        image: str, client_version: str = None, client_python_version=None
+    ):
+        """
+        This method main purpose is to provide enriched images for deployment processes which are being executed on
+        client side, such as building a workflow. The whole enrichment and construction of a workflow is being done on
+        client side unlike submitting job where the main enrichment and construction of the resource runtime is being
+        applied on the backend side. Therefore for the workflow case we need to provide it with already enriched
+        images.
+        :param image: image name
+        :param client_version: the client mlrun version
+        :param client_python_version: the client python version
+        :return: enriched image url
+        """
+        try:
+            return mlrun.utils.helpers.enrich_image_url(
+                image, client_version, client_python_version
+            )
+        # if for some reason the user provided un-parsable versions, fall back to resolve version only by server
+        except ValueError:
+            return mlrun.utils.helpers.enrich_image_url(image)
+
+    @staticmethod
     def _get_config_value_if_not_default(config_key):
         config_key_parts = config_key.split(".")
         current_config_value = config
         current_default_config_value = default_config
         for config_key_part in config_key_parts:
             current_config_value = getattr(current_config_value, config_key_part)
             current_default_config_value = current_default_config_value.get(
```

## mlrun/api/crud/functions.py

```diff
@@ -12,14 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import typing
 
 import sqlalchemy.orm
 
+import mlrun.api.api.utils
 import mlrun.api.schemas
 import mlrun.api.utils.projects.remotes.follower
 import mlrun.api.utils.singletons.db
 import mlrun.api.utils.singletons.project_member
 import mlrun.config
 import mlrun.errors
 import mlrun.utils.singleton
@@ -32,16 +33,30 @@
         self,
         db_session: sqlalchemy.orm.Session,
         function: dict,
         name: str,
         project: str = mlrun.mlconf.default_project,
         tag: str = "",
         versioned: bool = False,
+        auth_info: mlrun.api.schemas.AuthInfo = None,
     ) -> str:
         project = project or mlrun.mlconf.default_project
+        if auth_info:
+            function_obj = mlrun.new_function(
+                name=name, project=project, runtime=function, tag=tag
+            )
+            # not raising exception if no access key was provided as the store of the function can be part of
+            # intermediate steps or temporary objects which might not be executed at any phase and therefore we don't
+            # want to enrich if user didn't requested.
+            # (The way user will request to generate is by passing $generate in the metadata.credentials.access_key)
+            mlrun.api.api.utils.ensure_function_auth_and_sensitive_data_is_masked(
+                function_obj, auth_info, allow_empty_access_key=True
+            )
+            function = function_obj.to_dict()
+
         return mlrun.api.utils.singletons.db.get_db().store_function(
             db_session,
             function,
             name,
             project,
             tag,
             versioned,
@@ -73,18 +88,20 @@
     def list_functions(
         self,
         db_session: sqlalchemy.orm.Session,
         project: str = mlrun.mlconf.default_project,
         name: str = "",
         tag: str = "",
         labels: typing.List[str] = None,
+        hash_key: str = "",
     ) -> typing.List:
         project = project or mlrun.mlconf.default_project
         if labels is None:
             labels = []
         return mlrun.api.utils.singletons.db.get_db().list_functions(
-            db_session,
-            name,
-            project,
-            tag,
-            labels,
+            session=db_session,
+            name=name,
+            project=project,
+            tag=tag,
+            labels=labels,
+            hash_key=hash_key,
         )
```

## mlrun/api/crud/logs.py

```diff
@@ -9,21 +9,24 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import os
+import pathlib
 import shutil
 import typing
 from http import HTTPStatus
 
+from fastapi.concurrency import run_in_threadpool
 from sqlalchemy.orm import Session
 
 import mlrun.api.schemas
+import mlrun.api.utils.clients.log_collector as log_collector
 import mlrun.utils.singleton
 from mlrun.api.api.utils import log_and_raise, log_path, project_logs_path
 from mlrun.api.constants import LogSources
 from mlrun.api.utils.singletons.db import get_db
 from mlrun.api.utils.singletons.k8s import get_k8s
 from mlrun.runtimes.constants import PodPhases
 from mlrun.utils import logger
@@ -51,43 +54,137 @@
         project: str,
     ):
         project = project or mlrun.mlconf.default_project
         logs_path = project_logs_path(project)
         if logs_path.exists():
             shutil.rmtree(str(logs_path))
 
-    def get_logs(
+    async def get_logs(
         self,
         db_session: Session,
         project: str,
         uid: str,
         size: int = -1,
         offset: int = 0,
         source: LogSources = LogSources.AUTO,
-    ) -> typing.Tuple[str, bytes]:
+    ) -> typing.Tuple[str, typing.AsyncIterable[bytes]]:
         """
-        :return: Tuple with:
-            1. str of the run state (so watchers will know whether to continue polling for logs)
-            2. bytes of the logs themselves
+        Get logs
+        :param db_session: db session
+        :param project: project name
+        :param uid: run uid
+        :param size: number of bytes to return (default -1, return all)
+        :param offset: number of bytes to skip (default 0)
+        :param source: log source (default auto) Relevant only for legacy log_collector mode
+          if auto, it will use the mode configured in `mlrun.mlconf.log_collector.mode`
+          if other than auto, it will fall back to legacy log_collector mode
+        :return: run state and logs
         """
         project = project or mlrun.mlconf.default_project
-        out = b""
-        log_file = log_path(project, uid)
-        data = get_db().read_run(db_session, uid, project)
-        if not data:
+        run = await self._get_run_for_log(db_session, project, uid)
+        run_state = run.get("status", {}).get("state", "")
+        log_stream = None
+        if (
+            mlrun.mlconf.log_collector.mode
+            == mlrun.api.schemas.LogsCollectorMode.best_effort
+            and source == LogSources.AUTO
+        ):
+            try:
+                log_stream = self._get_logs_from_logs_collector(
+                    project,
+                    uid,
+                    size,
+                    offset,
+                )
+            except Exception as exc:
+                if mlrun.mlconf.log_collector.verbose:
+                    logger.warning(
+                        "Failed to get logs from logs collector, falling back to legacy method",
+                        exc=exc,
+                    )
+                log_stream = self._get_logs_legacy_method_generator_wrapper(
+                    db_session,
+                    project,
+                    uid,
+                    size,
+                    offset,
+                    source,
+                    run,
+                )
+        elif (
+            mlrun.mlconf.log_collector.mode
+            == mlrun.api.schemas.LogsCollectorMode.sidecar
+            and source == LogSources.AUTO
+        ):
+            log_stream = self._get_logs_from_logs_collector(
+                project,
+                uid,
+                size,
+                offset,
+            )
+        elif (
+            mlrun.mlconf.log_collector.mode
+            == mlrun.api.schemas.LogsCollectorMode.legacy
+            or source != LogSources.AUTO
+        ):
+            log_stream = self._get_logs_legacy_method_generator_wrapper(
+                db_session,
+                project,
+                uid,
+                size,
+                offset,
+                source,
+                run,
+            )
+        return run_state, log_stream
+
+    @staticmethod
+    async def _get_logs_from_logs_collector(
+        project: str,
+        run_uid: str,
+        size: int = -1,
+        offset: int = 0,
+    ) -> typing.AsyncIterable[bytes]:
+        log_collector_client = log_collector.LogCollectorClient()
+        async for log in log_collector_client.get_logs(
+            run_uid=run_uid,
+            project=project,
+            size=size,
+            offset=offset,
+        ):
+            yield log
+
+    def _get_logs_legacy_method(
+        self,
+        db_session: Session,
+        project: str,
+        uid: str,
+        size: int = -1,
+        offset: int = 0,
+        source: LogSources = LogSources.AUTO,
+        run: dict = None,
+    ) -> bytes:
+        """
+        :return: bytes of the logs themselves
+        """
+        project = project or mlrun.mlconf.default_project
+        log_contents = b""
+        log_file_exists, log_file = self.log_file_exists_for_run_uid(project, uid)
+        if not run:
+            run = get_db().read_run(db_session, uid, project)
+        if not run:
             log_and_raise(HTTPStatus.NOT_FOUND.value, project=project, uid=uid)
-        run_state = data.get("status", {}).get("state", "")
-        if log_file.exists() and source in [LogSources.AUTO, LogSources.PERSISTENCY]:
+        if log_file_exists and source in [LogSources.AUTO, LogSources.PERSISTENCY]:
             with log_file.open("rb") as fp:
                 fp.seek(offset)
-                out = fp.read(size)
+                log_contents = fp.read(size)
         elif source in [LogSources.AUTO, LogSources.K8S]:
             k8s = get_k8s()
             if k8s and k8s.is_running_inside_kubernetes_cluster():
-                run_kind = data.get("metadata", {}).get("labels", {}).get("kind")
+                run_kind = run.get("metadata", {}).get("labels", {}).get("kind")
                 pods = get_k8s().get_logger_pods(project, uid, run_kind)
                 if pods:
                     if len(pods) > 1:
 
                         # This shouldn't happen, but if it does, we log it here. No need to fail.
                         logger.debug(
                             "Got more than one pod in logger pods result",
@@ -96,26 +193,75 @@
                             project=project,
                             pods=pods,
                         )
                     pod, pod_phase = list(pods.items())[0]
                     if pod_phase != PodPhases.pending:
                         resp = get_k8s().logs(pod)
                         if resp:
-                            out = resp.encode()[offset:]
-        return run_state, out
+                            if size == -1:
+                                log_contents = resp.encode()[offset:]
+                            else:
+                                log_contents = resp.encode()[offset : offset + size]
+        return log_contents
+
+    async def _get_logs_legacy_method_generator_wrapper(
+        self,
+        db_session: Session,
+        project: str,
+        uid: str,
+        size: int = -1,
+        offset: int = 0,
+        source: LogSources = LogSources.AUTO,
+        run: dict = None,
+    ):
+        log_contents = await run_in_threadpool(
+            self._get_logs_legacy_method,
+            db_session,
+            project,
+            uid,
+            size,
+            offset,
+            source,
+            run,
+        )
+        yield log_contents
+
+    @staticmethod
+    async def _get_run_for_log(db_session: Session, project: str, uid: str) -> dict:
+        run = await run_in_threadpool(get_db().read_run, db_session, uid, project)
+        if not run:
+            log_and_raise(HTTPStatus.NOT_FOUND.value, project=project, uid=uid)
+        return run
 
     def get_log_mtime(self, project: str, uid: str) -> int:
         log_file = log_path(project, uid)
         if not log_file.exists():
             raise FileNotFoundError(f"Log file does not exist: {log_file}")
         return log_file.stat().st_mtime
 
-    def log_file_exists(self, project: str, uid: str) -> bool:
-        log_file = log_path(project, uid)
-        return log_file.exists()
+    @staticmethod
+    def log_file_exists_for_run_uid(project: str, uid: str) -> (bool, pathlib.Path):
+        """
+        Checks if the log file exists for the given project and uid
+        There could be two types of log files:
+        1. Log file which was created by the legacy logger with the following file format - project/<run-uid>)
+        2. Log file which was created by the new logger with the following file format- /project/<run-uid>-<pod-name>
+        Therefore, we check if the log file exists for both formats
+        :param project: project name
+        :param uid: run uid
+        :return: True if the log file exists, False otherwise, and the log file path
+        """
+        project_logs_dir = project_logs_path(project)
+        if not project_logs_dir.exists():
+            return False, None
+        for file in os.listdir(str(project_logs_dir)):
+            if file.startswith(uid):
+                return True, project_logs_dir / file
+
+        return False, None
 
     def _list_project_logs_uids(self, project: str) -> typing.List[str]:
         logs_path = project_logs_path(project)
         return [
             file
             for file in os.listdir(str(logs_path))
             if os.path.isfile(os.path.join(str(logs_path), file))
```

## mlrun/api/crud/pipelines.py

```diff
@@ -43,17 +43,17 @@
         namespace: typing.Optional[str] = None,
         sort_by: str = "",
         page_token: str = "",
         filter_: str = "",
         format_: mlrun.api.schemas.PipelinesFormat = mlrun.api.schemas.PipelinesFormat.metadata_only,
         page_size: typing.Optional[int] = None,
     ) -> typing.Tuple[int, typing.Optional[int], typing.List[dict]]:
-        if project != "*" and (page_token or page_size or sort_by):
+        if project != "*" and (page_token or page_size):
             raise mlrun.errors.MLRunInvalidArgumentError(
-                "Filtering by project can not be used together with pagination, or sorting"
+                "Filtering by project can not be used together with pagination"
             )
         if format_ == mlrun.api.schemas.PipelinesFormat.summary:
             # we don't support summary format in list pipelines since the returned runs doesn't include the workflow
             # manifest status that includes the nodes section we use to generate the DAG.
             # (There is a workflow manifest under the run's pipeline_spec field, but it doesn't include the status)
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "Summary format is not supported for list pipelines, use get instead"
@@ -69,14 +69,15 @@
             while page_token is not None:
                 # kfp doesn't allow us to pass both a page_token and the filter. When we have a token from previous
                 # call, we will strip out the filter and use the token to continue (the token contains the details of
                 # the filter that was used to create it)
                 response = kfp_client._run_api.list_runs(
                     page_token=page_token,
                     page_size=mlrun.api.schemas.PipelinesPagination.max_page_size,
+                    sort_by=sort_by,
                     filter=filter_ if page_token == "" else "",
                 )
                 run_dicts.extend([run.to_dict() for run in response.runs or []])
                 page_token = response.next_page_token
             project_runs = []
             for run_dict in run_dicts:
                 run_project = self.resolve_project_from_pipeline(run_dict)
```

## mlrun/api/crud/projects.py

```diff
@@ -135,15 +135,20 @@
         # delete runtime resources
         mlrun.api.crud.RuntimeResources().delete_runtime_resources(
             session,
             label_selector=f"mlrun/project={name}",
             force=True,
         )
 
-        mlrun.api.crud.Logs().delete_logs(name)
+        # log collector service will delete the logs, so we don't need to do it here
+        if (
+            mlrun.mlconf.log_collector.mode
+            == mlrun.api.schemas.LogsCollectorMode.legacy
+        ):
+            mlrun.api.crud.Logs().delete_logs(name)
 
         # delete db resources
         mlrun.api.utils.singletons.db.get_db().delete_project_related_resources(
             session, name
         )
 
         # delete model monitoring resources
@@ -224,31 +229,31 @@
                     schedules_count=project_to_schedule_count.get(project, 0),
                     feature_sets_count=project_to_feature_set_count.get(project, 0),
                     models_count=project_to_models_count.get(project, 0),
                     runs_failed_recent_count=project_to_recent_failed_runs_count.get(
                         project, 0
                     ),
                     runs_running_count=project_to_running_runs_count.get(project, 0),
-                    pipelines_running_count=project_to_running_pipelines_count.get(
-                        project, 0
-                    ),
+                    # project_to_running_pipelines_count is a defaultdict so it will return None if using dict.get()
+                    # and the key wasn't set yet, so we need to use the [] operator to get the default value of the dict
+                    pipelines_running_count=project_to_running_pipelines_count[project],
                 )
             )
         return project_summaries
 
     async def _get_project_resources_counters(
         self,
     ) -> typing.Tuple[
         typing.Dict[str, int],
         typing.Dict[str, int],
         typing.Dict[str, int],
         typing.Dict[str, int],
         typing.Dict[str, int],
         typing.Dict[str, int],
-        typing.Dict[str, int],
+        typing.Dict[str, typing.Union[int, None]],
     ]:
         now = datetime.datetime.now()
         if (
             not self._cache["project_resources_counters"]["ttl"]
             or self._cache["project_resources_counters"]["ttl"] < now
         ):
             logger.debug(
@@ -282,28 +287,41 @@
                 seconds=humanfriendly.parse_timespan(
                     mlrun.mlconf.httpdb.projects.counters_cache_ttl
                 )
             )
             self._cache["project_resources_counters"]["ttl"] = ttl_time
         return self._cache["project_resources_counters"]["result"]
 
+    @staticmethod
+    def _list_pipelines(
+        session,
+        format_: mlrun.api.schemas.PipelinesFormat = mlrun.api.schemas.PipelinesFormat.metadata_only,
+    ):
+        return mlrun.api.crud.Pipelines().list_pipelines(session, "*", format_=format_)
+
     async def _calculate_pipelines_counters(
         self,
-    ) -> typing.Dict[str, int]:
-        def _list_pipelines(session):
-            return mlrun.api.crud.Pipelines().list_pipelines(
-                session, "*", format_=mlrun.api.schemas.PipelinesFormat.metadata_only
-            )
-
-        project_to_running_pipelines_count = collections.defaultdict(int)
+    ) -> typing.Dict[str, typing.Union[int, None]]:
+        # creating defaultdict instead of a regular dict, because it possible that not all projects have pipelines
+        # and we want to return 0 for those projects, or None if we failed to get the information
+        project_to_running_pipelines_count = collections.defaultdict(lambda: 0)
         if not mlrun.mlconf.resolve_kfp_url():
+            # If KFP is not configured, return dict with 0 counters (no running pipelines)
             return project_to_running_pipelines_count
 
-        _, _, pipelines = await fastapi.concurrency.run_in_threadpool(
-            mlrun.api.db.session.run_function_with_new_db_session,
-            _list_pipelines,
-        )
+        try:
+            _, _, pipelines = await fastapi.concurrency.run_in_threadpool(
+                mlrun.api.db.session.run_function_with_new_db_session,
+                self._list_pipelines,
+            )
+        except Exception as exc:
+            # If list pipelines failed, set counters to None (unknown) to indicate that we failed to get the information
+            logger.warning(
+                "Failed to list pipelines. Pipelines counters will be set to None",
+                exc=mlrun.errors.err_to_str(exc),
+            )
+            return collections.defaultdict(lambda: None)
 
         for pipeline in pipelines:
             if pipeline["status"] not in mlrun.run.RunStatuses.stable_statuses():
                 project_to_running_pipelines_count[pipeline["project"]] += 1
         return project_to_running_pipelines_count
```

## mlrun/api/crud/runs.py

```diff
@@ -121,14 +121,16 @@
         last_update_time_from=None,
         last_update_time_to=None,
         partition_by: mlrun.api.schemas.RunPartitionByField = None,
         rows_per_partition: int = 1,
         partition_sort_by: mlrun.api.schemas.SortField = None,
         partition_order: mlrun.api.schemas.OrderType = mlrun.api.schemas.OrderType.desc,
         max_partitions: int = 0,
+        requested_logs: bool = None,
+        return_as_run_structs: bool = True,
     ):
         project = project or mlrun.mlconf.default_project
         return mlrun.api.utils.singletons.db.get_db().list_runs(
             db_session,
             name,
             uid,
             project,
@@ -142,14 +144,16 @@
             last_update_time_from,
             last_update_time_to,
             partition_by,
             rows_per_partition,
             partition_sort_by,
             partition_order,
             max_partitions,
+            requested_logs,
+            return_as_run_structs,
         )
 
     def delete_run(
         self,
         db_session: sqlalchemy.orm.Session,
         uid: str,
         iter: int,
```

## mlrun/api/crud/model_monitoring/__init__.py

```diff
@@ -8,10 +8,10 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
+# flake8: noqa: F401 - this is until we take care of the F401 violations with respect to __all__ & sphinx
 
-from .model_endpoint_store import ModelEndpointStoreType  # noqa: F401
-from .model_endpoints import ModelEndpoints  # noqa: F401
+from .model_endpoints import ModelEndpoints
```

## mlrun/api/crud/model_monitoring/model_endpoints.py

```diff
@@ -8,20 +8,19 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-
-
+import json
 import os
 import typing
+import warnings
 
-import nuclio.utils
 import sqlalchemy.orm
 
 import mlrun.api.api.endpoints.functions
 import mlrun.api.api.utils
 import mlrun.api.schemas
 import mlrun.api.schemas.model_endpoints
 import mlrun.api.utils.singletons.k8s
@@ -32,59 +31,63 @@
 import mlrun.feature_store
 import mlrun.model_monitoring.constants as model_monitoring_constants
 import mlrun.model_monitoring.helpers
 import mlrun.runtimes.function
 import mlrun.utils.helpers
 import mlrun.utils.model_monitoring
 import mlrun.utils.v3io_clients
+from mlrun.model_monitoring.stores import get_model_endpoint_store
 from mlrun.utils import logger
 
-from .model_endpoint_store import get_model_endpoint_target
-
 
 class ModelEndpoints:
     """Provide different methods for handling model endpoints such as listing, writing and deleting"""
 
     def create_or_patch(
         self,
         db_session: sqlalchemy.orm.Session,
         access_key: str,
         model_endpoint: mlrun.api.schemas.ModelEndpoint,
         auth_info: mlrun.api.schemas.AuthInfo = mlrun.api.schemas.AuthInfo(),
     ) -> mlrun.api.schemas.ModelEndpoint:
-        # TODO: deprecated, remove in 1.5.0.
+        # TODO: deprecated in 1.3.0, remove in 1.5.0.
+        warnings.warn(
+            "This is deprecated in 1.3.0, and will be removed in 1.5.0."
+            "Please use create_model_endpoint() for create or patch_model_endpoint() for update",
+            FutureWarning,
+        )
         """
-        Either create or updates the record of a given ModelEndpoint object.
+        Either create or updates the record of a given `ModelEndpoint` object.
         Leaving here for backwards compatibility, remove in 1.5.0.
 
         :param db_session:             A session that manages the current dialog with the database
         :param access_key:             Access key with permission to write to KV table
         :param model_endpoint:         Model endpoint object to update
         :param auth_info:              The auth info of the request
 
-        :return: Model endpoint object.
+        :return: `ModelEndpoint` object.
         """
 
         return self.create_model_endpoint(
             db_session=db_session, model_endpoint=model_endpoint
         )
 
     def create_model_endpoint(
         self,
         db_session: sqlalchemy.orm.Session,
         model_endpoint: mlrun.api.schemas.ModelEndpoint,
     ) -> mlrun.api.schemas.ModelEndpoint:
         """
         Creates model endpoint record in DB. The DB target type is defined under
-        mlrun.config.model_endpoint_monitoring.store_type (KV by default).
+        `mlrun.config.model_endpoint_monitoring.store_type` (V3IO-NOSQL by default).
 
         :param db_session:             A session that manages the current dialog with the database.
         :param model_endpoint:         Model endpoint object to update.
 
-        :return: Model endpoint object.
+        :return: `ModelEndpoint` object.
         """
 
         if model_endpoint.spec.model_uri or model_endpoint.status.feature_stats:
             logger.info(
                 "Getting feature metadata",
                 project=model_endpoint.metadata.project,
                 model=model_endpoint.spec.model,
@@ -104,31 +107,30 @@
                 )
             )
 
             # Get stats from model object if not found in model endpoint object
             if not model_endpoint.status.feature_stats and hasattr(
                 model_obj, "feature_stats"
             ):
-                model_endpoint.status.feature_stats = model_obj.feature_stats
-
+                model_endpoint.status.feature_stats = model_obj.spec.feature_stats
             # Get labels from model object if not found in model endpoint object
-            if not model_endpoint.spec.label_names and hasattr(model_obj, "outputs"):
+            if not model_endpoint.spec.label_names and model_obj.spec.outputs:
                 model_label_names = [
-                    self._clean_feature_name(f.name) for f in model_obj.outputs
+                    self._clean_feature_name(f.name) for f in model_obj.spec.outputs
                 ]
                 model_endpoint.spec.label_names = model_label_names
 
             # Get algorithm from model object if not found in model endpoint object
-            if not model_endpoint.spec.algorithm and hasattr(model_obj, "algorithm"):
-                model_endpoint.spec.algorithm = model_obj.algorithm
+            if not model_endpoint.spec.algorithm and model_obj.spec.algorithm:
+                model_endpoint.spec.algorithm = model_obj.spec.algorithm
 
             # Create monitoring feature set if monitoring found in model endpoint object
             if (
                 model_endpoint.spec.monitoring_mode
-                == mlrun.api.schemas.ModelMonitoringMode.enabled.value
+                == mlrun.model_monitoring.ModelMonitoringMode.enabled.value
             ):
                 monitoring_feature_set = self.create_monitoring_feature_set(
                     model_endpoint, model_obj, db_session, run_db
                 )
                 # Link model endpoint object to feature set URI
                 model_endpoint.status.monitoring_feature_set_uri = (
                     monitoring_feature_set.uri
@@ -155,18 +157,18 @@
             )
 
         # If none of the above was supplied, feature names will be assigned on first contact with the model monitoring
         # system
         logger.info("Creating model endpoint", endpoint_id=model_endpoint.metadata.uid)
 
         # Write the new model endpoint
-        model_endpoint_target = get_model_endpoint_target(
+        model_endpoint_store = get_model_endpoint_store(
             project=model_endpoint.metadata.project,
         )
-        model_endpoint_target.write_model_endpoint(endpoint=model_endpoint)
+        model_endpoint_store.write_model_endpoint(endpoint=model_endpoint.flat_dict())
 
         logger.info("Model endpoint created", endpoint_id=model_endpoint.metadata.uid)
 
         return model_endpoint
 
     @staticmethod
     def create_monitoring_feature_set(
@@ -204,25 +206,25 @@
 
         feature_set.metadata.labels = {
             "endpoint_id": model_endpoint.metadata.uid,
             "model_class": model_endpoint.spec.model_class,
         }
 
         # Add features to the feature set according to the model object
-        if model_obj.inputs.values():
-            for feature in model_obj.inputs.values():
+        if model_obj.spec.inputs:
+            for feature in model_obj.spec.inputs:
                 feature_set.add_feature(
                     mlrun.feature_store.Feature(
                         name=feature.name, value_type=feature.value_type
                     )
                 )
         # Check if features can be found within the feature vector
-        elif model_obj.feature_vector:
+        elif model_obj.spec.feature_vector:
             _, name, _, tag, _ = mlrun.utils.helpers.parse_artifact_uri(
-                model_obj.feature_vector
+                model_obj.spec.feature_vector
             )
             fv = run_db.get_feature_vector(
                 name=name, project=model_endpoint.metadata.project, tag=tag
             )
             for feature in fv.status.features:
                 if feature["name"] != fv.status.label_column:
                     feature_set.add_feature(
@@ -238,19 +240,20 @@
         # Define parquet target for this feature set
         parquet_path = (
             f"v3io:///projects/{model_endpoint.metadata.project}"
             f"/model-endpoints/parquet/key={model_endpoint.metadata.uid}"
         )
         parquet_target = mlrun.datastore.targets.ParquetTarget("parquet", parquet_path)
         driver = mlrun.datastore.targets.get_target_driver(parquet_target, feature_set)
-        driver.update_resource_status("created")
+
         feature_set.set_targets(
             [mlrun.datastore.targets.ParquetTarget(path=parquet_path)],
             with_defaults=False,
         )
+        driver.update_resource_status("created")
 
         # Save the new feature set
         feature_set._override_run_db(db_session)
         feature_set.save()
         logger.info(
             "Monitoring feature set created",
             model_endpoint=model_endpoint.spec.model,
@@ -258,15 +261,15 @@
         )
 
         return feature_set
 
     @staticmethod
     def _validate_length_features_and_labels(model_endpoint):
         """
-        Validate that the length of feature_stats is equal to the length of feature_names and label_names
+        Validate that the length of feature_stats is equal to the length of `feature_names` and `label_names`
 
         :param model_endpoint:    An object representing the model endpoint.
         """
 
         # Getting the length of label names, feature_names and feature_stats
         len_of_label_names = (
             0
@@ -285,16 +288,16 @@
                 f"label_names({len_of_label_names}"
             )
 
     def _adjust_feature_names_and_stats(
         self, model_endpoint
     ) -> typing.Tuple[typing.Dict, typing.List]:
         """
-        Create a clean matching version of feature names for both feature_stats and feature_names. Please note that
-        label names exist only in feature_stats and label_names.
+        Create a clean matching version of feature names for both `feature_stats` and `feature_names`. Please note that
+        label names exist only in `feature_stats` and `label_names`.
 
         :param model_endpoint:    An object representing the model endpoint.
         :return: A tuple of:
              [0] = Dictionary of feature stats with cleaned names
              [1] = List of cleaned feature names
         """
         clean_feature_stats = {}
@@ -309,121 +312,151 @@
                 model_endpoint.spec.label_names
                 and clean_name in model_endpoint.spec.label_names
             ):
                 continue
             clean_feature_names.append(clean_name)
         return clean_feature_stats, clean_feature_names
 
-    @staticmethod
     def patch_model_endpoint(
+        self,
         project: str,
         endpoint_id: str,
         attributes: dict,
     ) -> mlrun.api.schemas.ModelEndpoint:
         """
         Update a model endpoint record with a given attributes.
 
         :param project: The name of the project.
         :param endpoint_id: The unique id of the model endpoint.
         :param attributes: Dictionary of attributes that will be used for update the model endpoint. Note that the keys
-                           of the attributes dictionary should exist in the KV table. More details about the model
+                           of the attributes dictionary should exist in the DB table. More details about the model
                            endpoint available attributes can be found under
                            :py:class:`~mlrun.api.schemas.ModelEndpoint`.
 
-        :return: A patched ModelEndpoint object.
+        :return: A patched `ModelEndpoint` object.
         """
 
-        model_endpoint_target = get_model_endpoint_target(
+        # Generate a model endpoint store object and apply the update process
+        model_endpoint_store = get_model_endpoint_store(
             project=project,
         )
-        model_endpoint_target.update_model_endpoint(
+        model_endpoint_store.update_model_endpoint(
             endpoint_id=endpoint_id, attributes=attributes
         )
 
-        return model_endpoint_target.get_model_endpoint(
-            endpoint_id=endpoint_id, start="now-1h", end="now"
+        logger.info("Model endpoint table updated", endpoint_id=endpoint_id)
+
+        # Get the patched model endpoint record
+        model_endpoint_record = model_endpoint_store.get_model_endpoint(
+            endpoint_id=endpoint_id,
         )
 
+        return self._convert_into_model_endpoint_object(endpoint=model_endpoint_record)
+
     @staticmethod
     def delete_model_endpoint(
         project: str,
         endpoint_id: str,
     ):
         """
         Delete the record of a given model endpoint based on endpoint id.
 
         :param project:     The name of the project.
         :param endpoint_id: The id of the endpoint.
         """
-        model_endpoint_target = get_model_endpoint_target(
+        model_endpoint_store = get_model_endpoint_store(
             project=project,
         )
-        model_endpoint_target.delete_model_endpoint(endpoint_id=endpoint_id)
+        model_endpoint_store.delete_model_endpoint(endpoint_id=endpoint_id)
+
+        logger.info("Model endpoint table cleared", endpoint_id=endpoint_id)
 
-    @staticmethod
     def get_model_endpoint(
+        self,
         auth_info: mlrun.api.schemas.AuthInfo,
         project: str,
         endpoint_id: str,
         metrics: typing.List[str] = None,
         start: str = "now-1h",
         end: str = "now",
         feature_analysis: bool = False,
     ) -> mlrun.api.schemas.ModelEndpoint:
         """Get a single model endpoint object. You can apply different time series metrics that will be added to the
            result.
 
-        :param auth_info: The auth info of the request
-        :param project: The name of the project
-        :param endpoint_id:      The unique id of the model endpoint.
-        :param metrics:          A list of metrics to return for the model endpoint. There are pre-defined metrics for
-                                 model endpoints such as predictions_per_second and latency_avg_5m but also custom
-                                 metrics defined by the user. Please note that these metrics are stored in the time
-                                 series DB and the results will be appeared under model_endpoint.spec.metrics.
-        :param start:            The start time of the metrics. Can be represented by a string containing an RFC 3339
-                                 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
-                                 `'now-[0-9]+[mhd]'`, where `m` = minutes, `h` = hours, and `'d'` =
-                                 days), or 0 for the earliest time.
-        :param end:              The end time of the metrics. Can be represented by a string containing an RFC 3339
-                                 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
-                                 `'now-[0-9]+[mhd]'`, where `m` = minutes, `h` = hours, and `'d'` =
-                                 days), or 0 for the earliest time.
-        :param feature_analysis: When True, the base feature statistics and current feature statistics will be added to
-                                 the output of the resulting object.
+        :param auth_info:                  The auth info of the request
+        :param project:                    The name of the project
+        :param endpoint_id:                The unique id of the model endpoint.
+        :param metrics:                    A list of metrics to return for the model endpoint. There are pre-defined
+                                           metrics for model endpoints such as predictions_per_second and
+                                           latency_avg_5m but also custom metrics defined by the user. Please note that
+                                           these metrics are stored in the time series DB and the results will be
+                                           appeared under `model_endpoint.spec.metrics`.
+        :param start:                      The start time of the metrics. Can be represented by a string containing an
+                                           RFC 3339 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
+                                           `'now-[0-9]+[mhd]'`, where `m` = minutes, `h` = hours, and `'d'` = days), or
+                                           0 for the earliest time.
+        :param end:                        The end time of the metrics. Can be represented by a string containing an
+                                           RFC 3339 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
+                                           `'now-[0-9]+[mhd]'`, where `m` = minutes, `h` = hours, and `'d'` = days), or
+                                           0 for the earliest time.
+        :param feature_analysis:           When True, the base feature statistics and current feature statistics will
+                                           be added to the output of the resulting object.
 
-        :return: A ModelEndpoint object.
+        :return: A `ModelEndpoint` object.
         """
 
-        model_endpoint_target = get_model_endpoint_target(
+        logger.info(
+            "Getting model endpoint record from DB",
+            endpoint_id=endpoint_id,
+        )
+
+        # Generate a model endpoint store object and get the model endpoint record as a dictionary
+        model_endpoint_store = get_model_endpoint_store(
             project=project, access_key=auth_info.data_session
         )
-        return model_endpoint_target.get_model_endpoint(
+
+        model_endpoint_record = model_endpoint_store.get_model_endpoint(
             endpoint_id=endpoint_id,
-            metrics=metrics,
-            start=start,
-            end=end,
-            feature_analysis=feature_analysis,
         )
 
-    @staticmethod
+        # Convert to `ModelEndpoint` object
+        model_endpoint_object = self._convert_into_model_endpoint_object(
+            endpoint=model_endpoint_record, feature_analysis=feature_analysis
+        )
+
+        # If time metrics were provided, retrieve the results from the time series DB
+        if metrics:
+            self._add_real_time_metrics(
+                model_endpoint_store=model_endpoint_store,
+                model_endpoint_object=model_endpoint_object,
+                metrics=metrics,
+                start=start,
+                end=end,
+            )
+
+        return model_endpoint_object
+
     def list_model_endpoints(
+        self,
         auth_info: mlrun.api.schemas.AuthInfo,
         project: str,
         model: str = None,
         function: str = None,
         labels: typing.List[str] = None,
         metrics: typing.List[str] = None,
         start: str = "now-1h",
         end: str = "now",
         top_level: bool = False,
         uids: typing.List[str] = None,
-    ) -> mlrun.api.schemas.model_endpoints.ModelEndpointList:
+    ) -> mlrun.api.schemas.ModelEndpointList:
         """
-        Returns a list of ModelEndpointState objects. Each object represents the current state of a model endpoint.
-        This functions supports filtering by the following parameters:
+        Returns a list of `ModelEndpoint` objects, wrapped in `ModelEndpointList` object. Each `ModelEndpoint`
+        object represents the current state of a model endpoint. This functions supports filtering by the following
+        parameters:
         1) model
         2) function
         3) labels
         4) top level
         5) uids
         By default, when no filters are applied, all available endpoints for the given project will be listed.
 
@@ -432,30 +465,30 @@
         added to the output of this function.
 
         :param auth_info: The auth info of the request.
         :param project:   The name of the project.
         :param model:     The name of the model to filter by.
         :param function:  The name of the function to filter by.
         :param labels:    A list of labels to filter by. Label filters work by either filtering a specific value of a
-                          label (i.e. list("key==value")) or by looking for the existence of a given key (i.e. "key").
+                          label (i.e. list("key=value")) or by looking for the existence of a given key (i.e. "key").
         :param metrics:   A list of metrics to return for each endpoint. There are pre-defined metrics for model
-                          endpoints such as predictions_per_second and latency_avg_5m but also custom metrics defined
-                          by the user. Please note that these metrics are stored in the time series DB and the results
-                          will be appeared under model_endpoint.spec.metrics of each endpoint.
+                          endpoints such as `predictions_per_second` and `latency_avg_5m` but also custom metrics
+                          defined by the user. Please note that these metrics are stored in the time series DB and the
+                          results will be appeared under model_endpoint.spec.metrics of each endpoint.
         :param start:     The start time of the metrics. Can be represented by a string containing an RFC 3339 time,
                           a Unix timestamp in milliseconds, a relative time (`'now'` or `'now-[0-9]+[mhd]'`, where `m`
                           = minutes, `h` = hours, and `'d'` = days), or 0 for the earliest time.
         :param end:       The end time of the metrics. Can be represented by a string containing an RFC 3339 time,
                           a Unix timestamp in milliseconds, a relative time (`'now'` or `'now-[0-9]+[mhd]'`, where `m`
                           = minutes, `h` = hours, and `'d'` = days), or 0 for the earliest time.
-        :param top_level: If True will return only routers and endpoint that are NOT children of any router.
-        :param uids:      Will return ModelEndpointList of endpoints with uid in uids.
+        :param top_level: If True, return only routers and endpoints that are NOT children of any router.
+        :param uids:      List of model endpoint unique ids to include in the result.
 
-        :return: An object of ModelEndpointList which is literally a list of model endpoints along with some metadata.
-                 To get a standard list of model endpoints use ModelEndpointList.endpoints.
+        :return: An object of `ModelEndpointList` which is literally a list of model endpoints along with some metadata.
+                 To get a standard list of model endpoints use `ModelEndpointList.endpoints`.
         """
 
         logger.info(
             "Listing endpoints",
             project=project,
             model=model,
             function=function,
@@ -463,41 +496,183 @@
             metrics=metrics,
             start=start,
             end=end,
             top_level=top_level,
             uids=uids,
         )
 
-        endpoint_target = get_model_endpoint_target(
-            access_key=auth_info.data_session, project=project
-        )
-
         # Initialize an empty model endpoints list
         endpoint_list = mlrun.api.schemas.model_endpoints.ModelEndpointList(
             endpoints=[]
         )
 
-        # If list of model endpoint ids was not provided, retrieve it from the DB
-        if uids is None:
-            uids = endpoint_target.list_model_endpoints(
-                function=function, model=model, labels=labels, top_level=top_level
-            )
+        # Generate a model endpoint store object and get a list of model endpoint dictionaries
+        endpoint_store = get_model_endpoint_store(
+            access_key=auth_info.data_session, project=project
+        )
 
-        # Add each relevant model endpoint to the model endpoints list
-        for endpoint_id in uids:
-            endpoint = endpoint_target.get_model_endpoint(
-                metrics=metrics,
-                endpoint_id=endpoint_id,
-                start=start,
-                end=end,
+        endpoint_dictionary_list = endpoint_store.list_model_endpoints(
+            function=function,
+            model=model,
+            labels=labels,
+            top_level=top_level,
+            uids=uids,
+        )
+
+        for endpoint_dict in endpoint_dictionary_list:
+
+            # Convert to `ModelEndpoint` object
+            endpoint_obj = self._convert_into_model_endpoint_object(
+                endpoint=endpoint_dict
             )
-            endpoint_list.endpoints.append(endpoint)
+
+            # If time metrics were provided, retrieve the results from the time series DB
+            if metrics:
+                self._add_real_time_metrics(
+                    model_endpoint_store=endpoint_store,
+                    model_endpoint_object=endpoint_obj,
+                    metrics=metrics,
+                    start=start,
+                    end=end,
+                )
+
+            # Add the `ModelEndpoint` object into the model endpoints list
+            endpoint_list.endpoints.append(endpoint_obj)
 
         return endpoint_list
 
+    @staticmethod
+    def _add_real_time_metrics(
+        model_endpoint_store: mlrun.model_monitoring.stores.ModelEndpointStore,
+        model_endpoint_object: mlrun.api.schemas.ModelEndpoint,
+        metrics: typing.List[str] = None,
+        start: str = "now-1h",
+        end: str = "now",
+    ) -> mlrun.api.schemas.ModelEndpoint:
+        """Add real time metrics from the time series DB to a provided `ModelEndpoint` object. The real time metrics
+           will be stored under `ModelEndpoint.status.metrics.real_time`
+
+        :param model_endpoint_store:  `ModelEndpointStore` object that will be used for communicating with the database
+                                       and querying the required metrics.
+        :param model_endpoint_object: `ModelEndpoint` object that will be filled with the relevant
+                                       real time metrics.
+        :param metrics:                A list of metrics to return for each endpoint. There are pre-defined metrics for
+                                       model endpoints such as `predictions_per_second` and `latency_avg_5m` but also
+                                       custom metrics defined by the user. Please note that these metrics are stored in
+                                       the time series DB and the results will be appeared under
+                                       model_endpoint.spec.metrics of each endpoint.
+        :param start:                  The start time of the metrics. Can be represented by a string containing an RFC
+                                       3339 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
+                                       `'now-[0-9]+[mhd]'`, where `m`= minutes, `h` = hours, and `'d'` = days), or 0
+                                       for the earliest time.
+        :param end:                    The end time of the metrics. Can be represented by a string containing an RFC
+                                       3339 time, a Unix timestamp in milliseconds, a relative time (`'now'` or
+                                       `'now-[0-9]+[mhd]'`, where `m`= minutes, `h` = hours, and `'d'` = days), or 0
+                                       for the earliest time.
+
+        """
+        if model_endpoint_object.status.metrics is None:
+            model_endpoint_object.status.metrics = {}
+
+        endpoint_metrics = model_endpoint_store.get_endpoint_real_time_metrics(
+            endpoint_id=model_endpoint_object.metadata.uid,
+            start=start,
+            end=end,
+            metrics=metrics,
+        )
+        if endpoint_metrics:
+            model_endpoint_object.status.metrics[
+                model_monitoring_constants.EventKeyMetrics.REAL_TIME
+            ] = endpoint_metrics
+        return model_endpoint_object
+
+    def _convert_into_model_endpoint_object(
+        self, endpoint: typing.Dict[str, typing.Any], feature_analysis: bool = False
+    ) -> mlrun.api.schemas.ModelEndpoint:
+        """
+        Create a `ModelEndpoint` object according to a provided model endpoint dictionary.
+
+        :param endpoint:         Dictinoary that represents a DB record of a model endpoint which need to be converted
+                                 into a valid `ModelEndpoint` object.
+        :param feature_analysis: When True, the base feature statistics and current feature statistics will be added to
+                                 the output of the resulting object.
+
+        :return: A `ModelEndpoint` object.
+        """
+
+        # Convert into `ModelEndpoint` object
+        endpoint_obj = mlrun.api.schemas.ModelEndpoint().from_flat_dict(endpoint)
+
+        # If feature analysis was applied, add feature stats and current stats to the model endpoint result
+        if feature_analysis and endpoint_obj.spec.feature_names:
+
+            endpoint_features = self.get_endpoint_features(
+                feature_names=endpoint_obj.spec.feature_names,
+                feature_stats=endpoint_obj.status.feature_stats,
+                current_stats=endpoint_obj.status.current_stats,
+            )
+            if endpoint_features:
+                endpoint_obj.status.features = endpoint_features
+                # Add the latest drift measures results (calculated by the model monitoring batch)
+                drift_measures = self._json_loads_if_not_none(
+                    endpoint.get(
+                        model_monitoring_constants.EventFieldType.DRIFT_MEASURES
+                    )
+                )
+                endpoint_obj.status.drift_measures = drift_measures
+
+        return endpoint_obj
+
+    @staticmethod
+    def get_endpoint_features(
+        feature_names: typing.List[str],
+        feature_stats: dict = None,
+        current_stats: dict = None,
+    ) -> typing.List[mlrun.api.schemas.Features]:
+        """
+        Getting a new list of features that exist in feature_names along with their expected (feature_stats) and
+        actual (current_stats) stats. The expected stats were calculated during the creation of the model endpoint,
+        usually based on the data from the Model Artifact. The actual stats are based on the results from the latest
+        model monitoring batch job.
+
+        param feature_names: List of feature names.
+        param feature_stats: Dictionary of feature stats that were stored during the creation of the model endpoint
+                             object.
+        param current_stats: Dictionary of the latest stats that were stored during the last run of the model monitoring
+                             batch job.
+
+        return: List of feature objects. Each feature has a name, weight, expected values, and actual values. More info
+                can be found under `mlrun.api.schemas.Features`.
+        """
+
+        # Initialize feature and current stats dictionaries
+        safe_feature_stats = feature_stats or {}
+        safe_current_stats = current_stats or {}
+
+        # Create feature object and add it to a general features list
+        features = []
+        for name in feature_names:
+            if feature_stats is not None and name not in feature_stats:
+                logger.warn("Feature missing from 'feature_stats'", name=name)
+            if current_stats is not None and name not in current_stats:
+                logger.warn("Feature missing from 'current_stats'", name=name)
+            f = mlrun.api.schemas.Features.new(
+                name, safe_feature_stats.get(name), safe_current_stats.get(name)
+            )
+            features.append(f)
+        return features
+
+    @staticmethod
+    def _json_loads_if_not_none(field: typing.Any) -> typing.Any:
+        return (
+            json.loads(field)
+            if field and field != "null" and field is not None
+            else None
+        )
+
     def deploy_monitoring_functions(
         self,
         project: str,
         model_monitoring_access_key: str,
         db_session: sqlalchemy.orm.Session,
         auth_info: mlrun.api.schemas.AuthInfo,
         tracking_policy: mlrun.utils.model_monitoring.TrackingPolicy,
@@ -536,35 +711,38 @@
 
         endpoints = self.list_model_endpoints(auth_info, project_name)
         if endpoints.endpoints:
             raise mlrun.errors.MLRunPreconditionFailedError(
                 f"Project {project_name} can not be deleted since related resources found: model endpoints"
             )
 
-    def delete_model_endpoints_resources(self, project_name: str):
+    @staticmethod
+    def delete_model_endpoints_resources(project_name: str):
         """
         Delete all model endpoints resources.
 
         :param project_name: The name of the project.
         """
         auth_info = mlrun.api.schemas.AuthInfo(
             data_session=os.getenv("V3IO_ACCESS_KEY")
         )
 
         # We would ideally base on config.v3io_api but can't for backwards compatibility reasons,
         # we're using the igz version heuristic
         if not mlrun.mlconf.igz_version or not mlrun.mlconf.v3io_api:
             return
 
-        endpoints = self.list_model_endpoints(auth_info, project_name)
-
-        endpoint_target = get_model_endpoint_target(
+        # Generate a model endpoint store object and get a list of model endpoint dictionaries
+        endpoint_store = get_model_endpoint_store(
             access_key=auth_info.data_session, project=project_name
         )
-        endpoint_target.delete_model_endpoints_resources(endpoints)
+        endpoints = endpoint_store.list_model_endpoints()
+
+        # Delete model endpoints resources from databases using the model endpoint store object
+        endpoint_store.delete_model_endpoints_resources(endpoints)
 
     @staticmethod
     def deploy_model_monitoring_stream_processing(
         project: str,
         model_monitoring_access_key: str,
         db_session: sqlalchemy.orm.Session,
         auth_info: mlrun.api.schemas.AuthInfo,
@@ -585,22 +763,25 @@
         logger.info(
             "Checking if model monitoring stream is already deployed",
             project=project,
         )
         try:
             # validate that the model monitoring stream has not yet been deployed
             mlrun.runtimes.function.get_nuclio_deploy_status(
-                name="model-monitoring-stream", project=project, tag=""
+                name="model-monitoring-stream",
+                project=project,
+                tag="",
+                auth_info=auth_info,
             )
             logger.info(
                 "Detected model monitoring stream processing function already deployed",
                 project=project,
             )
             return
-        except nuclio.utils.DeployError:
+        except mlrun.errors.MLRunNotFoundError:
             logger.info(
                 "Deploying model monitoring stream processing function", project=project
             )
 
         fn = mlrun.model_monitoring.helpers.initial_model_monitoring_stream_processing_function(
             project, model_monitoring_access_key, db_session, tracking_policy
         )
@@ -662,37 +843,29 @@
         function_uri = function_uri.replace("db://", "")
 
         task = mlrun.new_task(name="model-monitoring-batch", project=project)
         task.spec.function = function_uri
 
         # Apply batching interval params
         interval_list = [
-            tracking_policy[
-                model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
-            ]["minute"],
-            tracking_policy[
-                model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
-            ]["hour"],
-            tracking_policy[
-                model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
-            ]["day"],
+            tracking_policy.default_batch_intervals.minute,
+            tracking_policy.default_batch_intervals.hour,
+            tracking_policy.default_batch_intervals.day,
         ]
         minutes, hours, days = self._get_batching_interval_param(interval_list)
         batch_dict = {"minutes": minutes, "hours": hours, "days": days}
 
         task.spec.parameters[
             model_monitoring_constants.EventFieldType.BATCH_INTERVALS_DICT
         ] = batch_dict
 
         data = {
             "task": task.to_dict(),
             "schedule": self._convert_to_cron_string(
-                tracking_policy[
-                    model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
-                ]
+                tracking_policy.default_batch_intervals
             ),
         }
 
         logger.info(
             "Deploying model monitoring batch processing function", project=project
         )
 
@@ -740,12 +913,14 @@
                 if isinstance(interval, (float, int)) or interval is None
                 else float(f"0{interval.partition('/')[-1]}")
                 for interval in intervals_list
             ]
         )
 
     @staticmethod
-    def _convert_to_cron_string(cron_trigger):
-        """Converting the batch interval dictionary into a ScheduleCronTrigger expression"""
+    def _convert_to_cron_string(
+        cron_trigger: mlrun.api.schemas.schedule.ScheduleCronTrigger,
+    ):
+        """Converting the batch interval `ScheduleCronTrigger` into a cron trigger expression"""
         return "{} {} {} * *".format(
-            cron_trigger["minute"], cron_trigger["hour"], cron_trigger["day"]
+            cron_trigger.minute, cron_trigger.hour, cron_trigger.day
         ).replace("None", "*")
```

## mlrun/api/db/base.py

```diff
@@ -55,14 +55,32 @@
         pass
 
     @abstractmethod
     def update_run(self, session, updates: dict, uid, project="", iter=0):
         pass
 
     @abstractmethod
+    def list_distinct_runs_uids(
+        self,
+        session,
+        project: str = None,
+        requested_logs_modes: List[bool] = None,
+        only_uids: bool = False,
+        last_update_time_from: datetime.datetime = None,
+        states: List[str] = None,
+    ):
+        pass
+
+    @abstractmethod
+    def update_runs_requested_logs(
+        self, session, uids: List[str], requested_logs: bool = True
+    ):
+        pass
+
+    @abstractmethod
     def read_run(self, session, uid, project="", iter=0):
         pass
 
     @abstractmethod
     def list_runs(
         self,
         session,
@@ -79,14 +97,16 @@
         last_update_time_from=None,
         last_update_time_to=None,
         partition_by: schemas.RunPartitionByField = None,
         rows_per_partition: int = 1,
         partition_sort_by: schemas.SortField = None,
         partition_order: schemas.OrderType = schemas.OrderType.desc,
         max_partitions: int = 0,
+        requested_logs: bool = None,
+        return_as_run_structs: bool = True,
     ):
         pass
 
     @abstractmethod
     def del_run(self, session, uid, project="", iter=0):
         pass
 
@@ -191,15 +211,23 @@
         pass
 
     @abstractmethod
     def delete_function(self, session, project: str, name: str):
         pass
 
     @abstractmethod
-    def list_functions(self, session, name=None, project="", tag="", labels=None):
+    def list_functions(
+        self,
+        session,
+        name: str = None,
+        project: str = None,
+        tag: str = None,
+        labels: List[str] = None,
+        hash_key: str = None,
+    ):
         pass
 
     @abstractmethod
     def create_schedule(
         self,
         session,
         project: str,
@@ -503,15 +531,17 @@
         project,
         name,
         tag=None,
         uid=None,
     ):
         pass
 
-    def list_artifact_tags(self, session, project, category):
+    def list_artifact_tags(
+        self, session, project, category: Union[str, schemas.ArtifactCategories] = None
+    ):
         return []
 
     def create_marketplace_source(
         self, session, ordered_source: schemas.IndexedMarketplaceSource
     ):
         pass
```

## mlrun/api/db/filedb/db.py

```diff
@@ -56,14 +56,30 @@
         )
 
     def update_run(self, session, updates: dict, uid, project="", iter=0):
         return self._transform_run_db_error(
             self.db.update_run, updates, uid, project, iter
         )
 
+    def list_distinct_runs_uids(
+        self,
+        session,
+        project: str = None,
+        requested_logs_modes: List[bool] = None,
+        only_uids: bool = False,
+        last_update_time_from: datetime.datetime = None,
+        states: List[str] = None,
+    ):
+        raise NotImplementedError()
+
+    def update_runs_requested_logs(
+        self, session, uids: List[str], requested_logs: bool = True
+    ):
+        raise NotImplementedError()
+
     def read_run(self, session, uid, project="", iter=0):
         return self._transform_run_db_error(self.db.read_run, uid, project, iter)
 
     def list_runs(
         self,
         session,
         name="",
@@ -79,14 +95,16 @@
         last_update_time_from=None,
         last_update_time_to=None,
         partition_by: schemas.RunPartitionByField = None,
         rows_per_partition: int = 1,
         partition_sort_by: schemas.SortField = None,
         partition_order: schemas.OrderType = schemas.OrderType.desc,
         max_partitions: int = 0,
+        requested_logs: bool = None,
+        return_as_run_structs: bool = True,
     ):
         return self._transform_run_db_error(
             self.db.list_runs,
             name,
             uid,
             project,
             labels,
@@ -99,14 +117,16 @@
             last_update_time_from,
             last_update_time_to,
             partition_by,
             rows_per_partition,
             partition_sort_by,
             partition_order,
             max_partitions,
+            requested_logs,
+            return_as_run_structs,
         )
 
     def del_run(self, session, uid, project="", iter=0):
         return self._transform_run_db_error(self.db.del_run, uid, project, iter)
 
     def del_runs(self, session, name="", project="", labels=None, state="", days_ago=0):
         return self._transform_run_db_error(
@@ -204,15 +224,17 @@
         return self._transform_run_db_error(
             self.db.get_function, name, project, tag, hash_key
         )
 
     def delete_function(self, session, project: str, name: str):
         raise NotImplementedError()
 
-    def list_functions(self, session, name=None, project="", tag="", labels=None):
+    def list_functions(
+        self, session, name=None, project="", tag="", labels=None, hash_key=None
+    ):
         return self._transform_run_db_error(
             self.db.list_functions, name, project, tag, labels
         )
 
     def store_schedule(self, session, data):
         return self._transform_run_db_error(self.db.store_schedule, data)
 
@@ -430,16 +452,20 @@
         patch_mode: schemas.PatchMode = schemas.PatchMode.replace,
     ) -> str:
         raise NotImplementedError()
 
     def delete_feature_vector(self, session, project, name, tag=None, uid=None):
         raise NotImplementedError()
 
-    def list_artifact_tags(self, session, project, category):
-        return self._transform_run_db_error(self.db.list_artifact_tags, project)
+    def list_artifact_tags(
+        self, session, project, category: Union[str, schemas.ArtifactCategories] = None
+    ):
+        return self._transform_run_db_error(
+            self.db.list_artifact_tags, project, category
+        )
 
     def create_schedule(
         self,
         session,
         project: str,
         name: str,
         kind: schemas.ScheduleKinds,
```

## mlrun/api/db/sqldb/db.py

```diff
@@ -69,14 +69,15 @@
     fill_object_hash,
     generate_artifact_uri,
     generate_object_uri,
     get_in,
     is_legacy_artifact,
     logger,
     update_in,
+    validate_artifact_key_name,
     validate_tag_name,
 )
 
 NULL = None  # Avoid flake8 issuing warnings when comparing in filter
 run_time_fmt = "%Y-%m-%dT%H:%M:%S.%fZ"
 unversioned_tagged_object_uid_prefix = "unversioned-"
 
@@ -188,14 +189,15 @@
             run = Run(
                 name=run_data["metadata"]["name"],
                 uid=uid,
                 project=project,
                 iteration=iter,
                 state=run_state(run_data),
                 start_time=run_start_time(run_data) or now,
+                requested_logs=False,
             )
         self._ensure_run_name_on_update(run, run_data)
         labels = run_labels(run_data)
         self._update_run_state(run, run_data)
         update_labels(run, labels)
         # Note that this code basically allowing anyone to override the run's start time after it was already set
         # This is done to enable the context initialization to set the start time to when the user's code actually
@@ -224,14 +226,80 @@
             run.start_time = start_time
         update_labels(run, run_labels(struct))
         self._update_run_updated_time(run, struct)
         run.struct = struct
         self._upsert(session, [run])
         self._delete_empty_labels(session, Run.Label)
 
+    def list_distinct_runs_uids(
+        self,
+        session,
+        project: str = None,
+        requested_logs_modes: typing.List[bool] = None,
+        only_uids=True,
+        last_update_time_from: datetime = None,
+        states: typing.List[str] = None,
+    ) -> typing.Union[typing.List[str], RunList]:
+        """
+        List all runs uids in the DB
+        :param session: DB session
+        :param project: Project name, `*` or `None` lists across all projects
+        :param requested_logs_modes: If not `None`, will return only runs with the given requested logs modes
+        :param only_uids: If True, will return only the uids of the runs as list of strings
+                          If False, will return the full run objects as RunList
+        :param last_update_time_from: If not `None`, will return only runs updated after this time
+        :param states: If not `None`, will return only runs with the given states
+        :return: List of runs uids or RunList
+        """
+        if only_uids:
+            # using distinct to avoid duplicates as there could be multiple runs with the same uid(different iterations)
+            query = self._query(session, distinct(Run.uid))
+        else:
+            query = self._query(session, Run)
+
+        if project and project != "*":
+            query = query.filter(Run.project == project)
+
+        if states:
+            query = query.filter(Run.state.in_(states))
+
+        if last_update_time_from is not None:
+            query = query.filter(Run.updated >= last_update_time_from)
+
+        if requested_logs_modes is not None:
+            query = query.filter(Run.requested_logs.in_(requested_logs_modes))
+
+        if not only_uids:
+            # group_by allows us to have a row per uid with the whole record rather than just the uid (as distinct does)
+            # note we cannot promise that the same row will be returned each time per uid as the order is not guaranteed
+            query = query.group_by(Run.uid)
+
+            runs = RunList()
+            for run in query:
+                runs.append(run.struct)
+
+            return runs
+
+        # from each row we expect to get a tuple of (uid,) so we need to extract the uid from the tuple
+        return [uid for uid, in query.all()]
+
+    def update_runs_requested_logs(
+        self, session, uids: List[str], requested_logs: bool = True
+    ):
+        # note that you should commit right after the synchronize_session=False
+        # https://stackoverflow.com/questions/70350298/what-does-synchronize-session-false-do-exactly-in-update-functions-for-sqlalch
+        self._query(session, Run).filter(Run.uid.in_(uids)).update(
+            {
+                Run.requested_logs: requested_logs,
+                Run.updated: datetime.now(timezone.utc),
+            },
+            synchronize_session=False,
+        )
+        session.commit()
+
     def read_run(self, session, uid, project=None, iter=0):
         project = project or config.default_project
         run = self._get_run(session, uid, project, iter)
         if not run:
             raise mlrun.errors.MLRunNotFoundError(f"Run {uid}:{project} not found")
         return run.struct
 
@@ -251,14 +319,16 @@
         last_update_time_from=None,
         last_update_time_to=None,
         partition_by: schemas.RunPartitionByField = None,
         rows_per_partition: int = 1,
         partition_sort_by: schemas.SortField = None,
         partition_order: schemas.OrderType = schemas.OrderType.desc,
         max_partitions: int = 0,
+        requested_logs: bool = None,
+        return_as_run_structs: bool = True,
     ):
         project = project or config.default_project
         query = self._find_runs(session, uid, project, labels)
         if name is not None:
             query = self._add_run_name_query(query, name)
         if states is not None:
             query = query.filter(Run.state.in_(states))
@@ -276,29 +346,32 @@
             if not sort:
                 raise mlrun.errors.MLRunInvalidArgumentError(
                     "Limiting the number of returned records without sorting will provide non-deterministic results"
                 )
             query = query.limit(last)
         if not iter:
             query = query.filter(Run.iteration == 0)
-
+        if requested_logs is not None:
+            query = query.filter(Run.requested_logs == requested_logs)
         if partition_by:
             self._assert_partition_by_parameters(
                 schemas.RunPartitionByField, partition_by, partition_sort_by
             )
             query = self._create_partitioned_query(
                 session,
                 query,
                 Run,
                 partition_by,
                 rows_per_partition,
                 partition_sort_by,
                 partition_order,
                 max_partitions,
             )
+        if not return_as_run_structs:
+            return query.all()
 
         runs = RunList()
         for run in query:
             runs.append(run.struct)
 
         return runs
 
@@ -430,15 +503,15 @@
             # 2. if the identifier.uid is None, we want to list all artifacts, so we pass "*"
             tag=identifier.uid or "*",
             as_records=True,
             # 1. because of backwards compatible that list_artifacts is keeping, we want to pass the function
             # indication that the tag which is passed is uid
             # 2. if uid wasn't passed as part of the identifiers then
             # we will ask for tag "*" and in that case we don't want to use the tag as uid
-            use_tag_as_uid=True if identifier.uid else False,
+            use_tag_as_uid=bool(identifier.uid),
         )
 
     @retry_on_conflict
     def store_artifact(
         self,
         session,
         key,
@@ -520,14 +593,16 @@
         else:
             updated, key, labels = self._process_artifact_dict_to_store(
                 artifact, key, iter
             )
         existed = True
         art = self._get_artifact(session, uid, project, key)
         if not art:
+            # for backwards compatibility only validating key name on new artifacts
+            validate_artifact_key_name(key, "artifact.key")
             art = Artifact(key=key, uid=uid, updated=updated, project=project)
             existed = False
 
         update_labels(art, labels)
 
         art.struct = artifact
         self._upsert(session, [art])
@@ -627,17 +702,15 @@
         project = project or config.default_project
 
         if best_iteration and iter is not None:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "best-iteration cannot be used when iter is specified"
             )
         # TODO: Refactor this area
-        # in case where tag is not given ids will be "latest" to mark to _find_artifacts to find the latest using the
-        # old way - by the updated field
-        ids = "latest"
+        ids = "*"
         if tag:
             # use_tag_as_uid is used to catch old artifacts which were created when logging artifacts using the project
             # producer and not by context, this because when were logging artifacts using the project producer we were
             # setting the artifact uid to be the same as the producer tag which at the time was "latest", this becomes a
             # problem with uid="latest" because there are also "latest" tags in the system, which means we will get ids
             # response from the `_resolve_tag` above and then we will iterate over the wrong artifact
             # use_tag_as_uid==None is keeping the old behavior
@@ -720,23 +793,20 @@
             # We need special handling for the case where iter==0, since in that case no iter prefix will exist.
             # Regex support is db-specific, and SQLAlchemy actually implements Python regex for SQLite anyway,
             # and even that only in SA 1.4. So doing this here rather than in the query.
             if iter == 0 and has_iteration:
                 continue
 
             artifact_struct = artifact.struct
-            # ids = "latest" and not tag means that it was not given by the user, so we will not set the tag in the
-            # artifact struct
-            if ids != "latest" or tag:
-                artifacts_with_tag = self._add_tags_to_artifact_struct(
-                    session, artifact_struct, artifact.id, tag
-                )
-                artifacts.extend(artifacts_with_tag)
-            else:
-                artifacts.append(artifact_struct)
+
+            # set the tags in the artifact struct
+            artifacts_with_tag = self._add_tags_to_artifact_struct(
+                session, artifact_struct, artifact.id, tag
+            )
+            artifacts.extend(artifacts_with_tag)
 
         return artifacts
 
     def _get_link_artifacts_by_keys_and_uids(self, session, project, identifiers):
         # identifiers are tuples of (key, uid)
         if not identifiers:
             return []
@@ -864,15 +934,16 @@
             uid = f"{unversioned_tagged_object_uid_prefix}{tag}"
 
         updated = datetime.now(timezone.utc)
         update_in(function, "metadata.updated", updated)
         body_name = function.get("metadata", {}).get("name")
         if body_name and body_name != name:
             raise mlrun.errors.MLRunInvalidArgumentError(
-                "Conflict between requested name and name in function body"
+                f"Conflict between requested name and name in function body, function name is {name} while body_name is"
+                f" {body_name}"
             )
         if not body_name:
             function.setdefault("metadata", {})["name"] = name
         fn = self._get_class_instance_by_uid(session, Function, name, project, uid)
         if not fn:
             fn = Function(
                 name=name,
@@ -950,24 +1021,31 @@
             ).all()
         ]
 
     def _delete_resources_tags(self, session: Session, project: str):
         for tagged_class in _tagged:
             self._delete(session, tagged_class, project=project)
 
-    def _delete_resources_labels(self, session: Session, project: str):
-        for labeled_class in _labeled:
-            if hasattr(labeled_class, "project"):
-                self._delete(session, labeled_class, project=project)
-
-    def list_functions(self, session, name=None, project=None, tag=None, labels=None):
+    def list_functions(
+        self,
+        session: Session,
+        name: str = None,
+        project: str = None,
+        tag: str = None,
+        labels: List[str] = None,
+        hash_key: str = None,
+    ) -> typing.Union[FunctionList, List[dict]]:
         project = project or config.default_project
         uids = None
         if tag:
             uids = self._resolve_class_tag_uids(session, Function, project, tag, name)
+            if hash_key:
+                uids = [uid for uid in uids if uid == hash_key] or None
+        if not tag and hash_key:
+            uids = [hash_key]
         functions = FunctionList()
         for function in self._find_functions(session, name, project, uids, labels):
             function_dict = function.struct
             if not tag:
                 function_tags = self._list_function_tags(session, project, function.id)
                 if len(function_tags) == 0:
 
@@ -990,14 +1068,19 @@
                         function_dict_copy["metadata"]["tag"] = function_tag
                         functions.append(function_dict_copy)
             else:
                 function_dict["metadata"]["tag"] = tag
                 functions.append(function_dict)
         return functions
 
+    def _delete_resources_labels(self, session: Session, project: str):
+        for labeled_class in _labeled:
+            if hasattr(labeled_class, "project"):
+                self._delete(session, labeled_class, project=project)
+
     def _delete_function_tags(self, session, project, function_name, commit=True):
         query = session.query(Function.Tag).filter(
             Function.Tag.project == project, Function.Tag.obj_name == function_name
         )
         for obj in query:
             session.delete(obj)
         if commit:
@@ -1209,18 +1292,18 @@
             name
             for name, in self._query(
                 session, distinct(FeatureVector.name), project=project
             ).all()
         ]
 
     def tag_artifacts(self, session, artifacts, project: str, name: str):
-        # found a bug in here, which is being exposed for when have multi-param execution, this because each
-        # artifact key is being concatenated with the key and the iteration, this because problemtic in this query
+        # found a bug in here, which is being exposed for when have multi-param execution.
+        # each artifact key is being concatenated with the key and the iteration, this is problematic in this query
         # because we are filtering by the key+iteration and not just the key ( which would require some regex )
-        # this would be fixed as part of the refactoring of the new artifact table structure where we would have
+        # it would be fixed as part of the refactoring of the new artifact table structure where we would have
         # column for iteration as well.
         for artifact in artifacts:
             query = (
                 self._query(
                     session,
                     artifact.Tag,
                     project=project,
```

## mlrun/api/db/sqldb/session.py

```diff
@@ -8,63 +8,70 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
+
+import typing
+
 from sqlalchemy import create_engine
 from sqlalchemy.engine import Engine
 from sqlalchemy.orm import Session
 from sqlalchemy.orm import sessionmaker as SessionMaker
 
 from mlrun.config import config
 
-engine: Engine = None
-_session_maker: SessionMaker = None
+# TODO: wrap the following functions in a singleton class
+_engines: typing.Dict[str, Engine] = {}
+_session_makers: typing.Dict[str, SessionMaker] = {}
 
 
 # doing lazy load to allow tests to initialize the engine
-def get_engine() -> Engine:
-    global engine
-    if engine is None:
-        _init_engine()
-    return engine
+def get_engine(dsn=None) -> Engine:
+    global _engines
+    dsn = dsn or config.httpdb.dsn
+    if dsn not in _engines:
+        _init_engine(dsn=dsn)
+    return _engines[dsn]
 
 
-def create_session() -> Session:
-    session_maker = _get_session_maker()
+def create_session(dsn=None) -> Session:
+    session_maker = _get_session_maker(dsn=dsn)
     return session_maker()
 
 
 # doing lazy load to allow tests to initialize the engine
-def _get_session_maker() -> SessionMaker:
-    global _session_maker
-    if _session_maker is None:
-        _init_session_maker()
-    return _session_maker
+def _get_session_maker(dsn) -> SessionMaker:
+    global _session_makers
+    dsn = dsn or config.httpdb.dsn
+    if dsn not in _session_makers:
+        _init_session_maker(dsn=dsn)
+    return _session_makers[dsn]
 
 
 # TODO: we accept the dsn here to enable tests to override it, the "right" thing will be that config will be easily
 #  overridable by tests (today when you import the config it is already being initialized.. should be lazy load)
 def _init_engine(dsn=None):
-    global engine
+    global _engines
     dsn = dsn or config.httpdb.dsn
     kwargs = {}
     if "mysql" in dsn:
         pool_size = config.httpdb.db.connections_pool_size
         if pool_size is None:
             pool_size = config.httpdb.max_workers
         max_overflow = config.httpdb.db.connections_pool_max_overflow
         if max_overflow is None:
             max_overflow = config.httpdb.max_workers
         kwargs = {
             "pool_size": pool_size,
             "max_overflow": max_overflow,
         }
     engine = create_engine(dsn, **kwargs)
-    _init_session_maker()
+    _engines[dsn] = engine
+    _init_session_maker(dsn=dsn)
 
 
-def _init_session_maker():
-    global _session_maker
-    _session_maker = SessionMaker(bind=get_engine())
+def _init_session_maker(dsn):
+    global _session_makers
+    _session_makers[dsn] = SessionMaker(bind=get_engine(dsn=dsn))
```

## mlrun/api/db/sqldb/models/models_mysql.py

```diff
@@ -16,84 +16,52 @@
 import pickle
 import warnings
 from datetime import datetime, timezone
 
 import orjson
 import sqlalchemy.dialects.mysql
 from sqlalchemy import (
+    BOOLEAN,
     JSON,
     Column,
     ForeignKey,
     Integer,
     String,
     Table,
     UniqueConstraint,
 )
 from sqlalchemy.ext.declarative import declarative_base
-from sqlalchemy.orm import class_mapper, relationship
+from sqlalchemy.orm import relationship
 
+import mlrun.utils.db
 from mlrun.api import schemas
 from mlrun.api.utils.db.sql_collation import SQLCollationUtil
 
 Base = declarative_base()
 NULL = None  # Avoid flake8 issuing warnings when comparing in filter
 run_time_fmt = "%Y-%m-%dT%H:%M:%S.%fZ"
 
 
-class BaseModel:
-    def to_dict(self, exclude=None):
-        """
-        NOTE - this function (currently) does not handle serializing relationships
-        """
-        exclude = exclude or []
-        mapper = class_mapper(self.__class__)
-        columns = [column.key for column in mapper.columns if column.key not in exclude]
-        get_key_value = (
-            lambda c: (c, getattr(self, c).isoformat())
-            if isinstance(getattr(self, c), datetime)
-            else (c, getattr(self, c))
-        )
-        return dict(map(get_key_value, columns))
-
-
-class HasStruct(BaseModel):
-    @property
-    def struct(self):
-        return pickle.loads(self.body)
-
-    @struct.setter
-    def struct(self, value):
-        self.body = pickle.dumps(value)
-
-    def to_dict(self, exclude=None):
-        """
-        NOTE - this function (currently) does not handle serializing relationships
-        """
-        exclude = exclude or []
-        exclude.append("body")
-        return super().to_dict(exclude)
-
-
 def make_label(table):
-    class Label(Base, BaseModel):
+    class Label(Base, mlrun.utils.db.BaseModel):
         __tablename__ = f"{table}_labels"
         __table_args__ = (
             UniqueConstraint("name", "parent", name=f"_{table}_labels_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         value = Column(String(255, collation=SQLCollationUtil.collation()))
         parent = Column(Integer, ForeignKey(f"{table}.id"))
 
     return Label
 
 
 def make_tag(table):
-    class Tag(Base, BaseModel):
+    class Tag(Base, mlrun.utils.db.BaseModel):
         __tablename__ = f"{table}_tags"
         __table_args__ = (
             UniqueConstraint("project", "name", "obj_id", name=f"_{table}_tags_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         project = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -102,15 +70,15 @@
 
     return Tag
 
 
 # TODO: don't want to refactor everything in one PR so splitting this function to 2 versions - eventually only this one
 #  should be used
 def make_tag_v2(table):
-    class Tag(Base, BaseModel):
+    class Tag(Base, mlrun.utils.db.BaseModel):
         __tablename__ = f"{table}_tags"
         __table_args__ = (
             UniqueConstraint("project", "name", "obj_name", name=f"_{table}_tags_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         project = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -121,15 +89,15 @@
     return Tag
 
 
 # quell SQLAlchemy warnings on duplicate class name (Label)
 with warnings.catch_warnings():
     warnings.simplefilter("ignore")
 
-    class Artifact(Base, HasStruct):
+    class Artifact(Base, mlrun.utils.db.HasStruct):
         __tablename__ = "artifacts"
         __table_args__ = (
             UniqueConstraint("uid", "project", "key", name="_artifacts_uc"),
         )
 
         Label = make_label(__tablename__)
         Tag = make_tag(__tablename__)
@@ -144,15 +112,15 @@
 
         labels = relationship(Label, cascade="all, delete-orphan")
         tags = relationship(Tag, cascade="all, delete-orphan")
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.key}/{self.uid}"
 
-    class Function(Base, HasStruct):
+    class Function(Base, mlrun.utils.db.HasStruct):
         __tablename__ = "functions"
         __table_args__ = (
             UniqueConstraint("name", "project", "uid", name="_functions_uc"),
         )
 
         Label = make_label(__tablename__)
         Tag = make_tag_v2(__tablename__)
@@ -167,27 +135,27 @@
 
         labels = relationship(Label, cascade="all, delete-orphan")
         tags = relationship(Tag, cascade="all, delete-orphan")
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.name}/{self.uid}"
 
-    class Log(Base, BaseModel):
+    class Log(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "logs"
 
         id = Column(Integer, primary_key=True)
         uid = Column(String(255, collation=SQLCollationUtil.collation()))
         project = Column(String(255, collation=SQLCollationUtil.collation()))
         # TODO: change to JSON, see mlrun/api/schemas/function.py::FunctionState for reasoning
         body = Column(sqlalchemy.dialects.mysql.MEDIUMBLOB)
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.uid}"
 
-    class Run(Base, HasStruct):
+    class Run(Base, mlrun.utils.db.HasStruct):
         __tablename__ = "runs"
         __table_args__ = (
             UniqueConstraint("uid", "project", "iteration", name="_runs_uc"),
         )
 
         Label = make_label(__tablename__)
         Tag = make_tag(__tablename__)
@@ -202,22 +170,27 @@
         state = Column(String(255, collation=SQLCollationUtil.collation()))
         # TODO: change to JSON, see mlrun/api/schemas/function.py::FunctionState for reasoning
         body = Column(sqlalchemy.dialects.mysql.MEDIUMBLOB)
         start_time = Column(sqlalchemy.dialects.mysql.TIMESTAMP(fsp=3))
         updated = Column(
             sqlalchemy.dialects.mysql.TIMESTAMP(fsp=3), default=datetime.utcnow
         )
+        # requested logs column indicates whether logs were requested for this run
+        # None - old runs prior to the column addition, logs were already collected for them, so no need to collect them
+        # False - logs were not requested for this run
+        # True - logs were requested for this run
+        requested_logs = Column(BOOLEAN, default=False, index=True)
 
         labels = relationship(Label, cascade="all, delete-orphan")
         tags = relationship(Tag, cascade="all, delete-orphan")
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.uid}/{self.iteration}"
 
-    class BackgroundTask(Base, BaseModel):
+    class BackgroundTask(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "background_tasks"
         __table_args__ = (
             UniqueConstraint("name", "project", name="_background_tasks_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(
@@ -233,15 +206,15 @@
         updated = Column(
             sqlalchemy.dialects.mysql.TIMESTAMP(fsp=3),
             default=datetime.now(timezone.utc),
         )
         state = Column(String(255, collation=SQLCollationUtil.collation()))
         timeout = Column(Integer)
 
-    class Schedule(Base, BaseModel):
+    class Schedule(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "schedules_v2"
         __table_args__ = (UniqueConstraint("project", "name", name="_schedules_v2_uc"),)
 
         Label = make_label(__tablename__)
 
         id = Column(Integer, primary_key=True)
         project = Column(
@@ -285,22 +258,22 @@
     project_users = Table(
         "project_users",
         Base.metadata,
         Column("project_id", Integer, ForeignKey("projects.id")),
         Column("user_id", Integer, ForeignKey("users.id")),
     )
 
-    class User(Base, BaseModel):
+    class User(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "users"
         __table_args__ = (UniqueConstraint("name", name="_users_uc"),)
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
 
-    class Project(Base, BaseModel):
+    class Project(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "projects"
         # For now since we use project name a lot
         __table_args__ = (UniqueConstraint("name", name="_projects_uc"),)
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         description = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -328,43 +301,43 @@
             if self._full_object:
                 return pickle.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
             self._full_object = pickle.dumps(value)
 
-    class Feature(Base, BaseModel):
+    class Feature(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "features"
         id = Column(Integer, primary_key=True)
         feature_set_id = Column(Integer, ForeignKey("feature_sets.id"))
 
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         value_type = Column(String(255, collation=SQLCollationUtil.collation()))
 
         Label = make_label(__tablename__)
         labels = relationship(Label, cascade="all, delete-orphan")
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.name}"
 
-    class Entity(Base, BaseModel):
+    class Entity(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "entities"
         id = Column(Integer, primary_key=True)
         feature_set_id = Column(Integer, ForeignKey("feature_sets.id"))
 
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         value_type = Column(String(255, collation=SQLCollationUtil.collation()))
 
         Label = make_label(__tablename__)
         labels = relationship(Label, cascade="all, delete-orphan")
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.name}"
 
-    class FeatureSet(Base, BaseModel):
+    class FeatureSet(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "feature_sets"
         __table_args__ = (
             UniqueConstraint("name", "project", "uid", name="_feature_set_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -397,17 +370,18 @@
         @property
         def full_object(self):
             if self._full_object:
                 return json.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
-            self._full_object = json.dumps(value)
+            # TODO - convert to pickle, to avoid issues with non-json serializable fields such as datetime
+            self._full_object = json.dumps(value, default=str)
 
-    class FeatureVector(Base, BaseModel):
+    class FeatureVector(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "feature_vectors"
         __table_args__ = (
             UniqueConstraint("name", "project", "uid", name="_feature_vectors_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -437,17 +411,18 @@
         @property
         def full_object(self):
             if self._full_object:
                 return json.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
-            self._full_object = json.dumps(value)
+            # TODO - convert to pickle, to avoid issues with non-json serializable fields such as datetime
+            self._full_object = json.dumps(value, default=str)
 
-    class MarketplaceSource(Base, BaseModel):
+    class MarketplaceSource(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "marketplace_sources"
         __table_args__ = (UniqueConstraint("name", name="_marketplace_sources_uc"),)
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         index = Column(Integer)
         created = Column(
@@ -467,17 +442,18 @@
         @property
         def full_object(self):
             if self._full_object:
                 return json.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
-            self._full_object = json.dumps(value)
+            # TODO - convert to pickle, to avoid issues with non-json serializable fields such as datetime
+            self._full_object = json.dumps(value, default=str)
 
-    class DataVersion(Base, BaseModel):
+    class DataVersion(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "data_versions"
         __table_args__ = (UniqueConstraint("version", name="_versions_uc"),)
 
         id = Column(Integer, primary_key=True)
         version = Column(String(255, collation=SQLCollationUtil.collation()))
         created = Column(
             sqlalchemy.dialects.mysql.TIMESTAMP(fsp=3),
```

## mlrun/api/db/sqldb/models/models_sqlite.py

```diff
@@ -16,85 +16,53 @@
 import pickle
 import warnings
 from datetime import datetime, timezone
 
 import orjson
 from sqlalchemy import (
     BLOB,
+    BOOLEAN,
     JSON,
     TIMESTAMP,
     Column,
     ForeignKey,
     Integer,
     String,
     Table,
     UniqueConstraint,
 )
 from sqlalchemy.ext.declarative import declarative_base
-from sqlalchemy.orm import class_mapper, relationship
+from sqlalchemy.orm import relationship
 
+import mlrun.utils.db
 from mlrun.api import schemas
 from mlrun.api.utils.db.sql_collation import SQLCollationUtil
 
 Base = declarative_base()
 NULL = None  # Avoid flake8 issuing warnings when comparing in filter
 run_time_fmt = "%Y-%m-%dT%H:%M:%S.%fZ"
 
 
-class BaseModel:
-    def to_dict(self, exclude=None):
-        """
-        NOTE - this function (currently) does not handle serializing relationships
-        """
-        exclude = exclude or []
-        mapper = class_mapper(self.__class__)
-        columns = [column.key for column in mapper.columns if column.key not in exclude]
-        get_key_value = (
-            lambda c: (c, getattr(self, c).isoformat())
-            if isinstance(getattr(self, c), datetime)
-            else (c, getattr(self, c))
-        )
-        return dict(map(get_key_value, columns))
-
-
-class HasStruct(BaseModel):
-    @property
-    def struct(self):
-        return pickle.loads(self.body)
-
-    @struct.setter
-    def struct(self, value):
-        self.body = pickle.dumps(value)
-
-    def to_dict(self, exclude=None):
-        """
-        NOTE - this function (currently) does not handle serializing relationships
-        """
-        exclude = exclude or []
-        exclude.append("body")
-        return super().to_dict(exclude)
-
-
 def make_label(table):
-    class Label(Base, BaseModel):
+    class Label(Base, mlrun.utils.db.BaseModel):
         __tablename__ = f"{table}_labels"
         __table_args__ = (
             UniqueConstraint("name", "parent", name=f"_{table}_labels_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         value = Column(String(255, collation=SQLCollationUtil.collation()))
         parent = Column(Integer, ForeignKey(f"{table}.id"))
 
     return Label
 
 
 def make_tag(table):
-    class Tag(Base, BaseModel):
+    class Tag(Base, mlrun.utils.db.BaseModel):
         __tablename__ = f"{table}_tags"
         __table_args__ = (
             UniqueConstraint("project", "name", "obj_id", name=f"_{table}_tags_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         project = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -103,15 +71,15 @@
 
     return Tag
 
 
 # TODO: don't want to refactor everything in one PR so splitting this function to 2 versions - eventually only this one
 #  should be used
 def make_tag_v2(table):
-    class Tag(Base, BaseModel):
+    class Tag(Base, mlrun.utils.db.BaseModel):
         __tablename__ = f"{table}_tags"
         __table_args__ = (
             UniqueConstraint("project", "name", "obj_name", name=f"_{table}_tags_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         project = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -125,15 +93,15 @@
     return Tag
 
 
 # quell SQLAlchemy warnings on duplicate class name (Label)
 with warnings.catch_warnings():
     warnings.simplefilter("ignore")
 
-    class Artifact(Base, HasStruct):
+    class Artifact(Base, mlrun.utils.db.HasStruct):
         __tablename__ = "artifacts"
         __table_args__ = (
             UniqueConstraint("uid", "project", "key", name="_artifacts_uc"),
         )
 
         Label = make_label(__tablename__)
         Tag = make_tag(__tablename__)
@@ -146,15 +114,15 @@
         # TODO: change to JSON, see mlrun/api/schemas/function.py::FunctionState for reasoning
         body = Column(BLOB)
         labels = relationship(Label)
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.key}/{self.uid}"
 
-    class Function(Base, HasStruct):
+    class Function(Base, mlrun.utils.db.HasStruct):
         __tablename__ = "functions"
         __table_args__ = (
             UniqueConstraint("name", "project", "uid", name="_functions_uc"),
         )
 
         Label = make_label(__tablename__)
         Tag = make_tag_v2(__tablename__)
@@ -167,27 +135,27 @@
         body = Column(BLOB)
         updated = Column(TIMESTAMP)
         labels = relationship(Label)
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.name}/{self.uid}"
 
-    class Log(Base, BaseModel):
+    class Log(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "logs"
 
         id = Column(Integer, primary_key=True)
         uid = Column(String(255, collation=SQLCollationUtil.collation()))
         project = Column(String(255, collation=SQLCollationUtil.collation()))
         # TODO: change to JSON, see mlrun/api/schemas/function.py::FunctionState for reasoning
         body = Column(BLOB)
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.uid}"
 
-    class Run(Base, HasStruct):
+    class Run(Base, mlrun.utils.db.HasStruct):
         __tablename__ = "runs"
         __table_args__ = (
             UniqueConstraint("uid", "project", "iteration", name="_runs_uc"),
         )
 
         Label = make_label(__tablename__)
         Tag = make_tag(__tablename__)
@@ -199,21 +167,26 @@
             String(255, collation=SQLCollationUtil.collation()), default="no-name"
         )
         iteration = Column(Integer)
         state = Column(String(255, collation=SQLCollationUtil.collation()))
         # TODO: change to JSON, see mlrun/api/schemas/function.py::FunctionState for reasoning
         body = Column(BLOB)
         start_time = Column(TIMESTAMP)
+        # requested logs column indicates whether logs were requested for this run
+        # None - old runs prior to the column addition, logs were already collected for them, so no need to collect them
+        # False - logs were not requested for this run
+        # True - logs were requested for this run
+        requested_logs = Column(BOOLEAN)
         updated = Column(TIMESTAMP, default=datetime.utcnow)
         labels = relationship(Label)
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.uid}/{self.iteration}"
 
-    class BackgroundTask(Base, BaseModel):
+    class BackgroundTask(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "background_tasks"
         __table_args__ = (
             UniqueConstraint("name", "project", name="_background_tasks_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(
@@ -223,15 +196,15 @@
             String(255, collation=SQLCollationUtil.collation()), nullable=False
         )
         created = Column(TIMESTAMP, default=datetime.now(timezone.utc))
         updated = Column(TIMESTAMP, default=datetime.now(timezone.utc))
         state = Column(String(255, collation=SQLCollationUtil.collation()))
         timeout = Column(Integer)
 
-    class Schedule(Base, BaseModel):
+    class Schedule(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "schedules_v2"
         __table_args__ = (UniqueConstraint("project", "name", name="_schedules_v2_uc"),)
 
         Label = make_label(__tablename__)
 
         id = Column(Integer, primary_key=True)
         project = Column(
@@ -275,22 +248,22 @@
     project_users = Table(
         "project_users",
         Base.metadata,
         Column("project_id", Integer, ForeignKey("projects.id")),
         Column("user_id", Integer, ForeignKey("users.id")),
     )
 
-    class User(Base, BaseModel):
+    class User(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "users"
         __table_args__ = (UniqueConstraint("name", name="_users_uc"),)
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
 
-    class Project(Base, BaseModel):
+    class Project(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "projects"
         # For now since we use project name a lot
         __table_args__ = (UniqueConstraint("name", name="_projects_uc"),)
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         description = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -316,43 +289,43 @@
             if self._full_object:
                 return pickle.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
             self._full_object = pickle.dumps(value)
 
-    class Feature(Base, BaseModel):
+    class Feature(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "features"
         id = Column(Integer, primary_key=True)
         feature_set_id = Column(Integer, ForeignKey("feature_sets.id"))
 
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         value_type = Column(String(255, collation=SQLCollationUtil.collation()))
 
         Label = make_label(__tablename__)
         labels = relationship(Label, cascade="all, delete-orphan")
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.name}"
 
-    class Entity(Base, BaseModel):
+    class Entity(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "entities"
         id = Column(Integer, primary_key=True)
         feature_set_id = Column(Integer, ForeignKey("feature_sets.id"))
 
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         value_type = Column(String(255, collation=SQLCollationUtil.collation()))
 
         Label = make_label(__tablename__)
         labels = relationship(Label, cascade="all, delete-orphan")
 
         def get_identifier_string(self) -> str:
             return f"{self.project}/{self.name}"
 
-    class FeatureSet(Base, BaseModel):
+    class FeatureSet(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "feature_sets"
         __table_args__ = (
             UniqueConstraint("name", "project", "uid", name="_feature_set_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -378,17 +351,17 @@
         @property
         def full_object(self):
             if self._full_object:
                 return json.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
-            self._full_object = json.dumps(value)
+            self._full_object = json.dumps(value, default=str)
 
-    class FeatureVector(Base, BaseModel):
+    class FeatureVector(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "feature_vectors"
         __table_args__ = (
             UniqueConstraint("name", "project", "uid", name="_feature_vectors_uc"),
         )
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
@@ -411,17 +384,17 @@
         @property
         def full_object(self):
             if self._full_object:
                 return json.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
-            self._full_object = json.dumps(value)
+            self._full_object = json.dumps(value, default=str)
 
-    class MarketplaceSource(Base, BaseModel):
+    class MarketplaceSource(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "marketplace_sources"
         __table_args__ = (UniqueConstraint("name", name="_marketplace_sources_uc"),)
 
         id = Column(Integer, primary_key=True)
         name = Column(String(255, collation=SQLCollationUtil.collation()))
         index = Column(Integer)
         created = Column(TIMESTAMP, default=datetime.now(timezone.utc))
@@ -435,17 +408,17 @@
         @property
         def full_object(self):
             if self._full_object:
                 return json.loads(self._full_object)
 
         @full_object.setter
         def full_object(self, value):
-            self._full_object = json.dumps(value)
+            self._full_object = json.dumps(value, default=str)
 
-    class DataVersion(Base, BaseModel):
+    class DataVersion(Base, mlrun.utils.db.BaseModel):
         __tablename__ = "data_versions"
         __table_args__ = (UniqueConstraint("version", name="_versions_uc"),)
 
         id = Column(Integer, primary_key=True)
         version = Column(String(255, collation=SQLCollationUtil.collation()))
         created = Column(TIMESTAMP, default=datetime.now(timezone.utc))
```

## mlrun/api/schemas/__init__.py

```diff
@@ -37,14 +37,15 @@
 )
 from .constants import (
     APIStates,
     ClusterizationRole,
     DeletionStrategy,
     FeatureStorePartitionByField,
     HeaderNames,
+    LogsCollectorMode,
     OrderType,
     PatchMode,
     RunPartitionByField,
     SortField,
 )
 from .feature_store import (
     EntitiesOutput,
@@ -95,21 +96,19 @@
     FeatureValues,
     GrafanaColumn,
     GrafanaDataPoint,
     GrafanaNumberColumn,
     GrafanaStringColumn,
     GrafanaTable,
     GrafanaTimeSeriesTarget,
-    Metric,
     ModelEndpoint,
     ModelEndpointList,
     ModelEndpointMetadata,
     ModelEndpointSpec,
     ModelEndpointStatus,
-    ModelMonitoringMode,
     ModelMonitoringStoreKinds,
 )
 from .object import ObjectKind, ObjectMetadata, ObjectSpec, ObjectStatus
 from .pipeline import PipelinesFormat, PipelinesOutput, PipelinesPagination
 from .project import (
     IguazioProject,
     Project,
```

## mlrun/api/schemas/client_spec.py

```diff
@@ -52,14 +52,15 @@
     preemptible_nodes_node_selector: typing.Optional[str]
     preemptible_nodes_tolerations: typing.Optional[str]
     default_preemption_mode: typing.Optional[str]
     force_run_local: typing.Optional[str]
     function: typing.Optional[Function]
     redis_url: typing.Optional[str]
     redis_type: typing.Optional[str]
+    sql_url: typing.Optional[str]
 
     # ce_mode is deprecated, we will use the full ce config instead and ce_mode will be removed in 1.6.0
     ce_mode: typing.Optional[str]
     ce: typing.Optional[dict]
     # not passing them as one object as it possible client user would like to override only one of the params
     calculate_artifact_hash: typing.Optional[str]
     generate_artifact_target_path_from_artifact_hash: typing.Optional[str]
```

## mlrun/api/schemas/constants.py

```diff
@@ -87,14 +87,18 @@
 class HeaderNames:
     projects_role = "x-projects-role"
     patch_mode = f"{headers_prefix}patch-mode"
     deletion_strategy = f"{headers_prefix}deletion-strategy"
     secret_store_token = f"{headers_prefix}secret-store-token"
     pipeline_arguments = f"{headers_prefix}pipeline-arguments"
     client_version = f"{headers_prefix}client-version"
+    python_version = f"{headers_prefix}client-python-version"
+    backend_version = f"{headers_prefix}be-version"
+    ui_version = f"{headers_prefix}ui-version"
+    ui_clear_cache = f"{headers_prefix}ui-clear-cache"
 
 
 class FeatureStorePartitionByField(mlrun.api.utils.helpers.StrEnum):
     name = "name"  # Supported for feature-store objects
 
     def to_partition_by_db_field(self, db_cls):
         if self.value == FeatureStorePartitionByField.name:
@@ -162,11 +166,30 @@
     offline = "offline"
     waiting_for_chief = "waiting_for_chief"
 
     @staticmethod
     def terminal_states():
         return [APIStates.online, APIStates.offline]
 
+    @staticmethod
+    def description(state: str):
+        return {
+            APIStates.online: "API is online",
+            APIStates.waiting_for_migrations: "API is waiting for migrations to be triggered. "
+            "Send POST request to /api/operations/migrations to trigger it",
+            APIStates.migrations_in_progress: "Migrations are in progress",
+            APIStates.migrations_failed: "Migrations failed, API can't be started",
+            APIStates.migrations_completed: "Migrations completed, API is waiting to become online",
+            APIStates.offline: "API is offline",
+            APIStates.waiting_for_chief: "API is waiting for chief to be ready",
+        }.get(state, f"Unknown API state '{state}'")
+
 
 class ClusterizationRole:
     chief = "chief"
     worker = "worker"
+
+
+class LogsCollectorMode:
+    legacy = "legacy"
+    sidecar = "sidecar"
+    best_effort = "best-effort"
```

## mlrun/api/schemas/feature_store.py

```diff
@@ -26,24 +26,24 @@
     ObjectStatus,
 )
 
 
 class Feature(BaseModel):
     name: str
     value_type: str
-    labels: Optional[dict]
+    labels: Optional[dict] = {}
 
     class Config:
         extra = Extra.allow
 
 
 class Entity(BaseModel):
     name: str
     value_type: str
-    labels: Optional[dict]
+    labels: Optional[dict] = {}
 
     class Config:
         extra = Extra.allow
 
 
 class FeatureSetSpec(ObjectSpec):
     entities: List[Entity] = []
```

## mlrun/api/schemas/frontend_spec.py

```diff
@@ -63,11 +63,12 @@
     function_deployment_mlrun_command: typing.Optional[str]
     auto_mount_type: typing.Optional[str]
     auto_mount_params: typing.Dict[str, str] = {}
     default_artifact_path: str
     default_function_pod_resources: Resources = Resources()
     default_function_preemption_mode: str
     feature_store_data_prefixes: typing.Optional[typing.Dict[str, str]]
+    allowed_artifact_path_prefixes_list: typing.List[str]
 
     # ce_mode is deprecated, we will use the full ce config instead and ce_mode will be removed in 1.6.0
     ce_mode: typing.Optional[str]
     ce: typing.Optional[dict]
```

## mlrun/api/schemas/marketplace.py

```diff
@@ -24,15 +24,15 @@
 
 
 # Defining a different base class (not ObjectMetadata), as there's no project and it differs enough to
 # justify a new class
 class MarketplaceObjectMetadata(BaseModel):
     name: str
     description: str = ""
-    labels: Optional[dict]
+    labels: Optional[dict] = {}
     updated: Optional[datetime]
     created: Optional[datetime]
 
     class Config:
         extra = Extra.allow
 
 
@@ -41,15 +41,15 @@
     functions = "functions"
 
 
 # Sources-related objects
 class MarketplaceSourceSpec(ObjectSpec):
     path: str  # URL to base directory, should include schema (s3://, etc...)
     channel: str
-    credentials: Optional[dict] = None
+    credentials: Optional[dict] = {}
 
 
 class MarketplaceSource(BaseModel):
     kind: ObjectKind = Field(ObjectKind.marketplace_source, const=True)
     metadata: MarketplaceObjectMetadata
     spec: MarketplaceSourceSpec
     status: Optional[ObjectStatus] = ObjectStatus(state="created")
```

## mlrun/api/schemas/model_endpoints.py

```diff
@@ -8,60 +8,94 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
+
+import json
+import typing
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 from pydantic import BaseModel, Field
 from pydantic.main import Extra
 
-import mlrun.api.utils.helpers
+import mlrun.model_monitoring
 from mlrun.api.schemas.object import ObjectKind, ObjectSpec, ObjectStatus
-from mlrun.utils.model_monitoring import EndpointType, create_model_endpoint_id
 
 
 class ModelMonitoringStoreKinds:
+    # TODO: do changes in examples & demos In 1.5.0 remove
     ENDPOINTS = "endpoints"
     EVENTS = "events"
 
 
 class ModelEndpointMetadata(BaseModel):
-    project: Optional[str]
-    labels: Optional[dict]
-    uid: Optional[str]
+    project: Optional[str] = ""
+    labels: Optional[dict] = {}
+    uid: Optional[str] = ""
 
     class Config:
         extra = Extra.allow
 
+    @classmethod
+    def from_flat_dict(cls, endpoint_dict: dict, json_parse_values: typing.List = None):
+        """Create a `ModelEndpointMetadata` object from an endpoint dictionary
 
-class ModelMonitoringMode(mlrun.api.utils.helpers.StrEnum):
-    enabled = "enabled"
-    disabled = "disabled"
+        :param endpoint_dict:     Model endpoint dictionary.
+        :param json_parse_values: List of dictionary keys with a JSON string value that will be parsed into a
+                                  dictionary using json.loads().
+        """
+        new_object = cls()
+        if json_parse_values is None:
+            json_parse_values = [mlrun.model_monitoring.EventFieldType.LABELS]
+
+        return _mapping_attributes(
+            base_model=new_object,
+            flattened_dictionary=endpoint_dict,
+            json_parse_values=json_parse_values,
+        )
 
 
 class ModelEndpointSpec(ObjectSpec):
-    function_uri: Optional[str]  # <project_name>/<function_name>:<tag>
-    model: Optional[str]  # <model_name>:<version>
-    model_class: Optional[str]
-    model_uri: Optional[str]
-    feature_names: Optional[List[str]]
-    label_names: Optional[List[str]]
-    stream_path: Optional[str]
-    algorithm: Optional[str]
-    monitor_configuration: Optional[dict]
-    active: Optional[bool]
-    monitoring_mode: Optional[str] = ModelMonitoringMode.disabled
+    function_uri: Optional[str] = ""  # <project_name>/<function_name>:<tag>
+    model: Optional[str] = ""  # <model_name>:<version>
+    model_class: Optional[str] = ""
+    model_uri: Optional[str] = ""
+    feature_names: Optional[List[str]] = []
+    label_names: Optional[List[str]] = []
+    stream_path: Optional[str] = ""
+    algorithm: Optional[str] = ""
+    monitor_configuration: Optional[dict] = {}
+    active: Optional[bool] = True
+    monitoring_mode: Optional[
+        mlrun.model_monitoring.ModelMonitoringMode
+    ] = mlrun.model_monitoring.ModelMonitoringMode.disabled.value
 
+    @classmethod
+    def from_flat_dict(cls, endpoint_dict: dict, json_parse_values: typing.List = None):
+        """Create a `ModelEndpointSpec` object from an endpoint dictionary
 
-class Metric(BaseModel):
-    name: str
-    values: List[Tuple[str, float]]
+        :param endpoint_dict:     Model endpoint dictionary.
+        :param json_parse_values: List of dictionary keys with a JSON string value that will be parsed into a
+                                  dictionary using json.loads().
+        """
+        new_object = cls()
+        if json_parse_values is None:
+            json_parse_values = [
+                mlrun.model_monitoring.EventFieldType.FEATURE_NAMES,
+                mlrun.model_monitoring.EventFieldType.LABEL_NAMES,
+                mlrun.model_monitoring.EventFieldType.MONITOR_CONFIGURATION,
+            ]
+        return _mapping_attributes(
+            base_model=new_object,
+            flattened_dictionary=endpoint_dict,
+            json_parse_values=json_parse_values,
+        )
 
 
 class Histogram(BaseModel):
     buckets: List[float]
     counts: List[int]
 
 
@@ -102,54 +136,137 @@
             weight=-1.0,
             expected=FeatureValues.from_dict(feature_stats),
             actual=FeatureValues.from_dict(current_stats),
         )
 
 
 class ModelEndpointStatus(ObjectStatus):
-    feature_stats: Optional[dict]
-    current_stats: Optional[dict]
-    first_request: Optional[str]
-    last_request: Optional[str]
-    accuracy: Optional[float]
-    error_count: Optional[int]
-    drift_status: Optional[str]
-    drift_measures: Optional[dict]
-    metrics: Optional[Dict[str, Metric]]
-    features: Optional[List[Features]]
-    children: Optional[List[str]]
-    children_uids: Optional[List[str]]
-    endpoint_type: Optional[EndpointType]
-    monitoring_feature_set_uri: Optional[str]
+    feature_stats: Optional[dict] = {}
+    current_stats: Optional[dict] = {}
+    first_request: Optional[str] = ""
+    last_request: Optional[str] = ""
+    error_count: Optional[int] = 0
+    drift_status: Optional[str] = ""
+    drift_measures: Optional[dict] = {}
+    metrics: Optional[Dict[str, Dict[str, Any]]] = {
+        mlrun.model_monitoring.EventKeyMetrics.GENERIC: {
+            mlrun.model_monitoring.EventLiveStats.LATENCY_AVG_1H: 0,
+            mlrun.model_monitoring.EventLiveStats.PREDICTIONS_PER_SECOND: 0,
+        }
+    }
+    features: Optional[List[Features]] = []
+    children: Optional[List[str]] = []
+    children_uids: Optional[List[str]] = []
+    endpoint_type: Optional[
+        mlrun.model_monitoring.EndpointType
+    ] = mlrun.model_monitoring.EndpointType.NODE_EP.value
+    monitoring_feature_set_uri: Optional[str] = ""
+    state: Optional[str] = ""
 
     class Config:
         extra = Extra.allow
 
+    @classmethod
+    def from_flat_dict(cls, endpoint_dict: dict, json_parse_values: typing.List = None):
+        """Create a `ModelEndpointStatus` object from an endpoint dictionary
+
+        :param endpoint_dict:     Model endpoint dictionary.
+        :param json_parse_values: List of dictionary keys with a JSON string value that will be parsed into a
+                                  dictionary using json.loads().
+        """
+        new_object = cls()
+        if json_parse_values is None:
+            json_parse_values = [
+                mlrun.model_monitoring.EventFieldType.FEATURE_STATS,
+                mlrun.model_monitoring.EventFieldType.CURRENT_STATS,
+                mlrun.model_monitoring.EventFieldType.DRIFT_MEASURES,
+                mlrun.model_monitoring.EventFieldType.METRICS,
+                mlrun.model_monitoring.EventFieldType.CHILDREN,
+                mlrun.model_monitoring.EventFieldType.CHILDREN_UIDS,
+                mlrun.model_monitoring.EventFieldType.ENDPOINT_TYPE,
+            ]
+        return _mapping_attributes(
+            base_model=new_object,
+            flattened_dictionary=endpoint_dict,
+            json_parse_values=json_parse_values,
+        )
+
 
 class ModelEndpoint(BaseModel):
     kind: ObjectKind = Field(ObjectKind.model_endpoint, const=True)
-    metadata: ModelEndpointMetadata
-    spec: ModelEndpointSpec
-    status: ModelEndpointStatus
+    metadata: ModelEndpointMetadata = ModelEndpointMetadata()
+    spec: ModelEndpointSpec = ModelEndpointSpec()
+    status: ModelEndpointStatus = ModelEndpointStatus()
 
     class Config:
         extra = Extra.allow
 
     def __init__(self, **data: Any):
         super().__init__(**data)
         if self.metadata.uid is None:
-            uid = create_model_endpoint_id(
+            uid = mlrun.model_monitoring.create_model_endpoint_uid(
                 function_uri=self.spec.function_uri,
                 versioned_model=self.spec.model,
             )
             self.metadata.uid = str(uid)
 
+    def flat_dict(self):
+        """Generate a flattened `ModelEndpoint` dictionary. The flattened dictionary result is important for storing
+        the model endpoint object in the database.
+
+        :return: Flattened `ModelEndpoint` dictionary.
+        """
+        # Convert the ModelEndpoint object into a dictionary using BaseModel dict() function
+        # In addition, remove the BaseModel kind as it is not required by the DB schema
+        model_endpoint_dictionary = self.dict(exclude={"kind"})
+
+        # Initialize a flattened dictionary that will be filled with the model endpoint dictionary attributes
+        flatten_dict = {}
+        for k_object in model_endpoint_dictionary:
+            for key in model_endpoint_dictionary[k_object]:
+                # If the value is not from type str or bool (e.g. dict), convert it into a JSON string
+                # for matching the database required format
+                if not isinstance(
+                    model_endpoint_dictionary[k_object][key], (str, bool)
+                ):
+                    flatten_dict[key] = json.dumps(
+                        model_endpoint_dictionary[k_object][key]
+                    )
+                else:
+                    flatten_dict[key] = model_endpoint_dictionary[k_object][key]
+
+        if mlrun.model_monitoring.EventFieldType.METRICS not in flatten_dict:
+            # Initialize metrics dictionary
+            flatten_dict[mlrun.model_monitoring.EventFieldType.METRICS] = {
+                mlrun.model_monitoring.EventKeyMetrics.GENERIC: {
+                    mlrun.model_monitoring.EventLiveStats.LATENCY_AVG_1H: 0,
+                    mlrun.model_monitoring.EventLiveStats.PREDICTIONS_PER_SECOND: 0,
+                }
+            }
+        # Remove the features from the dictionary as this field will be filled only within the feature analysis process
+        flatten_dict.pop(mlrun.model_monitoring.EventFieldType.FEATURES, None)
+        return flatten_dict
+
+    @classmethod
+    def from_flat_dict(cls, endpoint_dict: dict):
+        """Create a `ModelEndpoint` object from an endpoint flattened dictionary. Because the provided dictionary
+        is flattened, we pass it as is to the subclasses without splitting the keys into spec, metadata, and status.
+
+        :param endpoint_dict:     Model endpoint dictionary.
+        """
+
+        return cls(
+            metadata=ModelEndpointMetadata.from_flat_dict(endpoint_dict=endpoint_dict),
+            spec=ModelEndpointSpec.from_flat_dict(endpoint_dict=endpoint_dict),
+            status=ModelEndpointStatus.from_flat_dict(endpoint_dict=endpoint_dict),
+        )
+
 
 class ModelEndpointList(BaseModel):
-    endpoints: List[ModelEndpoint]
+    endpoints: List[ModelEndpoint] = []
 
 
 class GrafanaColumn(BaseModel):
     text: str
     type: str
 
 
@@ -179,7 +296,44 @@
 
 class GrafanaTimeSeriesTarget(BaseModel):
     target: str
     datapoints: List[Tuple[float, int]] = []
 
     def add_data_point(self, data_point: GrafanaDataPoint):
         self.datapoints.append((data_point.value, data_point.timestamp))
+
+
+def _mapping_attributes(
+    base_model: BaseModel,
+    flattened_dictionary: dict,
+    json_parse_values: typing.List = None,
+):
+    """Generate a `BaseModel` object with the provided dictionary attributes.
+
+    :param base_model:           `BaseModel` object (e.g. `ModelEndpointMetadata`).
+    :param flattened_dictionary: Flattened dictionary that contains the model endpoint attributes.
+    :param json_parse_values:    List of dictionary keys with a JSON string value that will be parsed into a
+                                 dictionary using json.loads().
+    """
+    # Get the fields of the provided base model object. These fields will be used to filter to relevent keys
+    # from the flattened dictionary.
+    wanted_keys = base_model.__fields__.keys()
+
+    # Generate a filtered flattened dictionary that will be parsed into the BaseModel object
+    dict_to_parse = {}
+    for field_key in wanted_keys:
+        if field_key in flattened_dictionary:
+            if field_key in json_parse_values:
+                # Parse the JSON value into a valid dictionary
+                dict_to_parse[field_key] = _json_loads_if_not_none(
+                    flattened_dictionary[field_key]
+                )
+            else:
+                dict_to_parse[field_key] = flattened_dictionary[field_key]
+
+    return base_model.parse_obj(dict_to_parse)
+
+
+def _json_loads_if_not_none(field: Any) -> Any:
+    return (
+        json.loads(field) if field and field != "null" and field is not None else None
+    )
```

## mlrun/api/schemas/object.py

```diff
@@ -20,15 +20,15 @@
 import mlrun.api.utils.helpers
 
 
 class ObjectMetadata(BaseModel):
     name: str
     project: Optional[str]
     tag: Optional[str]
-    labels: Optional[dict]
+    labels: Optional[dict] = {}
     updated: Optional[datetime]
     created: Optional[datetime]
     uid: Optional[str]
 
     class Config:
         extra = Extra.allow
```

## mlrun/api/schemas/project.py

```diff
@@ -28,16 +28,16 @@
     # internal - allowed only in follower mode, only for the leader for upgrade purposes
     leader = "leader"
 
 
 class ProjectMetadata(pydantic.BaseModel):
     name: str
     created: typing.Optional[datetime.datetime] = None
-    labels: typing.Optional[dict]
-    annotations: typing.Optional[dict]
+    labels: typing.Optional[dict] = {}
+    annotations: typing.Optional[dict] = {}
 
     class Config:
         extra = pydantic.Extra.allow
 
 
 class ProjectDesiredState(mlrun.api.utils.helpers.StrEnum):
     online = "online"
@@ -66,18 +66,18 @@
     state: typing.Optional[ProjectState]
 
 
 class ProjectSpec(pydantic.BaseModel):
     description: typing.Optional[str] = None
     owner: typing.Optional[str] = None
     goals: typing.Optional[str] = None
-    params: typing.Optional[dict] = None
-    functions: typing.Optional[list] = None
-    workflows: typing.Optional[list] = None
-    artifacts: typing.Optional[list] = None
+    params: typing.Optional[dict] = {}
+    functions: typing.Optional[list] = []
+    workflows: typing.Optional[list] = []
+    artifacts: typing.Optional[list] = []
     artifact_path: typing.Optional[str] = None
     conda: typing.Optional[str] = None
     source: typing.Optional[str] = None
     subpath: typing.Optional[str] = None
     origin_url: typing.Optional[str] = None
     desired_state: typing.Optional[ProjectDesiredState] = ProjectDesiredState.online
 
@@ -101,15 +101,15 @@
     name: str
     files_count: int
     feature_sets_count: int
     models_count: int
     runs_failed_recent_count: int
     runs_running_count: int
     schedules_count: int
-    pipelines_running_count: int
+    pipelines_running_count: typing.Optional[int] = None
 
 
 class IguazioProject(pydantic.BaseModel):
     data: dict
 
 
 class ProjectsOutput(pydantic.BaseModel):
```

## mlrun/api/schemas/schedule.py

```diff
@@ -9,15 +9,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from datetime import datetime
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, List, Optional, Union
 
 from pydantic import BaseModel
 
 import mlrun.api.utils.helpers
 from mlrun.api.schemas.auth import Credentials
 from mlrun.api.schemas.object import LabelRecord
 
@@ -32,16 +32,16 @@
     month: Optional[Union[int, str]]
     day: Optional[Union[int, str]]
     week: Optional[Union[int, str]]
     day_of_week: Optional[Union[int, str]]
     hour: Optional[Union[int, str]]
     minute: Optional[Union[int, str]]
     second: Optional[Union[int, str]]
-    start_date: Optional[Union[datetime, str]]
-    end_date: Optional[Union[datetime, str]]
+    start_date: Union[datetime, str] = None
+    end_date: Union[datetime, str] = None
 
     # APScheduler also supports datetime.tzinfo type, but Pydantic doesn't - so we don't
     timezone: Optional[str]
     jitter: Optional[int]
 
     @classmethod
     def from_crontab(cls, expr, timezone=None):
@@ -67,14 +67,20 @@
             hour=values[1],
             day=values[2],
             month=values[3],
             day_of_week=values[4],
             timezone=timezone,
         )
 
+    def to_crontab(self) -> str:
+        """
+        Convert the trigger to a crontab expression.
+        """
+        return f"{self.minute} {self.hour} {self.day} {self.month} {self.day_of_week}"
+
 
 class ScheduleKinds(mlrun.api.utils.helpers.StrEnum):
     job = "job"
     pipeline = "pipeline"
 
     # this is mainly for testing purposes
     local_function = "local_function"
@@ -86,27 +92,27 @@
         ]
 
 
 class ScheduleUpdate(BaseModel):
     scheduled_object: Optional[Any]
     cron_trigger: Optional[Union[str, ScheduleCronTrigger]]
     desired_state: Optional[str]
-    labels: Optional[dict]
+    labels: Optional[dict] = {}
     concurrency_limit: Optional[int]
     credentials: Credentials = Credentials()
 
 
 # Properties to receive via API on creation
 class ScheduleInput(BaseModel):
     name: str
     kind: ScheduleKinds
     scheduled_object: Any
     cron_trigger: Union[str, ScheduleCronTrigger]
     desired_state: Optional[str]
-    labels: Optional[dict]
+    labels: Optional[dict] = {}
     concurrency_limit: Optional[int]
     credentials: Credentials = Credentials()
 
 
 # the schedule object returned from the db layer
 class ScheduleRecord(ScheduleInput):
     creation_time: datetime
@@ -119,14 +125,14 @@
     class Config:
         orm_mode = True
 
 
 # Additional properties to return via API
 class ScheduleOutput(ScheduleRecord):
     next_run_time: Optional[datetime]
-    last_run: Optional[Dict]
-    labels: Optional[dict]
+    last_run: Optional[dict] = {}
+    labels: Optional[dict] = {}
     credentials: Credentials = Credentials()
 
 
 class SchedulesOutput(BaseModel):
     schedules: List[ScheduleOutput]
```

## mlrun/api/schemas/secret.py

```diff
@@ -24,15 +24,15 @@
 
     vault = "vault"
     kubernetes = "kubernetes"
 
 
 class SecretsData(BaseModel):
     provider: SecretProviderName = Field(SecretProviderName.vault)
-    secrets: Optional[dict]
+    secrets: Optional[dict] = {}
 
 
 class AuthSecretData(BaseModel):
     provider: SecretProviderName = Field(SecretProviderName.kubernetes)
     username: str
     access_key: str
 
@@ -42,12 +42,12 @@
             "username": "username",
             "access_key": "accessKey",
         }[field]
 
 
 class SecretKeysData(BaseModel):
     provider: SecretProviderName = Field(SecretProviderName.vault)
-    secret_keys: Optional[list]
+    secret_keys: Optional[list] = []
 
 
 class UserSecretCreationRequest(SecretsData):
     user: str
```

## mlrun/api/utils/scheduler.py

```diff
@@ -53,16 +53,16 @@
     _db_record_auth_label = "mlrun-auth-key"
 
     def __init__(self):
         scheduler_config = json.loads(config.httpdb.scheduling.scheduler_config)
         self._scheduler = AsyncIOScheduler(gconfig=scheduler_config, prefix=None)
         # this should be something that does not make any sense to be inside project name or job name
         self._job_id_separator = "-_-"
-        # we don't allow to schedule a job to run more then one time per X
-        # NOTE this cannot be less then one minute - see _validate_cron_trigger
+        # we don't allow to schedule a job to run more than one time per X
+        # NOTE this cannot be less than one minute - see _validate_cron_trigger
         self._min_allowed_interval = config.httpdb.scheduling.min_allowed_interval
         self._secrets_provider = schemas.SecretProviderName.kubernetes
 
     async def start(self, db_session: Session):
         logger.info("Starting scheduler")
         self._scheduler.start()
         # the scheduler shutdown and start operation are not fully async compatible yet -
@@ -546,26 +546,25 @@
     def _validate_cron_trigger(
         self,
         cron_trigger: schemas.ScheduleCronTrigger,
         # accepting now from outside for testing purposes
         now: datetime = None,
     ):
         """
-        Enforce no more then one job per min_allowed_interval
+        Enforce no more than one job per min_allowed_interval
         """
-        logger.debug("Validating cron trigger")
         apscheduler_cron_trigger = (
             self.transform_schemas_cron_trigger_to_apscheduler_cron_trigger(
                 cron_trigger
             )
         )
         now = now or datetime.now(apscheduler_cron_trigger.timezone)
         second_next_run_time = now
 
-        # doing 60 checks to allow one minute precision, if the _min_allowed_interval is less then one minute validation
+        # doing 60 checks to allow one minute precision, if the _min_allowed_interval is less than one minute validation
         # won't fail in certain scenarios that it should. See test_validate_cron_trigger_multi_checks for detailed
         # explanation
         for index in range(60):
             next_run_time = apscheduler_cron_trigger.get_next_fire_time(
                 None, second_next_run_time
             )
             # will be none if we got a schedule that has no next fire time - for example schedule with year=1999
```

## mlrun/api/utils/auth/providers/opa.py

```diff
@@ -10,14 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 
 import asyncio
+import contextlib
 import copy
 import datetime
 import typing
 
 import humanfriendly
 
 import mlrun.api.schemas
@@ -91,18 +92,18 @@
         if self._is_request_from_leader(auth_info.projects_role):
             return True
         if self._check_allowed_project_owners_cache(resource, auth_info):
             return True
         body = self._generate_permission_request_body(resource, action, auth_info)
         if self._log_level > 5:
             logger.debug("Sending request to OPA", body=body)
-        response = await self._send_request_to_api(
+        async with self._send_request_to_api(
             "POST", self._permission_query_path, json=body
-        )
-        response_body = await response.json()
+        ) as response:
+            response_body = await response.json()
         if self._log_level > 5:
             logger.debug("Received response from OPA", body=response_body)
         allowed = response_body["result"]
         if not allowed and raise_on_forbidden:
             raise mlrun.errors.MLRunAccessDeniedError(
                 f"Not allowed to {action} resource {resource}"
             )
@@ -130,18 +131,18 @@
                 allowed_by_cache = False
                 break
         if allowed_by_cache:
             return resources
         body = self._generate_filter_request_body(opa_resources, action, auth_info)
         if self._log_level > 5:
             logger.debug("Sending filter request to OPA", body=body)
-        response = await self._send_request_to_api(
+        async with self._send_request_to_api(
             "POST", self._permission_filter_path, json=body
-        )
-        response_body = await response.json()
+        ) as response:
+            response_body = await response.json()
         if self._log_level > 5:
             logger.debug("Received filter response from OPA", body=response_body)
         allowed_opa_resources = response_body["result"]
         allowed_resources = []
         for index, opa_resource in enumerate(opa_resources):
             if opa_resource in allowed_opa_resources:
                 allowed_resources.append(resources[index])
@@ -200,35 +201,46 @@
     def _is_request_from_leader(
         self, projects_role: typing.Optional[mlrun.api.schemas.ProjectsRole]
     ):
         if projects_role and projects_role.value == self._leader_name:
             return True
         return False
 
+    @contextlib.asynccontextmanager
     async def _send_request_to_api(self, method, path, **kwargs):
         url = f"{self._api_url}{path}"
         if kwargs.get("timeout") is None:
             kwargs["timeout"] = self._request_timeout
         await self._ensure_session()
-        async with self._session.request(
-            method, url, verify_ssl=False, **kwargs
-        ) as response:
+        response = None
+        try:
+            response = await self._session.request(
+                method, url, verify_ssl=False, **kwargs
+            )
             if not response.ok:
-                log_kwargs = copy.deepcopy(kwargs)
-                log_kwargs.update({"method": method, "path": path})
-                if response.content:
-                    try:
-                        data = await response.json()
-                    except Exception:
-                        pass
-                    else:
-                        log_kwargs.update({"data": data})
-                logger.warning("Request to opa failed", **log_kwargs)
-                mlrun.errors.raise_for_status(response)
-            return response
+                await self._on_request_api_failure(method, path, response, **kwargs)
+            yield response
+        finally:
+            if response:
+                response.release()
+
+    async def _on_request_api_failure(self, method, path, response, **kwargs):
+        log_kwargs = copy.deepcopy(kwargs)
+        log_kwargs.update({"method": method, "path": path})
+        if response.content:
+            try:
+                data = await response.json()
+            except Exception:
+                try:
+                    data = await response.text()
+                except Exception:
+                    data = None
+            log_kwargs.update({"data": data})
+        logger.warning("Request to opa failed", **log_kwargs)
+        mlrun.errors.raise_for_status(response)
 
     @staticmethod
     def _generate_permission_request_body(
         resource: str,
         action: mlrun.api.schemas.AuthorizationAction,
         auth_info: mlrun.api.schemas.AuthInfo,
     ) -> dict:
```

## mlrun/api/utils/clients/chief.py

```diff
@@ -226,17 +226,22 @@
             if http.cookies.Morsel().isReservedKey(cookie_name):
                 del request_kwargs["cookies"][cookie_name]
 
             # iguazio auth cookies might include special characters. to ensure the http client wont escape them
             # we will url-encode them (aka quote), so the value would be safe against such escaping.
             # e.g.: instead of having "x":"y" being escaped to "\"x\":\"y\"", it will be escaped to "%22x%22:%22y%22"
             elif cookie_name == "session" and mlrun.mlconf.is_running_on_iguazio():
-                request_kwargs["cookies"][cookie_name] = urllib.parse.quote(
+
+                # unquote first, to avoid double quoting ourselves, in case the cookie is already quoted
+                unquoted_session = urllib.parse.unquote(
                     request_kwargs["cookies"][cookie_name]
                 )
+                request_kwargs["cookies"][cookie_name] = urllib.parse.quote(
+                    unquoted_session
+                )
 
         request_kwargs.update(**kwargs)
         return request_kwargs
 
     @staticmethod
     async def _convert_requests_response_to_fastapi_response(
         chief_response: aiohttp.ClientResponse,
```

## mlrun/api/utils/clients/iguazio.py

```diff
@@ -449,15 +449,21 @@
     def _send_request_to_api(
         self, method, path, error_message: str, session=None, **kwargs
     ):
         url = f"{self._api_url}/api/{path}"
         self._prepare_request_kwargs(session, path, kwargs=kwargs)
         response = self._session.request(method, url, verify=False, **kwargs)
         if not response.ok:
-            self._handle_error_response(method, path, response, error_message, kwargs)
+            try:
+                response_body = response.json()
+            except Exception:
+                response_body = {}
+            self._handle_error_response(
+                method, path, response, response_body, error_message, kwargs
+            )
         return response
 
     def _generate_auth_info_from_session_verification_response(
         self,
         response_headers: typing.Mapping[str, typing.Any],
         response_body: typing.Mapping[typing.Any, typing.Any],
     ) -> mlrun.api.schemas.AuthInfo:
@@ -682,27 +688,30 @@
         # convert to strings. Do the same for params for niceness
         for kwarg in ["headers", "params"]:
             dict_ = kwargs.get(kwarg, {})
             for key in dict_.keys():
                 if isinstance(dict_[key], enum.Enum):
                     dict_[key] = dict_[key].value
 
-    def _handle_error_response(self, method, path, response, error_message, kwargs):
+    def _handle_error_response(
+        self, method, path, response, response_body, error_message, kwargs
+    ):
         log_kwargs = copy.deepcopy(kwargs)
         log_kwargs.update({"method": method, "path": path})
-        if response.content:
-            try:
-                data = response.json()
-                ctx = data.get("meta", {}).get("ctx")
-                errors = data.get("errors", [])
-            except Exception:
-                pass
-            else:
+        try:
+            ctx = response_body.get("meta", {}).get("ctx")
+            errors = response_body.get("errors", [])
+        except Exception:
+            pass
+        else:
+            if errors:
                 error_message = f"{error_message}: {str(errors)}"
+            if errors or ctx:
                 log_kwargs.update({"ctx": ctx, "errors": errors})
+
         logger.warning("Request to iguazio failed", **log_kwargs)
         mlrun.errors.raise_for_status(response, error_message)
 
 
 class AsyncClient(Client):
     def __init__(
         self,
@@ -783,16 +792,20 @@
         await self._ensure_async_session()
         response = None
         try:
             response = await self._async_session.request(
                 method, url, verify_ssl=False, **kwargs
             )
             if not response.ok:
+                try:
+                    response_body = await response.json()
+                except Exception:
+                    response_body = {}
                 self._handle_error_response(
-                    method, path, response, error_message, kwargs
+                    method, path, response, response_body, error_message, kwargs
                 )
             yield response
         finally:
             if response:
                 response.release()
 
     async def _ensure_async_session(self):
```

## mlrun/api/utils/db/backup.py

```diff
@@ -33,14 +33,18 @@
     ) -> None:
         self._backup_file_format = backup_file_format
         self._backup_rotation = backup_rotation
         self._backup_rotation_limit = backup_rotation_limit
 
     def backup_database(self, backup_file_name: str = None) -> None:
         backup_file_name = backup_file_name or self._generate_backup_file_name()
+
+        # ensure the backup directory exists
+        self._get_db_dir_path().mkdir(parents=True, exist_ok=True)
+
         if ":memory:" in mlconf.httpdb.dsn:
             return
         elif "mysql" in mlconf.httpdb.dsn:
             self._backup_database_mysql(backup_file_name)
         else:
             self._backup_database_sqlite(backup_file_name)
```

## mlrun/api/utils/db/mysql.py

```diff
@@ -79,15 +79,15 @@
             connection.close()
 
     def check_db_has_data(self):
         connection = self._create_connection()
         try:
             with connection.cursor() as cursor:
                 for check_table in self.check_tables:
-                    cursor.execute(f"SELECT COUNT(*) FROM `{check_table}`;")
+                    cursor.execute("SELECT COUNT(*) FROM %s;", (check_table,))
                     if cursor.fetchone()[0] > 0:
                         return True
             return False
         finally:
             connection.close()
 
     def _create_connection(self):
```

## mlrun/api/utils/projects/member.py

```diff
@@ -13,17 +13,20 @@
 # limitations under the License.
 #
 import abc
 import typing
 
 import sqlalchemy.orm
 
+import mlrun.api.crud
 import mlrun.api.db.session
 import mlrun.api.schemas
+import mlrun.api.utils.clients.log_collector
 import mlrun.utils.singleton
+from mlrun.utils import logger
 
 
 class Member(abc.ABC):
     @abc.abstractmethod
     def initialize(self):
         pass
 
@@ -143,7 +146,69 @@
     @abc.abstractmethod
     def get_project_owner(
         self,
         db_session: sqlalchemy.orm.Session,
         name: str,
     ) -> mlrun.api.schemas.ProjectOwner:
         pass
+
+    async def post_delete_project(
+        self,
+        project_name: str,
+    ):
+        if (
+            mlrun.mlconf.log_collector.mode
+            != mlrun.api.schemas.LogsCollectorMode.legacy
+        ):
+            await self._stop_logs_for_project(project_name)
+            await self._delete_project_logs(project_name)
+
+    @staticmethod
+    async def _stop_logs_for_project(
+        project_name: str,
+    ) -> None:
+
+        logger.debug("Stopping logs for project", project=project_name)
+
+        try:
+            log_collector_client = (
+                mlrun.api.utils.clients.log_collector.LogCollectorClient()
+            )
+            await log_collector_client.stop_logs(
+                project=project_name,
+            )
+        except Exception as exc:
+            logger.warning(
+                "Failed stopping logs for project's runs. Ignoring",
+                exc=mlrun.errors.err_to_str(exc),
+                project=project_name,
+            )
+
+        logger.debug(
+            "Successfully stopped logs for project's runs", project=project_name
+        )
+
+    @staticmethod
+    async def _delete_project_logs(
+        project_name: str,
+    ) -> None:
+
+        logger.debug("Deleting logs for project", project=project_name)
+
+        try:
+            log_collector_client = (
+                mlrun.api.utils.clients.log_collector.LogCollectorClient()
+            )
+            await log_collector_client.delete_logs(
+                project=project_name,
+            )
+        except Exception as exc:
+            logger.warning(
+                "Failed deleting project logs via the log collector. Falling back to deleting logs explicitly",
+                exc=mlrun.errors.err_to_str(exc),
+                project=project_name,
+            )
+
+            # fallback to deleting logs explicitly if the project logs deletion failed
+            mlrun.api.crud.Logs().delete_logs(project_name)
+
+        logger.debug("Successfully deleted project logs", project=project_name)
```

## mlrun/artifacts/base.py

```diff
@@ -12,18 +12,18 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import hashlib
 import os
 import pathlib
 import tempfile
 import typing
-import warnings
 import zipfile
 
 import yaml
+from deprecated import deprecated
 
 import mlrun
 import mlrun.errors
 
 from ..datastore import get_store_uri, is_store_uri, store_manager
 from ..model import ModelObj
 from ..utils import (
@@ -443,418 +443,146 @@
     # removed once we only work with the new Artifact structure.
 
     def is_inline(self):
         return self.spec._is_inline
 
     @property
     def inline(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.inline instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.inline
 
     @inline.setter
     def inline(self, body):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.inline instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.inline = body
 
     @property
     def tag(self):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.tag instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.metadata.tag
 
     @tag.setter
     def tag(self, tag):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.tag instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.metadata.tag = tag
 
     @property
     def key(self):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.key instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.metadata.key
 
     @key.setter
     def key(self, key):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.key instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.metadata.key = key
 
     @property
     def src_path(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.src_path instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.src_path
 
     @src_path.setter
     def src_path(self, src_path):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.src_path instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.src_path = src_path
 
     @property
     def target_path(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.target_path instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.target_path
 
     @target_path.setter
     def target_path(self, target_path):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.target_path instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.target_path = target_path
 
     @property
     def producer(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.producer instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.producer
 
     @producer.setter
     def producer(self, producer):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.producer instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.producer = producer
 
     @property
     def format(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.format instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.format
 
     @format.setter
     def format(self, format):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.format instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.format = format
 
     @property
     def viewer(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.viewer instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.viewer
 
     @viewer.setter
     def viewer(self, viewer):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.viewer instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.viewer = viewer
 
     @property
     def size(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.size instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.size
 
     @size.setter
     def size(self, size):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.size instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.size = size
 
     @property
     def db_key(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.db_key instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.db_key
 
     @db_key.setter
     def db_key(self, db_key):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.db_key instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.db_key = db_key
 
     @property
     def sources(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.sources instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.sources
 
     @sources.setter
     def sources(self, sources):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.sources instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.sources = sources
 
     @property
     def extra_data(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.extra_data instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.extra_data
 
     @extra_data.setter
     def extra_data(self, extra_data):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.extra_data instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.extra_data = extra_data
 
     @property
     def labels(self):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.metadata.labels instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.metadata.labels
 
     @labels.setter
     def labels(self, labels):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.labels instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.metadata.labels = labels
 
     @property
     def iter(self):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.metadata.iter instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.metadata.iter
 
     @iter.setter
     def iter(self, iter):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.iter instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.metadata.iter = iter
 
     @property
     def tree(self):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.metadata.tree instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.metadata.tree
 
     @tree.setter
     def tree(self, tree):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.tree instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.metadata.tree = tree
 
     @property
     def project(self):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.metadata.project instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.metadata.project
 
     @project.setter
     def project(self, project):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.project instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.metadata.project = project
 
     @property
     def hash(self):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.metadata.hash instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         return self.metadata.hash
 
     @hash.setter
     def hash(self, hash):
-        """This is a property of the metadata, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the metadata, use artifact.metadata.hash instead"
-            "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
-            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
-            PendingDeprecationWarning,
-        )
         self.metadata.hash = hash
 
     def generate_target_path(self, artifact_path, producer):
         return generate_target_path(self, artifact_path, producer)
 
 
 class DirArtifactSpec(ArtifactSpec):
@@ -963,14 +691,20 @@
         return self._spec
 
     @spec.setter
     def spec(self, spec):
         self._spec = self._verify_dict(spec, "spec", LinkArtifactSpec)
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyArtifact' will be removed in 1.5.0, use 'Artifact' instead",
+    category=FutureWarning,
+)
 class LegacyArtifact(ModelObj):
 
     _dict_fields = [
         "key",
         "kind",
         "iter",
         "tree",
@@ -1124,14 +858,20 @@
     def artifact_kind(self):
         return self.kind
 
     def generate_target_path(self, artifact_path, producer):
         return generate_target_path(self, artifact_path, producer)
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyDirArtifact' will be removed in 1.5.0, use 'DirArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyDirArtifact(LegacyArtifact):
     _dict_fields = [
         "key",
         "kind",
         "iter",
         "tree",
         "src_path",
@@ -1154,14 +894,20 @@
             file_path = os.path.join(self.src_path, f)
             if not os.path.isfile(file_path):
                 raise ValueError(f"file {file_path} not found, cant upload")
             target = os.path.join(self.target_path, f)
             store_manager.object(url=target).upload(file_path)
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyLinkArtifact' will be removed in 1.5.0, use 'LinkArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyLinkArtifact(LegacyArtifact):
     _dict_fields = LegacyArtifact._dict_fields + [
         "link_iteration",
         "link_key",
         "link_tree",
     ]
     kind = "link"
```

## mlrun/artifacts/dataset.py

```diff
@@ -9,20 +9,20 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import pathlib
-import warnings
 from io import StringIO
 from typing import Optional, Tuple
 
 import numpy as np
 import pandas as pd
+from deprecated import deprecated
 from pandas.io.json import build_table_schema
 
 import mlrun
 import mlrun.utils.helpers
 
 from ..datastore import is_store_uri, store_manager
 from .base import Artifact, ArtifactSpec, LegacyArtifact
@@ -277,133 +277,59 @@
             )
             or ignore_preview_limits
         ):
             artifact.status.stats = get_df_stats(df)
 
     @property
     def column_metadata(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.column_metadata instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.column_metadata
 
     @column_metadata.setter
     def column_metadata(self, column_metadata):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.column_metadata instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.column_metadata = column_metadata
 
     @property
     def schema(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.schema instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.schema
 
     @schema.setter
     def schema(self, schema):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.schema instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.schema = schema
 
     @property
     def header(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.header instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.header
 
     @header.setter
     def header(self, header):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.header instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.header = header
 
     @property
     def preview(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the status, use artifact.status.preview instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.status.preview
 
     @preview.setter
     def preview(self, preview):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the status, use artifact.status.preview instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.status.preview = preview
 
     @property
     def stats(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the status, use artifact.status.stats instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.status.stats
 
     @stats.setter
     def stats(self, stats):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the status, use artifact.status.stats instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.status.stats = stats
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyTableArtifact' will be removed in 1.5.0, use 'TableArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyTableArtifact(LegacyArtifact):
     _dict_fields = LegacyArtifact._dict_fields + ["schema", "header"]
     kind = "table"
 
     def __init__(
         self,
         key=None,
@@ -443,14 +369,20 @@
         if not self._is_df:
             return self._body
         csv_buffer = StringIO()
         self._body.to_csv(csv_buffer, line_terminator="\n", encoding="utf-8")
         return csv_buffer.getvalue()
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyDatasetArtifact' will be removed in 1.5.0, use 'DatasetArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyDatasetArtifact(LegacyArtifact):
     # List of all the supported saving formats of a DataFrame:
     SUPPORTED_FORMATS = ["csv", "parquet", "pq", "tsdb", "kv"]
 
     _dict_fields = LegacyArtifact._dict_fields + [
         "schema",
         "header",
```

## mlrun/artifacts/manager.py

```diff
@@ -14,15 +14,21 @@
 import pathlib
 import typing
 from os.path import isdir
 
 import mlrun.config
 
 from ..db import RunDBInterface
-from ..utils import is_legacy_artifact, is_relative_path, logger, validate_tag_name
+from ..utils import (
+    is_legacy_artifact,
+    is_relative_path,
+    logger,
+    validate_artifact_key_name,
+    validate_tag_name,
+)
 from .base import (
     Artifact,
     DirArtifact,
     LegacyArtifact,
     LegacyDirArtifact,
     LegacyLinkArtifact,
     LinkArtifact,
@@ -55,15 +61,15 @@
     "table": TableArtifact,
     "model": ModelArtifact,
     "dataset": DatasetArtifact,
     "plotly": PlotlyArtifact,
     "bokeh": BokehArtifact,
 }
 
-# TODO - Remove this when legacy types are deleted (1.2.0?)
+# TODO - Remove this when legacy types are deleted in 1.5.0
 legacy_artifact_types = {
     "": LegacyArtifact,
     "dir": LegacyDirArtifact,
     "link": LegacyLinkArtifact,
     "plot": LegacyPlotArtifact,
     "chart": LegacyChartArtifact,
     "table": LegacyTableArtifact,
@@ -171,14 +177,15 @@
                 item = DirArtifact(key, body, **kwargs)
             else:
                 item = Artifact(key, body, **kwargs)
         else:
             key = item.key
             target_path = target_path or item.target_path
 
+        validate_artifact_key_name(key, "artifact.key")
         src_path = local_path or item.src_path  # TODO: remove src_path
         if format == "html" or (src_path and pathlib.Path(src_path).suffix == "html"):
             viewer = "web-app"
         item.format = format or item.format
         item.src_path = src_path
 
         if db_key is None:
```

## mlrun/artifacts/model.py

```diff
@@ -8,19 +8,19 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import tempfile
-import warnings
 from os import path
 from typing import List
 
 import yaml
+from deprecated import deprecated
 
 import mlrun
 
 from ..data_types import InferOptions, get_infer_interface
 from ..datastore import is_store_uri, store_manager
 from ..features import Feature
 from ..model import ObjectList
@@ -163,230 +163,86 @@
 
     @spec.setter
     def spec(self, spec):
         self._spec = self._verify_dict(spec, "spec", ModelArtifactSpec)
 
     @property
     def inputs(self) -> List[Feature]:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ModelArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.inputs instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         """input feature list"""
         return self.spec.inputs
 
     @inputs.setter
     def inputs(self, inputs: List[Feature]):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ModelArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.inputs instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         """input feature list"""
         self.spec.inputs = inputs
 
     @property
     def outputs(self) -> List[Feature]:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ModelArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.outputs instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         """input feature list"""
         return self.spec.outputs
 
     @outputs.setter
     def outputs(self, outputs: List[Feature]):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ModelArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.outputs instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         """input feature list"""
         self.spec.outputs = outputs
 
     @property
     def model_file(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.model_file instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.model_file
 
     @model_file.setter
     def model_file(self, model_file):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.model_file instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.model_file = model_file
 
     @property
     def parameters(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.parameters instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.parameters
 
     @parameters.setter
     def parameters(self, parameters):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.parameters instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.parameters = parameters
 
     @property
     def metrics(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.metrics instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.metrics
 
     @metrics.setter
     def metrics(self, metrics):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.metrics instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.metrics = metrics
 
     @property
     def feature_stats(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_stats instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.feature_stats
 
     @feature_stats.setter
     def feature_stats(self, feature_stats):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_stats instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.feature_stats = feature_stats
 
     @property
     def feature_vector(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_vector instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.feature_vector
 
     @feature_vector.setter
     def feature_vector(self, feature_vector):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_vector instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.feature_vector = feature_vector
 
     @property
     def feature_weights(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_weights instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.feature_weights
 
     @feature_weights.setter
     def feature_weights(self, feature_weights):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_weights instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.feature_weights = feature_weights
 
     @property
     def model_target_file(self):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_weights instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.model_target_file
 
     @model_target_file.setter
     def model_target_file(self, model_target_file):
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used ArtifactLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use artifact.spec.feature_weights instead"
-            "This will be deprecated in 1.0.0, and will be removed in 1.2.0",
-            # TODO: In 1.0.0 do changes in examples & demos In 1.2.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.model_target_file = model_target_file
 
     def infer_from_df(self, df, label_columns=None, with_stats=True, num_bins=None):
         """infer inputs, outputs, and stats from provided df (training set)
 
         :param df:      dataframe to infer from
         :param label_columns: name of the label (target) column
@@ -509,14 +365,20 @@
         if src_model_path and path.isfile(src_model_path):
             with open(src_model_path, "rb") as fp:
                 return fp.read()
         target_model_path = path.join(self.spec.target_path, self.spec.model_file)
         return mlrun.get_dataitem(target_model_path).get()
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyModelArtifact' will be removed in 1.5.0, use 'ModelArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyModelArtifact(LegacyArtifact):
     """ML Model artifact
 
     Store link to ML model file(s) along with the model metrics, parameters, schema, and stats
     """
 
     _dict_fields = LegacyArtifact._dict_fields + [
@@ -683,15 +545,15 @@
         model_dir = model_dir.artifact_url
 
     if is_store_uri(model_dir):
         model_spec, target = store_manager.get_store_artifact(model_dir)
         if not model_spec or model_spec.kind != "model":
             raise ValueError(f"store artifact ({model_dir}) is not model kind")
         # in case model_target_file is specified, use it, because that means that the actual model target path
-        # in the store is different than the local model_file it was generated from
+        # in the store is different from the local model_file it was generated from
         model_file = _get_file_path(
             target, model_spec.model_target_file or model_spec.model_file
         )
         extra_dataitems = _get_extra(target, model_spec.extra_data)
 
     elif model_dir.lower().endswith(".yaml"):
         model_spec = _load_model_spec(model_dir)
```

## mlrun/artifacts/plots.py

```diff
@@ -10,14 +10,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import base64
 from io import BytesIO
 
+from deprecated import deprecated
+
 import mlrun
 
 from ..utils import dict_to_json
 from .base import Artifact, LegacyArtifact
 
 
 class PlotArtifact(Artifact):
@@ -238,14 +240,20 @@
         Get the artifact's body - the Plotly figure's html code.
 
         :return: The figure's html code.
         """
         return self._figure.to_html()
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyPlotArtifact' will be removed in 1.5.0, use 'PlotArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyPlotArtifact(LegacyArtifact):
     _TEMPLATE = """
 <h3 style="text-align:center">{}</h3>
 <img title="{}" src="data:image/png;base64,{}">
 """
     kind = "plot"
 
@@ -279,14 +287,20 @@
             canvas.print_png(png_output)
             data = png_output.getvalue()
 
         data_uri = base64.b64encode(data).decode("utf-8")
         return self._TEMPLATE.format(self.description or self.key, self.key, data_uri)
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyChartArtifact' will be removed in 1.5.0, use 'ChartArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyChartArtifact(LegacyArtifact):
     _TEMPLATE = """
 <html>
   <head>
     <script
         type="text/javascript"
         src="https://www.gstatic.com/charts/loader.js"></script>
@@ -347,14 +361,20 @@
         return (
             self._TEMPLATE.replace("$data$", dict_to_json(data))
             .replace("$opts$", dict_to_json(self.options))
             .replace("$chart$", self.chart)
         )
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyBokehArtifact' will be removed in 1.5.0, use 'BokehArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyBokehArtifact(LegacyArtifact):
     """
     Bokeh artifact is an artifact for saving Bokeh generated figures. They will be stored in a html format.
     """
 
     kind = "bokeh"
 
@@ -397,14 +417,20 @@
         """
         from bokeh.embed import file_html
         from bokeh.resources import CDN
 
         return file_html(self._figure, CDN, self.key)
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'LegacyPlotlyArtifact' will be removed in 1.5.0, use 'PlotlyArtifact' instead",
+    category=FutureWarning,
+)
 class LegacyPlotlyArtifact(LegacyArtifact):
     """
     Plotly artifact is an artifact for saving Plotly generated figures. They will be stored in a html format.
     """
 
     kind = "plotly"
```

## mlrun/data_types/__init__.py

```diff
@@ -10,15 +10,20 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 # flake8: noqa  - this is until we take care of the F401 violations with respect to __all__ & sphinx
 
-from .data_types import InferOptions, ValueType, pd_schema_to_value_type
+from .data_types import (
+    InferOptions,
+    ValueType,
+    pd_schema_to_value_type,
+    python_type_to_value_type,
+)
 from .infer import DFDataInfer
 
 
 class BaseDataInfer:
     infer_schema = None
     get_preview = None
     get_stats = None
```

## mlrun/data_types/data_types.py

```diff
@@ -9,19 +9,21 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 # this module is WIP
+from enum import Enum
+
 import pyarrow
 from pyarrow.lib import TimestampType
 
 
-class ValueType:
+class ValueType(str, Enum):
     """Feature value type. Used to define data types in Feature Tables."""
 
     UNKNOWN = ""
     BOOL = "bool"
     INT8 = "int8"
     INT16 = "int16"
     INT32 = "int32"
@@ -73,15 +75,17 @@
         pyarrow.float32(): ValueType.FLOAT,
         pyarrow.float64(): ValueType.DOUBLE,
     }
     return type_map.get(type_, ValueType.STRING)
 
 
 def python_type_to_value_type(value_type):
-    type_name = value_type.__name__
+    type_name = (
+        value_type.__name__ if hasattr(value_type, "__name__") else str(value_type)
+    )
     type_map = {
         "int": ValueType.INT64,
         "str": ValueType.STRING,
         "float": ValueType.DOUBLE,
         "bytes": ValueType.BYTES,
         "float64": ValueType.DOUBLE,
         "Float64": ValueType.DOUBLE,
```

## mlrun/data_types/infer.py

```diff
@@ -13,14 +13,16 @@
 # limitations under the License.
 #
 import numpy as np
 import pandas as pd
 import pyarrow
 from pandas.io.json._table_schema import convert_pandas_type_to_json_field
 
+from mlrun.utils import logger
+
 from .data_types import InferOptions, pa_type_to_value_type, pd_schema_to_value_type
 
 default_num_bins = 20
 
 
 def infer_schema_from_df(
     df: pd.DataFrame,
@@ -34,24 +36,29 @@
     timestamp_fields = []
     current_entities = list(entities.keys())
     entity_columns = entity_columns or []
     index_columns = dict()
 
     def upsert_entity(name, value_type):
         if name in current_entities:
-            entities[name].value_type = value_type
+            old_type = entities[name].value_type
+            if old_type != value_type:
+                logger.warning(
+                    f"Overriding type of entity '{name}' from '{old_type}' to '{value_type}'. "
+                    "This may result in errors or unusable data."
+                )
+                entities[name].value_type = value_type
         else:
             entities[name] = {"name": name, "value_type": value_type}
 
     # remove index column if no name provided
     if not df.index.name and df.index.is_numeric():
         df = df.reset_index().drop("index", axis=1)
 
     schema = pyarrow.Schema.from_pandas(df)
-    index_type = None
     for i in range(len(schema)):
         column = schema.names[i]
         value_type = pa_type_to_value_type(schema.types[i])
         if column in df.index.names:
             index_columns[column] = value_type
             continue
         is_entity = column in entity_columns or column in current_entities
```

## mlrun/data_types/spark.py

```diff
@@ -14,14 +14,16 @@
 #
 from datetime import datetime
 from os import environ
 
 import numpy as np
 from pyspark.sql.types import BooleanType, DoubleType, TimestampType
 
+from mlrun.utils import logger
+
 from .data_types import InferOptions, spark_to_value_type
 
 try:
     import pyspark.sql.functions as funcs
 except ImportError:
     pass
 
@@ -36,14 +38,20 @@
 ):
     timestamp_fields = []
     current_entities = list(entities.keys())
     entity_columns = entity_columns or []
 
     def upsert_entity(name, value_type):
         if name in current_entities:
+            old_type = entities[name].value_type
+            if old_type != value_type:
+                logger.warning(
+                    f"Overriding type of entity '{name}' from '{old_type}' to '{value_type}'."
+                    " This may result in errors or unusable data."
+                )
             entities[name].value_type = value_type
         else:
             entities[name] = {"name": name, "value_type": value_type}
 
     for column, s in df.dtypes:
         value_type = spark_to_value_type(s)
         is_entity = column in entity_columns or column in current_entities
```

## mlrun/datastore/base.py

```diff
@@ -148,14 +148,38 @@
         **kwargs,
     ):
         df_module = df_module or pd
         if url.endswith(".csv") or format == "csv":
             if columns:
                 kwargs["usecols"] = columns
             reader = df_module.read_csv
+            filesystem = self.get_filesystem()
+            if filesystem:
+                if filesystem.isdir(url):
+
+                    def reader(*args, **kwargs):
+                        base_path = args[0]
+                        file_entries = filesystem.listdir(base_path)
+                        filenames = []
+                        for file_entry in file_entries:
+                            if (
+                                file_entry["name"].endswith(".csv")
+                                and file_entry["size"] > 0
+                                and file_entry["type"] == "file"
+                            ):
+                                filename = file_entry["name"]
+                                filename = filename.split("/")[-1]
+                                filenames.append(filename)
+                        dfs = []
+                        for filename in filenames:
+                            updated_args = [f"{base_path}/{filename}"]
+                            updated_args.extend(args[1:])
+                            dfs.append(df_module.read_csv(*updated_args, **kwargs))
+                        return pd.concat(dfs)
+
         elif url.endswith(".parquet") or url.endswith(".pq") or format == "parquet":
             if columns:
                 kwargs["columns"] = columns
 
             def reader(*args, **kwargs):
                 if start_time or end_time:
                     if sys.version_info < (3, 7):
```

## mlrun/datastore/datastore.py

```diff
@@ -7,15 +7,15 @@
 #   http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
+import string
 from urllib.parse import urlparse
 
 import mlrun
 import mlrun.errors
 from mlrun.errors import err_to_str
 
 from ..utils import DB_SCHEMA, run_keys
@@ -46,15 +46,15 @@
     if parsed_url.port:
         endpoint += f":{parsed_url.port}"
     return schema, endpoint, parsed_url
 
 
 def schema_to_store(schema):
     # import store classes inside to enable making their dependencies optional (package extras)
-    if not schema or schema in ["file", "c", "d"]:
+    if not schema or schema in ["file"] + list(string.ascii_lowercase):
         return FileStore
     elif schema == "s3":
         try:
             from .s3 import S3Store
         except ImportError:
             raise mlrun.errors.MLRunMissingDependencyError(
                 "s3 packages are missing, use pip install mlrun[s3]"
```

## mlrun/datastore/redis.py

```diff
@@ -143,11 +143,14 @@
         if maxdepth is not None:
             raise NotImplementedError("maxdepth is not supported")
 
         key = RedisStore.build_redis_key(key, prefix_only=True)
 
         if recursive:
             key += "*" if key.endswith("/") else "/*"
-            for key in self.redis.scan_iter(key):
-                self.redis.delete(key)
+            for k in self.redis.scan_iter(key):
+                self.redis.delete(k)
+            key = f"_spark:{key}"
+            for k in self.redis.scan_iter(key):
+                self.redis.delete(k)
         else:
             self.redis.delete(key)
```

## mlrun/datastore/sources.py

```diff
@@ -15,14 +15,15 @@
 import os
 import warnings
 from base64 import b64encode
 from copy import copy
 from datetime import datetime
 from typing import Dict, List, Optional, Union
 
+import pandas as pd
 import v3io
 import v3io.dataplane
 from nuclio import KafkaTrigger
 from nuclio.config import split_path
 
 import mlrun
 from mlrun.secrets import SecretsStore
@@ -126,20 +127,25 @@
         name: str = "",
         path: str = None,
         attributes: Dict[str, str] = None,
         key_field: str = None,
         time_field: str = None,
         schedule: str = None,
         parse_dates: Union[None, int, str, List[int], List[str]] = None,
+        **kwargs,
     ):
-        super().__init__(name, path, attributes, key_field, time_field, schedule)
+        super().__init__(
+            name, path, attributes, key_field, time_field, schedule, **kwargs
+        )
         if time_field is not None:
             warnings.warn(
-                "CSVSource's time_field parameter is deprecated, use parse_dates instead",
-                PendingDeprecationWarning,
+                "CSVSource's time_field parameter is deprecated in 1.3.0 and will be removed in 1.5.0. "
+                "Use parse_dates instead.",
+                # TODO: remove in 1.5.0
+                FutureWarning,
             )
             if isinstance(parse_dates, (int, str)):
                 parse_dates = [parse_dates]
 
             if parse_dates is None:
                 parse_dates = [time_field]
             elif time_field not in parse_dates:
@@ -198,15 +204,15 @@
         if chunksize:
             kwargs["chunksize"] = chunksize
         return mlrun.store_manager.object(url=self.path).as_df(
             parse_dates=self._parse_dates, **kwargs
         )
 
     def is_iterator(self):
-        return True if self.attributes.get("chunksize") else False
+        return bool(self.attributes.get("chunksize"))
 
 
 class ParquetSource(BaseSourceDriver):
     """
     Reads Parquet file/dir as input source for a flow.
 
     :parameter name: name of the source
@@ -458,15 +464,15 @@
                 return rows.to_dataframe(dtypes=dtypes)
         else:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "table or query args must be specified"
             )
 
     def is_iterator(self):
-        return True if self.attributes.get("chunksize") else False
+        return bool(self.attributes.get("chunksize"))
 
     def to_spark_df(self, session, named_view=False, time_field=None):
         options = copy(self.attributes.get("spark_options", {}))
         credentials, gcp_project = self._get_credentials_string()
         if credentials:
             options["credentials"] = b64encode(credentials.encode("utf-8")).decode(
                 "utf-8"
@@ -632,16 +638,17 @@
     support_storey = True
 
     def __init__(
         self, df, key_field=None, time_field=None, context=None, iterator=False
     ):
         if time_field:
             warnings.warn(
-                "DataFrameSource's time_field parameter is deprecated and has no effect",
-                PendingDeprecationWarning,
+                "DataFrameSource's time_field parameter has no effect. "
+                "It is deprecated in 1.3.0 and will be removed in 1.5.0",
+                FutureWarning,
             )
 
         self._df = df
         if isinstance(key_field, str):
             self.key_field = [key_field]
         else:
             self.key_field = key_field
@@ -851,19 +858,129 @@
         func = function.add_trigger("kafka", trigger)
         replicas = 1 if not partitions else len(partitions)
         func.spec.min_replicas = replicas
         func.spec.max_replicas = replicas
         return func
 
 
+class SQLSource(BaseSourceDriver):
+    kind = "sqldb"
+    support_storey = True
+    support_spark = False
+
+    def __init__(
+        self,
+        name: str = "",
+        chunksize: int = None,
+        key_field: str = None,
+        time_field: str = None,
+        schedule: str = None,
+        start_time: Optional[Union[datetime, str]] = None,
+        end_time: Optional[Union[datetime, str]] = None,
+        db_url: str = None,
+        table_name: str = None,
+        spark_options: dict = None,
+        time_fields: List[str] = None,
+    ):
+        """
+        Reads SqlDB as input source for a flow.
+        example::
+            db_path = "mysql+pymysql://<username>:<password>@<host>:<port>/<db_name>"
+            source = SqlDBSource(
+                collection_name='source_name', db_path=self.db, key_field='key'
+            )
+        :param name:            source name
+        :param chunksize:       number of rows per chunk (default large single chunk)
+        :param key_field:       the column to be used as the key for the collection.
+        :param time_field:      the column to be parsed as timestamp for events. Defaults to None
+        :param start_time:      filters out data before this time
+        :param end_time:        filters out data after this time
+        :param schedule:        string to configure scheduling of the ingestion job.
+                                For example '*/30 * * * *' will
+                                cause the job to run every 30 minutes
+        :param db_url:         url string connection to sql database.
+                                If not set, the MLRUN_SQL__URL environment variable will be used.
+        :param table_name:      the name of the collection to access,
+                                from the current database
+        :param spark_options:   additional spark read options
+        :param time_fields :    all the field to be parsed as timestamp.
+        """
+
+        db_url = db_url or mlrun.mlconf.sql.url
+        if db_url is None:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                "cannot specify without db_path arg or secret MLRUN_SQL__URL"
+            )
+        attrs = {
+            "chunksize": chunksize,
+            "spark_options": spark_options,
+            "table_name": table_name,
+            "db_path": db_url,
+            "time_fields": time_fields,
+        }
+        attrs = {key: value for key, value in attrs.items() if value is not None}
+        super().__init__(
+            name,
+            attributes=attrs,
+            key_field=key_field,
+            time_field=time_field,
+            schedule=schedule,
+            start_time=start_time,
+            end_time=end_time,
+        )
+
+    def to_dataframe(self):
+        import sqlalchemy as db
+
+        query = self.attributes.get("query", None)
+        db_path = self.attributes.get("db_path")
+        table_name = self.attributes.get("table_name")
+        if not query:
+            query = f"SELECT * FROM {table_name}"
+        if table_name and db_path:
+            engine = db.create_engine(db_path)
+            with engine.connect() as con:
+                return pd.read_sql(
+                    query,
+                    con=con,
+                    chunksize=self.attributes.get("chunksize"),
+                    parse_dates=self.attributes.get("time_fields"),
+                )
+        else:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                "table_name and db_name args must be specified"
+            )
+
+    def to_step(self, key_field=None, time_field=None, context=None):
+        import storey
+
+        attributes = self.attributes or {}
+        if context:
+            attributes["context"] = context
+
+        return storey.SQLSource(
+            key_field=self.key_field or key_field,
+            time_field=self.time_field or time_field,
+            end_filter=self.end_time,
+            start_filter=self.start_time,
+            filter_column=self.time_field or time_field,
+            **attributes,
+        )
+        pass
+
+    def is_iterator(self):
+        return bool(self.attributes.get("chunksize"))
+
+
 # map of sources (exclude DF source which is not serializable)
 source_kind_to_driver = {
     "": BaseSourceDriver,
     CSVSource.kind: CSVSource,
     ParquetSource.kind: ParquetSource,
     HttpSource.kind: HttpSource,
     StreamSource.kind: StreamSource,
     KafkaSource.kind: KafkaSource,
     CustomSource.kind: CustomSource,
     BigQuerySource.kind: BigQuerySource,
     SnowflakeSource.kind: SnowflakeSource,
+    SQLSource.kind: SQLSource,
 }
```

## mlrun/datastore/targets.py

```diff
@@ -7,24 +7,27 @@
 #   http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import ast
+import datetime
 import os
 import random
 import time
-import typing
-import warnings
 from collections import Counter
 from copy import copy
-from typing import Union
+from typing import Any, Dict, List, Optional, Union
+from urllib.parse import urlparse
 
 import pandas as pd
+import sqlalchemy
+from storey.utils import hash_list, stringify_key
 
 import mlrun
 import mlrun.utils.helpers
 from mlrun.config import config
 from mlrun.model import DataSource, DataTarget, DataTargetBase, TargetPathObject
 from mlrun.utils import now_date
 from mlrun.utils.v3io_clients import get_frames_client
@@ -41,27 +44,29 @@
     nosql = "nosql"
     redisnosql = "redisnosql"
     tsdb = "tsdb"
     stream = "stream"
     kafka = "kafka"
     dataframe = "dataframe"
     custom = "custom"
+    sql = "sql"
 
     @staticmethod
     def all():
         return [
             TargetTypes.csv,
             TargetTypes.parquet,
             TargetTypes.nosql,
             TargetTypes.redisnosql,
             TargetTypes.tsdb,
             TargetTypes.stream,
             TargetTypes.kafka,
             TargetTypes.dataframe,
             TargetTypes.custom,
+            TargetTypes.sql,
         ]
 
 
 def generate_target_run_id():
     return f"{round(time.time() * 1000)}_{random.randint(0, 999)}"
 
 
@@ -260,33 +265,23 @@
         if not target.after_step:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "writer step location is undetermined due to graph branching"
                 ", set the target .after_step attribute or the graph .final_step"
             )
 
 
-def add_target_states(graph, resource, targets, to_df=False, final_state=None):
-    warnings.warn(
-        "This method is deprecated. Use add_target_steps instead",
-        # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-        PendingDeprecationWarning,
-    )
-    return add_target_steps(graph, resource, targets, to_df, final_state)
-
-
 def add_target_steps(graph, resource, targets, to_df=False, final_step=None):
     """add the target steps to the graph"""
     targets = targets or []
     key_columns = resource.spec.entities
     timestamp_key = resource.spec.timestamp_key
     features = resource.spec.features
     table = None
 
     for target in targets:
-
         # if fset is in passthrough mode, ingest skips writing the data to offline targets
         if resource.spec.passthrough and kind_to_driver[target.kind].is_offline:
             continue
 
         driver = get_target_driver(target, resource)
         table = driver.get_table_object() or table
         driver.update_resource_status()
@@ -372,67 +367,74 @@
     support_storey = False
     support_append = False
 
     def __init__(
         self,
         name: str = "",
         path=None,
-        attributes: typing.Dict[str, str] = None,
+        attributes: Dict[str, str] = None,
         after_step=None,
         columns=None,
         partitioned: bool = False,
-        key_bucketing_number: typing.Optional[int] = None,
-        partition_cols: typing.Optional[typing.List[str]] = None,
-        time_partitioning_granularity: typing.Optional[str] = None,
-        after_state=None,
-        max_events: typing.Optional[int] = None,
-        flush_after_seconds: typing.Optional[int] = None,
-        storage_options: typing.Dict[str, str] = None,
+        key_bucketing_number: Optional[int] = None,
+        partition_cols: Optional[List[str]] = None,
+        time_partitioning_granularity: Optional[str] = None,
+        max_events: Optional[int] = None,
+        flush_after_seconds: Optional[int] = None,
+        storage_options: Dict[str, str] = None,
+        schema: Dict[str, Any] = None,
+        credentials_prefix=None,
     ):
         super().__init__(
             self.kind,
             name,
             path,
             attributes,
             after_step,
             partitioned,
             key_bucketing_number,
             partition_cols,
             time_partitioning_granularity,
             max_events,
             flush_after_seconds,
-            after_state,
+            schema=schema,
+            credentials_prefix=credentials_prefix,
         )
-        if after_state:
-            warnings.warn(
-                "The after_state parameter is deprecated. Use after_step instead",
-                # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-                PendingDeprecationWarning,
-            )
-            after_step = after_step or after_state
 
         self.name = name or self.kind
         self.path = str(path) if path is not None else None
         self.after_step = after_step
         self.attributes = attributes or {}
         self.columns = columns or []
         self.partitioned = partitioned
         self.key_bucketing_number = key_bucketing_number
         self.partition_cols = partition_cols
         self.time_partitioning_granularity = time_partitioning_granularity
         self.max_events = max_events
         self.flush_after_seconds = flush_after_seconds
         self.storage_options = storage_options
+        self.schema = schema or {}
+        self.credentials_prefix = credentials_prefix
 
         self._target = None
         self._resource = None
         self._secrets = {}
 
+    def _get_credential(self, key, default_value=None):
+        return mlrun.get_secret_or_env(
+            key,
+            secret_provider=self._secrets,
+            default=default_value,
+            prefix=self.credentials_prefix,
+        )
+
     def _get_store(self):
-        store, _ = mlrun.store_manager.get_or_create_store(self.get_target_path())
+        store, _ = mlrun.store_manager.get_or_create_store(
+            self.get_target_path_with_credentials()
+        )
         return store
 
     def _get_column_list(self, features, timestamp_key, key_columns, with_type=False):
         result = []
         if self.columns:
             if with_type:
                 columns = set(self.columns)
@@ -466,15 +468,15 @@
     def write_dataframe(
         self,
         df,
         key_column=None,
         timestamp_key=None,
         chunk_id=0,
         **kwargs,
-    ) -> typing.Optional[int]:
+    ) -> Optional[int]:
         if hasattr(df, "rdd"):
             options = self.get_spark_options(key_column, timestamp_key)
             options.update(kwargs)
             df.write.mode("overwrite").save(**options)
         elif hasattr(df, "dask"):
             dask_options = self.get_dask_options()
             storage_options = self._get_store().get_storage_options()
@@ -520,16 +522,16 @@
                     ("year", "%Y"),
                     ("month", "%m"),
                     ("day", "%d"),
                     ("hour", "%H"),
                     ("minute", "%M"),
                 ]:
                     partition_cols.append(unit)
-                    target_df[unit] = getattr(
-                        pd.DatetimeIndex(target_df[timestamp_key]), unit
+                    target_df[unit] = pd.DatetimeIndex(target_df[timestamp_key]).format(
+                        date_format=fmt
                     )
                     if unit == time_partitioning_granularity:
                         break
             storage_options = self._get_store().get_storage_options()
             self._write_dataframe(
                 target_df,
                 storage_options,
@@ -555,40 +557,49 @@
     @classmethod
     def from_spec(cls, spec: DataTargetBase, resource=None):
         """create target driver from target spec or other target driver"""
         driver = cls()
         driver.name = spec.name
         driver.path = spec.path
         driver.attributes = spec.attributes
+        driver.schema = spec.schema
+        driver.credentials_prefix = spec.credentials_prefix
 
         if hasattr(spec, "columns"):
             driver.columns = spec.columns
 
+        if hasattr(spec, "_secrets"):
+            driver._secrets = spec._secrets
+
         driver.partitioned = spec.partitioned
 
         driver.key_bucketing_number = spec.key_bucketing_number
         driver.partition_cols = spec.partition_cols
 
         driver.time_partitioning_granularity = spec.time_partitioning_granularity
         driver.max_events = spec.max_events
         driver.flush_after_seconds = spec.flush_after_seconds
         driver.storage_options = spec.storage_options
+        driver.credentials_prefix = spec.credentials_prefix
 
         driver._resource = resource
         driver.run_id = spec.run_id
         return driver
 
     def get_table_object(self):
         """get storey Table object"""
         return None
 
     def get_target_path(self):
         path_object = self._target_path_object
         return path_object.get_absolute_path() if path_object else None
 
+    def get_target_path_with_credentials(self):
+        return self.get_target_path()
+
     def get_target_templated_path(self):
         path_object = self._target_path_object
         return path_object.get_templated_path() if path_object else None
 
     @property
     def _target_path_object(self):
         """return the actual/computed target path"""
@@ -619,14 +630,15 @@
         # TODO - instead of adding more fields to the status targets, we should consider changing any functionality
         #       that depends on "spec-fields" to use a merge between the status and the spec targets. One such place
         #       is the fset.to_dataframe() function.
         target.partitioned = self.partitioned
         target.key_bucketing_number = self.key_bucketing_number
         target.partition_cols = self.partition_cols
         target.time_partitioning_granularity = self.time_partitioning_granularity
+        target.credentials_prefix = self.credentials_prefix
 
         self._resource.status.update_target(target)
         return target
 
     def add_writer_step(
         self,
         graph,
@@ -634,25 +646,14 @@
         features,
         key_columns=None,
         timestamp_key=None,
         featureset_status=None,
     ):
         raise NotImplementedError()
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def purge(self):
         self._get_store().rm(self.get_target_path(), recursive=True)
 
     def as_df(
         self,
         columns=None,
         df_module=None,
@@ -672,15 +673,15 @@
             **kwargs,
         )
 
     def get_spark_options(self, key_column=None, timestamp_key=None, overwrite=True):
         # options used in spark.read.load(**options)
         raise NotImplementedError()
 
-    def prepare_spark_df(self, df):
+    def prepare_spark_df(self, df, key_columns):
         return df
 
     def get_dask_options(self):
         raise NotImplementedError()
 
 
 class ParquetTarget(BaseStoreTarget):
@@ -715,34 +716,25 @@
     support_dask = True
     support_append = True
 
     def __init__(
         self,
         name: str = "",
         path=None,
-        attributes: typing.Dict[str, str] = None,
+        attributes: Dict[str, str] = None,
         after_step=None,
         columns=None,
         partitioned: bool = None,
-        key_bucketing_number: typing.Optional[int] = None,
-        partition_cols: typing.Optional[typing.List[str]] = None,
-        time_partitioning_granularity: typing.Optional[str] = None,
-        after_state=None,
-        max_events: typing.Optional[int] = 10000,
-        flush_after_seconds: typing.Optional[int] = 900,
-        storage_options: typing.Dict[str, str] = None,
-    ):
-        if after_state:
-            warnings.warn(
-                "The after_state parameter is deprecated. Use after_step instead",
-                # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-                PendingDeprecationWarning,
-            )
-            after_step = after_step or after_state
-
+        key_bucketing_number: Optional[int] = None,
+        partition_cols: Optional[List[str]] = None,
+        time_partitioning_granularity: Optional[str] = None,
+        max_events: Optional[int] = 10000,
+        flush_after_seconds: Optional[int] = 900,
+        storage_options: Dict[str, str] = None,
+    ):
         self.path = path
         if partitioned is None:
             partitioned = not self.is_single_file()
 
         super().__init__(
             name,
             path,
@@ -776,25 +768,14 @@
         df.to_parquet(
             target_path,
             partition_cols=partition_cols,
             storage_options=storage_options,
             **kwargs,
         )
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def add_writer_step(
         self,
         graph,
         after,
         features,
         key_columns=None,
         timestamp_key=None,
@@ -941,25 +922,14 @@
     @staticmethod
     def _write_dataframe(df, storage_options, target_path, partition_cols, **kwargs):
         # avoid writing the range index unless explicitly specified via kwargs
         if isinstance(df.index, pd.RangeIndex):
             kwargs["index"] = kwargs.get("index", False)
         df.to_csv(target_path, storage_options=storage_options, **kwargs)
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def add_writer_step(
         self,
         graph,
         after,
         features,
         key_columns=None,
         timestamp_key=None,
@@ -986,15 +956,15 @@
     def get_spark_options(self, key_column=None, timestamp_key=None, overwrite=True):
         return {
             "path": store_path_to_spark(self.get_target_path()),
             "format": "csv",
             "header": "true",
         }
 
-    def prepare_spark_df(self, df):
+    def prepare_spark_df(self, df, key_columns):
         import pyspark.sql.functions as funcs
 
         for col_name, col_type in df.dtypes:
             if col_type == "timestamp":
                 # df.write.csv saves timestamps with millisecond precision, but we want microsecond precision
                 # for compatibility with storey.
                 df = df.withColumn(
@@ -1009,17 +979,22 @@
         entities=None,
         start_time=None,
         end_time=None,
         time_column=None,
         **kwargs,
     ):
         df = super().as_df(
-            columns=columns, df_module=df_module, entities=entities, **kwargs
+            columns=columns,
+            df_module=df_module,
+            entities=entities,
+            format="csv",
+            **kwargs,
         )
-        df.set_index(keys=entities, inplace=True)
+        if entities:
+            df.set_index(keys=entities, inplace=True)
         return df
 
     def is_single_file(self):
         if self.path:
             return self.path.endswith(".csv")
         return True
 
@@ -1035,25 +1010,14 @@
         if cls is NoSqlBaseTarget:
             raise TypeError(f"only children of '{cls.__name__}' may be instantiated")
         return object.__new__(cls)
 
     def get_table_object(self):
         raise NotImplementedError()
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def add_writer_step(
         self,
         graph,
         after,
         features,
         key_columns=None,
         timestamp_key=None,
@@ -1083,63 +1047,42 @@
             graph_shape="cylinder",
             class_name="storey.NoSqlTarget",
             columns=column_list,
             table=table,
             **self.attributes,
         )
 
+    def prepare_spark_df(self, df, key_columns):
+        raise NotImplementedError()
+
     def get_spark_options(self, key_column=None, timestamp_key=None, overwrite=True):
-        spark_options = {
-            "path": store_path_to_spark(self.get_target_path()),
-            "format": "io.iguaz.v3io.spark.sql.kv",
-        }
-        if isinstance(key_column, list) and len(key_column) >= 1:
-            if len(key_column) > 2:
-                raise mlrun.errors.MLRunInvalidArgumentError(
-                    f"Spark supports maximun of 2 keys and {key_column} are provided"
-                )
-            spark_options["key"] = key_column[0]
-            if len(key_column) > 1:
-                spark_options["sorting-key"] = key_column[1]
-        else:
-            spark_options["key"] = key_column
-        if not overwrite:
-            spark_options["columnUpdate"] = True
-        return spark_options
+        raise NotImplementedError()
 
     def get_dask_options(self):
         return {"format": "csv"}
 
     def as_df(self, columns=None, df_module=None, **kwargs):
         raise NotImplementedError()
 
-    def prepare_spark_df(self, df):
-        import pyspark.sql.functions as funcs
-
-        for col_name, col_type in df.dtypes:
-            if col_type.startswith("decimal("):
-                # V3IO does not support this level of precision
-                df = df.withColumn(col_name, funcs.col(col_name).cast("double"))
-        return df
-
     def write_dataframe(
         self, df, key_column=None, timestamp_key=None, chunk_id=0, **kwargs
     ):
         if hasattr(df, "rdd"):
             options = self.get_spark_options(key_column, timestamp_key)
             options.update(kwargs)
             df = self.prepare_spark_df(df)
             df.write.mode("overwrite").save(**options)
         else:
             # To prevent modification of the original dataframe and make sure
             # that the last event of a key is the one being persisted
-            df = df.groupby(df.index).last()
-            access_key = self._secrets.get(
-                "V3IO_ACCESS_KEY", os.getenv("V3IO_ACCESS_KEY")
-            )
+            if len(df.index.names) and df.index.names[0] is not None:
+                df = df.groupby(df.index.names).last()
+            else:
+                df = df.copy(deep=False)
+            access_key = self._get_credential("V3IO_ACCESS_KEY")
 
             _, path_with_container = parse_path(self.get_target_path())
             container, path = split_path(path_with_container)
 
             frames_client = get_frames_client(
                 token=access_key, address=config.v3io_framesd, container=container
             )
@@ -1159,53 +1102,132 @@
         endpoint, uri = parse_path(self.get_target_path())
         return Table(
             uri,
             V3ioDriver(webapi=endpoint),
             flush_interval_secs=mlrun.mlconf.feature_store.flush_interval,
         )
 
+    def get_spark_options(self, key_column=None, timestamp_key=None, overwrite=True):
+        spark_options = {
+            "path": store_path_to_spark(self.get_target_path()),
+            "format": "io.iguaz.v3io.spark.sql.kv",
+        }
+        if isinstance(key_column, list) and len(key_column) >= 1:
+            spark_options["key"] = key_column[0]
+            if len(key_column) > 2:
+                spark_options["sorting-key"] = "_spark_object_sorting_key"
+            if len(key_column) == 2:
+                spark_options["sorting-key"] = key_column[1]
+        else:
+            spark_options["key"] = key_column
+        if not overwrite:
+            spark_options["columnUpdate"] = True
+        return spark_options
+
+    def prepare_spark_df(self, df, key_columns):
+        from pyspark.sql.functions import col, udf
+        from pyspark.sql.types import StringType
+
+        for col_name, col_type in df.dtypes:
+            if col_type.startswith("decimal("):
+                # V3IO does not support this level of precision
+                df = df.withColumn(col_name, col(col_name).cast("double"))
+        if len(key_columns) > 2:
+            hash_and_concat_udf = udf(
+                lambda *x: hash_list([str(i) for i in x]), StringType()
+            )
+            return df.withColumn(
+                "_spark_object_sorting_key",
+                hash_and_concat_udf(*[col(c) for c in key_columns[1:]]),
+            )
+        return df
+
 
 class RedisNoSqlTarget(NoSqlBaseTarget):
     kind = TargetTypes.redisnosql
-    support_spark = False
+    support_spark = True
     writer_step_name = "RedisNoSqlTarget"
 
+    # Fetch server url from the RedisNoSqlTarget::__init__() 'path' parameter.
+    # If not set fetch it from 'mlrun.mlconf.redis.url' (MLRUN_REDIS__URL environment variable).
+    # Then look for username and password at REDIS_xxx secrets
+    def _get_server_endpoint(self):
+        endpoint, uri = parse_path(self.get_target_path())
+        endpoint = endpoint or mlrun.mlconf.redis.url
+        parsed_endpoint = urlparse(endpoint)
+        if parsed_endpoint.username or parsed_endpoint.password:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                "Provide Redis username and password only via secrets"
+            )
+        user = self._get_credential("REDIS_USER", "")
+        password = self._get_credential("REDIS_PASSWORD", "")
+        host = parsed_endpoint.hostname
+        port = parsed_endpoint.port if parsed_endpoint.port else "6379"
+        scheme = parsed_endpoint.scheme
+        if user or password:
+            endpoint = f"{scheme}://{user}:{password}@{host}:{port}"
+        else:
+            endpoint = f"{scheme}://{host}:{port}"
+        return endpoint, uri
+
     def get_table_object(self):
         from storey import Table
         from storey.redis_driver import RedisDriver
 
-        endpoint, uri = parse_path(self.get_target_path())
-        endpoint = endpoint or mlrun.mlconf.redis.url
+        endpoint, uri = self._get_server_endpoint()
 
         return Table(
             uri,
             RedisDriver(redis_url=endpoint, key_prefix="/"),
             flush_interval_secs=mlrun.mlconf.feature_store.flush_interval,
         )
 
+    def get_spark_options(self, key_column=None, timestamp_key=None, overwrite=True):
+        endpoint, uri = self._get_server_endpoint()
+        parsed_endpoint = urlparse(endpoint)
+
+        return {
+            "key.column": "_spark_object_name",
+            "table": "{" + store_path_to_spark(self.get_target_path()),
+            "format": "org.apache.spark.sql.redis",
+            "host": parsed_endpoint.hostname,
+            "port": parsed_endpoint.port,
+            "user": parsed_endpoint.username if parsed_endpoint.username else None,
+            "auth": parsed_endpoint.password if parsed_endpoint.password else None,
+        }
+
+    def get_target_path_with_credentials(self):
+        endpoint, uri = self._get_server_endpoint()
+        return endpoint
+
+    def prepare_spark_df(self, df, key_columns):
+        from pyspark.sql.functions import col, udf
+        from pyspark.sql.types import StringType
+
+        if len(key_columns) > 1:
+            hash_and_concat_udf = udf(
+                lambda *x: stringify_key([str(i) for i in x]) + "}:static", StringType()
+            )
+            return df.withColumn(
+                "_spark_object_name",
+                hash_and_concat_udf(*[col(c) for c in key_columns]),
+            )
+        else:
+            udf1 = udf(lambda x: str(x) + "}:static", StringType())
+            return df.withColumn("_spark_object_name", udf1(key_columns[0]))
+
 
 class StreamTarget(BaseStoreTarget):
     kind = TargetTypes.stream
     is_table = False
     is_online = False
     support_spark = False
     support_storey = True
     support_append = True
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def add_writer_step(
         self,
         graph,
         after,
         features,
         key_columns=None,
         timestamp_key=None,
@@ -1294,25 +1316,14 @@
     kind = TargetTypes.tsdb
     is_table = False
     is_online = False
     support_spark = False
     support_storey = True
     support_append = True
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def add_writer_step(
         self,
         graph,
         after,
         features,
         key_columns=None,
         timestamp_key=None,
@@ -1379,40 +1390,20 @@
     support_storey = True
 
     def __init__(
         self,
         class_name: str,
         name: str = "",
         after_step=None,
-        after_state=None,
         **attributes,
     ):
-        if after_state:
-            warnings.warn(
-                "The after_state parameter is deprecated. Use after_step instead",
-                # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-                PendingDeprecationWarning,
-            )
-            after_step = after_step or after_state
-
         attributes = attributes or {}
         attributes["class_name"] = class_name
         super().__init__(name, "", attributes, after_step=after_step)
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def add_writer_step(
         self,
         graph,
         after,
         features,
         key_columns=None,
         timestamp_key=None,
@@ -1436,28 +1427,17 @@
     def __init__(self, *args, name="dataframe", **kwargs):
         self._df = None
         super().__init__(*args, name=name, **kwargs)
 
     def set_df(self, df):
         self._df = df
 
-    def update_resource_status(self, status="", producer=None):
+    def update_resource_status(self, status="", producer=None, size=None):
         pass
 
-    def add_writer_state(
-        self, graph, after, features, key_columns=None, timestamp_key=None
-    ):
-        warnings.warn(
-            "This method is deprecated. Use add_writer_step instead",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        """add storey writer state to graph"""
-        self.add_writer_step(graph, after, features, key_columns, timestamp_key)
-
     def add_writer_step(
         self,
         graph,
         after,
         features,
         key_columns=None,
         timestamp_key=None,
@@ -1483,24 +1463,290 @@
         end_time=None,
         time_column=None,
         **kwargs,
     ):
         return self._df
 
 
+class SQLTarget(BaseStoreTarget):
+    kind = TargetTypes.sql
+    is_online = True
+    support_spark = False
+    support_storey = True
+
+    def __init__(
+        self,
+        name: str = "",
+        path=None,
+        attributes: Dict[str, str] = None,
+        after_step=None,
+        partitioned: bool = False,
+        key_bucketing_number: Optional[int] = None,
+        partition_cols: Optional[List[str]] = None,
+        time_partitioning_granularity: Optional[str] = None,
+        max_events: Optional[int] = None,
+        flush_after_seconds: Optional[int] = None,
+        storage_options: Dict[str, str] = None,
+        db_url: str = None,
+        table_name: str = None,
+        schema: Dict[str, Any] = None,
+        primary_key_column: str = "",
+        if_exists: str = "append",
+        create_table: bool = False,
+        # create_according_to_data: bool = False,
+        time_fields: List[str] = None,
+        varchar_len: int = 50,
+    ):
+        """
+        Write to SqlDB as output target for a flow.
+        example::
+             db_path = "sqlite:///stockmarket.db"
+             schema = {'time': datetime.datetime, 'ticker': str,
+                    'bid': float, 'ask': float, 'ind': int}
+             target = SqlDBTarget(table_name=f'{name}-tatget', db_path=db_path, create_table=True,
+                                   schema=schema, primary_key_column=key)
+        :param name:
+        :param path:
+        :param attributes:
+        :param after_step:
+        :param partitioned:
+        :param key_bucketing_number:
+        :param partition_cols:
+        :param time_partitioning_granularity:
+        :param max_events:
+        :param flush_after_seconds:
+        :param storage_options:
+        :param db_url:                     url string connection to sql database.
+                                            If not set, the MLRUN_SQL__URL environment variable will
+                                            be used.
+        :param table_name:                  the name of the table to access,
+                                            from the current database
+        :param schema:                      the schema of the table (must pass when
+                                            create_table=True)
+        :param primary_key_column:          the primary key of the table (must pass always)
+        :param if_exists:                   {'fail', 'replace', 'append'}, default 'append'
+                                            - fail: If table exists, do nothing.
+                                            - replace: If table exists, drop it, recreate it, and insert data.
+                                            - append: If table exists, insert data. Create if does not exist.
+        :param create_table:                pass True if you want to create new table named by
+                                            table_name with schema on current database.
+        :param create_according_to_data:    (not valid)
+        :param time_fields :    all the field to be parsed as timestamp.
+        :param varchar_len :    the defalut len of the all the varchar column (using if needed to create the table).
+        """
+        create_according_to_data = False  # TODO: open for user
+        db_url = db_url or mlrun.mlconf.sql.url
+        if db_url is None or table_name is None:
+            attr = {}
+        else:
+            # check for table existence and acts according to the user input
+            self._primary_key_column = primary_key_column
+
+            attr = {
+                "table_name": table_name,
+                "db_path": db_url,
+                "create_according_to_data": create_according_to_data,
+                "if_exists": if_exists,
+                "time_fields": time_fields,
+                "varchar_len": varchar_len,
+            }
+            path = (
+                f"mlrunSql://@{db_url}//@{table_name}"
+                f"//@{str(create_according_to_data)}//@{if_exists}//@{primary_key_column}//@{create_table}"
+            )
+
+        if attributes:
+            attributes.update(attr)
+        else:
+            attributes = attr
+
+        super().__init__(
+            name,
+            path,
+            attributes,
+            after_step,
+            list(schema.keys()) if schema else None,
+            partitioned,
+            key_bucketing_number,
+            partition_cols,
+            time_partitioning_granularity,
+            max_events=max_events,
+            flush_after_seconds=flush_after_seconds,
+            storage_options=storage_options,
+            schema=schema,
+        )
+
+    def get_table_object(self):
+        from storey import SQLDriver, Table
+
+        (db_path, table_name, _, _, primary_key, _) = self._parse_url()
+        try:
+            primary_key = ast.literal_eval(primary_key)
+        except Exception:
+            pass
+        return Table(
+            f"{db_path}/{table_name}",
+            SQLDriver(db_path=db_path, primary_key=primary_key),
+            flush_interval_secs=mlrun.mlconf.feature_store.flush_interval,
+        )
+
+    def add_writer_step(
+        self,
+        graph,
+        after,
+        features,
+        key_columns=None,
+        timestamp_key=None,
+        featureset_status=None,
+    ):
+        key_columns = list(key_columns.keys())
+        column_list = self._get_column_list(
+            features=features, timestamp_key=timestamp_key, key_columns=key_columns
+        )
+        table = self._resource.uri
+        self._create_sql_table()
+        for step in graph.steps.values():
+            if step.class_name == "storey.AggregateByKey":
+                raise mlrun.errors.MLRunRuntimeError(
+                    "SQLTarget does not support aggregation step"
+                )
+        graph.add_step(
+            name=self.name or "SqlTarget",
+            after=after,
+            graph_shape="cylinder",
+            class_name="storey.NoSqlTarget",
+            columns=column_list,
+            header=True,
+            table=table,
+            index_cols=key_columns,
+            **self.attributes,
+        )
+
+    def as_df(
+        self,
+        columns=None,
+        df_module=None,
+        entities=None,
+        start_time=None,
+        end_time=None,
+        time_column=None,
+        **kwargs,
+    ):
+        db_path, table_name, _, _, _, _ = self._parse_url()
+        engine = sqlalchemy.create_engine(db_path)
+        with engine.connect() as conn:
+            df = pd.read_sql(
+                f"SELECT * FROM {self.attributes.get('table_name')}",
+                con=conn,
+                parse_dates=self.attributes.get("time_fields"),
+            )
+            if self._primary_key_column:
+                df.set_index(self._primary_key_column, inplace=True)
+            if columns:
+                df = df[columns]
+        return df
+
+    def write_dataframe(
+        self, df, key_column=None, timestamp_key=None, chunk_id=0, **kwargs
+    ):
+        self._create_sql_table()
+
+        if hasattr(df, "rdd"):
+            raise ValueError("Spark is not supported")
+        else:
+            (
+                db_path,
+                table_name,
+                create_according_to_data,
+                if_exists,
+                primary_key,
+                _,
+            ) = self._parse_url()
+            create_according_to_data = bool(create_according_to_data)
+            engine = sqlalchemy.create_engine(
+                db_path,
+            )
+            connection = engine.connect()
+            if create_according_to_data:
+                # todo : create according to first row.
+                pass
+            df.to_sql(table_name, connection, if_exists=if_exists)
+
+    def _parse_url(self):
+        path = self.path[len("mlrunSql:///") :]
+        return path.split("//@")
+
+    def purge(self):
+        pass
+
+    def _create_sql_table(self):
+        (
+            db_path,
+            table_name,
+            create_according_to_data,
+            if_exists,
+            primary_key,
+            create_table,
+        ) = self._parse_url()
+        try:
+            primary_key = ast.literal_eval(primary_key)
+            primary_key_for_check = primary_key
+        except Exception:
+            primary_key_for_check = [primary_key]
+        engine = sqlalchemy.create_engine(db_path)
+        with engine.connect() as conn:
+            metadata = sqlalchemy.MetaData()
+            table_exists = engine.dialect.has_table(conn, table_name)
+            if not table_exists and not create_table:
+                raise ValueError(f"Table named {table_name} is not exist")
+
+            elif not table_exists and create_table:
+                TYPE_TO_SQL_TYPE = {
+                    int: sqlalchemy.Integer,
+                    str: sqlalchemy.String(self.attributes.get("varchar_len")),
+                    datetime.datetime: sqlalchemy.dialects.mysql.DATETIME(fsp=6),
+                    pd.Timestamp: sqlalchemy.dialects.mysql.DATETIME(fsp=6),
+                    bool: sqlalchemy.Boolean,
+                    float: sqlalchemy.Float,
+                    datetime.timedelta: sqlalchemy.Interval,
+                    pd.Timedelta: sqlalchemy.Interval,
+                }
+                # creat new table with the given name
+                columns = []
+                for col, col_type in self.schema.items():
+                    col_type = TYPE_TO_SQL_TYPE.get(col_type)
+                    if col_type is None:
+                        raise TypeError(f"{col_type} unsupported type")
+                    columns.append(
+                        sqlalchemy.Column(
+                            col, col_type, primary_key=(col in primary_key_for_check)
+                        )
+                    )
+
+                sqlalchemy.Table(table_name, metadata, *columns)
+                metadata.create_all(engine)
+                if_exists = "append"
+                self.path = (
+                    f"mlrunSql://@{db_path}//@{table_name}"
+                    f"//@{str(create_according_to_data)}//@{if_exists}//@{primary_key}//@{create_table}"
+                )
+                conn.close()
+
+
 kind_to_driver = {
     TargetTypes.parquet: ParquetTarget,
     TargetTypes.csv: CSVTarget,
     TargetTypes.nosql: NoSqlTarget,
     TargetTypes.redisnosql: RedisNoSqlTarget,
     TargetTypes.dataframe: DFTarget,
     TargetTypes.stream: StreamTarget,
     TargetTypes.kafka: KafkaTarget,
     TargetTypes.tsdb: TSDBTarget,
     TargetTypes.custom: CustomTarget,
+    TargetTypes.sql: SQLTarget,
 }
 
 
 def _get_target_path(driver, resource, run_id_mode=False):
     """return the default target path given the resource and target kind"""
     kind = driver.kind
     suffix = driver.suffix
```

## mlrun/datastore/utils.py

```diff
@@ -12,15 +12,19 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from urllib.parse import urlparse
 
 
 def store_path_to_spark(path):
-    if path.startswith("v3io:///"):
+    if path.startswith("redis://") or path.startswith("rediss://"):
+        url = urlparse(path)
+        if url.path:
+            path = url.path
+    elif path.startswith("v3io:///"):
         path = "v3io:" + path[len("v3io:/") :]
     elif path.startswith("s3://"):
         if path.startswith("s3:///"):
             # 's3:///' not supported since mlrun 0.9.0 should use s3:// instead
             from mlrun.errors import MLRunInvalidArgumentError
 
             valid_path = "s3:" + path[len("s3:/") :]
```

## mlrun/db/__init__.py

```diff
@@ -63,20 +63,20 @@
     ):
         return _run_db
     _last_db_url = url
 
     parsed_url = urlparse(url)
     scheme = parsed_url.scheme.lower()
     kwargs = {}
-    if "://" not in url or scheme in ["file", "s3", "v3io", "v3ios"]:
+    if "://" not in str(url) or scheme in ["file", "s3", "v3io", "v3ios"]:
         logger.warning(
             "Could not detect path to API server, Using Deprecated client interface"
         )
         logger.warning(
-            "Please make sure your env variable MLRUN_DB_PATH is configured correctly to point to the API server!"
+            "Please make sure your env variable MLRUN_DBPATH is configured correctly to point to the API server!"
         )
         cls = FileRunDB
     elif scheme in ("http", "https"):
         # import here to avoid circular imports
         from .httpdb import HTTPRunDB
 
         cls = HTTPRunDB
```

## mlrun/db/base.py

```diff
@@ -13,16 +13,16 @@
 # limitations under the License.
 
 import datetime
 import warnings
 from abc import ABC, abstractmethod
 from typing import List, Optional, Union
 
+import mlrun.model_monitoring.model_endpoint
 from mlrun.api import schemas
-from mlrun.api.schemas import ModelEndpoint
 
 
 class RunDBError(Exception):
     pass
 
 
 class RunDBInterface(ABC):
@@ -475,15 +475,17 @@
         pass
 
     @abstractmethod
     def create_model_endpoint(
         self,
         project: str,
         endpoint_id: str,
-        model_endpoint: ModelEndpoint,
+        model_endpoint: Union[
+            mlrun.model_monitoring.model_endpoint.ModelEndpoint, dict
+        ],
     ):
         pass
 
     @abstractmethod
     def delete_model_endpoint(
         self,
         project: str,
```

## mlrun/db/filedb.py

```diff
@@ -19,17 +19,17 @@
 from typing import List, Optional, Union
 
 import yaml
 from dateutil.parser import parse as parse_time
 
 import mlrun.api.schemas
 import mlrun.errors
+import mlrun.model_monitoring.model_endpoint
 
 from ..api import schemas
-from ..api.schemas import ModelEndpoint
 from ..config import config
 from ..datastore import store_manager
 from ..lists import ArtifactList, RunList
 from ..utils import (
     dict_to_json,
     dict_to_yaml,
     fill_function_hash,
@@ -107,15 +107,14 @@
             self._filepath(run_logs, project, self._run_path(uid, iter), "")
             + self.format
         )
         self.datastore.put(filepath, data)
 
     def update_run(self, updates: dict, uid, project="", iter=0):
         run = self.read_run(uid, project, iter=iter)
-        # TODO: Should we raise if run not found?
         if run and updates:
             for key, val in updates.items():
                 update_in(run, key, val)
         self.store_run(run, uid, project, iter=iter)
 
     def abort_run(self, uid, project="", iter=0):
         raise NotImplementedError()
@@ -777,15 +776,17 @@
     def list_artifact_tags(self, project=None, category=None):
         raise NotImplementedError()
 
     def create_model_endpoint(
         self,
         project: str,
         endpoint_id: str,
-        model_endpoint: ModelEndpoint,
+        model_endpoint: Union[
+            mlrun.model_monitoring.model_endpoint.ModelEndpoint, dict
+        ],
     ):
         raise NotImplementedError()
 
     def delete_model_endpoint(
         self,
         project: str,
         endpoint_id: str,
```

## mlrun/db/httpdb.py

```diff
@@ -34,7931 +34,7984 @@
 00000210: 6f6e 7320 616e 640a 2320 6c69 6d69 7461  ons and.# limita
 00000220: 7469 6f6e 7320 756e 6465 7220 7468 6520  tions under the 
 00000230: 4c69 6365 6e73 652e 0a69 6d70 6f72 7420  License..import 
 00000240: 656e 756d 0a69 6d70 6f72 7420 6874 7470  enum.import http
 00000250: 0a69 6d70 6f72 7420 7465 6d70 6669 6c65  .import tempfile
 00000260: 0a69 6d70 6f72 7420 7469 6d65 0a69 6d70  .import time.imp
 00000270: 6f72 7420 7472 6163 6562 6163 6b0a 696d  ort traceback.im
-00000280: 706f 7274 2077 6172 6e69 6e67 730a 6672  port warnings.fr
-00000290: 6f6d 2064 6174 6574 696d 6520 696d 706f  om datetime impo
-000002a0: 7274 2064 6174 6574 696d 650a 6672 6f6d  rt datetime.from
-000002b0: 206f 7320 696d 706f 7274 2070 6174 682c   os import path,
-000002c0: 2072 656d 6f76 650a 6672 6f6d 2074 7970   remove.from typ
-000002d0: 696e 6720 696d 706f 7274 2044 6963 742c  ing import Dict,
-000002e0: 204c 6973 742c 204f 7074 696f 6e61 6c2c   List, Optional,
-000002f0: 2055 6e69 6f6e 0a0a 696d 706f 7274 206b   Union..import k
-00000300: 6670 0a69 6d70 6f72 7420 7265 7175 6573  fp.import reques
-00000310: 7473 0a69 6d70 6f72 7420 7365 6d76 6572  ts.import semver
-00000320: 0a0a 696d 706f 7274 206d 6c72 756e 0a69  ..import mlrun.i
-00000330: 6d70 6f72 7420 6d6c 7275 6e2e 7072 6f6a  mport mlrun.proj
-00000340: 6563 7473 0a66 726f 6d20 6d6c 7275 6e2e  ects.from mlrun.
-00000350: 6170 6920 696d 706f 7274 2073 6368 656d  api import schem
-00000360: 6173 0a66 726f 6d20 6d6c 7275 6e2e 6572  as.from mlrun.er
-00000370: 726f 7273 2069 6d70 6f72 7420 4d4c 5275  rors import MLRu
-00000380: 6e49 6e76 616c 6964 4172 6775 6d65 6e74  nInvalidArgument
-00000390: 4572 726f 722c 2065 7272 5f74 6f5f 7374  Error, err_to_st
-000003a0: 720a 0a66 726f 6d20 2e2e 6170 692e 7363  r..from ..api.sc
-000003b0: 6865 6d61 7320 696d 706f 7274 204d 6f64  hemas import Mod
-000003c0: 656c 456e 6470 6f69 6e74 0a66 726f 6d20  elEndpoint.from 
-000003d0: 2e2e 6172 7469 6661 6374 7320 696d 706f  ..artifacts impo
-000003e0: 7274 2041 7274 6966 6163 740a 6672 6f6d  rt Artifact.from
-000003f0: 202e 2e63 6f6e 6669 6720 696d 706f 7274   ..config import
-00000400: 2063 6f6e 6669 670a 6672 6f6d 202e 2e66   config.from ..f
-00000410: 6561 7475 7265 5f73 746f 7265 2069 6d70  eature_store imp
-00000420: 6f72 7420 4665 6174 7572 6553 6574 2c20  ort FeatureSet, 
-00000430: 4665 6174 7572 6556 6563 746f 720a 6672  FeatureVector.fr
-00000440: 6f6d 202e 2e6c 6973 7473 2069 6d70 6f72  om ..lists impor
-00000450: 7420 4172 7469 6661 6374 4c69 7374 2c20  t ArtifactList, 
-00000460: 5275 6e4c 6973 740a 6672 6f6d 202e 2e72  RunList.from ..r
-00000470: 756e 7469 6d65 7320 696d 706f 7274 2042  untimes import B
-00000480: 6173 6552 756e 7469 6d65 0a66 726f 6d20  aseRuntime.from 
-00000490: 2e2e 7574 696c 7320 696d 706f 7274 2064  ..utils import d
-000004a0: 6174 6574 696d 655f 746f 5f69 736f 2c20  atetime_to_iso, 
-000004b0: 6469 6374 5f74 6f5f 6a73 6f6e 2c20 6c6f  dict_to_json, lo
-000004c0: 6767 6572 2c20 6e65 775f 7069 7065 5f6d  gger, new_pipe_m
-000004d0: 6574 612c 2076 6572 7369 6f6e 0a66 726f  eta, version.fro
-000004e0: 6d20 2e62 6173 6520 696d 706f 7274 2052  m .base import R
-000004f0: 756e 4442 4572 726f 722c 2052 756e 4442  unDBError, RunDB
-00000500: 496e 7465 7266 6163 650a 0a5f 6172 7469  Interface.._arti
-00000510: 6661 6374 5f6b 6579 7320 3d20 5b0a 2020  fact_keys = [.  
-00000520: 2020 2266 6f72 6d61 7422 2c0a 2020 2020    "format",.    
-00000530: 2269 6e6c 696e 6522 2c0a 2020 2020 226b  "inline",.    "k
-00000540: 6579 222c 0a20 2020 2022 7372 635f 7061  ey",.    "src_pa
-00000550: 7468 222c 0a20 2020 2022 7461 7267 6574  th",.    "target
-00000560: 5f70 6174 6822 2c0a 2020 2020 2276 6965  _path",.    "vie
-00000570: 7765 7222 2c0a 5d0a 0a0a 6465 6620 626f  wer",.]...def bo
-00000580: 6f6c 3273 7472 2876 616c 293a 0a20 2020  ol2str(val):.   
-00000590: 2072 6574 7572 6e20 2279 6573 2220 6966   return "yes" if
-000005a0: 2076 616c 2065 6c73 6520 226e 6f22 0a0a   val else "no"..
-000005b0: 0a63 6c61 7373 2048 5454 5052 756e 4442  .class HTTPRunDB
-000005c0: 2852 756e 4442 496e 7465 7266 6163 6529  (RunDBInterface)
-000005d0: 3a0a 2020 2020 2222 2249 6e74 6572 6661  :.    """Interfa
-000005e0: 6365 2066 6f72 2061 6363 6573 7369 6e67  ce for accessing
-000005f0: 2061 6e64 206d 616e 6970 756c 6174 696e   and manipulatin
-00000600: 6720 7468 6520 3a70 793a 6d6f 643a 606d  g the :py:mod:`m
-00000610: 6c72 756e 6020 7065 7273 6973 7465 6e74  lrun` persistent
-00000620: 2073 746f 7265 2c20 6d61 696e 7461 696e   store, maintain
-00000630: 696e 6720 7468 6520 6675 6c6c 2073 7461  ing the full sta
-00000640: 7465 0a20 2020 2061 6e64 2063 6174 616c  te.    and catal
-00000650: 6f67 206f 6620 6f62 6a65 6374 7320 7468  og of objects th
-00000660: 6174 204d 4c52 756e 2075 7365 732e 2054  at MLRun uses. T
-00000670: 6865 203a 7079 3a63 6c61 7373 3a60 4854  he :py:class:`HT
-00000680: 5450 5275 6e44 4260 2063 6c61 7373 2073  TPRunDB` class s
-00000690: 6572 7665 7320 6173 2061 2063 6c69 656e  erves as a clien
-000006a0: 742d 7369 6465 2070 726f 7879 2074 6f20  t-side proxy to 
-000006b0: 7468 6520 4d4c 5275 6e0a 2020 2020 4150  the MLRun.    AP
-000006c0: 4920 7365 7276 6963 6520 7768 6963 6820  I service which 
-000006d0: 6d61 696e 7461 696e 7320 7468 6520 6163  maintains the ac
-000006e0: 7475 616c 2064 6174 612d 7374 6f72 652c  tual data-store,
-000006f0: 2061 6363 6573 7365 7320 7468 6520 7365   accesses the se
-00000700: 7276 6572 2074 6872 6f75 6768 2052 4553  rver through RES
-00000710: 5420 4150 4973 2e0a 0a20 2020 2054 6865  T APIs...    The
-00000720: 2063 6c61 7373 2070 726f 7669 6465 7320   class provides 
-00000730: 6675 6e63 7469 6f6e 7320 666f 7220 6163  functions for ac
-00000740: 6365 7373 696e 6720 616e 6420 6d6f 6469  cessing and modi
-00000750: 6679 696e 6720 7468 6520 7661 7269 6f75  fying the variou
-00000760: 7320 6f62 6a65 6374 7320 7468 6174 2061  s objects that a
-00000770: 7265 2075 7365 6420 6279 204d 4c52 756e  re used by MLRun
-00000780: 2069 6e20 6974 730a 2020 2020 6f70 6572   in its.    oper
-00000790: 6174 696f 6e2e 2054 6865 2066 756e 6374  ation. The funct
-000007a0: 696f 6e73 2070 726f 7669 6465 6420 666f  ions provided fo
-000007b0: 6c6c 6f77 2073 6f6d 6520 7374 616e 6461  llow some standa
-000007c0: 7264 2067 7569 6465 6c69 6e65 732c 2077  rd guidelines, w
-000007d0: 6869 6368 2061 7265 3a0a 0a20 2020 202d  hich are:..    -
-000007e0: 2045 7665 7279 206f 626a 6563 7420 696e   Every object in
-000007f0: 204d 4c52 756e 2065 7869 7374 7320 696e   MLRun exists in
-00000800: 2074 6865 2063 6f6e 7465 7874 206f 6620   the context of 
-00000810: 6120 7072 6f6a 6563 7420 2865 7863 6570  a project (excep
-00000820: 7420 7072 6f6a 6563 7473 2074 6865 6d73  t projects thems
-00000830: 656c 7665 7329 2e20 5768 656e 2072 6566  elves). When ref
-00000840: 6572 656e 6369 6e67 2061 6e20 6f62 6a65  erencing an obje
-00000850: 6374 0a20 2020 2020 2074 6872 6f75 6768  ct.      through
-00000860: 2061 6e79 2041 5049 2c20 6120 7072 6f6a   any API, a proj
-00000870: 6563 7420 6e61 6d65 206d 7573 7420 6265  ect name must be
-00000880: 2070 726f 7669 6465 642e 2054 6865 2064   provided. The d
-00000890: 6566 6175 6c74 2066 6f72 206d 6f73 7420  efault for most 
-000008a0: 4150 4973 2069 7320 666f 7220 616e 2065  APIs is for an e
-000008b0: 6d70 7479 2070 726f 6a65 6374 206e 616d  mpty project nam
-000008c0: 652c 2077 6869 6368 0a20 2020 2020 2077  e, which.      w
-000008d0: 696c 6c20 6265 2072 6570 6c61 6365 6420  ill be replaced 
-000008e0: 6279 2074 6865 206e 616d 6520 6f66 2074  by the name of t
-000008f0: 6865 2064 6566 6175 6c74 2070 726f 6a65  he default proje
-00000900: 6374 2028 7573 7561 6c6c 7920 6060 6465  ct (usually ``de
-00000910: 6661 756c 7460 6029 2e20 5468 6572 6566  fault``). Theref
-00000920: 6f72 652c 2069 6620 7065 7266 6f72 6d69  ore, if performi
-00000930: 6e67 2061 6e20 4150 4920 746f 0a20 2020  ng an API to.   
-00000940: 2020 206c 6973 7420 6675 6e63 7469 6f6e     list function
-00000950: 732c 2066 6f72 2065 7861 6d70 6c65 2c20  s, for example, 
-00000960: 616e 6420 6e6f 7420 7072 6f76 6964 696e  and not providin
-00000970: 6720 6120 7072 6f6a 6563 7420 6e61 6d65  g a project name
-00000980: 202d 2074 6865 2072 6573 756c 7420 7769   - the result wi
-00000990: 6c6c 206e 6f74 2062 6520 6675 6e63 7469  ll not be functi
-000009a0: 6f6e 7320 6672 6f6d 2061 6c6c 0a20 2020  ons from all.   
-000009b0: 2020 2070 726f 6a65 6374 7320 6275 7420     projects but 
-000009c0: 7261 7468 6572 2066 726f 6d20 7468 6520  rather from the 
-000009d0: 6060 6465 6661 756c 7460 6020 7072 6f6a  ``default`` proj
-000009e0: 6563 742e 0a20 2020 202d 204d 616e 7920  ect..    - Many 
-000009f0: 6f62 6a65 6374 7320 6361 6e20 6265 2061  objects can be a
-00000a00: 7373 6967 6e65 6420 6c61 6265 6c73 2c20  ssigned labels, 
-00000a10: 616e 6420 6c69 7374 6564 2f71 7565 7269  and listed/queri
-00000a20: 6564 2062 7920 6c61 6265 6c2e 2054 6865  ed by label. The
-00000a30: 206c 6162 656c 2070 6172 616d 6574 6572   label parameter
-00000a40: 2066 6f72 2071 7565 7279 2041 5049 7320   for query APIs 
-00000a50: 616c 6c6f 7773 2066 6f72 0a20 2020 2020  allows for.     
-00000a60: 206c 6973 7469 6e67 206f 626a 6563 7473   listing objects
-00000a70: 2074 6861 743a 0a0a 2020 2020 2020 2d20   that:..      - 
-00000a80: 4861 7665 2061 2073 7065 6369 6669 6320  Have a specific 
-00000a90: 6c61 6265 6c2c 2062 7920 6173 6b69 6e67  label, by asking
-00000aa0: 2066 6f72 2060 606c 6162 656c 3d22 3c6c   for ``label="<l
-00000ab0: 6162 656c 5f6e 616d 653e 2260 602e 2049  abel_name>"``. I
-00000ac0: 6e20 7468 6973 2063 6173 6520 7468 6520  n this case the 
-00000ad0: 6163 7475 616c 2076 616c 7565 206f 6620  actual value of 
-00000ae0: 7468 6520 6c61 6265 6c0a 2020 2020 2020  the label.      
-00000af0: 2020 646f 6573 6e27 7420 6d61 7474 6572    doesn't matter
-00000b00: 2061 6e64 2065 7665 7279 206f 626a 6563   and every objec
-00000b10: 7420 7769 7468 2074 6861 7420 6c61 6265  t with that labe
-00000b20: 6c20 7769 6c6c 2062 6520 7265 7475 726e  l will be return
-00000b30: 6564 0a20 2020 2020 202d 2048 6176 6520  ed.      - Have 
-00000b40: 6120 6c61 6265 6c20 7769 7468 2061 2073  a label with a s
-00000b50: 7065 6369 6669 6320 7661 6c75 652e 2054  pecific value. T
-00000b60: 6869 7320 6973 2064 6f6e 6520 6279 2073  his is done by s
-00000b70: 7065 6369 6679 696e 6720 6060 6c61 6265  pecifying ``labe
-00000b80: 6c3d 223c 6c61 6265 6c5f 6e61 6d65 3e3d  l="<label_name>=
-00000b90: 3c6c 6162 656c 5f76 616c 7565 3e22 6060  <label_value>"``
-00000ba0: 2e20 496e 2074 6869 730a 2020 2020 2020  . In this.      
-00000bb0: 2020 6361 7365 206f 6e6c 7920 6f62 6a65    case only obje
-00000bc0: 6374 7320 7768 6f73 6520 6c61 6265 6c20  cts whose label 
-00000bd0: 6d61 7463 6865 7320 7468 6520 7661 6c75  matches the valu
-00000be0: 6520 7769 6c6c 2062 6520 7265 7475 726e  e will be return
-00000bf0: 6564 0a0a 2020 2020 2d20 4d6f 7374 206f  ed..    - Most o
-00000c00: 626a 6563 7473 2068 6176 6520 6120 6060  bjects have a ``
-00000c10: 6372 6561 7465 6060 206d 6574 686f 6420  create`` method 
-00000c20: 6173 2077 656c 6c20 6173 2061 2060 6073  as well as a ``s
-00000c30: 746f 7265 6060 206d 6574 686f 642e 2043  tore`` method. C
-00000c40: 7265 6174 6520 6361 6e20 6f6e 6c79 2062  reate can only b
-00000c50: 6520 6361 6c6c 6564 2077 6865 6e20 7375  e called when su
-00000c60: 6368 2061 6e0a 2020 2020 2020 646f 6573  ch an.      does
-00000c70: 206e 6f74 2065 7869 7374 2079 6574 2c20   not exist yet, 
-00000c80: 7768 696c 6520 7374 6f72 6520 616c 6c6f  while store allo
-00000c90: 7773 2066 6f72 2065 6974 6865 7220 6372  ws for either cr
-00000ca0: 6561 7469 6e67 2061 206e 6577 206f 626a  eating a new obj
-00000cb0: 6563 7420 6f72 206f 7665 7277 7269 7469  ect or overwriti
-00000cc0: 6e67 2061 6e20 6578 6973 7469 6e67 206f  ng an existing o
-00000cd0: 626a 6563 742e 0a20 2020 202d 2053 6f6d  bject..    - Som
-00000ce0: 6520 6f62 6a65 6374 7320 6861 7665 2061  e objects have a
-00000cf0: 2060 6076 6572 7369 6f6e 6564 6060 206f   ``versioned`` o
-00000d00: 7074 696f 6e2c 2069 6e20 7768 6963 6820  ption, in which 
-00000d10: 6361 7365 206f 7665 7277 7269 7469 6e67  case overwriting
-00000d20: 2074 6865 2073 616d 6520 6f62 6a65 6374   the same object
-00000d30: 2077 6974 6820 6120 6469 6666 6572 656e   with a differen
-00000d40: 7420 7665 7273 696f 6e20 6f66 0a20 2020  t version of.   
-00000d50: 2020 2069 7420 646f 6573 206e 6f74 2064     it does not d
-00000d60: 656c 6574 6520 7468 6520 7072 6576 696f  elete the previo
-00000d70: 7573 2076 6572 7369 6f6e 2c20 6275 7420  us version, but 
-00000d80: 7261 7468 6572 2063 7265 6174 6573 2061  rather creates a
-00000d90: 206e 6577 2076 6572 7369 6f6e 206f 6620   new version of 
-00000da0: 7468 6520 6f62 6a65 6374 2061 6e64 206b  the object and k
-00000db0: 6565 7073 2062 6f74 6820 7665 7273 696f  eeps both versio
-00000dc0: 6e73 2e0a 2020 2020 2020 5665 7273 696f  ns..      Versio
-00000dd0: 6e65 6420 6f62 6a65 6374 7320 7573 7561  ned objects usua
-00000de0: 6c6c 7920 6861 7665 2061 2060 6075 6964  lly have a ``uid
-00000df0: 6060 2070 726f 7065 7274 7920 7768 6963  `` property whic
-00000e00: 6820 6973 2062 6173 6564 206f 6e20 7468  h is based on th
-00000e10: 6569 7220 636f 6e74 656e 7420 616e 6420  eir content and 
-00000e20: 616c 6c6f 7773 2074 6f20 7265 6665 7265  allows to refere
-00000e30: 6e63 6520 610a 2020 2020 2020 7370 6563  nce a.      spec
-00000e40: 6966 6963 2076 6572 7369 6f6e 206f 6620  ific version of 
-00000e50: 616e 206f 626a 6563 7420 286f 7468 6572  an object (other
-00000e60: 2074 6861 6e20 7461 6767 696e 6720 6f62   than tagging ob
-00000e70: 6a65 6374 732c 2077 6869 6368 2061 6c73  jects, which als
-00000e80: 6f20 616c 6c6f 7773 2066 6f72 2065 6173  o allows for eas
-00000e90: 7920 7265 6665 7265 6e63 696e 6729 2e0a  y referencing)..
-00000ea0: 2020 2020 2d20 4d61 6e79 206f 626a 6563      - Many objec
-00000eb0: 7473 2068 6176 6520 626f 7468 2061 2060  ts have both a `
-00000ec0: 6073 746f 7265 6060 2066 756e 6374 696f  `store`` functio
-00000ed0: 6e20 616e 6420 6120 6060 7061 7463 6860  n and a ``patch`
-00000ee0: 6020 6675 6e63 7469 6f6e 2e20 5468 6573  ` function. Thes
-00000ef0: 6520 6172 6520 7573 6564 2069 6e20 7468  e are used in th
-00000f00: 6520 7361 6d65 2077 6179 2061 7320 7468  e same way as th
-00000f10: 650a 2020 2020 2020 636f 7272 6573 706f  e.      correspo
-00000f20: 6e64 696e 6720 5245 5354 2076 6572 6273  nding REST verbs
-00000f30: 202d 2061 2060 6073 746f 7265 6060 2069   - a ``store`` i
-00000f40: 7320 7061 7373 6564 2061 2066 756c 6c20  s passed a full 
-00000f50: 6f62 6a65 6374 2061 6e64 2077 696c 6c20  object and will 
-00000f60: 6261 7369 6361 6c6c 7920 7065 7266 6f72  basically perfor
-00000f70: 6d20 6120 5055 5420 6f70 6572 6174 696f  m a PUT operatio
-00000f80: 6e2c 0a20 2020 2020 2072 6570 6c61 6369  n,.      replaci
-00000f90: 6e67 2074 6865 2066 756c 6c20 6f62 6a65  ng the full obje
-00000fa0: 6374 2028 6966 2069 7420 6578 6973 7473  ct (if it exists
-00000fb0: 2920 7768 696c 6520 6060 7061 7463 6860  ) while ``patch`
-00000fc0: 6020 7265 6365 6976 6573 206a 7573 7420  ` receives just 
-00000fd0: 6120 6469 6374 696f 6e61 7279 2063 6f6e  a dictionary con
-00000fe0: 7461 696e 696e 6720 7468 6520 6469 6666  taining the diff
-00000ff0: 6572 656e 6365 7320 746f 0a20 2020 2020  erences to.     
-00001000: 2062 6520 6170 706c 6965 6420 746f 2074   be applied to t
-00001010: 6865 206f 626a 6563 742c 2061 6e64 2077  he object, and w
-00001020: 696c 6c20 6d65 7267 6520 7468 6f73 6520  ill merge those 
-00001030: 6368 616e 6765 7320 746f 2074 6865 2065  changes to the e
-00001040: 7869 7374 696e 6720 6f62 6a65 6374 2e20  xisting object. 
-00001050: 5468 6520 6060 7061 7463 6860 600a 2020  The ``patch``.  
-00001060: 2020 2020 6f70 6572 6174 696f 6e20 616c      operation al
-00001070: 736f 2068 6173 2061 2073 7472 6174 6567  so has a strateg
-00001080: 7920 6173 7369 676e 6564 2074 6f20 6974  y assigned to it
-00001090: 2077 6869 6368 2064 6574 6572 6d69 6e65   which determine
-000010a0: 7320 686f 7720 7468 6520 6d65 7267 6520  s how the merge 
-000010b0: 6c6f 6769 6320 7368 6f75 6c64 2062 6568  logic should beh
-000010c0: 6176 652e 0a20 2020 2020 2054 6865 2073  ave..      The s
-000010d0: 7472 6174 6567 7920 6361 6e20 6265 2065  trategy can be e
-000010e0: 6974 6865 7220 6060 7265 706c 6163 6560  ither ``replace`
-000010f0: 6020 6f72 2060 6061 6464 6974 6976 6560  ` or ``additive`
-00001100: 602e 2046 6f72 2066 7572 7468 6572 2064  `. For further d
-00001110: 6574 6169 6c73 206f 6e20 7468 6f73 6520  etails on those 
-00001120: 7374 7261 7465 6769 6573 2c20 7265 6665  strategies, refe
-00001130: 720a 2020 2020 2020 746f 2068 7474 7073  r.      to https
-00001140: 3a2f 2f70 7970 692e 6f72 672f 7072 6f6a  ://pypi.org/proj
-00001150: 6563 742f 6d65 7267 6564 6565 702f 0a20  ect/mergedeep/. 
-00001160: 2020 2022 2222 0a0a 2020 2020 6b69 6e64     """..    kind
-00001170: 203d 2022 6874 7470 220a 0a20 2020 2064   = "http"..    d
-00001180: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00001190: 2c20 6261 7365 5f75 726c 2c20 7573 6572  , base_url, user
-000011a0: 3d22 222c 2070 6173 7377 6f72 643d 2222  ="", password=""
-000011b0: 2c20 746f 6b65 6e3d 2222 293a 0a20 2020  , token=""):.   
-000011c0: 2020 2020 2073 656c 662e 6261 7365 5f75       self.base_u
-000011d0: 726c 203d 2062 6173 655f 7572 6c0a 2020  rl = base_url.  
-000011e0: 2020 2020 2020 7365 6c66 2e75 7365 7220        self.user 
-000011f0: 3d20 7573 6572 0a20 2020 2020 2020 2073  = user.        s
-00001200: 656c 662e 7061 7373 776f 7264 203d 2070  elf.password = p
-00001210: 6173 7377 6f72 640a 2020 2020 2020 2020  assword.        
-00001220: 7365 6c66 2e74 6f6b 656e 203d 2074 6f6b  self.token = tok
-00001230: 656e 0a20 2020 2020 2020 2073 656c 662e  en.        self.
-00001240: 7365 7276 6572 5f76 6572 7369 6f6e 203d  server_version =
-00001250: 2022 220a 2020 2020 2020 2020 7365 6c66   "".        self
-00001260: 2e73 6573 7369 6f6e 203d 204e 6f6e 650a  .session = None.
-00001270: 2020 2020 2020 2020 7365 6c66 2e5f 7761          self._wa
-00001280: 6974 5f66 6f72 5f70 726f 6a65 6374 5f74  it_for_project_t
-00001290: 6572 6d69 6e61 6c5f 7374 6174 655f 7265  erminal_state_re
-000012a0: 7472 795f 696e 7465 7276 616c 203d 2033  try_interval = 3
-000012b0: 0a20 2020 2020 2020 2073 656c 662e 5f77  .        self._w
-000012c0: 6169 745f 666f 725f 6261 636b 6772 6f75  ait_for_backgrou
-000012d0: 6e64 5f74 6173 6b5f 7465 726d 696e 616c  nd_task_terminal
-000012e0: 5f73 7461 7465 5f72 6574 7279 5f69 6e74  _state_retry_int
-000012f0: 6572 7661 6c20 3d20 330a 2020 2020 2020  erval = 3.      
-00001300: 2020 7365 6c66 2e5f 7761 6974 5f66 6f72    self._wait_for
-00001310: 5f70 726f 6a65 6374 5f64 656c 6574 696f  _project_deletio
-00001320: 6e5f 696e 7465 7276 616c 203d 2033 0a20  n_interval = 3. 
-00001330: 2020 2020 2020 2073 656c 662e 636c 6965         self.clie
-00001340: 6e74 5f76 6572 7369 6f6e 203d 2076 6572  nt_version = ver
-00001350: 7369 6f6e 2e56 6572 7369 6f6e 2829 2e67  sion.Version().g
-00001360: 6574 2829 5b22 7665 7273 696f 6e22 5d0a  et()["version"].
-00001370: 0a20 2020 2064 6566 205f 5f72 6570 725f  .    def __repr_
-00001380: 5f28 7365 6c66 293a 0a20 2020 2020 2020  _(self):.       
-00001390: 2063 6c73 203d 2073 656c 662e 5f5f 636c   cls = self.__cl
-000013a0: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 0a20  ass__.__name__. 
-000013b0: 2020 2020 2020 2072 6574 7572 6e20 6622         return f"
-000013c0: 7b63 6c73 7d28 7b73 656c 662e 6261 7365  {cls}({self.base
-000013d0: 5f75 726c 2172 7d29 220a 0a20 2020 2040  _url!r})"..    @
-000013e0: 7374 6174 6963 6d65 7468 6f64 0a20 2020  staticmethod.   
-000013f0: 2064 6566 2067 6574 5f61 7069 5f70 6174   def get_api_pat
-00001400: 685f 7072 6566 6978 2876 6572 7369 6f6e  h_prefix(version
-00001410: 3a20 7374 7220 3d20 4e6f 6e65 2920 2d3e  : str = None) ->
-00001420: 2073 7472 3a0a 2020 2020 2020 2020 2222   str:.        ""
-00001430: 220a 2020 2020 2020 2020 3a70 6172 616d  ".        :param
-00001440: 2076 6572 7369 6f6e 3a20 4150 4920 7665   version: API ve
-00001450: 7273 696f 6e20 746f 2075 7365 2c20 4e6f  rsion to use, No
-00001460: 6e65 2028 7468 6520 6465 6661 756c 7429  ne (the default)
-00001470: 2077 696c 6c20 6d65 616e 2074 6f20 7573   will mean to us
-00001480: 6520 7468 6520 6465 6661 756c 7420 7661  e the default va
-00001490: 6c75 6520 6672 6f6d 206d 6c63 6f6e 662c  lue from mlconf,
-000014a0: 0a20 2020 2020 2020 2020 666f 7220 756e  .         for un
-000014b0: 2d76 6572 7369 6f6e 6564 2061 7069 2073  -versioned api s
-000014c0: 6574 2061 6e20 656d 7074 7920 7374 7269  et an empty stri
-000014d0: 6e67 2e0a 2020 2020 2020 2020 2222 220a  ng..        """.
-000014e0: 2020 2020 2020 2020 6966 2076 6572 7369          if versi
-000014f0: 6f6e 2069 7320 6e6f 7420 4e6f 6e65 3a0a  on is not None:.
-00001500: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00001510: 726e 2066 2261 7069 2f7b 7665 7273 696f  rn f"api/{versio
-00001520: 6e7d 2220 6966 2076 6572 7369 6f6e 2065  n}" if version e
-00001530: 6c73 6520 2261 7069 220a 0a20 2020 2020  lse "api"..     
-00001540: 2020 2061 7069 5f76 6572 7369 6f6e 5f70     api_version_p
-00001550: 6174 6820 3d20 280a 2020 2020 2020 2020  ath = (.        
-00001560: 2020 2020 6622 6170 692f 7b63 6f6e 6669      f"api/{confi
-00001570: 672e 6170 695f 6261 7365 5f76 6572 7369  g.api_base_versi
-00001580: 6f6e 7d22 2069 6620 636f 6e66 6967 2e61  on}" if config.a
-00001590: 7069 5f62 6173 655f 7665 7273 696f 6e20  pi_base_version 
-000015a0: 656c 7365 2022 6170 6922 0a20 2020 2020  else "api".     
-000015b0: 2020 2029 0a20 2020 2020 2020 2072 6574     ).        ret
-000015c0: 7572 6e20 6170 695f 7665 7273 696f 6e5f  urn api_version_
-000015d0: 7061 7468 0a0a 2020 2020 6465 6620 6765  path..    def ge
-000015e0: 745f 6261 7365 5f61 7069 5f75 726c 2873  t_base_api_url(s
-000015f0: 656c 662c 2070 6174 683a 2073 7472 2c20  elf, path: str, 
-00001600: 7665 7273 696f 6e3a 2073 7472 203d 204e  version: str = N
-00001610: 6f6e 6529 202d 3e20 7374 723a 0a20 2020  one) -> str:.   
-00001620: 2020 2020 2070 6174 685f 7072 6566 6978       path_prefix
-00001630: 203d 2073 656c 662e 6765 745f 6170 695f   = self.get_api_
-00001640: 7061 7468 5f70 7265 6669 7828 7665 7273  path_prefix(vers
-00001650: 696f 6e29 0a20 2020 2020 2020 2075 726c  ion).        url
-00001660: 203d 2066 227b 7365 6c66 2e62 6173 655f   = f"{self.base_
-00001670: 7572 6c7d 2f7b 7061 7468 5f70 7265 6669  url}/{path_prefi
-00001680: 787d 2f7b 7061 7468 7d22 0a20 2020 2020  x}/{path}".     
-00001690: 2020 2072 6574 7572 6e20 7572 6c0a 0a20     return url.. 
-000016a0: 2020 2064 6566 2061 7069 5f63 616c 6c28     def api_call(
-000016b0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
-000016c0: 2020 2020 2020 206d 6574 686f 642c 0a20         method,. 
-000016d0: 2020 2020 2020 2070 6174 682c 0a20 2020         path,.   
-000016e0: 2020 2020 2065 7272 6f72 3d4e 6f6e 652c       error=None,
-000016f0: 0a20 2020 2020 2020 2070 6172 616d 733d  .        params=
-00001700: 4e6f 6e65 2c0a 2020 2020 2020 2020 626f  None,.        bo
-00001710: 6479 3d4e 6f6e 652c 0a20 2020 2020 2020  dy=None,.       
-00001720: 206a 736f 6e3d 4e6f 6e65 2c0a 2020 2020   json=None,.    
-00001730: 2020 2020 6865 6164 6572 733d 4e6f 6e65      headers=None
-00001740: 2c0a 2020 2020 2020 2020 7469 6d65 6f75  ,.        timeou
-00001750: 743d 3435 2c0a 2020 2020 2020 2020 7665  t=45,.        ve
-00001760: 7273 696f 6e3d 4e6f 6e65 2c0a 2020 2020  rsion=None,.    
-00001770: 293a 0a20 2020 2020 2020 2022 2222 5065  ):.        """Pe
-00001780: 7266 6f72 6d20 6120 6469 7265 6374 2052  rform a direct R
-00001790: 4553 5420 4150 4920 6361 6c6c 206f 6e20  EST API call on 
-000017a0: 7468 6520 3a70 793a 6d6f 643a 606d 6c72  the :py:mod:`mlr
-000017b0: 756e 6020 4150 4920 7365 7276 6572 2e0a  un` API server..
-000017c0: 0a20 2020 2020 2020 2043 6175 7469 6f6e  .        Caution
-000017d0: 3a0a 2020 2020 2020 2020 2020 2020 466f  :.            Fo
-000017e0: 7220 6164 7661 6e63 6564 2075 7361 6765  r advanced usage
-000017f0: 202d 2070 7265 6665 7220 7573 696e 6720   - prefer using 
-00001800: 7468 6520 7661 7269 6f75 7320 4150 4973  the various APIs
-00001810: 2065 7870 6f73 6564 2074 6872 6f75 6768   exposed through
-00001820: 2074 6869 7320 636c 6173 732c 2072 6174   this class, rat
-00001830: 6865 7220 7468 616e 0a20 2020 2020 2020  her than.       
-00001840: 2020 2020 2064 6972 6563 746c 7920 696e       directly in
-00001850: 766f 6b69 6e67 2052 4553 5420 6361 6c6c  voking REST call
-00001860: 732e 0a0a 2020 2020 2020 2020 3a70 6172  s...        :par
-00001870: 616d 206d 6574 686f 643a 2052 4553 5420  am method: REST 
-00001880: 6d65 7468 6f64 2028 504f 5354 2c20 4745  method (POST, GE
-00001890: 542c 2050 5554 2e2e 2e29 0a20 2020 2020  T, PUT...).     
-000018a0: 2020 203a 7061 7261 6d20 7061 7468 3a20     :param path: 
-000018b0: 5061 7468 2074 6f20 656e 6470 6f69 6e74  Path to endpoint
-000018c0: 2065 7865 6375 7465 642c 2066 6f72 2065   executed, for e
-000018d0: 7861 6d70 6c65 2060 6022 7072 6f6a 6563  xample ``"projec
-000018e0: 7473 2260 600a 2020 2020 2020 2020 3a70  ts"``.        :p
-000018f0: 6172 616d 2065 7272 6f72 3a20 4572 726f  aram error: Erro
-00001900: 7220 746f 2072 6574 7572 6e20 6966 2041  r to return if A
-00001910: 5049 2069 6e76 6f63 6174 696f 6e20 6661  PI invocation fa
-00001920: 696c 730a 2020 2020 2020 2020 3a70 6172  ils.        :par
-00001930: 616d 2070 6172 616d 733a 2052 6573 7420  am params: Rest 
-00001940: 7061 7261 6d65 7465 7273 2c20 7061 7373  parameters, pass
-00001950: 6564 2061 7320 6120 6469 6374 696f 6e61  ed as a dictiona
-00001960: 7279 3a20 6060 7b22 3c70 6172 616d 2d6e  ry: ``{"<param-n
-00001970: 616d 653e 223a 203c 2270 6172 616d 2d76  ame>": <"param-v
-00001980: 616c 7565 223e 7d60 600a 2020 2020 2020  alue">}``.      
-00001990: 2020 3a70 6172 616d 2062 6f64 793a 2050    :param body: P
-000019a0: 6179 6c6f 6164 2074 6f20 6265 2070 6173  ayload to be pas
-000019b0: 7365 6420 696e 2074 6865 2063 616c 6c2e  sed in the call.
-000019c0: 2049 6620 7573 696e 6720 4a53 4f4e 206f   If using JSON o
-000019d0: 626a 6563 7473 2c20 7072 6566 6572 2075  bjects, prefer u
-000019e0: 7369 6e67 2074 6865 2060 606a 736f 6e60  sing the ``json`
-000019f0: 6020 7061 7261 6d0a 2020 2020 2020 2020  ` param.        
-00001a00: 3a70 6172 616d 206a 736f 6e3a 204a 534f  :param json: JSO
-00001a10: 4e20 7061 796c 6f61 6420 746f 2062 6520  N payload to be 
-00001a20: 7061 7373 6564 2069 6e20 7468 6520 6361  passed in the ca
-00001a30: 6c6c 0a20 2020 2020 2020 203a 7061 7261  ll.        :para
-00001a40: 6d20 6865 6164 6572 733a 2052 4553 5420  m headers: REST 
-00001a50: 6865 6164 6572 732c 2070 6173 7365 6420  headers, passed 
-00001a60: 6173 2061 2064 6963 7469 6f6e 6172 793a  as a dictionary:
-00001a70: 2060 607b 223c 6865 6164 6572 2d6e 616d   ``{"<header-nam
-00001a80: 653e 223a 2022 3c68 6561 6465 722d 7661  e>": "<header-va
-00001a90: 6c75 653e 227d 6060 0a20 2020 2020 2020  lue>"}``.       
-00001aa0: 203a 7061 7261 6d20 7469 6d65 6f75 743a   :param timeout:
-00001ab0: 2041 5049 2063 616c 6c20 7469 6d65 6f75   API call timeou
-00001ac0: 740a 2020 2020 2020 2020 3a70 6172 616d  t.        :param
-00001ad0: 2076 6572 7369 6f6e 3a20 4150 4920 7665   version: API ve
-00001ae0: 7273 696f 6e20 746f 2075 7365 2c20 4e6f  rsion to use, No
-00001af0: 6e65 2028 7468 6520 6465 6661 756c 7429  ne (the default)
-00001b00: 2077 696c 6c20 6d65 616e 2074 6f20 7573   will mean to us
-00001b10: 6520 7468 6520 6465 6661 756c 7420 7661  e the default va
-00001b20: 6c75 6520 6672 6f6d 2063 6f6e 6669 672c  lue from config,
-00001b30: 0a20 2020 2020 2020 2020 666f 7220 756e  .         for un
-00001b40: 2d76 6572 7369 6f6e 6564 2061 7069 2073  -versioned api s
-00001b50: 6574 2061 6e20 656d 7074 7920 7374 7269  et an empty stri
-00001b60: 6e67 2e0a 0a20 2020 2020 2020 203a 7265  ng...        :re
-00001b70: 7475 726e 3a20 5079 7468 6f6e 2048 5454  turn: Python HTT
-00001b80: 5020 7265 7370 6f6e 7365 206f 626a 6563  P response objec
-00001b90: 740a 2020 2020 2020 2020 2222 220a 2020  t.        """.  
-00001ba0: 2020 2020 2020 7572 6c20 3d20 7365 6c66        url = self
-00001bb0: 2e67 6574 5f62 6173 655f 6170 695f 7572  .get_base_api_ur
-00001bc0: 6c28 7061 7468 2c20 7665 7273 696f 6e29  l(path, version)
-00001bd0: 0a20 2020 2020 2020 206b 7720 3d20 7b0a  .        kw = {.
-00001be0: 2020 2020 2020 2020 2020 2020 6b65 793a              key:
-00001bf0: 2076 616c 7565 0a20 2020 2020 2020 2020   value.         
-00001c00: 2020 2066 6f72 206b 6579 2c20 7661 6c75     for key, valu
-00001c10: 6520 696e 2028 0a20 2020 2020 2020 2020  e in (.         
-00001c20: 2020 2020 2020 2028 2270 6172 616d 7322         ("params"
-00001c30: 2c20 7061 7261 6d73 292c 0a20 2020 2020  , params),.     
-00001c40: 2020 2020 2020 2020 2020 2028 2264 6174             ("dat
-00001c50: 6122 2c20 626f 6479 292c 0a20 2020 2020  a", body),.     
-00001c60: 2020 2020 2020 2020 2020 2028 226a 736f             ("jso
-00001c70: 6e22 2c20 6a73 6f6e 292c 0a20 2020 2020  n", json),.     
-00001c80: 2020 2020 2020 2020 2020 2028 2268 6561             ("hea
-00001c90: 6465 7273 222c 2068 6561 6465 7273 292c  ders", headers),
-00001ca0: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-00001cb0: 2020 2020 2020 2020 2020 2069 6620 7661             if va
-00001cc0: 6c75 6520 6973 206e 6f74 204e 6f6e 650a  lue is not None.
-00001cd0: 2020 2020 2020 2020 7d0a 0a20 2020 2020          }..     
-00001ce0: 2020 2069 6620 7365 6c66 2e75 7365 723a     if self.user:
-00001cf0: 0a20 2020 2020 2020 2020 2020 206b 775b  .            kw[
-00001d00: 2261 7574 6822 5d20 3d20 2873 656c 662e  "auth"] = (self.
-00001d10: 7573 6572 2c20 7365 6c66 2e70 6173 7377  user, self.passw
-00001d20: 6f72 6429 0a20 2020 2020 2020 2065 6c69  ord).        eli
-00001d30: 6620 7365 6c66 2e74 6f6b 656e 3a0a 2020  f self.token:.  
-00001d40: 2020 2020 2020 2020 2020 2320 4967 7561            # Igua
-00001d50: 7a69 6f20 6175 7468 2064 6f65 736e 2774  zio auth doesn't
-00001d60: 2073 7570 706f 7274 2070 6173 7369 6e67   support passing
-00001d70: 2074 6f6b 656e 2074 6872 6f75 6768 2062   token through b
-00001d80: 6561 7265 722c 2073 6f20 7573 6520 636f  earer, so use co
-00001d90: 6f6b 6965 2069 6e73 7465 6164 0a20 2020  okie instead.   
-00001da0: 2020 2020 2020 2020 2069 6620 6d6c 7275           if mlru
-00001db0: 6e2e 706c 6174 666f 726d 732e 6967 7561  n.platforms.igua
-00001dc0: 7a69 6f2e 6973 5f69 6775 617a 696f 5f73  zio.is_iguazio_s
-00001dd0: 6573 7369 6f6e 2873 656c 662e 746f 6b65  ession(self.toke
-00001de0: 6e29 3a0a 2020 2020 2020 2020 2020 2020  n):.            
-00001df0: 2020 2020 7365 7373 696f 6e5f 636f 6f6b      session_cook
-00001e00: 6965 203d 2066 276a 3a7b 7b22 7369 6422  ie = f'j:{{"sid"
-00001e10: 3a20 227b 7365 6c66 2e74 6f6b 656e 7d22  : "{self.token}"
-00001e20: 7d7d 270a 2020 2020 2020 2020 2020 2020  }}'.            
-00001e30: 2020 2020 636f 6f6b 6965 7320 3d20 7b0a      cookies = {.
-00001e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001e50: 2020 2020 2273 6573 7369 6f6e 223a 2073      "session": s
-00001e60: 6573 7369 6f6e 5f63 6f6f 6b69 652c 0a20  ession_cookie,. 
-00001e70: 2020 2020 2020 2020 2020 2020 2020 207d                 }
-00001e80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001e90: 206b 775b 2263 6f6f 6b69 6573 225d 203d   kw["cookies"] =
-00001ea0: 2063 6f6f 6b69 6573 0a20 2020 2020 2020   cookies.       
-00001eb0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00001ec0: 2020 2020 2020 2020 2020 2069 6620 2241             if "A
-00001ed0: 7574 686f 7269 7a61 7469 6f6e 2220 6e6f  uthorization" no
-00001ee0: 7420 696e 206b 772e 7365 7464 6566 6175  t in kw.setdefau
-00001ef0: 6c74 2822 6865 6164 6572 7322 2c20 7b7d  lt("headers", {}
-00001f00: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00001f10: 2020 2020 2020 206b 775b 2268 6561 6465         kw["heade
-00001f20: 7273 225d 2e75 7064 6174 6528 7b22 4175  rs"].update({"Au
-00001f30: 7468 6f72 697a 6174 696f 6e22 3a20 2242  thorization": "B
-00001f40: 6561 7265 7220 2220 2b20 7365 6c66 2e74  earer " + self.t
-00001f50: 6f6b 656e 7d29 0a0a 2020 2020 2020 2020  oken})..        
-00001f60: 6966 206d 6c72 756e 2e61 7069 2e73 6368  if mlrun.api.sch
-00001f70: 656d 6173 2e48 6561 6465 724e 616d 6573  emas.HeaderNames
-00001f80: 2e63 6c69 656e 745f 7665 7273 696f 6e20  .client_version 
-00001f90: 6e6f 7420 696e 206b 772e 7365 7464 6566  not in kw.setdef
-00001fa0: 6175 6c74 280a 2020 2020 2020 2020 2020  ault(.          
-00001fb0: 2020 2268 6561 6465 7273 222c 207b 7d0a    "headers", {}.
-00001fc0: 2020 2020 2020 2020 293a 0a20 2020 2020          ):.     
-00001fd0: 2020 2020 2020 206b 775b 2268 6561 6465         kw["heade
-00001fe0: 7273 225d 2e75 7064 6174 6528 0a20 2020  rs"].update(.   
-00001ff0: 2020 2020 2020 2020 2020 2020 207b 6d6c               {ml
-00002000: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
-00002010: 4865 6164 6572 4e61 6d65 732e 636c 6965  HeaderNames.clie
-00002020: 6e74 5f76 6572 7369 6f6e 3a20 7365 6c66  nt_version: self
-00002030: 2e63 6c69 656e 745f 7665 7273 696f 6e7d  .client_version}
-00002040: 0a20 2020 2020 2020 2020 2020 2029 0a0a  .            )..
-00002050: 2020 2020 2020 2020 2320 7265 7175 6573          # reques
-00002060: 7473 206e 6f20 6c6f 6e67 6572 2073 7570  ts no longer sup
-00002070: 706f 7274 7320 6865 6164 6572 2076 616c  ports header val
-00002080: 7565 7320 746f 2062 6520 656e 756d 2028  ues to be enum (
-00002090: 6874 7470 733a 2f2f 6769 7468 7562 2e63  https://github.c
-000020a0: 6f6d 2f70 7366 2f72 6571 7565 7374 732f  om/psf/requests/
-000020b0: 7075 6c6c 2f36 3135 3429 0a20 2020 2020  pull/6154).     
-000020c0: 2020 2023 2063 6f6e 7665 7274 2074 6f20     # convert to 
-000020d0: 7374 7269 6e67 732e 2044 6f20 7468 6520  strings. Do the 
-000020e0: 7361 6d65 2066 6f72 2070 6172 616d 7320  same for params 
-000020f0: 666f 7220 6e69 6365 6e65 7373 0a20 2020  for niceness.   
-00002100: 2020 2020 2066 6f72 2064 6963 745f 2069       for dict_ i
-00002110: 6e20 5b68 6561 6465 7273 2c20 7061 7261  n [headers, para
-00002120: 6d73 5d3a 0a20 2020 2020 2020 2020 2020  ms]:.           
-00002130: 2069 6620 6469 6374 5f20 6973 206e 6f74   if dict_ is not
-00002140: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-00002150: 2020 2020 2020 2066 6f72 206b 6579 2069         for key i
-00002160: 6e20 6469 6374 5f2e 6b65 7973 2829 3a0a  n dict_.keys():.
-00002170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002180: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
-00002190: 6528 6469 6374 5f5b 6b65 795d 2c20 656e  e(dict_[key], en
-000021a0: 756d 2e45 6e75 6d29 3a0a 2020 2020 2020  um.Enum):.      
-000021b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000021c0: 2020 6469 6374 5f5b 6b65 795d 203d 2064    dict_[key] = d
-000021d0: 6963 745f 5b6b 6579 5d2e 7661 6c75 650a  ict_[key].value.
-000021e0: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-000021f0: 7365 6c66 2e73 6573 7369 6f6e 3a0a 2020  self.session:.  
-00002200: 2020 2020 2020 2020 2020 7365 6c66 2e73            self.s
-00002210: 6573 7369 6f6e 203d 206d 6c72 756e 2e75  ession = mlrun.u
-00002220: 7469 6c73 2e48 5454 5053 6573 7369 6f6e  tils.HTTPSession
-00002230: 5769 7468 5265 7472 7928 0a20 2020 2020  WithRetry(.     
-00002240: 2020 2020 2020 2020 2020 2072 6574 7279             retry
-00002250: 5f6f 6e5f 6578 6365 7074 696f 6e3d 636f  _on_exception=co
-00002260: 6e66 6967 2e68 7474 7064 622e 7265 7472  nfig.httpdb.retr
-00002270: 795f 6170 695f 6361 6c6c 5f6f 6e5f 6578  y_api_call_on_ex
-00002280: 6365 7074 696f 6e0a 2020 2020 2020 2020  ception.        
-00002290: 2020 2020 2020 2020 3d3d 206d 6c72 756e          == mlrun
-000022a0: 2e61 7069 2e73 6368 656d 6173 2e48 5454  .api.schemas.HTT
-000022b0: 5053 6573 7369 6f6e 5265 7472 794d 6f64  PSessionRetryMod
-000022c0: 652e 656e 6162 6c65 642e 7661 6c75 650a  e.enabled.value.
-000022d0: 2020 2020 2020 2020 2020 2020 290a 0a20              ).. 
-000022e0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-000022f0: 2020 2020 2020 2020 7265 7370 6f6e 7365          response
-00002300: 203d 2073 656c 662e 7365 7373 696f 6e2e   = self.session.
-00002310: 7265 7175 6573 7428 0a20 2020 2020 2020  request(.       
-00002320: 2020 2020 2020 2020 206d 6574 686f 642c           method,
-00002330: 2075 726c 2c20 7469 6d65 6f75 743d 7469   url, timeout=ti
-00002340: 6d65 6f75 742c 2076 6572 6966 793d 4661  meout, verify=Fa
-00002350: 6c73 652c 202a 2a6b 770a 2020 2020 2020  lse, **kw.      
-00002360: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-00002370: 6578 6365 7074 2072 6571 7565 7374 732e  except requests.
-00002380: 5265 7175 6573 7445 7863 6570 7469 6f6e  RequestException
-00002390: 2061 7320 6578 633a 0a20 2020 2020 2020   as exc:.       
-000023a0: 2020 2020 2065 7272 6f72 203d 2066 227b       error = f"{
-000023b0: 6572 725f 746f 5f73 7472 2865 7863 297d  err_to_str(exc)}
-000023c0: 3a20 7b65 7272 6f72 7d22 2069 6620 6572  : {error}" if er
-000023d0: 726f 7220 656c 7365 2065 7272 5f74 6f5f  ror else err_to_
-000023e0: 7374 7228 6578 6329 0a20 2020 2020 2020  str(exc).       
-000023f0: 2020 2020 2072 6169 7365 206d 6c72 756e       raise mlrun
-00002400: 2e65 7272 6f72 732e 4d4c 5275 6e52 756e  .errors.MLRunRun
-00002410: 7469 6d65 4572 726f 7228 6572 726f 7229  timeError(error)
-00002420: 2066 726f 6d20 6578 630a 0a20 2020 2020   from exc..     
-00002430: 2020 2069 6620 6e6f 7420 7265 7370 6f6e     if not respon
-00002440: 7365 2e6f 6b3a 0a20 2020 2020 2020 2020  se.ok:.         
-00002450: 2020 2069 6620 7265 7370 6f6e 7365 2e63     if response.c
-00002460: 6f6e 7465 6e74 3a0a 2020 2020 2020 2020  ontent:.        
-00002470: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
-00002480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002490: 2064 6174 6120 3d20 7265 7370 6f6e 7365   data = response
-000024a0: 2e6a 736f 6e28 290a 2020 2020 2020 2020  .json().        
-000024b0: 2020 2020 2020 2020 2020 2020 6572 726f              erro
-000024c0: 725f 6465 7461 696c 7320 3d20 6461 7461  r_details = data
-000024d0: 2e67 6574 2822 6465 7461 696c 222c 207b  .get("detail", {
-000024e0: 7d29 0a20 2020 2020 2020 2020 2020 2020  }).             
-000024f0: 2020 2020 2020 2069 6620 6e6f 7420 6572         if not er
-00002500: 726f 725f 6465 7461 696c 733a 0a20 2020  ror_details:.   
-00002510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002520: 2020 2020 206c 6f67 6765 722e 7761 726e       logger.warn
-00002530: 696e 6728 2246 6169 6c65 6420 7061 7273  ing("Failed pars
-00002540: 696e 6720 6572 726f 7220 7265 7370 6f6e  ing error respon
-00002550: 7365 2062 6f64 7922 2c20 6461 7461 3d64  se body", data=d
-00002560: 6174 6129 0a20 2020 2020 2020 2020 2020  ata).           
-00002570: 2020 2020 2065 7863 6570 7420 4578 6365       except Exce
-00002580: 7074 696f 6e3a 0a20 2020 2020 2020 2020  ption:.         
-00002590: 2020 2020 2020 2020 2020 2065 7272 6f72             error
-000025a0: 5f64 6574 6169 6c73 203d 2022 220a 2020  _details = "".  
-000025b0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-000025c0: 2065 7272 6f72 5f64 6574 6169 6c73 3a0a   error_details:.
-000025d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025e0: 2020 2020 6572 726f 725f 6465 7461 696c      error_detail
-000025f0: 7320 3d20 6622 6465 7461 696c 733a 207b  s = f"details: {
-00002600: 6572 726f 725f 6465 7461 696c 737d 220a  error_details}".
-00002610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002620: 2020 2020 6572 726f 7220 3d20 6622 7b65      error = f"{e
-00002630: 7272 6f72 7d20 7b65 7272 6f72 5f64 6574  rror} {error_det
-00002640: 6169 6c73 7d22 2069 6620 6572 726f 7220  ails}" if error 
-00002650: 656c 7365 2065 7272 6f72 5f64 6574 6169  else error_detai
-00002660: 6c73 0a20 2020 2020 2020 2020 2020 2020  ls.             
-00002670: 2020 2020 2020 206d 6c72 756e 2e65 7272         mlrun.err
-00002680: 6f72 732e 7261 6973 655f 666f 725f 7374  ors.raise_for_st
-00002690: 6174 7573 2872 6573 706f 6e73 652c 2065  atus(response, e
-000026a0: 7272 6f72 290a 0a20 2020 2020 2020 2020  rror)..         
-000026b0: 2020 206d 6c72 756e 2e65 7272 6f72 732e     mlrun.errors.
-000026c0: 7261 6973 655f 666f 725f 7374 6174 7573  raise_for_status
-000026d0: 2872 6573 706f 6e73 652c 2065 7272 6f72  (response, error
-000026e0: 290a 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-000026f0: 6e20 7265 7370 6f6e 7365 0a0a 2020 2020  n response..    
-00002700: 6465 6620 5f70 6174 685f 6f66 2873 656c  def _path_of(sel
-00002710: 662c 2070 7265 6669 782c 2070 726f 6a65  f, prefix, proje
-00002720: 6374 2c20 7569 6429 3a0a 2020 2020 2020  ct, uid):.      
-00002730: 2020 7072 6f6a 6563 7420 3d20 7072 6f6a    project = proj
-00002740: 6563 7420 6f72 2063 6f6e 6669 672e 6465  ect or config.de
-00002750: 6661 756c 745f 7072 6f6a 6563 740a 2020  fault_project.  
-00002760: 2020 2020 2020 7265 7475 726e 2066 227b        return f"{
-00002770: 7072 6566 6978 7d2f 7b70 726f 6a65 6374  prefix}/{project
-00002780: 7d2f 7b75 6964 7d22 0a0a 2020 2020 6465  }/{uid}"..    de
-00002790: 6620 636f 6e6e 6563 7428 7365 6c66 2c20  f connect(self, 
-000027a0: 7365 6372 6574 733d 4e6f 6e65 293a 0a20  secrets=None):. 
-000027b0: 2020 2020 2020 2022 2222 436f 6e6e 6563         """Connec
-000027c0: 7420 746f 2074 6865 204d 4c52 756e 2041  t to the MLRun A
-000027d0: 5049 2073 6572 7665 722e 204d 7573 7420  PI server. Must 
-000027e0: 6265 2063 616c 6c65 6420 7072 696f 7220  be called prior 
-000027f0: 746f 2065 7865 6375 7469 6e67 2061 6e79  to executing any
-00002800: 206f 7468 6572 206d 6574 686f 642e 0a20   other method.. 
-00002810: 2020 2020 2020 2054 6865 2063 6f64 6520         The code 
-00002820: 7574 696c 697a 6573 2074 6865 2055 524c  utilizes the URL
-00002830: 2066 6f72 2074 6865 2041 5049 2073 6572   for the API ser
-00002840: 7665 7220 6672 6f6d 2074 6865 2063 6f6e  ver from the con
-00002850: 6669 6775 7261 7469 6f6e 202d 2060 606d  figuration - ``m
-00002860: 6c63 6f6e 662e 6462 7061 7468 6060 2e0a  lconf.dbpath``..
-00002870: 0a20 2020 2020 2020 2046 6f72 2065 7861  .        For exa
-00002880: 6d70 6c65 3a3a 0a0a 2020 2020 2020 2020  mple::..        
-00002890: 2020 2020 6d6c 636f 6e66 2e64 6270 6174      mlconf.dbpat
-000028a0: 6820 3d20 6d6c 636f 6e66 2e64 6270 6174  h = mlconf.dbpat
-000028b0: 6820 6f72 2027 6874 7470 3a2f 2f6d 6c72  h or 'http://mlr
-000028c0: 756e 2d61 7069 3a38 3038 3027 0a20 2020  un-api:8080'.   
-000028d0: 2020 2020 2020 2020 2064 6220 3d20 6765           db = ge
-000028e0: 745f 7275 6e5f 6462 2829 2e63 6f6e 6e65  t_run_db().conne
-000028f0: 6374 2829 0a20 2020 2020 2020 2022 2222  ct().        """
-00002900: 0a20 2020 2020 2020 2023 2068 6163 6b20  .        # hack 
-00002910: 746f 2061 6c6c 6f77 2075 6e69 7420 7465  to allow unit te
-00002920: 7374 7320 746f 2069 6e73 7461 6e74 6961  sts to instantia
-00002930: 7465 2048 5454 5052 756e 4442 2077 6974  te HTTPRunDB wit
-00002940: 686f 7574 2061 2072 6561 6c20 7365 7276  hout a real serv
-00002950: 6572 2062 6568 696e 640a 2020 2020 2020  er behind.      
-00002960: 2020 6966 2022 6d6f 636b 2d73 6572 7665    if "mock-serve
-00002970: 7222 2069 6e20 7365 6c66 2e62 6173 655f  r" in self.base_
-00002980: 7572 6c3a 0a20 2020 2020 2020 2020 2020  url:.           
-00002990: 2072 6574 7572 6e0a 2020 2020 2020 2020   return.        
-000029a0: 7265 7370 203d 2073 656c 662e 6170 695f  resp = self.api_
-000029b0: 6361 6c6c 2822 4745 5422 2c20 2263 6c69  call("GET", "cli
-000029c0: 656e 742d 7370 6563 222c 2074 696d 656f  ent-spec", timeo
-000029d0: 7574 3d35 290a 2020 2020 2020 2020 7472  ut=5).        tr
-000029e0: 793a 0a20 2020 2020 2020 2020 2020 2073  y:.            s
-000029f0: 6572 7665 725f 6366 6720 3d20 7265 7370  erver_cfg = resp
-00002a00: 2e6a 736f 6e28 290a 2020 2020 2020 2020  .json().        
-00002a10: 2020 2020 7365 6c66 2e73 6572 7665 725f      self.server_
-00002a20: 7665 7273 696f 6e20 3d20 7365 7276 6572  version = server
-00002a30: 5f63 6667 5b22 7665 7273 696f 6e22 5d0a  _cfg["version"].
-00002a40: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00002a50: 2e5f 7661 6c69 6461 7465 5f76 6572 7369  ._validate_versi
-00002a60: 6f6e 5f63 6f6d 7061 7469 6269 6c69 7479  on_compatibility
-00002a70: 2873 656c 662e 7365 7276 6572 5f76 6572  (self.server_ver
-00002a80: 7369 6f6e 2c20 636f 6e66 6967 2e76 6572  sion, config.ver
-00002a90: 7369 6f6e 290a 2020 2020 2020 2020 2020  sion).          
-00002aa0: 2020 636f 6e66 6967 2e6e 616d 6573 7061    config.namespa
-00002ab0: 6365 203d 2063 6f6e 6669 672e 6e61 6d65  ce = config.name
-00002ac0: 7370 6163 6520 6f72 2073 6572 7665 725f  space or server_
-00002ad0: 6366 672e 6765 7428 226e 616d 6573 7061  cfg.get("namespa
-00002ae0: 6365 2229 0a20 2020 2020 2020 2020 2020  ce").           
-00002af0: 2069 6620 280a 2020 2020 2020 2020 2020   if (.          
-00002b00: 2020 2020 2020 226e 616d 6573 7061 6365        "namespace
-00002b10: 2220 696e 2073 6572 7665 725f 6366 670a  " in server_cfg.
-00002b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b30: 616e 6420 7365 7276 6572 5f63 6667 5b22  and server_cfg["
-00002b40: 6e61 6d65 7370 6163 6522 5d20 213d 2063  namespace"] != c
-00002b50: 6f6e 6669 672e 6e61 6d65 7370 6163 650a  onfig.namespace.
-00002b60: 2020 2020 2020 2020 2020 2020 293a 0a20              ):. 
-00002b70: 2020 2020 2020 2020 2020 2020 2020 206c                 l
-00002b80: 6f67 6765 722e 7761 726e 696e 6728 0a20  ogger.warning(. 
-00002b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ba0: 2020 2066 2277 6172 6e69 6e67 212c 2073     f"warning!, s
-00002bb0: 6572 7665 7220 287b 7365 7276 6572 5f63  erver ({server_c
-00002bc0: 6667 5b27 6e61 6d65 7370 6163 6527 5d7d  fg['namespace']}
-00002bd0: 2920 616e 6420 636c 6965 6e74 2028 7b63  ) and client ({c
-00002be0: 6f6e 6669 672e 6e61 6d65 7370 6163 657d  onfig.namespace}
-00002bf0: 2922 0a20 2020 2020 2020 2020 2020 2020  )".             
-00002c00: 2020 2020 2020 2022 206e 616d 6573 7061         " namespa
-00002c10: 6365 2064 6f6e 2774 206d 6174 6368 220a  ce don't match".
-00002c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c30: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-00002c40: 2063 6f6e 6669 672e 6365 2e6d 6f64 6520   config.ce.mode 
-00002c50: 616e 6420 636f 6e66 6967 2e63 652e 6d6f  and config.ce.mo
-00002c60: 6465 2021 3d20 7365 7276 6572 5f63 6667  de != server_cfg
-00002c70: 2e67 6574 2822 6365 5f6d 6f64 6522 2c20  .get("ce_mode", 
-00002c80: 2222 293a 0a20 2020 2020 2020 2020 2020  ""):.           
-00002c90: 2020 2020 206c 6f67 6765 722e 7761 726e       logger.warn
-00002ca0: 696e 6728 0a20 2020 2020 2020 2020 2020  ing(.           
-00002cb0: 2020 2020 2020 2020 2066 2277 6172 6e69           f"warni
-00002cc0: 6e67 212c 2073 6572 7665 7220 287b 7365  ng!, server ({se
-00002cd0: 7276 6572 5f63 6667 5b27 6365 5f6d 6f64  rver_cfg['ce_mod
-00002ce0: 6527 5d7d 2920 616e 6420 636c 6965 6e74  e']}) and client
-00002cf0: 2028 7b63 6f6e 6669 672e 6365 2e6d 6f64   ({config.ce.mod
-00002d00: 657d 2922 0a20 2020 2020 2020 2020 2020  e})".           
-00002d10: 2020 2020 2020 2020 2022 2043 4520 6d6f           " CE mo
-00002d20: 6465 2064 6f6e 2774 206d 6174 6368 220a  de don't match".
-00002d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d40: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
-00002d50: 6e66 6967 2e63 6520 3d20 7365 7276 6572  nfig.ce = server
-00002d60: 5f63 6667 2e67 6574 2822 6365 2229 206f  _cfg.get("ce") o
-00002d70: 7220 636f 6e66 6967 2e63 650a 0a20 2020  r config.ce..   
-00002d80: 2020 2020 2020 2020 2023 2067 6574 2064           # get d
-00002d90: 6566 6175 6c74 7320 6672 6f6d 2072 656d  efaults from rem
-00002da0: 6f74 6520 7365 7276 6572 0a20 2020 2020  ote server.     
-00002db0: 2020 2020 2020 2063 6f6e 6669 672e 7265         config.re
-00002dc0: 6d6f 7465 5f68 6f73 7420 3d20 636f 6e66  mote_host = conf
-00002dd0: 6967 2e72 656d 6f74 655f 686f 7374 206f  ig.remote_host o
-00002de0: 7220 7365 7276 6572 5f63 6667 2e67 6574  r server_cfg.get
-00002df0: 2822 7265 6d6f 7465 5f68 6f73 7422 290a  ("remote_host").
-00002e00: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
-00002e10: 6967 2e6d 7069 6a6f 625f 6372 645f 7665  ig.mpijob_crd_ve
-00002e20: 7273 696f 6e20 3d20 636f 6e66 6967 2e6d  rsion = config.m
-00002e30: 7069 6a6f 625f 6372 645f 7665 7273 696f  pijob_crd_versio
-00002e40: 6e20 6f72 2073 6572 7665 725f 6366 672e  n or server_cfg.
-00002e50: 6765 7428 0a20 2020 2020 2020 2020 2020  get(.           
-00002e60: 2020 2020 2022 6d70 696a 6f62 5f63 7264       "mpijob_crd
-00002e70: 5f76 6572 7369 6f6e 220a 2020 2020 2020  _version".      
-00002e80: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-00002e90: 2020 2020 636f 6e66 6967 2e75 692e 7572      config.ui.ur
-00002ea0: 6c20 3d20 636f 6e66 6967 2e72 6573 6f6c  l = config.resol
-00002eb0: 7665 5f75 695f 7572 6c28 2920 6f72 2073  ve_ui_url() or s
-00002ec0: 6572 7665 725f 6366 672e 6765 7428 2275  erver_cfg.get("u
-00002ed0: 695f 7572 6c22 290a 2020 2020 2020 2020  i_url").        
-00002ee0: 2020 2020 636f 6e66 6967 2e61 7274 6966      config.artif
-00002ef0: 6163 745f 7061 7468 203d 2063 6f6e 6669  act_path = confi
-00002f00: 672e 6172 7469 6661 6374 5f70 6174 6820  g.artifact_path 
-00002f10: 6f72 2073 6572 7665 725f 6366 672e 6765  or server_cfg.ge
-00002f20: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-00002f30: 2020 2022 6172 7469 6661 6374 5f70 6174     "artifact_pat
-00002f40: 6822 0a20 2020 2020 2020 2020 2020 2029  h".            )
-00002f50: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00002f60: 6669 672e 6665 6174 7572 655f 7374 6f72  fig.feature_stor
-00002f70: 652e 6461 7461 5f70 7265 6669 7865 7320  e.data_prefixes 
-00002f80: 3d20 280a 2020 2020 2020 2020 2020 2020  = (.            
-00002f90: 2020 2020 636f 6e66 6967 2e66 6561 7475      config.featu
-00002fa0: 7265 5f73 746f 7265 2e64 6174 615f 7072  re_store.data_pr
-00002fb0: 6566 6978 6573 0a20 2020 2020 2020 2020  efixes.         
-00002fc0: 2020 2020 2020 206f 7220 7365 7276 6572         or server
-00002fd0: 5f63 6667 2e67 6574 2822 6665 6174 7572  _cfg.get("featur
-00002fe0: 655f 7374 6f72 655f 6461 7461 5f70 7265  e_store_data_pre
-00002ff0: 6669 7865 7322 290a 2020 2020 2020 2020  fixes").        
-00003000: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-00003010: 2020 636f 6e66 6967 2e73 7061 726b 5f61    config.spark_a
-00003020: 7070 5f69 6d61 6765 203d 2063 6f6e 6669  pp_image = confi
-00003030: 672e 7370 6172 6b5f 6170 705f 696d 6167  g.spark_app_imag
-00003040: 6520 6f72 2073 6572 7665 725f 6366 672e  e or server_cfg.
-00003050: 6765 7428 0a20 2020 2020 2020 2020 2020  get(.           
-00003060: 2020 2020 2022 7370 6172 6b5f 6170 705f       "spark_app_
-00003070: 696d 6167 6522 0a20 2020 2020 2020 2020  image".         
-00003080: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
-00003090: 2063 6f6e 6669 672e 7370 6172 6b5f 6170   config.spark_ap
-000030a0: 705f 696d 6167 655f 7461 6720 3d20 636f  p_image_tag = co
-000030b0: 6e66 6967 2e73 7061 726b 5f61 7070 5f69  nfig.spark_app_i
-000030c0: 6d61 6765 5f74 6167 206f 7220 7365 7276  mage_tag or serv
-000030d0: 6572 5f63 6667 2e67 6574 280a 2020 2020  er_cfg.get(.    
-000030e0: 2020 2020 2020 2020 2020 2020 2273 7061              "spa
-000030f0: 726b 5f61 7070 5f69 6d61 6765 5f74 6167  rk_app_image_tag
-00003100: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
-00003110: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
-00003120: 6967 2e73 7061 726b 5f68 6973 746f 7279  ig.spark_history
-00003130: 5f73 6572 7665 725f 7061 7468 203d 2028  _server_path = (
-00003140: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003150: 2063 6f6e 6669 672e 7370 6172 6b5f 6869   config.spark_hi
-00003160: 7374 6f72 795f 7365 7276 6572 5f70 6174  story_server_pat
-00003170: 680a 2020 2020 2020 2020 2020 2020 2020  h.              
-00003180: 2020 6f72 2073 6572 7665 725f 6366 672e    or server_cfg.
-00003190: 6765 7428 2273 7061 726b 5f68 6973 746f  get("spark_histo
-000031a0: 7279 5f73 6572 7665 725f 7061 7468 2229  ry_server_path")
-000031b0: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-000031c0: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
-000031d0: 672e 6874 7470 6462 2e62 7569 6c64 6572  g.httpdb.builder
-000031e0: 2e64 6f63 6b65 725f 7265 6769 7374 7279  .docker_registry
-000031f0: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
-00003200: 2020 2020 2063 6f6e 6669 672e 6874 7470       config.http
-00003210: 6462 2e62 7569 6c64 6572 2e64 6f63 6b65  db.builder.docke
-00003220: 725f 7265 6769 7374 7279 0a20 2020 2020  r_registry.     
-00003230: 2020 2020 2020 2020 2020 206f 7220 7365             or se
-00003240: 7276 6572 5f63 6667 2e67 6574 2822 646f  rver_cfg.get("do
-00003250: 636b 6572 5f72 6567 6973 7472 7922 290a  cker_registry").
-00003260: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-00003270: 2020 2020 2020 2020 2020 636f 6e66 6967            config
-00003280: 2e68 7474 7064 622e 6170 695f 7572 6c20  .httpdb.api_url 
-00003290: 3d20 636f 6e66 6967 2e68 7474 7064 622e  = config.httpdb.
-000032a0: 6170 695f 7572 6c20 6f72 2073 6572 7665  api_url or serve
-000032b0: 725f 6366 672e 6765 7428 2261 7069 5f75  r_cfg.get("api_u
-000032c0: 726c 2229 0a20 2020 2020 2020 2020 2020  rl").           
-000032d0: 2063 6f6e 6669 672e 6e75 636c 696f 5f76   config.nuclio_v
-000032e0: 6572 7369 6f6e 203d 2063 6f6e 6669 672e  ersion = config.
-000032f0: 6e75 636c 696f 5f76 6572 7369 6f6e 206f  nuclio_version o
-00003300: 7220 7365 7276 6572 5f63 6667 2e67 6574  r server_cfg.get
-00003310: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00003320: 2020 226e 7563 6c69 6f5f 7665 7273 696f    "nuclio_versio
-00003330: 6e22 0a20 2020 2020 2020 2020 2020 2029  n".            )
-00003340: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00003350: 6669 672e 6465 6661 756c 745f 6675 6e63  fig.default_func
-00003360: 7469 6f6e 5f70 7269 6f72 6974 795f 636c  tion_priority_cl
-00003370: 6173 735f 6e61 6d65 203d 2028 0a20 2020  ass_name = (.   
-00003380: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
-00003390: 6669 672e 6465 6661 756c 745f 6675 6e63  fig.default_func
-000033a0: 7469 6f6e 5f70 7269 6f72 6974 795f 636c  tion_priority_cl
-000033b0: 6173 735f 6e61 6d65 0a20 2020 2020 2020  ass_name.       
-000033c0: 2020 2020 2020 2020 206f 7220 7365 7276           or serv
-000033d0: 6572 5f63 6667 2e67 6574 2822 6465 6661  er_cfg.get("defa
-000033e0: 756c 745f 6675 6e63 7469 6f6e 5f70 7269  ult_function_pri
-000033f0: 6f72 6974 795f 636c 6173 735f 6e61 6d65  ority_class_name
-00003400: 2229 0a20 2020 2020 2020 2020 2020 2029  ").            )
-00003410: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00003420: 6669 672e 7661 6c69 645f 6675 6e63 7469  fig.valid_functi
-00003430: 6f6e 5f70 7269 6f72 6974 795f 636c 6173  on_priority_clas
-00003440: 735f 6e61 6d65 7320 3d20 280a 2020 2020  s_names = (.    
-00003450: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
-00003460: 6967 2e76 616c 6964 5f66 756e 6374 696f  ig.valid_functio
-00003470: 6e5f 7072 696f 7269 7479 5f63 6c61 7373  n_priority_class
-00003480: 5f6e 616d 6573 0a20 2020 2020 2020 2020  _names.         
-00003490: 2020 2020 2020 206f 7220 7365 7276 6572         or server
-000034a0: 5f63 6667 2e67 6574 2822 7661 6c69 645f  _cfg.get("valid_
-000034b0: 6675 6e63 7469 6f6e 5f70 7269 6f72 6974  function_priorit
-000034c0: 795f 636c 6173 735f 6e61 6d65 7322 290a  y_class_names").
-000034d0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-000034e0: 2020 2020 2020 2020 2020 636f 6e66 6967            config
-000034f0: 2e61 7274 6966 6163 7473 2e63 616c 6375  .artifacts.calcu
-00003500: 6c61 7465 5f68 6173 6820 3d20 280a 2020  late_hash = (.  
-00003510: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00003520: 6e66 6967 2e61 7274 6966 6163 7473 2e63  nfig.artifacts.c
-00003530: 616c 6375 6c61 7465 5f68 6173 680a 2020  alculate_hash.  
-00003540: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00003550: 2063 6f6e 6669 672e 6172 7469 6661 6374   config.artifact
-00003560: 732e 6361 6c63 756c 6174 655f 6861 7368  s.calculate_hash
-00003570: 2069 7320 6e6f 7420 4e6f 6e65 0a20 2020   is not None.   
-00003580: 2020 2020 2020 2020 2020 2020 2065 6c73               els
-00003590: 6520 7365 7276 6572 5f63 6667 2e67 6574  e server_cfg.get
-000035a0: 2822 6361 6c63 756c 6174 655f 6172 7469  ("calculate_arti
-000035b0: 6661 6374 5f68 6173 6822 290a 2020 2020  fact_hash").    
-000035c0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-000035d0: 2020 2020 2020 636f 6e66 6967 2e61 7274        config.art
-000035e0: 6966 6163 7473 2e67 656e 6572 6174 655f  ifacts.generate_
-000035f0: 7461 7267 6574 5f70 6174 685f 6672 6f6d  target_path_from
-00003600: 5f61 7274 6966 6163 745f 6861 7368 203d  _artifact_hash =
-00003610: 2028 0a20 2020 2020 2020 2020 2020 2020   (.             
-00003620: 2020 2063 6f6e 6669 672e 6172 7469 6661     config.artifa
-00003630: 6374 732e 6765 6e65 7261 7465 5f74 6172  cts.generate_tar
-00003640: 6765 745f 7061 7468 5f66 726f 6d5f 6172  get_path_from_ar
-00003650: 7469 6661 6374 5f68 6173 680a 2020 2020  tifact_hash.    
-00003660: 2020 2020 2020 2020 2020 2020 6966 2063              if c
-00003670: 6f6e 6669 672e 6172 7469 6661 6374 732e  onfig.artifacts.
-00003680: 6765 6e65 7261 7465 5f74 6172 6765 745f  generate_target_
-00003690: 7061 7468 5f66 726f 6d5f 6172 7469 6661  path_from_artifa
-000036a0: 6374 5f68 6173 6820 6973 206e 6f74 204e  ct_hash is not N
-000036b0: 6f6e 650a 2020 2020 2020 2020 2020 2020  one.            
-000036c0: 2020 2020 656c 7365 2073 6572 7665 725f      else server_
-000036d0: 6366 672e 6765 7428 2267 656e 6572 6174  cfg.get("generat
-000036e0: 655f 6172 7469 6661 6374 5f74 6172 6765  e_artifact_targe
-000036f0: 745f 7061 7468 5f66 726f 6d5f 6172 7469  t_path_from_arti
-00003700: 6661 6374 5f68 6173 6822 290a 2020 2020  fact_hash").    
-00003710: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
-00003720: 2020 2020 2020 2063 6f6e 6669 672e 7265         config.re
-00003730: 6469 732e 7572 6c20 3d20 636f 6e66 6967  dis.url = config
-00003740: 2e72 6564 6973 2e75 726c 206f 7220 7365  .redis.url or se
-00003750: 7276 6572 5f63 6667 2e67 6574 2822 7265  rver_cfg.get("re
-00003760: 6469 735f 7572 6c22 290a 2020 2020 2020  dis_url").      
-00003770: 2020 2020 2020 2320 616c 6c6f 7720 636c        # allow cl
-00003780: 6965 6e74 2074 6f20 7365 7420 7468 6520  ient to set the 
-00003790: 6465 6661 756c 7420 7061 7274 6961 6c20  default partial 
-000037a0: 5741 2066 6f72 206c 6163 6b20 6f66 2073  WA for lack of s
-000037b0: 7570 706f 7274 206f 6620 7065 722d 7461  upport of per-ta
-000037c0: 7267 6574 2061 7578 696c 6961 7279 206f  rget auxiliary o
-000037d0: 7074 696f 6e73 0a20 2020 2020 2020 2020  ptions.         
-000037e0: 2020 2063 6f6e 6669 672e 7265 6469 732e     config.redis.
-000037f0: 7479 7065 203d 2063 6f6e 6669 672e 7265  type = config.re
-00003800: 6469 732e 7479 7065 206f 7220 7365 7276  dis.type or serv
-00003810: 6572 5f63 6667 2e67 6574 2822 7265 6469  er_cfg.get("redi
-00003820: 735f 7479 7065 2229 0a0a 2020 2020 2020  s_type")..      
-00003830: 2020 2020 2020 2320 5468 6573 6520 6861        # These ha
-00003840: 7665 2061 2064 6566 6175 6c74 2076 616c  ve a default val
-00003850: 7565 2c20 7468 6572 6566 6f72 6520 6c6f  ue, therefore lo
-00003860: 6361 6c20 636f 6e66 6967 2077 696c 6c20  cal config will 
-00003870: 616c 7761 7973 2068 6176 6520 6120 7661  always have a va
-00003880: 6c75 652c 2070 7269 6f72 6974 697a 6520  lue, prioritize 
-00003890: 7468 650a 2020 2020 2020 2020 2020 2020  the.            
-000038a0: 2320 4150 4920 7661 6c75 6520 6669 7273  # API value firs
-000038b0: 740a 2020 2020 2020 2020 2020 2020 636f  t.            co
-000038c0: 6e66 6967 2e75 692e 7072 6f6a 6563 7473  nfig.ui.projects
-000038d0: 5f70 7265 6669 7820 3d20 280a 2020 2020  _prefix = (.    
-000038e0: 2020 2020 2020 2020 2020 2020 7365 7276              serv
-000038f0: 6572 5f63 6667 2e67 6574 2822 7569 5f70  er_cfg.get("ui_p
-00003900: 726f 6a65 6374 735f 7072 6566 6978 2229  rojects_prefix")
-00003910: 206f 7220 636f 6e66 6967 2e75 692e 7072   or config.ui.pr
-00003920: 6f6a 6563 7473 5f70 7265 6669 780a 2020  ojects_prefix.  
-00003930: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
-00003940: 2020 2020 2020 2020 636f 6e66 6967 2e6b          config.k
-00003950: 6670 5f69 6d61 6765 203d 2073 6572 7665  fp_image = serve
-00003960: 725f 6366 672e 6765 7428 226b 6670 5f69  r_cfg.get("kfp_i
-00003970: 6d61 6765 2229 206f 7220 636f 6e66 6967  mage") or config
-00003980: 2e6b 6670 5f69 6d61 6765 0a20 2020 2020  .kfp_image.     
-00003990: 2020 2020 2020 2063 6f6e 6669 672e 6b66         config.kf
-000039a0: 705f 7572 6c20 3d20 7365 7276 6572 5f63  p_url = server_c
-000039b0: 6667 2e67 6574 2822 6b66 705f 7572 6c22  fg.get("kfp_url"
-000039c0: 2920 6f72 2063 6f6e 6669 672e 6b66 705f  ) or config.kfp_
-000039d0: 7572 6c0a 2020 2020 2020 2020 2020 2020  url.            
-000039e0: 636f 6e66 6967 2e64 6173 6b5f 6b66 705f  config.dask_kfp_
-000039f0: 696d 6167 6520 3d20 280a 2020 2020 2020  image = (.      
-00003a00: 2020 2020 2020 2020 2020 7365 7276 6572            server
-00003a10: 5f63 6667 2e67 6574 2822 6461 736b 5f6b  _cfg.get("dask_k
-00003a20: 6670 5f69 6d61 6765 2229 206f 7220 636f  fp_image") or co
-00003a30: 6e66 6967 2e64 6173 6b5f 6b66 705f 696d  nfig.dask_kfp_im
-00003a40: 6167 650a 2020 2020 2020 2020 2020 2020  age.            
-00003a50: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
-00003a60: 6e66 6967 2e73 6372 6170 655f 6d65 7472  nfig.scrape_metr
-00003a70: 6963 7320 3d20 280a 2020 2020 2020 2020  ics = (.        
-00003a80: 2020 2020 2020 2020 7365 7276 6572 5f63          server_c
-00003a90: 6667 2e67 6574 2822 7363 7261 7065 5f6d  fg.get("scrape_m
-00003aa0: 6574 7269 6373 2229 0a20 2020 2020 2020  etrics").       
-00003ab0: 2020 2020 2020 2020 2069 6620 7365 7276           if serv
-00003ac0: 6572 5f63 6667 2e67 6574 2822 7363 7261  er_cfg.get("scra
-00003ad0: 7065 5f6d 6574 7269 6373 2229 2069 7320  pe_metrics") is 
-00003ae0: 6e6f 7420 4e6f 6e65 0a20 2020 2020 2020  not None.       
-00003af0: 2020 2020 2020 2020 2065 6c73 6520 636f           else co
-00003b00: 6e66 6967 2e73 6372 6170 655f 6d65 7472  nfig.scrape_metr
-00003b10: 6963 730a 2020 2020 2020 2020 2020 2020  ics.            
-00003b20: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
-00003b30: 6e66 6967 2e68 7562 5f75 726c 203d 2073  nfig.hub_url = s
-00003b40: 6572 7665 725f 6366 672e 6765 7428 2268  erver_cfg.get("h
-00003b50: 7562 5f75 726c 2229 206f 7220 636f 6e66  ub_url") or conf
-00003b60: 6967 2e68 7562 5f75 726c 0a20 2020 2020  ig.hub_url.     
-00003b70: 2020 2020 2020 2063 6f6e 6669 672e 6465         config.de
-00003b80: 6661 756c 745f 6675 6e63 7469 6f6e 5f6e  fault_function_n
-00003b90: 6f64 655f 7365 6c65 6374 6f72 203d 2028  ode_selector = (
-00003ba0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003bb0: 2073 6572 7665 725f 6366 672e 6765 7428   server_cfg.get(
-00003bc0: 2264 6566 6175 6c74 5f66 756e 6374 696f  "default_functio
-00003bd0: 6e5f 6e6f 6465 5f73 656c 6563 746f 7222  n_node_selector"
-00003be0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00003bf0: 2020 6f72 2063 6f6e 6669 672e 6465 6661    or config.defa
-00003c00: 756c 745f 6675 6e63 7469 6f6e 5f6e 6f64  ult_function_nod
-00003c10: 655f 7365 6c65 6374 6f72 0a20 2020 2020  e_selector.     
-00003c20: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-00003c30: 2020 2020 2063 6f6e 6669 672e 6967 7a5f       config.igz_
-00003c40: 7665 7273 696f 6e20 3d20 7365 7276 6572  version = server
-00003c50: 5f63 6667 2e67 6574 2822 6967 7a5f 7665  _cfg.get("igz_ve
-00003c60: 7273 696f 6e22 2920 6f72 2063 6f6e 6669  rsion") or confi
-00003c70: 672e 6967 7a5f 7665 7273 696f 6e0a 2020  g.igz_version.  
-00003c80: 2020 2020 2020 2020 2020 636f 6e66 6967            config
-00003c90: 2e73 746f 7261 6765 2e61 7574 6f5f 6d6f  .storage.auto_mo
-00003ca0: 756e 745f 7479 7065 203d 2028 0a20 2020  unt_type = (.   
-00003cb0: 2020 2020 2020 2020 2020 2020 2073 6572               ser
-00003cc0: 7665 725f 6366 672e 6765 7428 2261 7574  ver_cfg.get("aut
-00003cd0: 6f5f 6d6f 756e 745f 7479 7065 2229 206f  o_mount_type") o
-00003ce0: 7220 636f 6e66 6967 2e73 746f 7261 6765  r config.storage
-00003cf0: 2e61 7574 6f5f 6d6f 756e 745f 7479 7065  .auto_mount_type
-00003d00: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-00003d10: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
-00003d20: 672e 7374 6f72 6167 652e 6175 746f 5f6d  g.storage.auto_m
-00003d30: 6f75 6e74 5f70 6172 616d 7320 3d20 280a  ount_params = (.
-00003d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d50: 7365 7276 6572 5f63 6667 2e67 6574 2822  server_cfg.get("
-00003d60: 6175 746f 5f6d 6f75 6e74 5f70 6172 616d  auto_mount_param
-00003d70: 7322 2920 6f72 2063 6f6e 6669 672e 7374  s") or config.st
-00003d80: 6f72 6167 652e 6175 746f 5f6d 6f75 6e74  orage.auto_mount
-00003d90: 5f70 6172 616d 730a 2020 2020 2020 2020  _params.        
-00003da0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-00003db0: 2020 636f 6e66 6967 2e73 7061 726b 5f6f    config.spark_o
-00003dc0: 7065 7261 746f 725f 7665 7273 696f 6e20  perator_version 
-00003dd0: 3d20 280a 2020 2020 2020 2020 2020 2020  = (.            
-00003de0: 2020 2020 7365 7276 6572 5f63 6667 2e67      server_cfg.g
-00003df0: 6574 2822 7370 6172 6b5f 6f70 6572 6174  et("spark_operat
-00003e00: 6f72 5f76 6572 7369 6f6e 2229 0a20 2020  or_version").   
-00003e10: 2020 2020 2020 2020 2020 2020 206f 7220               or 
-00003e20: 636f 6e66 6967 2e73 7061 726b 5f6f 7065  config.spark_ope
-00003e30: 7261 746f 725f 7665 7273 696f 6e0a 2020  rator_version.  
-00003e40: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
-00003e50: 2020 2020 2020 2020 636f 6e66 6967 2e64          config.d
-00003e60: 6566 6175 6c74 5f74 656e 736f 7262 6f61  efault_tensorboa
-00003e70: 7264 5f6c 6f67 735f 7061 7468 203d 2028  rd_logs_path = (
-00003e80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003e90: 2073 6572 7665 725f 6366 672e 6765 7428   server_cfg.get(
-00003ea0: 2264 6566 6175 6c74 5f74 656e 736f 7262  "default_tensorb
-00003eb0: 6f61 7264 5f6c 6f67 735f 7061 7468 2229  oard_logs_path")
-00003ec0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003ed0: 206f 7220 636f 6e66 6967 2e64 6566 6175   or config.defau
-00003ee0: 6c74 5f74 656e 736f 7262 6f61 7264 5f6c  lt_tensorboard_l
-00003ef0: 6f67 735f 7061 7468 0a20 2020 2020 2020  ogs_path.       
-00003f00: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
-00003f10: 2020 2063 6f6e 6669 672e 6465 6661 756c     config.defaul
-00003f20: 745f 6675 6e63 7469 6f6e 5f70 6f64 5f72  t_function_pod_r
-00003f30: 6573 6f75 7263 6573 203d 2028 0a20 2020  esources = (.   
-00003f40: 2020 2020 2020 2020 2020 2020 2073 6572               ser
-00003f50: 7665 725f 6366 672e 6765 7428 2264 6566  ver_cfg.get("def
-00003f60: 6175 6c74 5f66 756e 6374 696f 6e5f 706f  ault_function_po
-00003f70: 645f 7265 736f 7572 6365 7322 290a 2020  d_resources").  
-00003f80: 2020 2020 2020 2020 2020 2020 2020 6f72                or
-00003f90: 2063 6f6e 6669 672e 6465 6661 756c 745f   config.default_
-00003fa0: 6675 6e63 7469 6f6e 5f70 6f64 5f72 6573  function_pod_res
-00003fb0: 6f75 7263 6573 0a20 2020 2020 2020 2020  ources.         
-00003fc0: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
-00003fd0: 2063 6f6e 6669 672e 6675 6e63 7469 6f6e   config.function
-00003fe0: 5f64 6566 6175 6c74 732e 7072 6565 6d70  _defaults.preemp
-00003ff0: 7469 6f6e 5f6d 6f64 6520 3d20 280a 2020  tion_mode = (.  
-00004000: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00004010: 7276 6572 5f63 6667 2e67 6574 2822 6465  rver_cfg.get("de
-00004020: 6661 756c 745f 7072 6565 6d70 7469 6f6e  fault_preemption
-00004030: 5f6d 6f64 6522 290a 2020 2020 2020 2020  _mode").        
-00004040: 2020 2020 2020 2020 6f72 2063 6f6e 6669          or confi
-00004050: 672e 6675 6e63 7469 6f6e 5f64 6566 6175  g.function_defau
-00004060: 6c74 732e 7072 6565 6d70 7469 6f6e 5f6d  lts.preemption_m
-00004070: 6f64 650a 2020 2020 2020 2020 2020 2020  ode.            
-00004080: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
-00004090: 6e66 6967 2e70 7265 656d 7074 6962 6c65  nfig.preemptible
-000040a0: 5f6e 6f64 6573 2e6e 6f64 655f 7365 6c65  _nodes.node_sele
-000040b0: 6374 6f72 203d 2028 0a20 2020 2020 2020  ctor = (.       
-000040c0: 2020 2020 2020 2020 2073 6572 7665 725f           server_
-000040d0: 6366 672e 6765 7428 2270 7265 656d 7074  cfg.get("preempt
-000040e0: 6962 6c65 5f6e 6f64 6573 5f6e 6f64 655f  ible_nodes_node_
-000040f0: 7365 6c65 6374 6f72 2229 0a20 2020 2020  selector").     
-00004100: 2020 2020 2020 2020 2020 206f 7220 636f             or co
-00004110: 6e66 6967 2e70 7265 656d 7074 6962 6c65  nfig.preemptible
-00004120: 5f6e 6f64 6573 2e6e 6f64 655f 7365 6c65  _nodes.node_sele
-00004130: 6374 6f72 0a20 2020 2020 2020 2020 2020  ctor.           
-00004140: 2029 0a20 2020 2020 2020 2020 2020 2063   ).            c
-00004150: 6f6e 6669 672e 7072 6565 6d70 7469 626c  onfig.preemptibl
-00004160: 655f 6e6f 6465 732e 746f 6c65 7261 7469  e_nodes.tolerati
-00004170: 6f6e 7320 3d20 280a 2020 2020 2020 2020  ons = (.        
-00004180: 2020 2020 2020 2020 7365 7276 6572 5f63          server_c
-00004190: 6667 2e67 6574 2822 7072 6565 6d70 7469  fg.get("preempti
-000041a0: 626c 655f 6e6f 6465 735f 746f 6c65 7261  ble_nodes_tolera
-000041b0: 7469 6f6e 7322 290a 2020 2020 2020 2020  tions").        
-000041c0: 2020 2020 2020 2020 6f72 2063 6f6e 6669          or confi
-000041d0: 672e 7072 6565 6d70 7469 626c 655f 6e6f  g.preemptible_no
-000041e0: 6465 732e 746f 6c65 7261 7469 6f6e 730a  des.tolerations.
-000041f0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
-00004200: 2020 2020 2020 2020 2020 636f 6e66 6967            config
-00004210: 2e66 6f72 6365 5f72 756e 5f6c 6f63 616c  .force_run_local
-00004220: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
-00004230: 2020 2020 2073 6572 7665 725f 6366 672e       server_cfg.
-00004240: 6765 7428 2266 6f72 6365 5f72 756e 5f6c  get("force_run_l
-00004250: 6f63 616c 2229 206f 7220 636f 6e66 6967  ocal") or config
-00004260: 2e66 6f72 6365 5f72 756e 5f6c 6f63 616c  .force_run_local
-00004270: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-00004280: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
-00004290: 672e 6675 6e63 7469 6f6e 203d 2073 6572  g.function = ser
-000042a0: 7665 725f 6366 672e 6765 7428 2266 756e  ver_cfg.get("fun
-000042b0: 6374 696f 6e22 2920 6f72 2063 6f6e 6669  ction") or confi
-000042c0: 672e 6675 6e63 7469 6f6e 0a20 2020 2020  g.function.     
-000042d0: 2020 2020 2020 2063 6f6e 6669 672e 6874         config.ht
-000042e0: 7470 6462 2e6c 6f67 7320 3d20 7365 7276  tpdb.logs = serv
-000042f0: 6572 5f63 6667 2e67 6574 2822 6c6f 6773  er_cfg.get("logs
-00004300: 2229 206f 7220 636f 6e66 6967 2e68 7474  ") or config.htt
-00004310: 7064 622e 6c6f 6773 0a0a 2020 2020 2020  pdb.logs..      
-00004320: 2020 6578 6365 7074 2045 7863 6570 7469    except Excepti
-00004330: 6f6e 2061 7320 6578 633a 0a20 2020 2020  on as exc:.     
-00004340: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
-00004350: 726e 696e 6728 0a20 2020 2020 2020 2020  rning(.         
-00004360: 2020 2020 2020 2022 4661 696c 6564 2073         "Failed s
-00004370: 796e 6369 6e67 2063 6f6e 6669 6720 6672  yncing config fr
-00004380: 6f6d 2073 6572 7665 7222 2c0a 2020 2020  om server",.    
-00004390: 2020 2020 2020 2020 2020 2020 6578 633d              exc=
-000043a0: 6572 725f 746f 5f73 7472 2865 7863 292c  err_to_str(exc),
-000043b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000043c0: 2074 7261 6365 6261 636b 3d74 7261 6365   traceback=trace
-000043d0: 6261 636b 2e66 6f72 6d61 745f 6578 6328  back.format_exc(
-000043e0: 292c 0a20 2020 2020 2020 2020 2020 2029  ),.            )
-000043f0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00004400: 7365 6c66 0a0a 2020 2020 6465 6620 7374  self..    def st
-00004410: 6f72 655f 6c6f 6728 7365 6c66 2c20 7569  ore_log(self, ui
-00004420: 642c 2070 726f 6a65 6374 3d22 222c 2062  d, project="", b
-00004430: 6f64 793d 4e6f 6e65 2c20 6170 7065 6e64  ody=None, append
-00004440: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
-00004450: 2022 2222 5361 7665 2061 206c 6f67 2070   """Save a log p
-00004460: 6572 7369 7374 656e 746c 792e 0a0a 2020  ersistently...  
-00004470: 2020 2020 2020 3a70 6172 616d 2075 6964        :param uid
-00004480: 3a20 4c6f 6720 756e 6971 7565 2049 440a  : Log unique ID.
-00004490: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
-000044a0: 726f 6a65 6374 3a20 5072 6f6a 6563 7420  roject: Project 
-000044b0: 6e61 6d65 2066 6f72 2077 6869 6368 2074  name for which t
-000044c0: 6869 7320 6c6f 6720 6265 6c6f 6e67 730a  his log belongs.
-000044d0: 2020 2020 2020 2020 3a70 6172 616d 2062          :param b
-000044e0: 6f64 793a 2054 6865 2061 6374 7561 6c20  ody: The actual 
-000044f0: 6c6f 6720 746f 2073 746f 7265 0a20 2020  log to store.   
-00004500: 2020 2020 203a 7061 7261 6d20 6170 7065       :param appe
-00004510: 6e64 3a20 5768 6574 6865 7220 746f 2061  nd: Whether to a
-00004520: 7070 656e 6420 7468 6520 6c6f 6720 7072  ppend the log pr
-00004530: 6f76 6964 6564 2069 6e20 6060 626f 6479  ovided in ``body
-00004540: 6060 2074 6f20 616e 2065 7869 7374 696e  `` to an existin
-00004550: 6720 6c6f 6720 7769 7468 2074 6865 2073  g log with the s
-00004560: 616d 6520 6060 7569 6460 6020 6f72 2074  ame ``uid`` or t
-00004570: 6f0a 2020 2020 2020 2020 2020 2020 6372  o.            cr
-00004580: 6561 7465 2061 206e 6577 206c 6f67 2e20  eate a new log. 
-00004590: 4966 2073 6574 2074 6f20 6060 4661 6c73  If set to ``Fals
-000045a0: 6560 602c 2061 6e20 6578 6973 7469 6e67  e``, an existing
-000045b0: 206c 6f67 2077 6974 6820 7361 6d65 2060   log with same `
-000045c0: 6075 6964 6060 2077 696c 6c20 6265 206f  `uid`` will be o
-000045d0: 7665 7277 7269 7474 656e 0a20 2020 2020  verwritten.     
-000045e0: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
-000045f0: 6966 206e 6f74 2062 6f64 793a 0a20 2020  if not body:.   
-00004600: 2020 2020 2020 2020 2072 6574 7572 6e0a           return.
-00004610: 0a20 2020 2020 2020 2070 6174 6820 3d20  .        path = 
-00004620: 7365 6c66 2e5f 7061 7468 5f6f 6628 226c  self._path_of("l
-00004630: 6f67 222c 2070 726f 6a65 6374 2c20 7569  og", project, ui
-00004640: 6429 0a20 2020 2020 2020 2070 6172 616d  d).        param
-00004650: 7320 3d20 7b22 6170 7065 6e64 223a 2062  s = {"append": b
-00004660: 6f6f 6c32 7374 7228 6170 7065 6e64 297d  ool2str(append)}
-00004670: 0a20 2020 2020 2020 2065 7272 6f72 203d  .        error =
-00004680: 2066 2273 746f 7265 206c 6f67 207b 7072   f"store log {pr
-00004690: 6f6a 6563 747d 2f7b 7569 647d 220a 2020  oject}/{uid}".  
-000046a0: 2020 2020 2020 7365 6c66 2e61 7069 5f63        self.api_c
-000046b0: 616c 6c28 2250 4f53 5422 2c20 7061 7468  all("POST", path
-000046c0: 2c20 6572 726f 722c 2070 6172 616d 732c  , error, params,
-000046d0: 2062 6f64 7929 0a0a 2020 2020 6465 6620   body)..    def 
-000046e0: 6765 745f 6c6f 6728 7365 6c66 2c20 7569  get_log(self, ui
-000046f0: 642c 2070 726f 6a65 6374 3d22 222c 206f  d, project="", o
-00004700: 6666 7365 743d 302c 2073 697a 653d 2d31  ffset=0, size=-1
-00004710: 293a 0a20 2020 2020 2020 2022 2222 5265  ):.        """Re
-00004720: 7472 6965 7665 2061 206c 6f67 2e0a 0a20  trieve a log... 
-00004730: 2020 2020 2020 203a 7061 7261 6d20 7569         :param ui
-00004740: 643a 204c 6f67 2075 6e69 7175 6520 4944  d: Log unique ID
-00004750: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00004760: 7072 6f6a 6563 743a 2050 726f 6a65 6374  project: Project
-00004770: 206e 616d 6520 666f 7220 7768 6963 6820   name for which 
-00004780: 7468 6520 6c6f 6720 6265 6c6f 6e67 730a  the log belongs.
-00004790: 2020 2020 2020 2020 3a70 6172 616d 206f          :param o
-000047a0: 6666 7365 743a 2052 6574 7269 6576 6520  ffset: Retrieve 
-000047b0: 7061 7274 6961 6c20 6c6f 672c 2067 6574  partial log, get
-000047c0: 2075 7020 746f 2060 6073 697a 6560 6020   up to ``size`` 
-000047d0: 6279 7465 7320 7374 6172 7469 6e67 2061  bytes starting a
-000047e0: 7420 6f66 6673 6574 2060 606f 6666 7365  t offset ``offse
-000047f0: 7460 600a 2020 2020 2020 2020 2020 2020  t``.            
-00004800: 6672 6f6d 2062 6567 696e 6e69 6e67 206f  from beginning o
-00004810: 6620 6c6f 670a 2020 2020 2020 2020 3a70  f log.        :p
-00004820: 6172 616d 2073 697a 653a 2053 6565 2060  aram size: See `
-00004830: 606f 6666 7365 7460 602e 2049 6620 7365  `offset``. If se
-00004840: 7420 746f 2060 602d 3160 6020 2874 6865  t to ``-1`` (the
-00004850: 2064 6566 6175 6c74 2920 7769 6c6c 2072   default) will r
-00004860: 6574 7269 6576 6520 616c 6c20 6461 7461  etrieve all data
-00004870: 2074 6f20 656e 6420 6f66 206c 6f67 2e0a   to end of log..
-00004880: 2020 2020 2020 2020 3a72 6574 7572 6e73          :returns
-00004890: 3a20 5468 6520 666f 6c6c 6f77 696e 6720  : The following 
-000048a0: 6f62 6a65 6374 733a 0a0a 2020 2020 2020  objects:..      
-000048b0: 2020 2020 2020 2d20 7374 6174 6520 2d20        - state - 
-000048c0: 5468 6520 7374 6174 6520 6f66 2074 6865  The state of the
-000048d0: 2072 756e 7469 6d65 206f 626a 6563 7420   runtime object 
-000048e0: 7768 6963 6820 6765 6e65 7261 7465 7320  which generates 
-000048f0: 7468 6973 206c 6f67 2c20 6966 2069 7420  this log, if it 
-00004900: 6578 6973 7473 2e20 496e 2063 6173 6520  exists. In case 
-00004910: 6e6f 206b 6e6f 776e 2073 7461 7465 0a20  no known state. 
-00004920: 2020 2020 2020 2020 2020 2020 2065 7869               exi
-00004930: 7374 732c 2074 6869 7320 7769 6c6c 2062  sts, this will b
-00004940: 6520 6060 756e 6b6e 6f77 6e60 602e 0a20  e ``unknown``.. 
-00004950: 2020 2020 2020 2020 2020 202d 2063 6f6e             - con
-00004960: 7465 6e74 202d 2054 6865 2061 6374 7561  tent - The actua
-00004970: 6c20 6c6f 6720 636f 6e74 656e 742e 0a20  l log content.. 
-00004980: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-00004990: 2020 2020 7061 7261 6d73 203d 207b 226f      params = {"o
-000049a0: 6666 7365 7422 3a20 6f66 6673 6574 2c20  ffset": offset, 
-000049b0: 2273 697a 6522 3a20 7369 7a65 7d0a 2020  "size": size}.  
-000049c0: 2020 2020 2020 7061 7468 203d 2073 656c        path = sel
-000049d0: 662e 5f70 6174 685f 6f66 2822 6c6f 6722  f._path_of("log"
-000049e0: 2c20 7072 6f6a 6563 742c 2075 6964 290a  , project, uid).
-000049f0: 2020 2020 2020 2020 6572 726f 7220 3d20          error = 
-00004a00: 6622 6765 7420 6c6f 6720 7b70 726f 6a65  f"get log {proje
-00004a10: 6374 7d2f 7b75 6964 7d22 0a20 2020 2020  ct}/{uid}".     
-00004a20: 2020 2072 6573 7020 3d20 7365 6c66 2e61     resp = self.a
-00004a30: 7069 5f63 616c 6c28 2247 4554 222c 2070  pi_call("GET", p
-00004a40: 6174 682c 2065 7272 6f72 2c20 7061 7261  ath, error, para
-00004a50: 6d73 3d70 6172 616d 7329 0a20 2020 2020  ms=params).     
-00004a60: 2020 2069 6620 7265 7370 2e68 6561 6465     if resp.heade
-00004a70: 7273 3a0a 2020 2020 2020 2020 2020 2020  rs:.            
-00004a80: 7374 6174 6520 3d20 7265 7370 2e68 6561  state = resp.hea
-00004a90: 6465 7273 2e67 6574 2822 782d 6d6c 7275  ders.get("x-mlru
-00004aa0: 6e2d 7275 6e2d 7374 6174 6522 2c20 2222  n-run-state", ""
-00004ab0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
-00004ac0: 7475 726e 2073 7461 7465 2e6c 6f77 6572  turn state.lower
-00004ad0: 2829 2c20 7265 7370 2e63 6f6e 7465 6e74  (), resp.content
-00004ae0: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00004af0: 2022 756e 6b6e 6f77 6e22 2c20 7265 7370   "unknown", resp
-00004b00: 2e63 6f6e 7465 6e74 0a0a 2020 2020 6465  .content..    de
-00004b10: 6620 7761 7463 685f 6c6f 6728 7365 6c66  f watch_log(self
-00004b20: 2c20 7569 642c 2070 726f 6a65 6374 3d22  , uid, project="
-00004b30: 222c 2077 6174 6368 3d54 7275 652c 206f  ", watch=True, o
-00004b40: 6666 7365 743d 3029 3a0a 2020 2020 2020  ffset=0):.      
-00004b50: 2020 2222 2252 6574 7269 6576 6520 6c6f    """Retrieve lo
-00004b60: 6773 206f 6620 6120 7275 6e6e 696e 6720  gs of a running 
-00004b70: 7072 6f63 6573 732c 2061 6e64 2077 6174  process, and wat
-00004b80: 6368 2074 6865 2070 726f 6772 6573 7320  ch the progress 
-00004b90: 6f66 2074 6865 2065 7865 6375 7469 6f6e  of the execution
-00004ba0: 2075 6e74 696c 2069 7420 636f 6d70 6c65   until it comple
-00004bb0: 7465 732e 2054 6869 730a 2020 2020 2020  tes. This.      
-00004bc0: 2020 6d65 7468 6f64 2077 696c 6c20 7072    method will pr
-00004bd0: 696e 7420 6f75 7420 7468 6520 6c6f 6773  int out the logs
-00004be0: 2061 6e64 2063 6f6e 7469 6e75 6520 746f   and continue to
-00004bf0: 2070 6572 696f 6469 6361 6c6c 7920 706f   periodically po
-00004c00: 6c6c 2066 6f72 2c20 616e 6420 7072 696e  ll for, and prin
-00004c10: 742c 206e 6577 206c 6f67 7320 6173 206c  t, new logs as l
-00004c20: 6f6e 6720 6173 2074 6865 0a20 2020 2020  ong as the.     
-00004c30: 2020 2073 7461 7465 206f 6620 7468 6520     state of the 
-00004c40: 7275 6e74 696d 6520 7768 6963 6820 6765  runtime which ge
-00004c50: 6e65 7261 7465 7320 7468 6973 206c 6f67  nerates this log
-00004c60: 2069 7320 6569 7468 6572 2060 6070 656e   is either ``pen
-00004c70: 6469 6e67 6060 206f 7220 6060 7275 6e6e  ding`` or ``runn
-00004c80: 696e 6760 602e 0a0a 2020 2020 2020 2020  ing``...        
-00004c90: 3a70 6172 616d 2075 6964 3a20 5468 6520  :param uid: The 
-00004ca0: 7569 6420 6f66 2074 6865 206c 6f67 206f  uid of the log o
-00004cb0: 626a 6563 7420 746f 2077 6174 6368 2e0a  bject to watch..
-00004cc0: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
-00004cd0: 726f 6a65 6374 3a20 5072 6f6a 6563 7420  roject: Project 
-00004ce0: 7468 6174 2074 6865 206c 6f67 2062 656c  that the log bel
-00004cf0: 6f6e 6773 2074 6f2e 0a20 2020 2020 2020  ongs to..       
-00004d00: 203a 7061 7261 6d20 7761 7463 683a 2049   :param watch: I
-00004d10: 6620 7365 7420 746f 2060 6054 7275 6560  f set to ``True`
-00004d20: 6020 7769 6c6c 2063 6f6e 7469 6e75 6520  ` will continue 
-00004d30: 7472 6163 6b69 6e67 2074 6865 206c 6f67  tracking the log
-00004d40: 2061 7320 6465 7363 7269 6265 6420 6162   as described ab
-00004d50: 6f76 652e 204f 7468 6572 7769 7365 2074  ove. Otherwise t
-00004d60: 6869 7320 6675 6e63 7469 6f6e 0a20 2020  his function.   
-00004d70: 2020 2020 2020 2020 2069 7320 7072 6163           is prac
-00004d80: 7469 6361 6c6c 7920 6571 7569 7661 6c65  tically equivale
-00004d90: 6e74 2074 6f20 7468 6520 3a70 793a 6675  nt to the :py:fu
-00004da0: 6e63 3a60 7e67 6574 5f6c 6f67 6020 6675  nc:`~get_log` fu
-00004db0: 6e63 7469 6f6e 2e0a 2020 2020 2020 2020  nction..        
-00004dc0: 3a70 6172 616d 206f 6666 7365 743a 204d  :param offset: M
-00004dd0: 696e 696d 616c 206f 6666 7365 7420 696e  inimal offset in
-00004de0: 2074 6865 206c 6f67 2074 6f20 7761 7463   the log to watc
-00004df0: 682e 0a20 2020 2020 2020 203a 7265 7475  h..        :retu
-00004e00: 726e 733a 2054 6865 2066 696e 616c 2073  rns: The final s
-00004e10: 7461 7465 206f 6620 7468 6520 6c6f 6720  tate of the log 
-00004e20: 6265 696e 6720 7761 7463 6865 642e 0a20  being watched.. 
-00004e30: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-00004e40: 2020 2020 7374 6174 652c 2074 6578 7420      state, text 
-00004e50: 3d20 7365 6c66 2e67 6574 5f6c 6f67 2875  = self.get_log(u
-00004e60: 6964 2c20 7072 6f6a 6563 742c 206f 6666  id, project, off
-00004e70: 7365 743d 6f66 6673 6574 290a 2020 2020  set=offset).    
-00004e80: 2020 2020 6966 2074 6578 743a 0a20 2020      if text:.   
-00004e90: 2020 2020 2020 2020 2070 7269 6e74 2874           print(t
-00004ea0: 6578 742e 6465 636f 6465 2829 290a 2020  ext.decode()).  
-00004eb0: 2020 2020 2020 6966 2077 6174 6368 3a0a        if watch:.
-00004ec0: 2020 2020 2020 2020 2020 2020 6e69 6c5f              nil_
-00004ed0: 7265 7370 203d 2030 0a20 2020 2020 2020  resp = 0.       
-00004ee0: 2020 2020 2077 6869 6c65 2073 7461 7465       while state
-00004ef0: 2069 6e20 5b22 7065 6e64 696e 6722 2c20   in ["pending", 
-00004f00: 2272 756e 6e69 6e67 225d 3a0a 2020 2020  "running"]:.    
-00004f10: 2020 2020 2020 2020 2020 2020 6f66 6673              offs
-00004f20: 6574 202b 3d20 6c65 6e28 7465 7874 290a  et += len(text).
-00004f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004f40: 2320 6966 2077 6520 6765 7420 3320 6e69  # if we get 3 ni
-00004f50: 6c20 7265 7370 6f6e 7365 7320 696e 2061  l responses in a
-00004f60: 2072 6f77 2c20 696e 6372 6561 7365 2074   row, increase t
-00004f70: 6865 2073 6c65 6570 2074 696d 6520 746f  he sleep time to
-00004f80: 2031 3020 7365 636f 6e64 730a 2020 2020   10 seconds.    
-00004f90: 2020 2020 2020 2020 2020 2020 2320 544f              # TO
-00004fa0: 444f 3a20 7265 6661 6374 6f72 2074 6869  DO: refactor thi
-00004fb0: 7320 746f 2075 7365 2061 2063 6f6e 6469  s to use a condi
-00004fc0: 7469 6f6e 616c 2062 6163 6b6f 6666 206d  tional backoff m
-00004fd0: 6563 6861 6e69 736d 0a20 2020 2020 2020  echanism.       
-00004fe0: 2020 2020 2020 2020 2069 6620 6e69 6c5f           if nil_
-00004ff0: 7265 7370 203c 2033 3a0a 2020 2020 2020  resp < 3:.      
-00005000: 2020 2020 2020 2020 2020 2020 2020 7469                ti
-00005010: 6d65 2e73 6c65 6570 2869 6e74 286d 6c72  me.sleep(int(mlr
-00005020: 756e 2e6d 6c63 6f6e 662e 6874 7470 6462  un.mlconf.httpdb
-00005030: 2e6c 6f67 732e 7075 6c6c 5f6c 6f67 735f  .logs.pull_logs_
-00005040: 6465 6661 756c 745f 696e 7465 7276 616c  default_interval
-00005050: 2929 0a20 2020 2020 2020 2020 2020 2020  )).             
-00005060: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00005070: 2020 2020 2020 2020 2020 2020 2074 696d               tim
-00005080: 652e 736c 6565 7028 0a20 2020 2020 2020  e.sleep(.       
-00005090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000050a0: 2069 6e74 280a 2020 2020 2020 2020 2020   int(.          
-000050b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000050c0: 2020 6d6c 7275 6e2e 6d6c 636f 6e66 2e68    mlrun.mlconf.h
-000050d0: 7474 7064 622e 6c6f 6773 2e70 756c 6c5f  ttpdb.logs.pull_
-000050e0: 6c6f 6773 5f62 6163 6b6f 6666 5f6e 6f5f  logs_backoff_no_
-000050f0: 6c6f 6773 5f64 6566 6175 6c74 5f69 6e74  logs_default_int
-00005100: 6572 7661 6c0a 2020 2020 2020 2020 2020  erval.          
-00005110: 2020 2020 2020 2020 2020 2020 2020 290a                ).
-00005120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005130: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-00005140: 2020 2020 2020 7374 6174 652c 2074 6578        state, tex
-00005150: 7420 3d20 7365 6c66 2e67 6574 5f6c 6f67  t = self.get_log
-00005160: 2875 6964 2c20 7072 6f6a 6563 742c 206f  (uid, project, o
-00005170: 6666 7365 743d 6f66 6673 6574 290a 2020  ffset=offset).  
-00005180: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00005190: 2074 6578 743a 0a20 2020 2020 2020 2020   text:.         
-000051a0: 2020 2020 2020 2020 2020 206e 696c 5f72             nil_r
-000051b0: 6573 7020 3d20 300a 2020 2020 2020 2020  esp = 0.        
-000051c0: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-000051d0: 7428 7465 7874 2e64 6563 6f64 6528 292c  t(text.decode(),
-000051e0: 2065 6e64 3d22 2229 0a20 2020 2020 2020   end="").       
-000051f0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00005200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005210: 2020 206e 696c 5f72 6573 7020 2b3d 2031     nil_resp += 1
-00005220: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00005230: 2020 2020 2020 2020 2020 206f 6666 7365             offse
-00005240: 7420 2b3d 206c 656e 2874 6578 7429 0a0a  t += len(text)..
-00005250: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00005260: 7461 7465 2c20 6f66 6673 6574 0a0a 2020  tate, offset..  
-00005270: 2020 6465 6620 7374 6f72 655f 7275 6e28    def store_run(
-00005280: 7365 6c66 2c20 7374 7275 6374 2c20 7569  self, struct, ui
-00005290: 642c 2070 726f 6a65 6374 3d22 222c 2069  d, project="", i
-000052a0: 7465 723d 3029 3a0a 2020 2020 2020 2020  ter=0):.        
-000052b0: 2222 2253 746f 7265 2072 756e 2064 6574  """Store run det
-000052c0: 6169 6c73 2069 6e20 7468 6520 4442 2e20  ails in the DB. 
-000052d0: 5468 6973 206d 6574 686f 6420 6973 2075  This method is u
-000052e0: 7375 616c 6c79 2063 616c 6c65 6420 6672  sually called fr
-000052f0: 6f6d 2077 6974 6869 6e20 6f74 6865 7220  om within other 
-00005300: 3a70 793a 6d6f 643a 606d 6c72 756e 6020  :py:mod:`mlrun` 
-00005310: 666c 6f77 730a 2020 2020 2020 2020 616e  flows.        an
-00005320: 6420 6e6f 7420 6361 6c6c 6564 2064 6972  d not called dir
-00005330: 6563 746c 7920 6279 2074 6865 2075 7365  ectly by the use
-00005340: 722e 2222 220a 0a20 2020 2020 2020 2070  r."""..        p
-00005350: 6174 6820 3d20 7365 6c66 2e5f 7061 7468  ath = self._path
-00005360: 5f6f 6628 2272 756e 222c 2070 726f 6a65  _of("run", proje
-00005370: 6374 2c20 7569 6429 0a20 2020 2020 2020  ct, uid).       
-00005380: 2070 6172 616d 7320 3d20 7b22 6974 6572   params = {"iter
-00005390: 223a 2069 7465 727d 0a20 2020 2020 2020  ": iter}.       
-000053a0: 2065 7272 6f72 203d 2066 2273 746f 7265   error = f"store
-000053b0: 2072 756e 207b 7072 6f6a 6563 747d 2f7b   run {project}/{
-000053c0: 7569 647d 220a 2020 2020 2020 2020 626f  uid}".        bo
-000053d0: 6479 203d 205f 6173 5f6a 736f 6e28 7374  dy = _as_json(st
-000053e0: 7275 6374 290a 2020 2020 2020 2020 7365  ruct).        se
-000053f0: 6c66 2e61 7069 5f63 616c 6c28 2250 4f53  lf.api_call("POS
-00005400: 5422 2c20 7061 7468 2c20 6572 726f 722c  T", path, error,
-00005410: 2070 6172 616d 733d 7061 7261 6d73 2c20   params=params, 
-00005420: 626f 6479 3d62 6f64 7929 0a0a 2020 2020  body=body)..    
-00005430: 6465 6620 7570 6461 7465 5f72 756e 2873  def update_run(s
-00005440: 656c 662c 2075 7064 6174 6573 3a20 6469  elf, updates: di
-00005450: 6374 2c20 7569 642c 2070 726f 6a65 6374  ct, uid, project
-00005460: 3d22 222c 2069 7465 723d 3029 3a0a 2020  ="", iter=0):.  
-00005470: 2020 2020 2020 2222 2255 7064 6174 6520        """Update 
-00005480: 7468 6520 6465 7461 696c 7320 6f66 2061  the details of a
-00005490: 2073 746f 7265 6420 7275 6e20 696e 2074   stored run in t
-000054a0: 6865 2044 422e 2222 220a 0a20 2020 2020  he DB."""..     
-000054b0: 2020 2070 6174 6820 3d20 7365 6c66 2e5f     path = self._
-000054c0: 7061 7468 5f6f 6628 2272 756e 222c 2070  path_of("run", p
-000054d0: 726f 6a65 6374 2c20 7569 6429 0a20 2020  roject, uid).   
-000054e0: 2020 2020 2070 6172 616d 7320 3d20 7b22       params = {"
-000054f0: 6974 6572 223a 2069 7465 727d 0a20 2020  iter": iter}.   
-00005500: 2020 2020 2065 7272 6f72 203d 2066 2275       error = f"u
-00005510: 7064 6174 6520 7275 6e20 7b70 726f 6a65  pdate run {proje
-00005520: 6374 7d2f 7b75 6964 7d22 0a20 2020 2020  ct}/{uid}".     
-00005530: 2020 2062 6f64 7920 3d20 5f61 735f 6a73     body = _as_js
-00005540: 6f6e 2875 7064 6174 6573 290a 2020 2020  on(updates).    
-00005550: 2020 2020 7365 6c66 2e61 7069 5f63 616c      self.api_cal
-00005560: 6c28 2250 4154 4348 222c 2070 6174 682c  l("PATCH", path,
-00005570: 2065 7272 6f72 2c20 7061 7261 6d73 3d70   error, params=p
-00005580: 6172 616d 732c 2062 6f64 793d 626f 6479  arams, body=body
-00005590: 290a 0a20 2020 2064 6566 2061 626f 7274  )..    def abort
-000055a0: 5f72 756e 2873 656c 662c 2075 6964 2c20  _run(self, uid, 
-000055b0: 7072 6f6a 6563 743d 2222 2c20 6974 6572  project="", iter
-000055c0: 3d30 293a 0a20 2020 2020 2020 2022 2222  =0):.        """
-000055d0: 0a20 2020 2020 2020 2041 626f 7274 2061  .        Abort a
-000055e0: 2072 756e 6e69 6e67 2072 756e 202d 2077   running run - w
-000055f0: 696c 6c20 7265 6d6f 7665 2074 6865 2072  ill remove the r
-00005600: 756e 2773 2072 756e 7469 6d65 2072 6573  un's runtime res
-00005610: 6f75 7263 6573 2061 6e64 206d 6172 6b20  ources and mark 
-00005620: 6974 7320 7374 6174 6520 6173 2061 626f  its state as abo
-00005630: 7274 6564 0a20 2020 2020 2020 2022 2222  rted.        """
-00005640: 0a20 2020 2020 2020 2073 656c 662e 7570  .        self.up
-00005650: 6461 7465 5f72 756e 280a 2020 2020 2020  date_run(.      
-00005660: 2020 2020 2020 7b22 7374 6174 7573 2e73        {"status.s
-00005670: 7461 7465 223a 206d 6c72 756e 2e72 756e  tate": mlrun.run
-00005680: 7469 6d65 732e 636f 6e73 7461 6e74 732e  times.constants.
-00005690: 5275 6e53 7461 7465 732e 6162 6f72 7465  RunStates.aborte
-000056a0: 647d 2c0a 2020 2020 2020 2020 2020 2020  d},.            
-000056b0: 7569 642c 0a20 2020 2020 2020 2020 2020  uid,.           
-000056c0: 2070 726f 6a65 6374 2c0a 2020 2020 2020   project,.      
-000056d0: 2020 2020 2020 6974 6572 2c0a 2020 2020        iter,.    
-000056e0: 2020 2020 290a 0a20 2020 2064 6566 2072      )..    def r
-000056f0: 6561 645f 7275 6e28 7365 6c66 2c20 7569  ead_run(self, ui
-00005700: 642c 2070 726f 6a65 6374 3d22 222c 2069  d, project="", i
-00005710: 7465 723d 3029 3a0a 2020 2020 2020 2020  ter=0):.        
-00005720: 2222 2252 6561 6420 7468 6520 6465 7461  """Read the deta
-00005730: 696c 7320 6f66 2061 2073 746f 7265 6420  ils of a stored 
-00005740: 7275 6e20 6672 6f6d 2074 6865 2044 422e  run from the DB.
-00005750: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-00005760: 2075 6964 3a20 5468 6520 7275 6e27 7320   uid: The run's 
-00005770: 756e 6971 7565 2049 442e 0a20 2020 2020  unique ID..     
-00005780: 2020 203a 7061 7261 6d20 7072 6f6a 6563     :param projec
-00005790: 743a 2050 726f 6a65 6374 206e 616d 652e  t: Project name.
-000057a0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-000057b0: 6974 6572 3a20 4974 6572 6174 696f 6e20  iter: Iteration 
-000057c0: 7769 7468 696e 2061 2073 7065 6369 6669  within a specifi
-000057d0: 6320 6578 6563 7574 696f 6e2e 0a20 2020  c execution..   
-000057e0: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
-000057f0: 2020 7061 7468 203d 2073 656c 662e 5f70    path = self._p
-00005800: 6174 685f 6f66 2822 7275 6e22 2c20 7072  ath_of("run", pr
-00005810: 6f6a 6563 742c 2075 6964 290a 2020 2020  oject, uid).    
-00005820: 2020 2020 7061 7261 6d73 203d 207b 2269      params = {"i
-00005830: 7465 7222 3a20 6974 6572 7d0a 2020 2020  ter": iter}.    
-00005840: 2020 2020 6572 726f 7220 3d20 6622 6765      error = f"ge
-00005850: 7420 7275 6e20 7b70 726f 6a65 6374 7d2f  t run {project}/
-00005860: 7b75 6964 7d22 0a20 2020 2020 2020 2072  {uid}".        r
-00005870: 6573 7020 3d20 7365 6c66 2e61 7069 5f63  esp = self.api_c
-00005880: 616c 6c28 2247 4554 222c 2070 6174 682c  all("GET", path,
-00005890: 2065 7272 6f72 2c20 7061 7261 6d73 3d70   error, params=p
-000058a0: 6172 616d 7329 0a20 2020 2020 2020 2072  arams).        r
-000058b0: 6574 7572 6e20 7265 7370 2e6a 736f 6e28  eturn resp.json(
-000058c0: 295b 2264 6174 6122 5d0a 0a20 2020 2064  )["data"]..    d
-000058d0: 6566 2064 656c 5f72 756e 2873 656c 662c  ef del_run(self,
-000058e0: 2075 6964 2c20 7072 6f6a 6563 743d 2222   uid, project=""
-000058f0: 2c20 6974 6572 3d30 293a 0a20 2020 2020  , iter=0):.     
-00005900: 2020 2022 2222 4465 6c65 7465 2064 6574     """Delete det
-00005910: 6169 6c73 206f 6620 6120 7370 6563 6966  ails of a specif
-00005920: 6963 2072 756e 2066 726f 6d20 4442 2e0a  ic run from DB..
-00005930: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00005940: 7569 643a 2055 6e69 7175 6520 4944 2066  uid: Unique ID f
-00005950: 6f72 2074 6865 2073 7065 6369 6669 6320  or the specific 
-00005960: 7275 6e20 746f 2064 656c 6574 652e 0a20  run to delete.. 
-00005970: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
-00005980: 6f6a 6563 743a 2050 726f 6a65 6374 2074  oject: Project t
-00005990: 6861 7420 7468 6520 7275 6e20 6265 6c6f  hat the run belo
-000059a0: 6e67 7320 746f 2e0a 2020 2020 2020 2020  ngs to..        
-000059b0: 3a70 6172 616d 2069 7465 723a 2049 7465  :param iter: Ite
-000059c0: 7261 7469 6f6e 2077 6974 6869 6e20 6120  ration within a 
-000059d0: 7370 6563 6966 6963 2074 6173 6b2e 0a20  specific task.. 
-000059e0: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-000059f0: 2020 2020 7061 7468 203d 2073 656c 662e      path = self.
-00005a00: 5f70 6174 685f 6f66 2822 7275 6e22 2c20  _path_of("run", 
-00005a10: 7072 6f6a 6563 742c 2075 6964 290a 2020  project, uid).  
-00005a20: 2020 2020 2020 7061 7261 6d73 203d 207b        params = {
-00005a30: 2269 7465 7222 3a20 6974 6572 7d0a 2020  "iter": iter}.  
-00005a40: 2020 2020 2020 6572 726f 7220 3d20 6622        error = f"
-00005a50: 6465 6c20 7275 6e20 7b70 726f 6a65 6374  del run {project
-00005a60: 7d2f 7b75 6964 7d22 0a20 2020 2020 2020  }/{uid}".       
-00005a70: 2073 656c 662e 6170 695f 6361 6c6c 2822   self.api_call("
-00005a80: 4445 4c45 5445 222c 2070 6174 682c 2065  DELETE", path, e
-00005a90: 7272 6f72 2c20 7061 7261 6d73 3d70 6172  rror, params=par
-00005aa0: 616d 7329 0a0a 2020 2020 6465 6620 6c69  ams)..    def li
-00005ab0: 7374 5f72 756e 7328 0a20 2020 2020 2020  st_runs(.       
-00005ac0: 2073 656c 662c 0a20 2020 2020 2020 206e   self,.        n
-00005ad0: 616d 653d 4e6f 6e65 2c0a 2020 2020 2020  ame=None,.      
-00005ae0: 2020 7569 643a 204f 7074 696f 6e61 6c5b    uid: Optional[
-00005af0: 556e 696f 6e5b 7374 722c 204c 6973 745b  Union[str, List[
-00005b00: 7374 725d 5d5d 203d 204e 6f6e 652c 0a20  str]]] = None,. 
-00005b10: 2020 2020 2020 2070 726f 6a65 6374 3d4e         project=N
-00005b20: 6f6e 652c 0a20 2020 2020 2020 206c 6162  one,.        lab
-00005b30: 656c 733d 4e6f 6e65 2c0a 2020 2020 2020  els=None,.      
-00005b40: 2020 7374 6174 653d 4e6f 6e65 2c0a 2020    state=None,.  
-00005b50: 2020 2020 2020 736f 7274 3d54 7275 652c        sort=True,
-00005b60: 0a20 2020 2020 2020 206c 6173 743d 302c  .        last=0,
-00005b70: 0a20 2020 2020 2020 2069 7465 723d 4661  .        iter=Fa
-00005b80: 6c73 652c 0a20 2020 2020 2020 2073 7461  lse,.        sta
-00005b90: 7274 5f74 696d 655f 6672 6f6d 3a20 6461  rt_time_from: da
-00005ba0: 7465 7469 6d65 203d 204e 6f6e 652c 0a20  tetime = None,. 
-00005bb0: 2020 2020 2020 2073 7461 7274 5f74 696d         start_tim
-00005bc0: 655f 746f 3a20 6461 7465 7469 6d65 203d  e_to: datetime =
-00005bd0: 204e 6f6e 652c 0a20 2020 2020 2020 206c   None,.        l
-00005be0: 6173 745f 7570 6461 7465 5f74 696d 655f  ast_update_time_
-00005bf0: 6672 6f6d 3a20 6461 7465 7469 6d65 203d  from: datetime =
-00005c00: 204e 6f6e 652c 0a20 2020 2020 2020 206c   None,.        l
-00005c10: 6173 745f 7570 6461 7465 5f74 696d 655f  ast_update_time_
-00005c20: 746f 3a20 6461 7465 7469 6d65 203d 204e  to: datetime = N
-00005c30: 6f6e 652c 0a20 2020 2020 2020 2070 6172  one,.        par
-00005c40: 7469 7469 6f6e 5f62 793a 2055 6e69 6f6e  tition_by: Union
-00005c50: 5b73 6368 656d 6173 2e52 756e 5061 7274  [schemas.RunPart
-00005c60: 6974 696f 6e42 7946 6965 6c64 2c20 7374  itionByField, st
-00005c70: 725d 203d 204e 6f6e 652c 0a20 2020 2020  r] = None,.     
-00005c80: 2020 2072 6f77 735f 7065 725f 7061 7274     rows_per_part
-00005c90: 6974 696f 6e3a 2069 6e74 203d 2031 2c0a  ition: int = 1,.
-00005ca0: 2020 2020 2020 2020 7061 7274 6974 696f          partitio
-00005cb0: 6e5f 736f 7274 5f62 793a 2055 6e69 6f6e  n_sort_by: Union
-00005cc0: 5b73 6368 656d 6173 2e53 6f72 7446 6965  [schemas.SortFie
-00005cd0: 6c64 2c20 7374 725d 203d 204e 6f6e 652c  ld, str] = None,
-00005ce0: 0a20 2020 2020 2020 2070 6172 7469 7469  .        partiti
-00005cf0: 6f6e 5f6f 7264 6572 3a20 556e 696f 6e5b  on_order: Union[
-00005d00: 7363 6865 6d61 732e 4f72 6465 7254 7970  schemas.OrderTyp
-00005d10: 652c 2073 7472 5d20 3d20 7363 6865 6d61  e, str] = schema
-00005d20: 732e 4f72 6465 7254 7970 652e 6465 7363  s.OrderType.desc
-00005d30: 2c0a 2020 2020 2020 2020 6d61 785f 7061  ,.        max_pa
-00005d40: 7274 6974 696f 6e73 3a20 696e 7420 3d20  rtitions: int = 
-00005d50: 302c 0a20 2020 2029 202d 3e20 5275 6e4c  0,.    ) -> RunL
-00005d60: 6973 743a 0a20 2020 2020 2020 2022 2222  ist:.        """
-00005d70: 5265 7472 6965 7665 2061 206c 6973 7420  Retrieve a list 
-00005d80: 6f66 2072 756e 732c 2066 696c 7465 7265  of runs, filtere
-00005d90: 6420 6279 2076 6172 696f 7573 206f 7074  d by various opt
-00005da0: 696f 6e73 2e0a 2020 2020 2020 2020 4578  ions..        Ex
-00005db0: 616d 706c 653a 3a0a 0a20 2020 2020 2020  ample::..       
-00005dc0: 2020 2020 2072 756e 7320 3d20 6462 2e6c       runs = db.l
-00005dd0: 6973 745f 7275 6e73 286e 616d 653d 2764  ist_runs(name='d
-00005de0: 6f77 6e6c 6f61 6427 2c20 7072 6f6a 6563  ownload', projec
-00005df0: 743d 2769 7269 7327 2c20 6c61 6265 6c73  t='iris', labels
-00005e00: 3d27 6f77 6e65 723d 6164 6d69 6e27 290a  ='owner=admin').
-00005e10: 2020 2020 2020 2020 2020 2020 2320 4966              # If
-00005e20: 2072 756e 6e69 6e67 2069 6e20 4a75 7079   running in Jupy
-00005e30: 7465 722c 2063 616e 2075 7365 2074 6865  ter, can use the
-00005e40: 202e 7368 6f77 2829 2066 756e 6374 696f   .show() functio
-00005e50: 6e20 746f 2064 6973 706c 6179 2074 6865  n to display the
-00005e60: 2072 6573 756c 7473 0a20 2020 2020 2020   results.       
-00005e70: 2020 2020 2064 622e 6c69 7374 5f72 756e       db.list_run
-00005e80: 7328 6e61 6d65 3d27 272c 2070 726f 6a65  s(name='', proje
-00005e90: 6374 3d70 726f 6a65 6374 5f6e 616d 6529  ct=project_name)
-00005ea0: 2e73 686f 7728 290a 0a0a 2020 2020 2020  .show()...      
-00005eb0: 2020 3a70 6172 616d 206e 616d 653a 204e    :param name: N
-00005ec0: 616d 6520 6f66 2074 6865 2072 756e 2074  ame of the run t
-00005ed0: 6f20 7265 7472 6965 7665 2e0a 2020 2020  o retrieve..    
-00005ee0: 2020 2020 3a70 6172 616d 2075 6964 3a20      :param uid: 
-00005ef0: 556e 6971 7565 2049 4420 6f66 2074 6865  Unique ID of the
-00005f00: 2072 756e 2c20 6f72 2061 206c 6973 7420   run, or a list 
-00005f10: 6f66 2072 756e 2055 4944 732e 0a20 2020  of run UIDs..   
-00005f20: 2020 2020 203a 7061 7261 6d20 7072 6f6a       :param proj
-00005f30: 6563 743a 2050 726f 6a65 6374 2074 6861  ect: Project tha
-00005f40: 7420 7468 6520 7275 6e73 2062 656c 6f6e  t the runs belon
-00005f50: 6773 2074 6f2e 0a20 2020 2020 2020 203a  gs to..        :
-00005f60: 7061 7261 6d20 6c61 6265 6c73 3a20 4c69  param labels: Li
-00005f70: 7374 2072 756e 7320 7468 6174 2068 6176  st runs that hav
-00005f80: 6520 6120 7370 6563 6966 6963 206c 6162  e a specific lab
-00005f90: 656c 2061 7373 6967 6e65 642e 2043 7572  el assigned. Cur
-00005fa0: 7265 6e74 6c79 206f 6e6c 7920 6120 7369  rently only a si
-00005fb0: 6e67 6c65 206c 6162 656c 2066 696c 7465  ngle label filte
-00005fc0: 7220 6361 6e20 6265 0a20 2020 2020 2020  r can be.       
-00005fd0: 2020 2020 2061 7070 6c69 6564 2c20 6f74       applied, ot
-00005fe0: 6865 7277 6973 6520 7265 7375 6c74 2077  herwise result w
-00005ff0: 696c 6c20 6265 2065 6d70 7479 2e0a 2020  ill be empty..  
-00006000: 2020 2020 2020 3a70 6172 616d 2073 7461        :param sta
-00006010: 7465 3a20 4c69 7374 206f 6e6c 7920 7275  te: List only ru
-00006020: 6e73 2077 686f 7365 2073 7461 7465 2069  ns whose state i
-00006030: 7320 7370 6563 6966 6965 642e 0a20 2020  s specified..   
-00006040: 2020 2020 203a 7061 7261 6d20 736f 7274       :param sort
-00006050: 3a20 5768 6574 6865 7220 746f 2073 6f72  : Whether to sor
-00006060: 7420 7468 6520 7265 7375 6c74 2061 6363  t the result acc
-00006070: 6f72 6469 6e67 2074 6f20 7468 6569 7220  ording to their 
-00006080: 7374 6172 7420 7469 6d65 2e20 4f74 6865  start time. Othe
-00006090: 7277 6973 652c 2072 6573 756c 7473 2077  rwise, results w
-000060a0: 696c 6c20 6265 0a20 2020 2020 2020 2020  ill be.         
-000060b0: 2020 2072 6574 7572 6e65 6420 6279 2074     returned by t
-000060c0: 6865 6972 2069 6e74 6572 6e61 6c20 6f72  heir internal or
-000060d0: 6465 7220 696e 2074 6865 2044 4220 286f  der in the DB (o
-000060e0: 7264 6572 2077 696c 6c20 6e6f 7420 6265  rder will not be
-000060f0: 2067 7561 7261 6e74 6565 6429 2e0a 2020   guaranteed)..  
-00006100: 2020 2020 2020 3a70 6172 616d 206c 6173        :param las
-00006110: 743a 2044 6570 7265 6361 7465 6420 2d20  t: Deprecated - 
-00006120: 6375 7272 656e 746c 7920 6e6f 7420 7573  currently not us
-00006130: 6564 2e0a 2020 2020 2020 2020 3a70 6172  ed..        :par
-00006140: 616d 2069 7465 723a 2049 6620 6060 5472  am iter: If ``Tr
-00006150: 7565 6060 2072 6574 7572 6e20 7275 6e73  ue`` return runs
-00006160: 2066 726f 6d20 616c 6c20 6974 6572 6174   from all iterat
-00006170: 696f 6e73 2e20 4f74 6865 7277 6973 652c  ions. Otherwise,
-00006180: 2072 6574 7572 6e20 6f6e 6c79 2072 756e   return only run
-00006190: 7320 7768 6f73 6520 6060 6974 6572 6060  s whose ``iter``
-000061a0: 2069 7320 302e 0a20 2020 2020 2020 203a   is 0..        :
-000061b0: 7061 7261 6d20 7374 6172 745f 7469 6d65  param start_time
-000061c0: 5f66 726f 6d3a 2046 696c 7465 7220 6279  _from: Filter by
-000061d0: 2072 756e 2073 7461 7274 2074 696d 6520   run start time 
-000061e0: 696e 2060 605b 7374 6172 745f 7469 6d65  in ``[start_time
-000061f0: 5f66 726f 6d2c 2073 7461 7274 5f74 696d  _from, start_tim
-00006200: 655f 746f 5d60 602e 0a20 2020 2020 2020  e_to]``..       
-00006210: 203a 7061 7261 6d20 7374 6172 745f 7469   :param start_ti
-00006220: 6d65 5f74 6f3a 2046 696c 7465 7220 6279  me_to: Filter by
-00006230: 2072 756e 2073 7461 7274 2074 696d 6520   run start time 
-00006240: 696e 2060 605b 7374 6172 745f 7469 6d65  in ``[start_time
-00006250: 5f66 726f 6d2c 2073 7461 7274 5f74 696d  _from, start_tim
-00006260: 655f 746f 5d60 602e 0a20 2020 2020 2020  e_to]``..       
-00006270: 203a 7061 7261 6d20 6c61 7374 5f75 7064   :param last_upd
-00006280: 6174 655f 7469 6d65 5f66 726f 6d3a 2046  ate_time_from: F
-00006290: 696c 7465 7220 6279 2072 756e 206c 6173  ilter by run las
-000062a0: 7420 7570 6461 7465 2074 696d 6520 696e  t update time in
-000062b0: 2060 6028 6c61 7374 5f75 7064 6174 655f   ``(last_update_
-000062c0: 7469 6d65 5f66 726f 6d2c 0a20 2020 2020  time_from,.     
-000062d0: 2020 2020 2020 206c 6173 745f 7570 6461         last_upda
-000062e0: 7465 5f74 696d 655f 746f 2960 602e 0a20  te_time_to)``.. 
-000062f0: 2020 2020 2020 203a 7061 7261 6d20 6c61         :param la
-00006300: 7374 5f75 7064 6174 655f 7469 6d65 5f74  st_update_time_t
-00006310: 6f3a 2046 696c 7465 7220 6279 2072 756e  o: Filter by run
-00006320: 206c 6173 7420 7570 6461 7465 2074 696d   last update tim
-00006330: 6520 696e 2060 6028 6c61 7374 5f75 7064  e in ``(last_upd
-00006340: 6174 655f 7469 6d65 5f66 726f 6d2c 206c  ate_time_from, l
-00006350: 6173 745f 7570 6461 7465 5f74 696d 655f  ast_update_time_
-00006360: 746f 2960 602e 0a20 2020 2020 2020 203a  to)``..        :
-00006370: 7061 7261 6d20 7061 7274 6974 696f 6e5f  param partition_
-00006380: 6279 3a20 4669 656c 6420 746f 2067 726f  by: Field to gro
-00006390: 7570 2072 6573 756c 7473 2062 792e 204f  up results by. O
-000063a0: 6e6c 7920 616c 6c6f 7765 6420 7661 6c75  nly allowed valu
-000063b0: 6520 6973 2060 6e61 6d65 602e 2057 6865  e is `name`. Whe
-000063c0: 6e20 6070 6172 7469 7469 6f6e 5f62 7960  n `partition_by`
-000063d0: 2069 7320 7370 6563 6966 6965 642c 0a20   is specified,. 
-000063e0: 2020 2020 2020 2020 2020 2074 6865 2060             the `
-000063f0: 7061 7274 6974 696f 6e5f 736f 7274 5f62  partition_sort_b
-00006400: 7960 2070 6172 616d 6574 6572 206d 7573  y` parameter mus
-00006410: 7420 6265 2070 726f 7669 6465 6420 6173  t be provided as
-00006420: 2077 656c 6c2e 0a20 2020 2020 2020 203a   well..        :
-00006430: 7061 7261 6d20 726f 7773 5f70 6572 5f70  param rows_per_p
-00006440: 6172 7469 7469 6f6e 3a20 486f 7720 6d61  artition: How ma
-00006450: 6e79 2074 6f70 2072 6f77 7320 2870 6572  ny top rows (per
-00006460: 2073 6f72 7469 6e67 2064 6566 696e 6564   sorting defined
-00006470: 2062 7920 6070 6172 7469 7469 6f6e 5f73   by `partition_s
-00006480: 6f72 745f 6279 6020 616e 6420 6070 6172  ort_by` and `par
-00006490: 7469 7469 6f6e 5f6f 7264 6572 6029 0a20  tition_order`). 
-000064a0: 2020 2020 2020 2020 2020 2074 6f20 7265             to re
-000064b0: 7475 726e 2070 6572 2067 726f 7570 2e20  turn per group. 
-000064c0: 4465 6661 756c 7420 7661 6c75 6520 6973  Default value is
-000064d0: 2031 2e0a 2020 2020 2020 2020 3a70 6172   1..        :par
-000064e0: 616d 2070 6172 7469 7469 6f6e 5f73 6f72  am partition_sor
-000064f0: 745f 6279 3a20 5768 6174 2066 6965 6c64  t_by: What field
-00006500: 2074 6f20 736f 7274 2074 6865 2072 6573   to sort the res
-00006510: 756c 7473 2062 792c 2077 6974 6869 6e20  ults by, within 
-00006520: 6561 6368 2070 6172 7469 7469 6f6e 2064  each partition d
-00006530: 6566 696e 6564 2062 7920 6070 6172 7469  efined by `parti
-00006540: 7469 6f6e 5f62 7960 2e0a 2020 2020 2020  tion_by`..      
-00006550: 2020 2020 2020 4375 7272 656e 746c 7920        Currently 
-00006560: 7468 6520 6f6e 6c79 2061 6c6c 6f77 6564  the only allowed
-00006570: 2076 616c 7565 7320 6172 6520 6063 7265   values are `cre
-00006580: 6174 6564 6020 616e 6420 6075 7064 6174  ated` and `updat
-00006590: 6564 602e 0a20 2020 2020 2020 203a 7061  ed`..        :pa
-000065a0: 7261 6d20 7061 7274 6974 696f 6e5f 6f72  ram partition_or
-000065b0: 6465 723a 204f 7264 6572 206f 6620 736f  der: Order of so
-000065c0: 7274 696e 6720 7769 7468 696e 2070 6172  rting within par
-000065d0: 7469 7469 6f6e 7320 2d20 6061 7363 6020  titions - `asc` 
-000065e0: 6f72 2060 6465 7363 602e 2044 6566 6175  or `desc`. Defau
-000065f0: 6c74 2069 7320 6064 6573 6360 2e0a 2020  lt is `desc`..  
-00006600: 2020 2020 2020 3a70 6172 616d 206d 6178        :param max
-00006610: 5f70 6172 7469 7469 6f6e 733a 204d 6178  _partitions: Max
-00006620: 696d 616c 206e 756d 6265 7220 6f66 2070  imal number of p
-00006630: 6172 7469 7469 6f6e 7320 746f 2069 6e63  artitions to inc
-00006640: 6c75 6465 2069 6e20 7468 6520 7265 7375  lude in the resu
-00006650: 6c74 2e20 4465 6661 756c 7420 6973 2060  lt. Default is `
-00006660: 3060 2077 6869 6368 206d 6561 6e73 206e  0` which means n
-00006670: 6f0a 2020 2020 2020 2020 2020 2020 6c69  o.            li
-00006680: 6d69 742e 0a20 2020 2020 2020 2022 2222  mit..        """
-00006690: 0a0a 2020 2020 2020 2020 7072 6f6a 6563  ..        projec
-000066a0: 7420 3d20 7072 6f6a 6563 7420 6f72 2063  t = project or c
-000066b0: 6f6e 6669 672e 6465 6661 756c 745f 7072  onfig.default_pr
-000066c0: 6f6a 6563 740a 2020 2020 2020 2020 7061  oject.        pa
-000066d0: 7261 6d73 203d 207b 0a20 2020 2020 2020  rams = {.       
-000066e0: 2020 2020 2022 6e61 6d65 223a 206e 616d       "name": nam
-000066f0: 652c 0a20 2020 2020 2020 2020 2020 2022  e,.            "
-00006700: 7569 6422 3a20 7569 642c 0a20 2020 2020  uid": uid,.     
-00006710: 2020 2020 2020 2022 7072 6f6a 6563 7422         "project"
-00006720: 3a20 7072 6f6a 6563 742c 0a20 2020 2020  : project,.     
-00006730: 2020 2020 2020 2022 6c61 6265 6c22 3a20         "label": 
-00006740: 6c61 6265 6c73 206f 7220 5b5d 2c0a 2020  labels or [],.  
-00006750: 2020 2020 2020 2020 2020 2273 7461 7465            "state
-00006760: 223a 2073 7461 7465 2c0a 2020 2020 2020  ": state,.      
-00006770: 2020 2020 2020 2273 6f72 7422 3a20 626f        "sort": bo
-00006780: 6f6c 3273 7472 2873 6f72 7429 2c0a 2020  ol2str(sort),.  
-00006790: 2020 2020 2020 2020 2020 2269 7465 7222            "iter"
-000067a0: 3a20 626f 6f6c 3273 7472 2869 7465 7229  : bool2str(iter)
-000067b0: 2c0a 2020 2020 2020 2020 2020 2020 2273  ,.            "s
-000067c0: 7461 7274 5f74 696d 655f 6672 6f6d 223a  tart_time_from":
-000067d0: 2064 6174 6574 696d 655f 746f 5f69 736f   datetime_to_iso
-000067e0: 2873 7461 7274 5f74 696d 655f 6672 6f6d  (start_time_from
-000067f0: 292c 0a20 2020 2020 2020 2020 2020 2022  ),.            "
-00006800: 7374 6172 745f 7469 6d65 5f74 6f22 3a20  start_time_to": 
-00006810: 6461 7465 7469 6d65 5f74 6f5f 6973 6f28  datetime_to_iso(
-00006820: 7374 6172 745f 7469 6d65 5f74 6f29 2c0a  start_time_to),.
-00006830: 2020 2020 2020 2020 2020 2020 226c 6173              "las
-00006840: 745f 7570 6461 7465 5f74 696d 655f 6672  t_update_time_fr
-00006850: 6f6d 223a 2064 6174 6574 696d 655f 746f  om": datetime_to
-00006860: 5f69 736f 286c 6173 745f 7570 6461 7465  _iso(last_update
-00006870: 5f74 696d 655f 6672 6f6d 292c 0a20 2020  _time_from),.   
-00006880: 2020 2020 2020 2020 2022 6c61 7374 5f75           "last_u
-00006890: 7064 6174 655f 7469 6d65 5f74 6f22 3a20  pdate_time_to": 
-000068a0: 6461 7465 7469 6d65 5f74 6f5f 6973 6f28  datetime_to_iso(
-000068b0: 6c61 7374 5f75 7064 6174 655f 7469 6d65  last_update_time
-000068c0: 5f74 6f29 2c0a 2020 2020 2020 2020 7d0a  _to),.        }.
-000068d0: 0a20 2020 2020 2020 2069 6620 7061 7274  .        if part
-000068e0: 6974 696f 6e5f 6279 3a0a 2020 2020 2020  ition_by:.      
-000068f0: 2020 2020 2020 7061 7261 6d73 2e75 7064        params.upd
-00006900: 6174 6528 0a20 2020 2020 2020 2020 2020  ate(.           
-00006910: 2020 2020 2073 656c 662e 5f67 656e 6572       self._gener
-00006920: 6174 655f 7061 7274 6974 696f 6e5f 6279  ate_partition_by
-00006930: 5f70 6172 616d 7328 0a20 2020 2020 2020  _params(.       
-00006940: 2020 2020 2020 2020 2020 2020 2073 6368               sch
-00006950: 656d 6173 2e52 756e 5061 7274 6974 696f  emas.RunPartitio
-00006960: 6e42 7946 6965 6c64 2c0a 2020 2020 2020  nByField,.      
-00006970: 2020 2020 2020 2020 2020 2020 2020 7061                pa
-00006980: 7274 6974 696f 6e5f 6279 2c0a 2020 2020  rtition_by,.    
-00006990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000069a0: 726f 7773 5f70 6572 5f70 6172 7469 7469  rows_per_partiti
-000069b0: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
-000069c0: 2020 2020 2020 2020 7061 7274 6974 696f          partitio
-000069d0: 6e5f 736f 7274 5f62 792c 0a20 2020 2020  n_sort_by,.     
-000069e0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-000069f0: 6172 7469 7469 6f6e 5f6f 7264 6572 2c0a  artition_order,.
-00006a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006a10: 2020 2020 6d61 785f 7061 7274 6974 696f      max_partitio
-00006a20: 6e73 2c0a 2020 2020 2020 2020 2020 2020  ns,.            
-00006a30: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
-00006a40: 2020 290a 2020 2020 2020 2020 6572 726f    ).        erro
-00006a50: 7220 3d20 226c 6973 7420 7275 6e73 220a  r = "list runs".
-00006a60: 2020 2020 2020 2020 7265 7370 203d 2073          resp = s
-00006a70: 656c 662e 6170 695f 6361 6c6c 2822 4745  elf.api_call("GE
-00006a80: 5422 2c20 2272 756e 7322 2c20 6572 726f  T", "runs", erro
-00006a90: 722c 2070 6172 616d 733d 7061 7261 6d73  r, params=params
-00006aa0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00006ab0: 2052 756e 4c69 7374 2872 6573 702e 6a73   RunList(resp.js
-00006ac0: 6f6e 2829 5b22 7275 6e73 225d 290a 0a20  on()["runs"]).. 
-00006ad0: 2020 2064 6566 2064 656c 5f72 756e 7328     def del_runs(
-00006ae0: 7365 6c66 2c20 6e61 6d65 3d4e 6f6e 652c  self, name=None,
-00006af0: 2070 726f 6a65 6374 3d4e 6f6e 652c 206c   project=None, l
-00006b00: 6162 656c 733d 4e6f 6e65 2c20 7374 6174  abels=None, stat
-00006b10: 653d 4e6f 6e65 2c20 6461 7973 5f61 676f  e=None, days_ago
-00006b20: 3d30 293a 0a20 2020 2020 2020 2022 2222  =0):.        """
-00006b30: 4465 6c65 7465 2061 2067 726f 7570 206f  Delete a group o
-00006b40: 6620 7275 6e73 2069 6465 6e74 6966 6965  f runs identifie
-00006b50: 6420 6279 2074 6865 2070 6172 616d 6574  d by the paramet
-00006b60: 6572 7320 6f66 2074 6865 2066 756e 6374  ers of the funct
-00006b70: 696f 6e2e 0a0a 2020 2020 2020 2020 4578  ion...        Ex
-00006b80: 616d 706c 653a 3a0a 0a20 2020 2020 2020  ample::..       
-00006b90: 2020 2020 2064 622e 6465 6c5f 7275 6e73       db.del_runs
-00006ba0: 2873 7461 7465 3d27 636f 6d70 6c65 7465  (state='complete
-00006bb0: 6427 290a 0a20 2020 2020 2020 203a 7061  d')..        :pa
-00006bc0: 7261 6d20 6e61 6d65 3a20 4e61 6d65 206f  ram name: Name o
-00006bd0: 6620 7468 6520 7461 736b 2077 6869 6368  f the task which
-00006be0: 2074 6865 2072 756e 7320 6265 6c6f 6e67   the runs belong
-00006bf0: 2074 6f2e 0a20 2020 2020 2020 203a 7061   to..        :pa
-00006c00: 7261 6d20 7072 6f6a 6563 743a 2050 726f  ram project: Pro
-00006c10: 6a65 6374 2074 6f20 7768 6963 6820 7468  ject to which th
-00006c20: 6520 7275 6e73 2062 656c 6f6e 672e 0a20  e runs belong.. 
-00006c30: 2020 2020 2020 203a 7061 7261 6d20 6c61         :param la
-00006c40: 6265 6c73 3a20 4669 6c74 6572 2072 756e  bels: Filter run
-00006c50: 7320 7468 6174 2061 7265 206c 6162 656c  s that are label
-00006c60: 6564 2075 7369 6e67 2074 6865 7365 2073  ed using these s
-00006c70: 7065 6369 6669 6320 6c61 6265 6c20 7661  pecific label va
-00006c80: 6c75 6573 2e0a 2020 2020 2020 2020 3a70  lues..        :p
-00006c90: 6172 616d 2073 7461 7465 3a20 4669 6c74  aram state: Filt
-00006ca0: 6572 206f 6e6c 7920 7275 6e73 2077 6869  er only runs whi
-00006cb0: 6368 2061 7265 2069 6e20 7468 6973 2073  ch are in this s
-00006cc0: 7461 7465 2e0a 2020 2020 2020 2020 3a70  tate..        :p
-00006cd0: 6172 616d 2064 6179 735f 6167 6f3a 2046  aram days_ago: F
-00006ce0: 696c 7465 7220 7275 6e73 2077 686f 7365  ilter runs whose
-00006cf0: 2073 7461 7274 2074 696d 6520 6973 206e   start time is n
-00006d00: 6577 6572 2074 6861 6e20 7468 6973 2070  ewer than this p
-00006d10: 6172 616d 6574 6572 2e0a 2020 2020 2020  arameter..      
-00006d20: 2020 2222 220a 0a20 2020 2020 2020 2070    """..        p
-00006d30: 726f 6a65 6374 203d 2070 726f 6a65 6374  roject = project
-00006d40: 206f 7220 636f 6e66 6967 2e64 6566 6175   or config.defau
-00006d50: 6c74 5f70 726f 6a65 6374 0a20 2020 2020  lt_project.     
-00006d60: 2020 2070 6172 616d 7320 3d20 7b0a 2020     params = {.  
-00006d70: 2020 2020 2020 2020 2020 226e 616d 6522            "name"
-00006d80: 3a20 6e61 6d65 2c0a 2020 2020 2020 2020  : name,.        
-00006d90: 2020 2020 2270 726f 6a65 6374 223a 2070      "project": p
-00006da0: 726f 6a65 6374 2c0a 2020 2020 2020 2020  roject,.        
-00006db0: 2020 2020 226c 6162 656c 223a 206c 6162      "label": lab
-00006dc0: 656c 7320 6f72 205b 5d2c 0a20 2020 2020  els or [],.     
-00006dd0: 2020 2020 2020 2022 7374 6174 6522 3a20         "state": 
-00006de0: 7374 6174 652c 0a20 2020 2020 2020 2020  state,.         
-00006df0: 2020 2022 6461 7973 5f61 676f 223a 2073     "days_ago": s
-00006e00: 7472 2864 6179 735f 6167 6f29 2c0a 2020  tr(days_ago),.  
-00006e10: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
-00006e20: 6572 726f 7220 3d20 2264 656c 2072 756e  error = "del run
-00006e30: 7322 0a20 2020 2020 2020 2073 656c 662e  s".        self.
-00006e40: 6170 695f 6361 6c6c 2822 4445 4c45 5445  api_call("DELETE
-00006e50: 222c 2022 7275 6e73 222c 2065 7272 6f72  ", "runs", error
-00006e60: 2c20 7061 7261 6d73 3d70 6172 616d 7329  , params=params)
-00006e70: 0a0a 2020 2020 6465 6620 7374 6f72 655f  ..    def store_
-00006e80: 6172 7469 6661 6374 2873 656c 662c 206b  artifact(self, k
-00006e90: 6579 2c20 6172 7469 6661 6374 2c20 7569  ey, artifact, ui
-00006ea0: 642c 2069 7465 723d 4e6f 6e65 2c20 7461  d, iter=None, ta
-00006eb0: 673d 4e6f 6e65 2c20 7072 6f6a 6563 743d  g=None, project=
-00006ec0: 2222 293a 0a20 2020 2020 2020 2022 2222  ""):.        """
-00006ed0: 5374 6f72 6520 616e 2061 7274 6966 6163  Store an artifac
-00006ee0: 7420 696e 2074 6865 2044 422e 0a0a 2020  t in the DB...  
-00006ef0: 2020 2020 2020 3a70 6172 616d 206b 6579        :param key
-00006f00: 3a20 4964 656e 7469 6679 696e 6720 6b65  : Identifying ke
-00006f10: 7920 6f66 2074 6865 2061 7274 6966 6163  y of the artifac
-00006f20: 742e 0a20 2020 2020 2020 203a 7061 7261  t..        :para
-00006f30: 6d20 6172 7469 6661 6374 3a20 5468 6520  m artifact: The 
-00006f40: 6163 7475 616c 2061 7274 6966 6163 7420  actual artifact 
-00006f50: 746f 2073 746f 7265 2e0a 2020 2020 2020  to store..      
-00006f60: 2020 3a70 6172 616d 2075 6964 3a20 4120    :param uid: A 
-00006f70: 756e 6971 7565 2049 4420 666f 7220 7468  unique ID for th
-00006f80: 6973 2073 7065 6369 6669 6320 7665 7273  is specific vers
-00006f90: 696f 6e20 6f66 2074 6865 2061 7274 6966  ion of the artif
-00006fa0: 6163 742e 0a20 2020 2020 2020 203a 7061  act..        :pa
-00006fb0: 7261 6d20 6974 6572 3a20 5468 6520 7461  ram iter: The ta
-00006fc0: 736b 2069 7465 7261 7469 6f6e 2077 6869  sk iteration whi
-00006fd0: 6368 2067 656e 6572 6174 6564 2074 6869  ch generated thi
-00006fe0: 7320 6172 7469 6661 6374 2e20 4966 2060  s artifact. If `
-00006ff0: 6069 7465 7260 6020 6973 206e 6f74 2060  `iter`` is not `
-00007000: 604e 6f6e 6560 6020 7468 6520 6974 6572  `None`` the iter
-00007010: 6174 696f 6e20 7769 6c6c 0a20 2020 2020  ation will.     
-00007020: 2020 2020 2020 2062 6520 6164 6465 6420         be added 
-00007030: 746f 2074 6865 206b 6579 2070 726f 7669  to the key provi
-00007040: 6465 6420 746f 2067 656e 6572 6174 6520  ded to generate 
-00007050: 6120 756e 6971 7565 206b 6579 2066 6f72  a unique key for
-00007060: 2074 6865 2061 7274 6966 6163 7420 6f66   the artifact of
-00007070: 2074 6865 2073 7065 6369 6669 6320 6974   the specific it
-00007080: 6572 6174 696f 6e2e 0a20 2020 2020 2020  eration..       
-00007090: 203a 7061 7261 6d20 7461 673a 2054 6167   :param tag: Tag
-000070a0: 206f 6620 7468 6520 6172 7469 6661 6374   of the artifact
-000070b0: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-000070c0: 2070 726f 6a65 6374 3a20 5072 6f6a 6563   project: Projec
-000070d0: 7420 7468 6174 2074 6865 2061 7274 6966  t that the artif
-000070e0: 6163 7420 6265 6c6f 6e67 7320 746f 2e0a  act belongs to..
-000070f0: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
-00007100: 2020 2020 2065 6e64 706f 696e 745f 7061       endpoint_pa
-00007110: 7468 203d 2066 2270 726f 6a65 6374 732f  th = f"projects/
-00007120: 7b70 726f 6a65 6374 7d2f 6172 7469 6661  {project}/artifa
-00007130: 6374 732f 7b75 6964 7d2f 7b6b 6579 7d22  cts/{uid}/{key}"
-00007140: 0a20 2020 2020 2020 2070 6172 616d 7320  .        params 
-00007150: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
-00007160: 2274 6167 223a 2074 6167 2c0a 2020 2020  "tag": tag,.    
-00007170: 2020 2020 7d0a 2020 2020 2020 2020 6966      }.        if
-00007180: 2069 7465 723a 0a20 2020 2020 2020 2020   iter:.         
-00007190: 2020 2070 6172 616d 735b 2269 7465 7222     params["iter"
-000071a0: 5d20 3d20 7374 7228 6974 6572 290a 0a20  ] = str(iter).. 
-000071b0: 2020 2020 2020 2065 7272 6f72 203d 2066         error = f
-000071c0: 2273 746f 7265 2061 7274 6966 6163 7420  "store artifact 
-000071d0: 7b70 726f 6a65 6374 7d2f 7b75 6964 7d2f  {project}/{uid}/
-000071e0: 7b6b 6579 7d22 0a0a 2020 2020 2020 2020  {key}"..        
-000071f0: 626f 6479 203d 205f 6173 5f6a 736f 6e28  body = _as_json(
-00007200: 6172 7469 6661 6374 290a 2020 2020 2020  artifact).      
-00007210: 2020 7365 6c66 2e61 7069 5f63 616c 6c28    self.api_call(
-00007220: 2250 4f53 5422 2c20 656e 6470 6f69 6e74  "POST", endpoint
-00007230: 5f70 6174 682c 2065 7272 6f72 2c20 7061  _path, error, pa
-00007240: 7261 6d73 3d70 6172 616d 732c 2062 6f64  rams=params, bod
-00007250: 793d 626f 6479 290a 0a20 2020 2064 6566  y=body)..    def
-00007260: 2072 6561 645f 6172 7469 6661 6374 2873   read_artifact(s
-00007270: 656c 662c 206b 6579 2c20 7461 673d 4e6f  elf, key, tag=No
-00007280: 6e65 2c20 6974 6572 3d4e 6f6e 652c 2070  ne, iter=None, p
-00007290: 726f 6a65 6374 3d22 2229 3a0a 2020 2020  roject=""):.    
-000072a0: 2020 2020 2222 2252 6561 6420 616e 2061      """Read an a
-000072b0: 7274 6966 6163 742c 2069 6465 6e74 6966  rtifact, identif
-000072c0: 6965 6420 6279 2069 7473 206b 6579 2c20  ied by its key, 
-000072d0: 7461 6720 616e 6420 6974 6572 6174 696f  tag and iteratio
-000072e0: 6e2e 2222 220a 0a20 2020 2020 2020 2070  n."""..        p
-000072f0: 726f 6a65 6374 203d 2070 726f 6a65 6374  roject = project
-00007300: 206f 7220 636f 6e66 6967 2e64 6566 6175   or config.defau
-00007310: 6c74 5f70 726f 6a65 6374 0a20 2020 2020  lt_project.     
-00007320: 2020 2074 6167 203d 2074 6167 206f 7220     tag = tag or 
-00007330: 226c 6174 6573 7422 0a20 2020 2020 2020  "latest".       
-00007340: 2065 6e64 706f 696e 745f 7061 7468 203d   endpoint_path =
-00007350: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
-00007360: 6a65 6374 7d2f 6172 7469 6661 6374 732f  ject}/artifacts/
-00007370: 7b6b 6579 7d3f 7461 673d 7b74 6167 7d22  {key}?tag={tag}"
-00007380: 0a20 2020 2020 2020 2065 7272 6f72 203d  .        error =
-00007390: 2066 2272 6561 6420 6172 7469 6661 6374   f"read artifact
-000073a0: 207b 7072 6f6a 6563 747d 2f7b 6b65 797d   {project}/{key}
-000073b0: 220a 2020 2020 2020 2020 2320 6578 706c  ".        # expl
-000073c0: 6963 6974 6c79 2073 6574 2061 7274 6966  icitly set artif
-000073d0: 6163 7473 2066 6f72 6d61 7420 746f 2027  acts format to '
-000073e0: 6675 6c6c 2720 7369 6e63 6520 6f6c 6420  full' since old 
-000073f0: 7365 7276 6572 7320 6d61 7920 6465 6661  servers may defa
-00007400: 756c 7420 746f 2027 6c65 6761 6379 270a  ult to 'legacy'.
-00007410: 2020 2020 2020 2020 7061 7261 6d73 203d          params =
-00007420: 207b 2266 6f72 6d61 7422 3a20 7363 6865   {"format": sche
-00007430: 6d61 732e 4172 7469 6661 6374 7346 6f72  mas.ArtifactsFor
-00007440: 6d61 742e 6675 6c6c 2e76 616c 7565 7d0a  mat.full.value}.
-00007450: 2020 2020 2020 2020 6966 2069 7465 723a          if iter:
-00007460: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
-00007470: 616d 735b 2269 7465 7222 5d20 3d20 7374  ams["iter"] = st
-00007480: 7228 6974 6572 290a 2020 2020 2020 2020  r(iter).        
-00007490: 7265 7370 203d 2073 656c 662e 6170 695f  resp = self.api_
-000074a0: 6361 6c6c 2822 4745 5422 2c20 656e 6470  call("GET", endp
-000074b0: 6f69 6e74 5f70 6174 682c 2065 7272 6f72  oint_path, error
-000074c0: 2c20 7061 7261 6d73 3d70 6172 616d 7329  , params=params)
-000074d0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000074e0: 7265 7370 2e6a 736f 6e28 295b 2264 6174  resp.json()["dat
-000074f0: 6122 5d0a 0a20 2020 2064 6566 2064 656c  a"]..    def del
-00007500: 5f61 7274 6966 6163 7428 7365 6c66 2c20  _artifact(self, 
-00007510: 6b65 792c 2074 6167 3d4e 6f6e 652c 2070  key, tag=None, p
-00007520: 726f 6a65 6374 3d22 2229 3a0a 2020 2020  roject=""):.    
-00007530: 2020 2020 2222 2244 656c 6574 6520 616e      """Delete an
-00007540: 2061 7274 6966 6163 742e 2222 220a 0a20   artifact.""".. 
-00007550: 2020 2020 2020 2065 6e64 706f 696e 745f         endpoint_
-00007560: 7061 7468 203d 2066 2270 726f 6a65 6374  path = f"project
-00007570: 732f 7b70 726f 6a65 6374 7d2f 6172 7469  s/{project}/arti
-00007580: 6661 6374 732f 7b6b 6579 7d22 0a20 2020  facts/{key}".   
-00007590: 2020 2020 2070 6172 616d 7320 3d20 7b0a       params = {.
-000075a0: 2020 2020 2020 2020 2020 2020 226b 6579              "key
-000075b0: 223a 206b 6579 2c0a 2020 2020 2020 2020  ": key,.        
-000075c0: 2020 2020 2274 6167 223a 2074 6167 2c0a      "tag": tag,.
-000075d0: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-000075e0: 2020 6572 726f 7220 3d20 6622 6465 6c20    error = f"del 
-000075f0: 6172 7469 6661 6374 207b 7072 6f6a 6563  artifact {projec
-00007600: 747d 2f7b 6b65 797d 220a 2020 2020 2020  t}/{key}".      
-00007610: 2020 7365 6c66 2e61 7069 5f63 616c 6c28    self.api_call(
-00007620: 2244 454c 4554 4522 2c20 656e 6470 6f69  "DELETE", endpoi
-00007630: 6e74 5f70 6174 682c 2065 7272 6f72 2c20  nt_path, error, 
-00007640: 7061 7261 6d73 3d70 6172 616d 7329 0a0a  params=params)..
-00007650: 2020 2020 6465 6620 6c69 7374 5f61 7274      def list_art
-00007660: 6966 6163 7473 280a 2020 2020 2020 2020  ifacts(.        
-00007670: 7365 6c66 2c0a 2020 2020 2020 2020 6e61  self,.        na
-00007680: 6d65 3d4e 6f6e 652c 0a20 2020 2020 2020  me=None,.       
-00007690: 2070 726f 6a65 6374 3d4e 6f6e 652c 0a20   project=None,. 
-000076a0: 2020 2020 2020 2074 6167 3d4e 6f6e 652c         tag=None,
-000076b0: 0a20 2020 2020 2020 206c 6162 656c 733d  .        labels=
-000076c0: 4e6f 6e65 2c0a 2020 2020 2020 2020 7369  None,.        si
-000076d0: 6e63 653d 4e6f 6e65 2c0a 2020 2020 2020  nce=None,.      
-000076e0: 2020 756e 7469 6c3d 4e6f 6e65 2c0a 2020    until=None,.  
-000076f0: 2020 2020 2020 6974 6572 3a20 696e 7420        iter: int 
-00007700: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-00007710: 6265 7374 5f69 7465 7261 7469 6f6e 3a20  best_iteration: 
-00007720: 626f 6f6c 203d 2046 616c 7365 2c0a 2020  bool = False,.  
-00007730: 2020 2020 2020 6b69 6e64 3a20 7374 7220        kind: str 
-00007740: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-00007750: 6361 7465 676f 7279 3a20 556e 696f 6e5b  category: Union[
-00007760: 7374 722c 2073 6368 656d 6173 2e41 7274  str, schemas.Art
-00007770: 6966 6163 7443 6174 6567 6f72 6965 735d  ifactCategories]
-00007780: 203d 204e 6f6e 652c 0a20 2020 2029 202d   = None,.    ) -
-00007790: 3e20 4172 7469 6661 6374 4c69 7374 3a0a  > ArtifactList:.
-000077a0: 2020 2020 2020 2020 2222 224c 6973 7420          """List 
-000077b0: 6172 7469 6661 6374 7320 6669 6c74 6572  artifacts filter
-000077c0: 6564 2062 7920 7661 7269 6f75 7320 7061  ed by various pa
-000077d0: 7261 6d65 7465 7273 2e0a 0a20 2020 2020  rameters...     
-000077e0: 2020 2045 7861 6d70 6c65 733a 3a0a 0a20     Examples::.. 
-000077f0: 2020 2020 2020 2020 2020 2023 2053 686f             # Sho
-00007800: 7720 6c61 7465 7374 2076 6572 7369 6f6e  w latest version
-00007810: 206f 6620 616c 6c20 6172 7469 6661 6374   of all artifact
-00007820: 7320 696e 2070 726f 6a65 6374 0a20 2020  s in project.   
-00007830: 2020 2020 2020 2020 206c 6174 6573 745f           latest_
-00007840: 6172 7469 6661 6374 7320 3d20 6462 2e6c  artifacts = db.l
-00007850: 6973 745f 6172 7469 6661 6374 7328 2727  ist_artifacts(''
-00007860: 2c20 7461 673d 276c 6174 6573 7427 2c20  , tag='latest', 
-00007870: 7072 6f6a 6563 743d 2769 7269 7327 290a  project='iris').
-00007880: 2020 2020 2020 2020 2020 2020 2320 6368              # ch
-00007890: 6563 6b20 6469 6666 6572 656e 7420 6172  eck different ar
-000078a0: 7469 6661 6374 2076 6572 7369 6f6e 7320  tifact versions 
-000078b0: 666f 7220 6120 7370 6563 6966 6963 2061  for a specific a
-000078c0: 7274 6966 6163 740a 2020 2020 2020 2020  rtifact.        
-000078d0: 2020 2020 7265 7375 6c74 5f76 6572 7369      result_versi
-000078e0: 6f6e 7320 3d20 6462 2e6c 6973 745f 6172  ons = db.list_ar
-000078f0: 7469 6661 6374 7328 2772 6573 756c 7473  tifacts('results
-00007900: 272c 2074 6167 3d27 2a27 2c20 7072 6f6a  ', tag='*', proj
-00007910: 6563 743d 2769 7269 7327 290a 0a20 2020  ect='iris')..   
-00007920: 2020 2020 203a 7061 7261 6d20 6e61 6d65       :param name
-00007930: 3a20 4e61 6d65 206f 6620 6172 7469 6661  : Name of artifa
-00007940: 6374 7320 746f 2072 6574 7269 6576 652e  cts to retrieve.
-00007950: 204e 616d 6520 6973 2075 7365 6420 6173   Name is used as
-00007960: 2061 206c 696b 6520 7175 6572 792c 2061   a like query, a
-00007970: 6e64 2069 7320 6e6f 7420 6361 7365 2d73  nd is not case-s
-00007980: 656e 7369 7469 7665 2e20 5468 6973 206d  ensitive. This m
-00007990: 6561 6e73 0a20 2020 2020 2020 2020 2020  eans.           
-000079a0: 2074 6861 7420 7175 6572 7969 6e67 2066   that querying f
-000079b0: 6f72 2060 606e 616d 6560 6020 6d61 7920  or ``name`` may 
-000079c0: 7265 7475 726e 2061 7274 6966 6163 7473  return artifacts
-000079d0: 206e 616d 6564 2060 606d 795f 4e61 6d65   named ``my_Name
-000079e0: 5f31 6060 206f 7220 6060 7375 726e 616d  _1`` or ``surnam
-000079f0: 6560 602e 0a20 2020 2020 2020 203a 7061  e``..        :pa
-00007a00: 7261 6d20 7072 6f6a 6563 743a 2050 726f  ram project: Pro
-00007a10: 6a65 6374 206e 616d 652e 0a20 2020 2020  ject name..     
-00007a20: 2020 203a 7061 7261 6d20 7461 673a 2052     :param tag: R
-00007a30: 6574 7572 6e20 6172 7469 6661 6374 7320  eturn artifacts 
-00007a40: 6173 7369 676e 6564 2074 6869 7320 7461  assigned this ta
-00007a50: 672e 0a20 2020 2020 2020 203a 7061 7261  g..        :para
-00007a60: 6d20 6c61 6265 6c73 3a20 5265 7475 726e  m labels: Return
-00007a70: 2061 7274 6966 6163 7473 2074 6861 7420   artifacts that 
-00007a80: 6861 7665 2074 6865 7365 206c 6162 656c  have these label
-00007a90: 732e 0a20 2020 2020 2020 203a 7061 7261  s..        :para
-00007aa0: 6d20 7369 6e63 653a 204e 6f74 2069 6e20  m since: Not in 
-00007ab0: 7573 6520 696e 203a 7079 3a63 6c61 7373  use in :py:class
-00007ac0: 3a60 4854 5450 5275 6e44 4260 2e0a 2020  :`HTTPRunDB`..  
-00007ad0: 2020 2020 2020 3a70 6172 616d 2075 6e74        :param unt
-00007ae0: 696c 3a20 4e6f 7420 696e 2075 7365 2069  il: Not in use i
-00007af0: 6e20 3a70 793a 636c 6173 733a 6048 5454  n :py:class:`HTT
-00007b00: 5052 756e 4442 602e 0a20 2020 2020 2020  PRunDB`..       
-00007b10: 203a 7061 7261 6d20 6974 6572 3a20 5265   :param iter: Re
-00007b20: 7475 726e 2061 7274 6966 6163 7473 2066  turn artifacts f
-00007b30: 726f 6d20 6120 7370 6563 6966 6963 2069  rom a specific i
-00007b40: 7465 7261 7469 6f6e 2028 7768 6572 6520  teration (where 
-00007b50: 6060 6974 6572 3d30 6060 206d 6561 6e73  ``iter=0`` means
-00007b60: 2074 6865 2072 6f6f 7420 6974 6572 6174   the root iterat
-00007b70: 696f 6e29 2e20 4966 0a20 2020 2020 2020  ion). If.       
-00007b80: 2020 2020 2060 604e 6f6e 6560 6020 2864       ``None`` (d
-00007b90: 6566 6175 6c74 2920 7265 7475 726e 2061  efault) return a
-00007ba0: 7274 6966 6163 7473 2066 726f 6d20 616c  rtifacts from al
-00007bb0: 6c20 6974 6572 6174 696f 6e73 2e0a 2020  l iterations..  
-00007bc0: 2020 2020 2020 3a70 6172 616d 2062 6573        :param bes
-00007bd0: 745f 6974 6572 6174 696f 6e3a 2052 6574  t_iteration: Ret
-00007be0: 7572 6e73 2074 6865 2061 7274 6966 6163  urns the artifac
-00007bf0: 7420 7768 6963 6820 6265 6c6f 6e67 7320  t which belongs 
-00007c00: 746f 2074 6865 2062 6573 7420 6974 6572  to the best iter
-00007c10: 6174 696f 6e20 6f66 2061 2067 6976 656e  ation of a given
-00007c20: 2072 756e 2c20 696e 2074 6865 2063 6173   run, in the cas
-00007c30: 6520 6f66 0a20 2020 2020 2020 2020 2020  e of.           
-00007c40: 2061 7274 6966 6163 7473 2067 656e 6572   artifacts gener
-00007c50: 6174 6564 2066 726f 6d20 6120 6879 7065  ated from a hype
-00007c60: 722d 7061 7261 6d20 7275 6e2e 2049 6620  r-param run. If 
-00007c70: 6f6e 6c79 2061 2073 696e 676c 6520 6974  only a single it
-00007c80: 6572 6174 696f 6e20 6578 6973 7473 2c20  eration exists, 
-00007c90: 7769 6c6c 2072 6574 7572 6e20 7468 6520  will return the 
-00007ca0: 6172 7469 6661 6374 0a20 2020 2020 2020  artifact.       
-00007cb0: 2020 2020 2066 726f 6d20 7468 6174 2069       from that i
-00007cc0: 7465 7261 7469 6f6e 2e20 4966 2075 7369  teration. If usi
-00007cd0: 6e67 2060 6062 6573 745f 6974 6572 6060  ng ``best_iter``
-00007ce0: 2c20 7468 6520 6060 6974 6572 6060 2070  , the ``iter`` p
-00007cf0: 6172 616d 6574 6572 206d 7573 7420 6e6f  arameter must no
-00007d00: 7420 6265 2075 7365 642e 0a20 2020 2020  t be used..     
-00007d10: 2020 203a 7061 7261 6d20 6b69 6e64 3a20     :param kind: 
-00007d20: 5265 7475 726e 2061 7274 6966 6163 7473  Return artifacts
-00007d30: 206f 6620 7468 6520 7265 7175 6573 7465   of the requeste
-00007d40: 6420 6b69 6e64 2e0a 2020 2020 2020 2020  d kind..        
-00007d50: 3a70 6172 616d 2063 6174 6567 6f72 793a  :param category:
-00007d60: 2052 6574 7572 6e20 6172 7469 6661 6374   Return artifact
-00007d70: 7320 6f66 2074 6865 2072 6571 7565 7374  s of the request
-00007d80: 6564 2063 6174 6567 6f72 792e 0a20 2020  ed category..   
-00007d90: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
-00007da0: 2020 7072 6f6a 6563 7420 3d20 7072 6f6a    project = proj
-00007db0: 6563 7420 6f72 2063 6f6e 6669 672e 6465  ect or config.de
-00007dc0: 6661 756c 745f 7072 6f6a 6563 740a 0a20  fault_project.. 
-00007dd0: 2020 2020 2020 2070 6172 616d 7320 3d20         params = 
-00007de0: 7b0a 2020 2020 2020 2020 2020 2020 226e  {.            "n
-00007df0: 616d 6522 3a20 6e61 6d65 2c0a 2020 2020  ame": name,.    
-00007e00: 2020 2020 2020 2020 2274 6167 223a 2074          "tag": t
-00007e10: 6167 2c0a 2020 2020 2020 2020 2020 2020  ag,.            
-00007e20: 226c 6162 656c 223a 206c 6162 656c 7320  "label": labels 
-00007e30: 6f72 205b 5d2c 0a20 2020 2020 2020 2020  or [],.         
-00007e40: 2020 2022 6974 6572 223a 2069 7465 722c     "iter": iter,
-00007e50: 0a20 2020 2020 2020 2020 2020 2022 6265  .            "be
-00007e60: 7374 2d69 7465 7261 7469 6f6e 223a 2062  st-iteration": b
-00007e70: 6573 745f 6974 6572 6174 696f 6e2c 0a20  est_iteration,. 
-00007e80: 2020 2020 2020 2020 2020 2022 6b69 6e64             "kind
-00007e90: 223a 206b 696e 642c 0a20 2020 2020 2020  ": kind,.       
-00007ea0: 2020 2020 2022 6361 7465 676f 7279 223a       "category":
-00007eb0: 2063 6174 6567 6f72 792c 0a20 2020 2020   category,.     
-00007ec0: 2020 2020 2020 2022 666f 726d 6174 223a         "format":
-00007ed0: 2073 6368 656d 6173 2e41 7274 6966 6163   schemas.Artifac
-00007ee0: 7473 466f 726d 6174 2e66 756c 6c2e 7661  tsFormat.full.va
-00007ef0: 6c75 652c 0a20 2020 2020 2020 207d 0a20  lue,.        }. 
-00007f00: 2020 2020 2020 2065 7272 6f72 203d 2022         error = "
-00007f10: 6c69 7374 2061 7274 6966 6163 7473 220a  list artifacts".
-00007f20: 2020 2020 2020 2020 656e 6470 6f69 6e74          endpoint
-00007f30: 5f70 6174 6820 3d20 6622 7072 6f6a 6563  _path = f"projec
-00007f40: 7473 2f7b 7072 6f6a 6563 747d 2f61 7274  ts/{project}/art
-00007f50: 6966 6163 7473 220a 2020 2020 2020 2020  ifacts".        
-00007f60: 7265 7370 203d 2073 656c 662e 6170 695f  resp = self.api_
-00007f70: 6361 6c6c 2822 4745 5422 2c20 656e 6470  call("GET", endp
-00007f80: 6f69 6e74 5f70 6174 682c 2065 7272 6f72  oint_path, error
-00007f90: 2c20 7061 7261 6d73 3d70 6172 616d 7329  , params=params)
-00007fa0: 0a20 2020 2020 2020 2076 616c 7565 7320  .        values 
-00007fb0: 3d20 4172 7469 6661 6374 4c69 7374 2872  = ArtifactList(r
-00007fc0: 6573 702e 6a73 6f6e 2829 5b22 6172 7469  esp.json()["arti
-00007fd0: 6661 6374 7322 5d29 0a20 2020 2020 2020  facts"]).       
-00007fe0: 2076 616c 7565 732e 7461 6720 3d20 7461   values.tag = ta
-00007ff0: 670a 2020 2020 2020 2020 7265 7475 726e  g.        return
-00008000: 2076 616c 7565 730a 0a20 2020 2064 6566   values..    def
-00008010: 2064 656c 5f61 7274 6966 6163 7473 2873   del_artifacts(s
-00008020: 656c 662c 206e 616d 653d 4e6f 6e65 2c20  elf, name=None, 
-00008030: 7072 6f6a 6563 743d 4e6f 6e65 2c20 7461  project=None, ta
-00008040: 673d 4e6f 6e65 2c20 6c61 6265 6c73 3d4e  g=None, labels=N
-00008050: 6f6e 652c 2064 6179 735f 6167 6f3d 3029  one, days_ago=0)
-00008060: 3a0a 2020 2020 2020 2020 2222 2244 656c  :.        """Del
-00008070: 6574 6520 6172 7469 6661 6374 7320 7265  ete artifacts re
-00008080: 6665 7265 6e63 6564 2062 7920 7468 6520  ferenced by the 
-00008090: 7061 7261 6d65 7465 7273 2e0a 0a20 2020  parameters...   
-000080a0: 2020 2020 203a 7061 7261 6d20 6e61 6d65       :param name
-000080b0: 3a20 4e61 6d65 206f 6620 6172 7469 6661  : Name of artifa
-000080c0: 6374 7320 746f 2064 656c 6574 652e 204e  cts to delete. N
-000080d0: 6f74 6520 7468 6174 2074 6869 7320 6973  ote that this is
-000080e0: 2061 206c 696b 6520 7175 6572 792c 2061   a like query, a
-000080f0: 6e64 2069 7320 6361 7365 2d69 6e73 656e  nd is case-insen
-00008100: 7369 7469 7665 2e20 5365 650a 2020 2020  sitive. See.    
-00008110: 2020 2020 2020 2020 3a70 793a 6675 6e63          :py:func
-00008120: 3a60 7e6c 6973 745f 6172 7469 6661 6374  :`~list_artifact
-00008130: 7360 2066 6f72 206d 6f72 6520 6465 7461  s` for more deta
-00008140: 696c 732e 0a20 2020 2020 2020 203a 7061  ils..        :pa
-00008150: 7261 6d20 7072 6f6a 6563 743a 2050 726f  ram project: Pro
-00008160: 6a65 6374 2074 6861 7420 6172 7469 6661  ject that artifa
-00008170: 6374 7320 6265 6c6f 6e67 2074 6f2e 0a20  cts belong to.. 
-00008180: 2020 2020 2020 203a 7061 7261 6d20 7461         :param ta
-00008190: 673a 2043 686f 6f73 6520 6172 7469 6661  g: Choose artifa
-000081a0: 6374 7320 7768 6f20 6172 6520 6173 7369  cts who are assi
-000081b0: 676e 6564 2074 6869 7320 7461 672e 0a20  gned this tag.. 
-000081c0: 2020 2020 2020 203a 7061 7261 6d20 6c61         :param la
-000081d0: 6265 6c73 3a20 4368 6f6f 7365 2061 7274  bels: Choose art
-000081e0: 6966 6163 7473 2077 6869 6368 2061 7265  ifacts which are
-000081f0: 206c 6162 656c 6564 2e0a 2020 2020 2020   labeled..      
-00008200: 2020 3a70 6172 616d 2064 6179 735f 6167    :param days_ag
-00008210: 6f3a 2054 6869 7320 7061 7261 6d65 7465  o: This paramete
-00008220: 7220 6973 2064 6570 7265 6361 7465 6420  r is deprecated 
-00008230: 616e 6420 6e6f 7420 7573 6564 2e0a 2020  and not used..  
-00008240: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-00008250: 2020 7072 6f6a 6563 7420 3d20 7072 6f6a    project = proj
-00008260: 6563 7420 6f72 2063 6f6e 6669 672e 6465  ect or config.de
-00008270: 6661 756c 745f 7072 6f6a 6563 740a 2020  fault_project.  
-00008280: 2020 2020 2020 7061 7261 6d73 203d 207b        params = {
-00008290: 0a20 2020 2020 2020 2020 2020 2022 6e61  .            "na
-000082a0: 6d65 223a 206e 616d 652c 0a20 2020 2020  me": name,.     
-000082b0: 2020 2020 2020 2022 7461 6722 3a20 7461         "tag": ta
-000082c0: 672c 0a20 2020 2020 2020 2020 2020 2022  g,.            "
-000082d0: 6c61 6265 6c22 3a20 6c61 6265 6c73 206f  label": labels o
-000082e0: 7220 5b5d 2c0a 2020 2020 2020 2020 2020  r [],.          
-000082f0: 2020 2264 6179 735f 6167 6f22 3a20 7374    "days_ago": st
-00008300: 7228 6461 7973 5f61 676f 292c 0a20 2020  r(days_ago),.   
-00008310: 2020 2020 207d 0a20 2020 2020 2020 2065       }.        e
-00008320: 7272 6f72 203d 2022 6465 6c20 6172 7469  rror = "del arti
-00008330: 6661 6374 7322 0a20 2020 2020 2020 2065  facts".        e
-00008340: 6e64 706f 696e 745f 7061 7468 203d 2066  ndpoint_path = f
-00008350: 2270 726f 6a65 6374 732f 7b70 726f 6a65  "projects/{proje
-00008360: 6374 7d2f 6172 7469 6661 6374 7322 0a20  ct}/artifacts". 
-00008370: 2020 2020 2020 2073 656c 662e 6170 695f         self.api_
-00008380: 6361 6c6c 2822 4445 4c45 5445 222c 2065  call("DELETE", e
-00008390: 6e64 706f 696e 745f 7061 7468 2c20 6572  ndpoint_path, er
-000083a0: 726f 722c 2070 6172 616d 733d 7061 7261  ror, params=para
-000083b0: 6d73 290a 0a20 2020 2064 6566 206c 6973  ms)..    def lis
-000083c0: 745f 6172 7469 6661 6374 5f74 6167 7328  t_artifact_tags(
-000083d0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
-000083e0: 2020 2020 2020 2070 726f 6a65 6374 3d4e         project=N
-000083f0: 6f6e 652c 0a20 2020 2020 2020 2063 6174  one,.        cat
-00008400: 6567 6f72 793a 2055 6e69 6f6e 5b73 7472  egory: Union[str
-00008410: 2c20 7363 6865 6d61 732e 4172 7469 6661  , schemas.Artifa
-00008420: 6374 4361 7465 676f 7269 6573 5d20 3d20  ctCategories] = 
-00008430: 4e6f 6e65 2c0a 2020 2020 2920 2d3e 204c  None,.    ) -> L
-00008440: 6973 745b 7374 725d 3a0a 2020 2020 2020  ist[str]:.      
-00008450: 2020 2222 2252 6574 7572 6e20 6120 6c69    """Return a li
-00008460: 7374 206f 6620 616c 6c20 7468 6520 7461  st of all the ta
-00008470: 6773 2061 7373 6967 6e65 6420 746f 2061  gs assigned to a
-00008480: 7274 6966 6163 7473 2069 6e20 7468 6520  rtifacts in the 
-00008490: 7363 6f70 6520 6f66 2074 6865 2067 6976  scope of the giv
-000084a0: 656e 2070 726f 6a65 6374 2e22 2222 0a0a  en project."""..
-000084b0: 2020 2020 2020 2020 7072 6f6a 6563 7420          project 
-000084c0: 3d20 7072 6f6a 6563 7420 6f72 2063 6f6e  = project or con
-000084d0: 6669 672e 6465 6661 756c 745f 7072 6f6a  fig.default_proj
-000084e0: 6563 740a 2020 2020 2020 2020 6572 726f  ect.        erro
-000084f0: 725f 6d65 7373 6167 6520 3d20 6622 4661  r_message = f"Fa
-00008500: 696c 6564 206c 6973 7469 6e67 2061 7274  iled listing art
-00008510: 6966 6163 7420 7461 6773 2e20 7072 6f6a  ifact tags. proj
-00008520: 6563 743d 7b70 726f 6a65 6374 7d22 0a20  ect={project}". 
-00008530: 2020 2020 2020 2070 6172 616d 7320 3d20         params = 
-00008540: 7b22 6361 7465 676f 7279 223a 2063 6174  {"category": cat
-00008550: 6567 6f72 797d 2069 6620 6361 7465 676f  egory} if catego
-00008560: 7279 2065 6c73 6520 7b7d 0a0a 2020 2020  ry else {}..    
-00008570: 2020 2020 7265 7370 6f6e 7365 203d 2073      response = s
-00008580: 656c 662e 6170 695f 6361 6c6c 280a 2020  elf.api_call(.  
-00008590: 2020 2020 2020 2020 2020 2247 4554 222c            "GET",
-000085a0: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
-000085b0: 6a65 6374 7d2f 6172 7469 6661 6374 2d74  ject}/artifact-t
-000085c0: 6167 7322 2c20 6572 726f 725f 6d65 7373  ags", error_mess
-000085d0: 6167 652c 2070 6172 616d 733d 7061 7261  age, params=para
-000085e0: 6d73 0a20 2020 2020 2020 2029 0a20 2020  ms.        ).   
-000085f0: 2020 2020 2072 6574 7572 6e20 7265 7370       return resp
-00008600: 6f6e 7365 2e6a 736f 6e28 295b 2274 6167  onse.json()["tag
-00008610: 7322 5d0a 0a20 2020 2064 6566 2073 746f  s"]..    def sto
-00008620: 7265 5f66 756e 6374 696f 6e28 7365 6c66  re_function(self
-00008630: 2c20 6675 6e63 7469 6f6e 2c20 6e61 6d65  , function, name
-00008640: 2c20 7072 6f6a 6563 743d 2222 2c20 7461  , project="", ta
-00008650: 673d 4e6f 6e65 2c20 7665 7273 696f 6e65  g=None, versione
-00008660: 643d 4661 6c73 6529 3a0a 2020 2020 2020  d=False):.      
-00008670: 2020 2222 2253 746f 7265 2061 2066 756e    """Store a fun
-00008680: 6374 696f 6e20 6f62 6a65 6374 2e20 4675  ction object. Fu
-00008690: 6e63 7469 6f6e 2069 7320 6964 656e 7469  nction is identi
-000086a0: 6669 6564 2062 7920 6974 7320 6e61 6d65  fied by its name
-000086b0: 2061 6e64 2074 6167 2c20 616e 6420 6361   and tag, and ca
-000086c0: 6e20 6265 2076 6572 7369 6f6e 6564 2e22  n be versioned."
-000086d0: 2222 0a0a 2020 2020 2020 2020 7061 7261  ""..        para
-000086e0: 6d73 203d 207b 2274 6167 223a 2074 6167  ms = {"tag": tag
-000086f0: 2c20 2276 6572 7369 6f6e 6564 223a 2076  , "versioned": v
-00008700: 6572 7369 6f6e 6564 7d0a 2020 2020 2020  ersioned}.      
-00008710: 2020 7072 6f6a 6563 7420 3d20 7072 6f6a    project = proj
-00008720: 6563 7420 6f72 2063 6f6e 6669 672e 6465  ect or config.de
-00008730: 6661 756c 745f 7072 6f6a 6563 740a 2020  fault_project.  
-00008740: 2020 2020 2020 7061 7468 203d 2073 656c        path = sel
-00008750: 662e 5f70 6174 685f 6f66 2822 6675 6e63  f._path_of("func
-00008760: 222c 2070 726f 6a65 6374 2c20 6e61 6d65  ", project, name
-00008770: 290a 0a20 2020 2020 2020 2065 7272 6f72  )..        error
-00008780: 203d 2066 2273 746f 7265 2066 756e 6374   = f"store funct
-00008790: 696f 6e20 7b70 726f 6a65 6374 7d2f 7b6e  ion {project}/{n
-000087a0: 616d 657d 220a 2020 2020 2020 2020 7265  ame}".        re
-000087b0: 7370 203d 2073 656c 662e 6170 695f 6361  sp = self.api_ca
-000087c0: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
-000087d0: 2250 4f53 5422 2c20 7061 7468 2c20 6572  "POST", path, er
-000087e0: 726f 722c 2070 6172 616d 733d 7061 7261  ror, params=para
-000087f0: 6d73 2c20 626f 6479 3d64 6963 745f 746f  ms, body=dict_to
-00008800: 5f6a 736f 6e28 6675 6e63 7469 6f6e 290a  _json(function).
-00008810: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
-00008820: 2020 2023 2068 6173 6820 6b65 7920 6f70     # hash key op
-00008830: 7469 6f6e 616c 2074 6f20 6265 2062 6163  tional to be bac
-00008840: 6b77 6172 6473 2063 6f6d 7061 7469 626c  kwards compatibl
-00008850: 6520 746f 2041 5049 2076 3c30 2e34 2e31  e to API v<0.4.1
-00008860: 3020 696e 2077 6869 6368 2069 7420 7761  0 in which it wa
-00008870: 736e 2774 2069 6e20 7468 6520 7265 7370  sn't in the resp
-00008880: 6f6e 7365 0a20 2020 2020 2020 2072 6574  onse.        ret
-00008890: 7572 6e20 7265 7370 2e6a 736f 6e28 292e  urn resp.json().
-000088a0: 6765 7428 2268 6173 685f 6b65 7922 290a  get("hash_key").
-000088b0: 0a20 2020 2064 6566 2067 6574 5f66 756e  .    def get_fun
-000088c0: 6374 696f 6e28 7365 6c66 2c20 6e61 6d65  ction(self, name
-000088d0: 2c20 7072 6f6a 6563 743d 2222 2c20 7461  , project="", ta
-000088e0: 673d 4e6f 6e65 2c20 6861 7368 5f6b 6579  g=None, hash_key
-000088f0: 3d22 2229 3a0a 2020 2020 2020 2020 2222  =""):.        ""
-00008900: 2252 6574 7269 6576 6520 6465 7461 696c  "Retrieve detail
-00008910: 7320 6f66 2061 2073 7065 6369 6669 6320  s of a specific 
-00008920: 6675 6e63 7469 6f6e 2c20 6964 656e 7469  function, identi
-00008930: 6669 6564 2062 7920 6974 7320 6e61 6d65  fied by its name
-00008940: 2061 6e64 2070 6f74 656e 7469 616c 6c79   and potentially
-00008950: 2061 2074 6167 206f 7220 6675 6e63 7469   a tag or functi
-00008960: 6f6e 2068 6173 682e 2222 220a 0a20 2020  on hash."""..   
-00008970: 2020 2020 2070 6172 616d 7320 3d20 7b22       params = {"
-00008980: 7461 6722 3a20 7461 672c 2022 6861 7368  tag": tag, "hash
-00008990: 5f6b 6579 223a 2068 6173 685f 6b65 797d  _key": hash_key}
-000089a0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-000089b0: 203d 2070 726f 6a65 6374 206f 7220 636f   = project or co
-000089c0: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
-000089d0: 6a65 6374 0a20 2020 2020 2020 2070 6174  ject.        pat
-000089e0: 6820 3d20 7365 6c66 2e5f 7061 7468 5f6f  h = self._path_o
-000089f0: 6628 2266 756e 6322 2c20 7072 6f6a 6563  f("func", projec
-00008a00: 742c 206e 616d 6529 0a20 2020 2020 2020  t, name).       
-00008a10: 2065 7272 6f72 203d 2066 2267 6574 2066   error = f"get f
-00008a20: 756e 6374 696f 6e20 7b70 726f 6a65 6374  unction {project
-00008a30: 7d2f 7b6e 616d 657d 220a 2020 2020 2020  }/{name}".      
-00008a40: 2020 7265 7370 203d 2073 656c 662e 6170    resp = self.ap
-00008a50: 695f 6361 6c6c 2822 4745 5422 2c20 7061  i_call("GET", pa
-00008a60: 7468 2c20 6572 726f 722c 2070 6172 616d  th, error, param
-00008a70: 733d 7061 7261 6d73 290a 2020 2020 2020  s=params).      
-00008a80: 2020 7265 7475 726e 2072 6573 702e 6a73    return resp.js
-00008a90: 6f6e 2829 5b22 6675 6e63 225d 0a0a 2020  on()["func"]..  
-00008aa0: 2020 6465 6620 6465 6c65 7465 5f66 756e    def delete_fun
-00008ab0: 6374 696f 6e28 7365 6c66 2c20 6e61 6d65  ction(self, name
-00008ac0: 3a20 7374 722c 2070 726f 6a65 6374 3a20  : str, project: 
-00008ad0: 7374 7220 3d20 2222 293a 0a20 2020 2020  str = ""):.     
-00008ae0: 2020 2022 2222 4465 6c65 7465 2061 2066     """Delete a f
-00008af0: 756e 6374 696f 6e20 6265 6c6f 6e67 696e  unction belongin
-00008b00: 6720 746f 2061 2073 7065 6369 6669 6320  g to a specific 
-00008b10: 7072 6f6a 6563 742e 2222 220a 0a20 2020  project."""..   
-00008b20: 2020 2020 2070 726f 6a65 6374 203d 2070       project = p
-00008b30: 726f 6a65 6374 206f 7220 636f 6e66 6967  roject or config
-00008b40: 2e64 6566 6175 6c74 5f70 726f 6a65 6374  .default_project
-00008b50: 0a20 2020 2020 2020 2070 6174 6820 3d20  .        path = 
-00008b60: 6622 7072 6f6a 6563 7473 2f7b 7072 6f6a  f"projects/{proj
-00008b70: 6563 747d 2f66 756e 6374 696f 6e73 2f7b  ect}/functions/{
-00008b80: 6e61 6d65 7d22 0a20 2020 2020 2020 2065  name}".        e
-00008b90: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
-00008ba0: 2246 6169 6c65 6420 6465 6c65 7469 6e67  "Failed deleting
-00008bb0: 2066 756e 6374 696f 6e20 7b70 726f 6a65   function {proje
-00008bc0: 6374 7d2f 7b6e 616d 657d 220a 2020 2020  ct}/{name}".    
-00008bd0: 2020 2020 7365 6c66 2e61 7069 5f63 616c      self.api_cal
-00008be0: 6c28 2244 454c 4554 4522 2c20 7061 7468  l("DELETE", path
-00008bf0: 2c20 6572 726f 725f 6d65 7373 6167 6529  , error_message)
-00008c00: 0a0a 2020 2020 6465 6620 6c69 7374 5f66  ..    def list_f
-00008c10: 756e 6374 696f 6e73 2873 656c 662c 206e  unctions(self, n
-00008c20: 616d 653d 4e6f 6e65 2c20 7072 6f6a 6563  ame=None, projec
-00008c30: 743d 4e6f 6e65 2c20 7461 673d 4e6f 6e65  t=None, tag=None
-00008c40: 2c20 6c61 6265 6c73 3d4e 6f6e 6529 3a0a  , labels=None):.
-00008c50: 2020 2020 2020 2020 2222 2252 6574 7269          """Retri
-00008c60: 6576 6520 6120 6c69 7374 206f 6620 6675  eve a list of fu
-00008c70: 6e63 7469 6f6e 732c 2066 696c 7465 7265  nctions, filtere
-00008c80: 6420 6279 2073 7065 6369 6669 6320 6372  d by specific cr
-00008c90: 6974 6572 6961 2e0a 0a20 2020 2020 2020  iteria...       
-00008ca0: 203a 7061 7261 6d20 6e61 6d65 3a20 5265   :param name: Re
-00008cb0: 7475 726e 206f 6e6c 7920 6675 6e63 7469  turn only functi
-00008cc0: 6f6e 7320 7769 7468 2061 2073 7065 6369  ons with a speci
-00008cd0: 6669 6320 6e61 6d65 2e0a 2020 2020 2020  fic name..      
-00008ce0: 2020 3a70 6172 616d 2070 726f 6a65 6374    :param project
-00008cf0: 3a20 5265 7475 726e 2066 756e 6374 696f  : Return functio
-00008d00: 6e73 2062 656c 6f6e 6769 6e67 2074 6f20  ns belonging to 
-00008d10: 7468 6973 2070 726f 6a65 6374 2e20 4966  this project. If
-00008d20: 206e 6f74 2073 7065 6369 6669 6564 2c20   not specified, 
-00008d30: 7468 6520 6465 6661 756c 7420 7072 6f6a  the default proj
-00008d40: 6563 7420 6973 2075 7365 642e 0a20 2020  ect is used..   
-00008d50: 2020 2020 203a 7061 7261 6d20 7461 673a       :param tag:
-00008d60: 2052 6574 7572 6e20 6675 6e63 7469 6f6e   Return function
-00008d70: 2076 6572 7369 6f6e 7320 7769 7468 2073   versions with s
-00008d80: 7065 6369 6669 6320 7461 6773 2e0a 2020  pecific tags..  
-00008d90: 2020 2020 2020 3a70 6172 616d 206c 6162        :param lab
-00008da0: 656c 733a 2052 6574 7572 6e20 6675 6e63  els: Return func
-00008db0: 7469 6f6e 7320 7468 6174 2068 6176 6520  tions that have 
-00008dc0: 7370 6563 6966 6963 206c 6162 656c 7320  specific labels 
-00008dd0: 6173 7369 676e 6564 2074 6f20 7468 656d  assigned to them
-00008de0: 2e0a 2020 2020 2020 2020 3a72 6574 7572  ..        :retur
-00008df0: 6e73 3a20 4c69 7374 206f 6620 6675 6e63  ns: List of func
-00008e00: 7469 6f6e 206f 626a 6563 7473 2028 6173  tion objects (as
-00008e10: 2064 6963 7469 6f6e 6172 7929 2e0a 2020   dictionary)..  
-00008e20: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
-00008e30: 2020 2070 6172 616d 7320 3d20 7b0a 2020     params = {.  
-00008e40: 2020 2020 2020 2020 2020 2270 726f 6a65            "proje
-00008e50: 6374 223a 2070 726f 6a65 6374 206f 7220  ct": project or 
-00008e60: 636f 6e66 6967 2e64 6566 6175 6c74 5f70  config.default_p
-00008e70: 726f 6a65 6374 2c0a 2020 2020 2020 2020  roject,.        
-00008e80: 2020 2020 226e 616d 6522 3a20 6e61 6d65      "name": name
-00008e90: 2c0a 2020 2020 2020 2020 2020 2020 2274  ,.            "t
-00008ea0: 6167 223a 2074 6167 2c0a 2020 2020 2020  ag": tag,.      
-00008eb0: 2020 2020 2020 226c 6162 656c 223a 206c        "label": l
-00008ec0: 6162 656c 7320 6f72 205b 5d2c 0a20 2020  abels or [],.   
-00008ed0: 2020 2020 207d 0a20 2020 2020 2020 2065       }.        e
-00008ee0: 7272 6f72 203d 2022 6c69 7374 2066 756e  rror = "list fun
-00008ef0: 6374 696f 6e73 220a 2020 2020 2020 2020  ctions".        
-00008f00: 7265 7370 203d 2073 656c 662e 6170 695f  resp = self.api_
-00008f10: 6361 6c6c 2822 4745 5422 2c20 2266 756e  call("GET", "fun
-00008f20: 6373 222c 2065 7272 6f72 2c20 7061 7261  cs", error, para
-00008f30: 6d73 3d70 6172 616d 7329 0a20 2020 2020  ms=params).     
-00008f40: 2020 2072 6574 7572 6e20 7265 7370 2e6a     return resp.j
-00008f50: 736f 6e28 295b 2266 756e 6373 225d 0a0a  son()["funcs"]..
-00008f60: 2020 2020 6465 6620 6c69 7374 5f72 756e      def list_run
-00008f70: 7469 6d65 5f72 6573 6f75 7263 6573 280a  time_resources(.
-00008f80: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-00008f90: 2020 2020 2020 7072 6f6a 6563 743a 204f        project: O
-00008fa0: 7074 696f 6e61 6c5b 7374 725d 203d 204e  ptional[str] = N
-00008fb0: 6f6e 652c 0a20 2020 2020 2020 206c 6162  one,.        lab
-00008fc0: 656c 5f73 656c 6563 746f 723a 204f 7074  el_selector: Opt
-00008fd0: 696f 6e61 6c5b 7374 725d 203d 204e 6f6e  ional[str] = Non
-00008fe0: 652c 0a20 2020 2020 2020 206b 696e 643a  e,.        kind:
-00008ff0: 204f 7074 696f 6e61 6c5b 7374 725d 203d   Optional[str] =
-00009000: 204e 6f6e 652c 0a20 2020 2020 2020 206f   None,.        o
-00009010: 626a 6563 745f 6964 3a20 4f70 7469 6f6e  bject_id: Option
-00009020: 616c 5b73 7472 5d20 3d20 4e6f 6e65 2c0a  al[str] = None,.
-00009030: 2020 2020 2020 2020 6772 6f75 705f 6279          group_by
-00009040: 3a20 4f70 7469 6f6e 616c 5b6d 6c72 756e  : Optional[mlrun
-00009050: 2e61 7069 2e73 6368 656d 6173 2e4c 6973  .api.schemas.Lis
-00009060: 7452 756e 7469 6d65 5265 736f 7572 6365  tRuntimeResource
-00009070: 7347 726f 7570 4279 4669 656c 645d 203d  sGroupByField] =
-00009080: 204e 6f6e 652c 0a20 2020 2029 202d 3e20   None,.    ) -> 
-00009090: 556e 696f 6e5b 0a20 2020 2020 2020 206d  Union[.        m
-000090a0: 6c72 756e 2e61 7069 2e73 6368 656d 6173  lrun.api.schemas
-000090b0: 2e52 756e 7469 6d65 5265 736f 7572 6365  .RuntimeResource
-000090c0: 734f 7574 7075 742c 0a20 2020 2020 2020  sOutput,.       
-000090d0: 206d 6c72 756e 2e61 7069 2e73 6368 656d   mlrun.api.schem
-000090e0: 6173 2e47 726f 7570 6564 4279 4a6f 6252  as.GroupedByJobR
-000090f0: 756e 7469 6d65 5265 736f 7572 6365 734f  untimeResourcesO
-00009100: 7574 7075 742c 0a20 2020 2020 2020 206d  utput,.        m
-00009110: 6c72 756e 2e61 7069 2e73 6368 656d 6173  lrun.api.schemas
-00009120: 2e47 726f 7570 6564 4279 5072 6f6a 6563  .GroupedByProjec
-00009130: 7452 756e 7469 6d65 5265 736f 7572 6365  tRuntimeResource
-00009140: 734f 7574 7075 742c 0a20 2020 205d 3a0a  sOutput,.    ]:.
-00009150: 2020 2020 2020 2020 2222 224c 6973 7420          """List 
-00009160: 6375 7272 656e 7420 7275 6e74 696d 6520  current runtime 
-00009170: 7265 736f 7572 6365 732c 2077 6869 6368  resources, which
-00009180: 2061 7265 2075 7375 616c 6c79 2028 6275   are usually (bu
-00009190: 7420 6e6f 7420 6c69 6d69 7465 6420 746f  t not limited to
-000091a0: 2920 4b75 6265 726e 6574 6573 2070 6f64  ) Kubernetes pod
-000091b0: 7320 6f72 2043 5244 732e 0a20 2020 2020  s or CRDs..     
-000091c0: 2020 2046 756e 6374 696f 6e20 6170 706c     Function appl
-000091d0: 6965 7320 666f 7220 7275 6e73 206f 6620  ies for runs of 
-000091e0: 7479 7065 2060 5b27 6461 736b 272c 2027  type `['dask', '
-000091f0: 6a6f 6227 2c20 2773 7061 726b 272c 2027  job', 'spark', '
-00009200: 7265 6d6f 7465 2d73 7061 726b 272c 2027  remote-spark', '
-00009210: 6d70 696a 6f62 275d 602c 2061 6e64 2077  mpijob']`, and w
-00009220: 696c 6c20 7265 7475 726e 2070 6572 0a20  ill return per. 
-00009230: 2020 2020 2020 2072 756e 7469 6d65 206b         runtime k
-00009240: 696e 6420 6120 6c69 7374 206f 6620 7468  ind a list of th
-00009250: 6520 7275 6e74 696d 6520 7265 736f 7572  e runtime resour
-00009260: 6365 7320 2877 6869 6368 206d 6179 2068  ces (which may h
-00009270: 6176 6520 616c 7265 6164 7920 636f 6d70  ave already comp
-00009280: 6c65 7465 6420 7468 6569 7220 6578 6563  leted their exec
-00009290: 7574 696f 6e29 2e0a 0a20 2020 2020 2020  ution)...       
-000092a0: 203a 7061 7261 6d20 7072 6f6a 6563 743a   :param project:
-000092b0: 2047 6574 206f 6e6c 7920 7275 6e74 696d   Get only runtim
-000092c0: 6520 7265 736f 7572 6365 7320 6f66 2061  e resources of a
-000092d0: 2073 7065 6369 6669 6320 7072 6f6a 6563   specific projec
-000092e0: 742c 2062 7920 6465 6661 756c 7420 4e6f  t, by default No
-000092f0: 6e65 2c20 7768 6963 6820 7769 6c6c 2072  ne, which will r
-00009300: 6574 7572 6e20 6f6e 6c79 2074 6865 0a20  eturn only the. 
-00009310: 2020 2020 2020 2020 2020 2070 726f 6a65             proje
-00009320: 6374 7320 796f 7527 7265 2061 7574 686f  cts you're autho
-00009330: 7269 7a65 6420 746f 2073 6565 2e0a 2020  rized to see..  
-00009340: 2020 2020 2020 3a70 6172 616d 206c 6162        :param lab
-00009350: 656c 5f73 656c 6563 746f 723a 2041 206c  el_selector: A l
-00009360: 6162 656c 2066 696c 7465 7220 7468 6174  abel filter that
-00009370: 2077 696c 6c20 6265 2070 6173 7365 6420   will be passed 
-00009380: 746f 204b 7562 6572 6e65 7465 7320 666f  to Kubernetes fo
-00009390: 7220 6669 6c74 6572 696e 6720 7468 6520  r filtering the 
-000093a0: 7265 7375 6c74 7320 6163 636f 7264 696e  results accordin
-000093b0: 670a 2020 2020 2020 2020 2020 2020 746f  g.            to
-000093c0: 2074 6865 6972 206c 6162 656c 732e 0a20   their labels.. 
-000093d0: 2020 2020 2020 203a 7061 7261 6d20 6b69         :param ki
-000093e0: 6e64 3a20 5468 6520 6b69 6e64 206f 6620  nd: The kind of 
-000093f0: 7275 6e74 696d 6520 746f 2071 7565 7279  runtime to query
-00009400: 2e20 4d61 7920 6265 206f 6e65 206f 6620  . May be one of 
-00009410: 605b 2764 6173 6b27 2c20 276a 6f62 272c  `['dask', 'job',
-00009420: 2027 7370 6172 6b27 2c20 2772 656d 6f74   'spark', 'remot
-00009430: 652d 7370 6172 6b27 2c20 276d 7069 6a6f  e-spark', 'mpijo
-00009440: 6227 5d60 0a20 2020 2020 2020 203a 7061  b']`.        :pa
-00009450: 7261 6d20 6f62 6a65 6374 5f69 643a 2054  ram object_id: T
-00009460: 6865 2069 6465 6e74 6966 6965 7220 6f66  he identifier of
-00009470: 2074 6865 206d 6c72 756e 206f 626a 6563   the mlrun objec
-00009480: 7420 746f 2071 7565 7279 2069 7473 2072  t to query its r
-00009490: 756e 7469 6d65 2072 6573 6f75 7263 6573  untime resources
-000094a0: 2e20 666f 7220 6d6f 7374 2066 756e 6374  . for most funct
-000094b0: 696f 6e20 7275 6e74 696d 6573 2c0a 2020  ion runtimes,.  
-000094c0: 2020 2020 2020 2020 2020 7275 6e74 696d            runtim
-000094d0: 6520 7265 736f 7572 6365 7320 6172 6520  e resources are 
-000094e0: 7065 7220 5275 6e2c 2066 6f72 2077 6869  per Run, for whi
-000094f0: 6368 2074 6865 2069 6465 6e74 6966 6965  ch the identifie
-00009500: 7220 6973 2074 6865 2052 756e 2773 2055  r is the Run's U
-00009510: 4944 2e20 466f 7220 6461 736b 2072 756e  ID. For dask run
-00009520: 7469 6d65 2c20 7468 6520 7275 6e74 696d  time, the runtim
-00009530: 650a 2020 2020 2020 2020 2020 2020 7265  e.            re
-00009540: 736f 7572 6365 7320 6172 6520 7065 7220  sources are per 
-00009550: 4675 6e63 7469 6f6e 2c20 666f 7220 7768  Function, for wh
-00009560: 6963 6820 7468 6520 6964 656e 7469 6669  ich the identifi
-00009570: 6572 2069 7320 7468 6520 4675 6e63 7469  er is the Functi
-00009580: 6f6e 2773 206e 616d 652e 0a20 2020 2020  on's name..     
-00009590: 2020 203a 7061 7261 6d20 6772 6f75 705f     :param group_
-000095a0: 6279 3a20 4f62 6a65 6374 2074 6f20 6772  by: Object to gr
-000095b0: 6f75 7020 7265 7375 6c74 7320 6279 2e20  oup results by. 
-000095c0: 416c 6c6f 7765 6420 7661 6c75 6573 2061  Allowed values a
-000095d0: 7265 2060 6a6f 6260 2061 6e64 2060 7072  re `job` and `pr
-000095e0: 6f6a 6563 7460 2e0a 2020 2020 2020 2020  oject`..        
-000095f0: 2222 220a 2020 2020 2020 2020 7061 7261  """.        para
-00009600: 6d73 203d 207b 0a20 2020 2020 2020 2020  ms = {.         
-00009610: 2020 2022 6c61 6265 6c5f 7365 6c65 6374     "label_select
-00009620: 6f72 223a 206c 6162 656c 5f73 656c 6563  or": label_selec
-00009630: 746f 722c 0a20 2020 2020 2020 2020 2020  tor,.           
-00009640: 2022 6772 6f75 702d 6279 223a 2067 726f   "group-by": gro
-00009650: 7570 5f62 792c 0a20 2020 2020 2020 2020  up_by,.         
-00009660: 2020 2022 6b69 6e64 223a 206b 696e 642c     "kind": kind,
-00009670: 0a20 2020 2020 2020 2020 2020 2022 6f62  .            "ob
-00009680: 6a65 6374 2d69 6422 3a20 6f62 6a65 6374  ject-id": object
-00009690: 5f69 642c 0a20 2020 2020 2020 207d 0a20  _id,.        }. 
-000096a0: 2020 2020 2020 2070 726f 6a65 6374 5f70         project_p
-000096b0: 6174 6820 3d20 7072 6f6a 6563 7420 6966  ath = project if
-000096c0: 2070 726f 6a65 6374 2065 6c73 6520 222a   project else "*
-000096d0: 220a 2020 2020 2020 2020 6572 726f 7220  ".        error 
-000096e0: 3d20 2246 6169 6c65 6420 6c69 7374 696e  = "Failed listin
-000096f0: 6720 7275 6e74 696d 6520 7265 736f 7572  g runtime resour
-00009700: 6365 7322 0a20 2020 2020 2020 2072 6573  ces".        res
-00009710: 706f 6e73 6520 3d20 7365 6c66 2e61 7069  ponse = self.api
-00009720: 5f63 616c 6c28 0a20 2020 2020 2020 2020  _call(.         
-00009730: 2020 2022 4745 5422 2c20 6622 7072 6f6a     "GET", f"proj
-00009740: 6563 7473 2f7b 7072 6f6a 6563 745f 7061  ects/{project_pa
-00009750: 7468 7d2f 7275 6e74 696d 652d 7265 736f  th}/runtime-reso
-00009760: 7572 6365 7322 2c20 6572 726f 722c 2070  urces", error, p
-00009770: 6172 616d 733d 7061 7261 6d73 0a20 2020  arams=params.   
-00009780: 2020 2020 2029 0a20 2020 2020 2020 2069       ).        i
-00009790: 6620 6772 6f75 705f 6279 2069 7320 4e6f  f group_by is No
-000097a0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-000097b0: 7374 7275 6374 7572 6564 5f6c 6973 7420  structured_list 
-000097c0: 3d20 5b0a 2020 2020 2020 2020 2020 2020  = [.            
-000097d0: 2020 2020 6d6c 7275 6e2e 6170 692e 7363      mlrun.api.sc
-000097e0: 6865 6d61 732e 4b69 6e64 5275 6e74 696d  hemas.KindRuntim
-000097f0: 6552 6573 6f75 7263 6573 282a 2a6b 696e  eResources(**kin
-00009800: 645f 7275 6e74 696d 655f 7265 736f 7572  d_runtime_resour
-00009810: 6365 7329 0a20 2020 2020 2020 2020 2020  ces).           
-00009820: 2020 2020 2066 6f72 206b 696e 645f 7275       for kind_ru
-00009830: 6e74 696d 655f 7265 736f 7572 6365 7320  ntime_resources 
-00009840: 696e 2072 6573 706f 6e73 652e 6a73 6f6e  in response.json
-00009850: 2829 0a20 2020 2020 2020 2020 2020 205d  ().            ]
-00009860: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00009870: 7572 6e20 7374 7275 6374 7572 6564 5f6c  urn structured_l
-00009880: 6973 740a 2020 2020 2020 2020 656c 6966  ist.        elif
-00009890: 2067 726f 7570 5f62 7920 3d3d 206d 6c72   group_by == mlr
-000098a0: 756e 2e61 7069 2e73 6368 656d 6173 2e4c  un.api.schemas.L
-000098b0: 6973 7452 756e 7469 6d65 5265 736f 7572  istRuntimeResour
-000098c0: 6365 7347 726f 7570 4279 4669 656c 642e  cesGroupByField.
-000098d0: 6a6f 623a 0a20 2020 2020 2020 2020 2020  job:.           
-000098e0: 2073 7472 7563 7475 7265 645f 6469 6374   structured_dict
-000098f0: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
-00009900: 2020 666f 7220 7072 6f6a 6563 742c 206a    for project, j
-00009910: 6f62 5f72 756e 7469 6d65 5f72 6573 6f75  ob_runtime_resou
-00009920: 7263 6573 5f6d 6170 2069 6e20 7265 7370  rces_map in resp
-00009930: 6f6e 7365 2e6a 736f 6e28 292e 6974 656d  onse.json().item
-00009940: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
-00009950: 2020 2020 2066 6f72 206a 6f62 5f69 642c       for job_id,
-00009960: 2072 756e 7469 6d65 5f72 6573 6f75 7263   runtime_resourc
-00009970: 6573 2069 6e20 6a6f 625f 7275 6e74 696d  es in job_runtim
-00009980: 655f 7265 736f 7572 6365 735f 6d61 702e  e_resources_map.
-00009990: 6974 656d 7328 293a 0a20 2020 2020 2020  items():.       
-000099a0: 2020 2020 2020 2020 2020 2020 2073 7472               str
-000099b0: 7563 7475 7265 645f 6469 6374 2e73 6574  uctured_dict.set
-000099c0: 6465 6661 756c 7428 7072 6f6a 6563 742c  default(project,
-000099d0: 207b 7d29 5b0a 2020 2020 2020 2020 2020   {})[.          
-000099e0: 2020 2020 2020 2020 2020 2020 2020 6a6f                jo
-000099f0: 625f 6964 0a20 2020 2020 2020 2020 2020  b_id.           
-00009a00: 2020 2020 2020 2020 205d 203d 206d 6c72           ] = mlr
-00009a10: 756e 2e61 7069 2e73 6368 656d 6173 2e52  un.api.schemas.R
-00009a20: 756e 7469 6d65 5265 736f 7572 6365 7328  untimeResources(
-00009a30: 2a2a 7275 6e74 696d 655f 7265 736f 7572  **runtime_resour
-00009a40: 6365 7329 0a20 2020 2020 2020 2020 2020  ces).           
-00009a50: 2072 6574 7572 6e20 7374 7275 6374 7572   return structur
-00009a60: 6564 5f64 6963 740a 2020 2020 2020 2020  ed_dict.        
-00009a70: 656c 6966 2067 726f 7570 5f62 7920 3d3d  elif group_by ==
-00009a80: 206d 6c72 756e 2e61 7069 2e73 6368 656d   mlrun.api.schem
-00009a90: 6173 2e4c 6973 7452 756e 7469 6d65 5265  as.ListRuntimeRe
-00009aa0: 736f 7572 6365 7347 726f 7570 4279 4669  sourcesGroupByFi
-00009ab0: 656c 642e 7072 6f6a 6563 743a 0a20 2020  eld.project:.   
-00009ac0: 2020 2020 2020 2020 2073 7472 7563 7475           structu
-00009ad0: 7265 645f 6469 6374 203d 207b 7d0a 2020  red_dict = {}.  
-00009ae0: 2020 2020 2020 2020 2020 666f 7220 7072            for pr
-00009af0: 6f6a 6563 742c 206b 696e 645f 7275 6e74  oject, kind_runt
-00009b00: 696d 655f 7265 736f 7572 6365 735f 6d61  ime_resources_ma
-00009b10: 7020 696e 2072 6573 706f 6e73 652e 6a73  p in response.js
-00009b20: 6f6e 2829 2e69 7465 6d73 2829 3a0a 2020  on().items():.  
-00009b30: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-00009b40: 7220 6b69 6e64 2c20 7275 6e74 696d 655f  r kind, runtime_
-00009b50: 7265 736f 7572 6365 7320 696e 206b 696e  resources in kin
-00009b60: 645f 7275 6e74 696d 655f 7265 736f 7572  d_runtime_resour
-00009b70: 6365 735f 6d61 702e 6974 656d 7328 293a  ces_map.items():
-00009b80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009b90: 2020 2020 2073 7472 7563 7475 7265 645f       structured_
-00009ba0: 6469 6374 2e73 6574 6465 6661 756c 7428  dict.setdefault(
-00009bb0: 7072 6f6a 6563 742c 207b 7d29 5b0a 2020  project, {})[.  
-00009bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009bd0: 2020 2020 2020 6b69 6e64 0a20 2020 2020        kind.     
-00009be0: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
-00009bf0: 203d 206d 6c72 756e 2e61 7069 2e73 6368   = mlrun.api.sch
-00009c00: 656d 6173 2e52 756e 7469 6d65 5265 736f  emas.RuntimeReso
-00009c10: 7572 6365 7328 2a2a 7275 6e74 696d 655f  urces(**runtime_
-00009c20: 7265 736f 7572 6365 7329 0a20 2020 2020  resources).     
-00009c30: 2020 2020 2020 2072 6574 7572 6e20 7374         return st
-00009c40: 7275 6374 7572 6564 5f64 6963 740a 2020  ructured_dict.  
-00009c50: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00009c60: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-00009c70: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-00009c80: 7228 0a20 2020 2020 2020 2020 2020 2020  r(.             
-00009c90: 2020 2066 2250 726f 7669 6465 6420 6772     f"Provided gr
-00009ca0: 6f75 7020 6279 2066 6965 6c64 2069 7320  oup by field is 
-00009cb0: 6e6f 7420 7375 7070 6f72 7465 642e 2067  not supported. g
-00009cc0: 726f 7570 5f62 793d 7b67 726f 7570 5f62  roup_by={group_b
-00009cd0: 797d 220a 2020 2020 2020 2020 2020 2020  y}".            
-00009ce0: 290a 0a20 2020 2064 6566 206c 6973 745f  )..    def list_
-00009cf0: 7275 6e74 696d 6573 2873 656c 662c 206c  runtimes(self, l
-00009d00: 6162 656c 5f73 656c 6563 746f 723a 2073  abel_selector: s
-00009d10: 7472 203d 204e 6f6e 6529 202d 3e20 4c69  tr = None) -> Li
-00009d20: 7374 3a0a 2020 2020 2020 2020 2222 2244  st:.        """D
-00009d30: 6570 7265 6361 7465 6420 7573 6520 3a70  eprecated use :p
-00009d40: 793a 6675 6e63 3a60 7e6c 6973 745f 7275  y:func:`~list_ru
-00009d50: 6e74 696d 655f 7265 736f 7572 6365 7360  ntime_resources`
-00009d60: 2069 6e73 7465 6164 2222 220a 2020 2020   instead""".    
-00009d70: 2020 2020 7761 726e 696e 6773 2e77 6172      warnings.war
-00009d80: 6e28 0a20 2020 2020 2020 2020 2020 2022  n(.            "
-00009d90: 5468 6973 206d 6574 686f 6420 6973 2064  This method is d
-00009da0: 6570 7265 6361 7465 642c 2075 7365 206c  eprecated, use l
-00009db0: 6973 745f 7275 6e74 696d 655f 7265 736f  ist_runtime_reso
-00009dc0: 7572 6365 7320 696e 7374 6561 6422 0a20  urces instead". 
-00009dd0: 2020 2020 2020 2020 2020 2022 5468 6973             "This
-00009de0: 2077 696c 6c20 6265 2072 656d 6f76 6564   will be removed
-00009df0: 2069 6e20 302e 392e 3022 2c0a 2020 2020   in 0.9.0",.    
-00009e00: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
-00009e10: 5265 6d6f 7665 2069 6e20 302e 392e 300a  Remove in 0.9.0.
-00009e20: 2020 2020 2020 2020 2020 2020 4465 7072              Depr
-00009e30: 6563 6174 696f 6e57 6172 6e69 6e67 2c0a  ecationWarning,.
-00009e40: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00009e50: 2020 7061 7261 6d73 203d 207b 226c 6162    params = {"lab
-00009e60: 656c 5f73 656c 6563 746f 7222 3a20 6c61  el_selector": la
-00009e70: 6265 6c5f 7365 6c65 6374 6f72 7d0a 2020  bel_selector}.  
-00009e80: 2020 2020 2020 6572 726f 7220 3d20 226c        error = "l
-00009e90: 6973 7420 7275 6e74 696d 6573 220a 2020  ist runtimes".  
-00009ea0: 2020 2020 2020 7265 7370 203d 2073 656c        resp = sel
-00009eb0: 662e 6170 695f 6361 6c6c 2822 4745 5422  f.api_call("GET"
-00009ec0: 2c20 2272 756e 7469 6d65 7322 2c20 6572  , "runtimes", er
-00009ed0: 726f 722c 2070 6172 616d 733d 7061 7261  ror, params=para
-00009ee0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-00009ef0: 726e 2072 6573 702e 6a73 6f6e 2829 0a0a  rn resp.json()..
-00009f00: 2020 2020 6465 6620 6765 745f 7275 6e74      def get_runt
-00009f10: 696d 6528 7365 6c66 2c20 6b69 6e64 3a20  ime(self, kind: 
-00009f20: 7374 722c 206c 6162 656c 5f73 656c 6563  str, label_selec
-00009f30: 746f 723a 2073 7472 203d 204e 6f6e 6529  tor: str = None)
-00009f40: 202d 3e20 4469 6374 3a0a 2020 2020 2020   -> Dict:.      
-00009f50: 2020 2222 2244 6570 7265 6361 7465 6420    """Deprecated 
-00009f60: 7573 6520 3a70 793a 6675 6e63 3a60 7e6c  use :py:func:`~l
-00009f70: 6973 745f 7275 6e74 696d 655f 7265 736f  ist_runtime_reso
-00009f80: 7572 6365 7360 2028 7769 7468 206b 696e  urces` (with kin
-00009f90: 6420 6669 6c74 6572 2920 696e 7374 6561  d filter) instea
-00009fa0: 6422 2222 0a20 2020 2020 2020 2077 6172  d""".        war
-00009fb0: 6e69 6e67 732e 7761 726e 280a 2020 2020  nings.warn(.    
-00009fc0: 2020 2020 2020 2020 2254 6869 7320 6d65          "This me
-00009fd0: 7468 6f64 2069 7320 6465 7072 6563 6174  thod is deprecat
-00009fe0: 6564 2c20 7573 6520 6c69 7374 5f72 756e  ed, use list_run
-00009ff0: 7469 6d65 5f72 6573 6f75 7263 6573 2028  time_resources (
-0000a000: 7769 7468 206b 696e 6420 6669 6c74 6572  with kind filter
-0000a010: 2920 696e 7374 6561 6422 0a20 2020 2020  ) instead".     
-0000a020: 2020 2020 2020 2022 5468 6973 2077 696c         "This wil
-0000a030: 6c20 6265 2072 656d 6f76 6564 2069 6e20  l be removed in 
-0000a040: 302e 392e 3022 2c0a 2020 2020 2020 2020  0.9.0",.        
-0000a050: 2020 2020 2320 544f 444f 3a20 5265 6d6f      # TODO: Remo
-0000a060: 7665 2069 6e20 302e 392e 300a 2020 2020  ve in 0.9.0.    
-0000a070: 2020 2020 2020 2020 4465 7072 6563 6174          Deprecat
-0000a080: 696f 6e57 6172 6e69 6e67 2c0a 2020 2020  ionWarning,.    
-0000a090: 2020 2020 290a 2020 2020 2020 2020 7061      ).        pa
-0000a0a0: 7261 6d73 203d 207b 226c 6162 656c 5f73  rams = {"label_s
-0000a0b0: 656c 6563 746f 7222 3a20 6c61 6265 6c5f  elector": label_
-0000a0c0: 7365 6c65 6374 6f72 7d0a 2020 2020 2020  selector}.      
-0000a0d0: 2020 7061 7468 203d 2066 2272 756e 7469    path = f"runti
-0000a0e0: 6d65 732f 7b6b 696e 647d 220a 2020 2020  mes/{kind}".    
-0000a0f0: 2020 2020 6572 726f 7220 3d20 6622 6765      error = f"ge
-0000a100: 7420 7275 6e74 696d 6520 7b6b 696e 647d  t runtime {kind}
-0000a110: 220a 2020 2020 2020 2020 7265 7370 203d  ".        resp =
-0000a120: 2073 656c 662e 6170 695f 6361 6c6c 2822   self.api_call("
-0000a130: 4745 5422 2c20 7061 7468 2c20 6572 726f  GET", path, erro
-0000a140: 722c 2070 6172 616d 733d 7061 7261 6d73  r, params=params
-0000a150: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0000a160: 2072 6573 702e 6a73 6f6e 2829 0a0a 2020   resp.json()..  
-0000a170: 2020 6465 6620 6465 6c65 7465 5f72 756e    def delete_run
-0000a180: 7469 6d65 5f72 6573 6f75 7263 6573 280a  time_resources(.
-0000a190: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-0000a1a0: 2020 2020 2020 7072 6f6a 6563 743a 204f        project: O
-0000a1b0: 7074 696f 6e61 6c5b 7374 725d 203d 204e  ptional[str] = N
-0000a1c0: 6f6e 652c 0a20 2020 2020 2020 206c 6162  one,.        lab
-0000a1d0: 656c 5f73 656c 6563 746f 723a 204f 7074  el_selector: Opt
-0000a1e0: 696f 6e61 6c5b 7374 725d 203d 204e 6f6e  ional[str] = Non
-0000a1f0: 652c 0a20 2020 2020 2020 206b 696e 643a  e,.        kind:
-0000a200: 204f 7074 696f 6e61 6c5b 7374 725d 203d   Optional[str] =
-0000a210: 204e 6f6e 652c 0a20 2020 2020 2020 206f   None,.        o
-0000a220: 626a 6563 745f 6964 3a20 4f70 7469 6f6e  bject_id: Option
-0000a230: 616c 5b73 7472 5d20 3d20 4e6f 6e65 2c0a  al[str] = None,.
-0000a240: 2020 2020 2020 2020 666f 7263 653a 2062          force: b
-0000a250: 6f6f 6c20 3d20 4661 6c73 652c 0a20 2020  ool = False,.   
-0000a260: 2020 2020 2067 7261 6365 5f70 6572 696f       grace_perio
-0000a270: 643a 2069 6e74 203d 204e 6f6e 652c 0a20  d: int = None,. 
-0000a280: 2020 2029 202d 3e20 6d6c 7275 6e2e 6170     ) -> mlrun.ap
-0000a290: 692e 7363 6865 6d61 732e 4772 6f75 7065  i.schemas.Groupe
-0000a2a0: 6442 7950 726f 6a65 6374 5275 6e74 696d  dByProjectRuntim
-0000a2b0: 6552 6573 6f75 7263 6573 4f75 7470 7574  eResourcesOutput
-0000a2c0: 3a0a 2020 2020 2020 2020 2222 2244 656c  :.        """Del
-0000a2d0: 6574 6520 616c 6c20 7275 6e74 696d 6520  ete all runtime 
-0000a2e0: 7265 736f 7572 6365 7320 7768 6963 6820  resources which 
-0000a2f0: 6172 6520 696e 2074 6572 6d69 6e61 6c20  are in terminal 
-0000a300: 7374 6174 652e 0a0a 2020 2020 2020 2020  state...        
-0000a310: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
-0000a320: 4465 6c65 7465 206f 6e6c 7920 7275 6e74  Delete only runt
-0000a330: 696d 6520 7265 736f 7572 6365 7320 6f66  ime resources of
-0000a340: 2061 2073 7065 6369 6669 6320 7072 6f6a   a specific proj
-0000a350: 6563 742c 2062 7920 6465 6661 756c 7420  ect, by default 
-0000a360: 4e6f 6e65 2c20 7768 6963 6820 7769 6c6c  None, which will
-0000a370: 2064 656c 6574 6520 6f6e 6c79 0a20 2020   delete only.   
-0000a380: 2020 2020 2020 2020 2066 726f 6d20 7468           from th
-0000a390: 6520 7072 6f6a 6563 7473 2079 6f75 2772  e projects you'r
-0000a3a0: 6520 6175 7468 6f72 697a 6564 2074 6f20  e authorized to 
-0000a3b0: 6465 6c65 7465 2066 726f 6d2e 0a20 2020  delete from..   
-0000a3c0: 2020 2020 203a 7061 7261 6d20 6c61 6265       :param labe
-0000a3d0: 6c5f 7365 6c65 6374 6f72 3a20 4465 6c65  l_selector: Dele
-0000a3e0: 7465 206f 6e6c 7920 7275 6e74 696d 6520  te only runtime 
-0000a3f0: 7265 736f 7572 6365 7320 6d61 7463 6869  resources matchi
-0000a400: 6e67 2074 6865 206c 6162 656c 2073 656c  ng the label sel
-0000a410: 6563 746f 722e 0a20 2020 2020 2020 203a  ector..        :
-0000a420: 7061 7261 6d20 6b69 6e64 3a20 5468 6520  param kind: The 
-0000a430: 6b69 6e64 206f 6620 7275 6e74 696d 6520  kind of runtime 
-0000a440: 746f 2064 656c 6574 652e 204d 6179 2062  to delete. May b
-0000a450: 6520 6f6e 6520 6f66 2060 5b27 6461 736b  e one of `['dask
-0000a460: 272c 2027 6a6f 6227 2c20 2773 7061 726b  ', 'job', 'spark
-0000a470: 272c 2027 7265 6d6f 7465 2d73 7061 726b  ', 'remote-spark
-0000a480: 272c 2027 6d70 696a 6f62 275d 600a 2020  ', 'mpijob']`.  
-0000a490: 2020 2020 2020 3a70 6172 616d 206f 626a        :param obj
-0000a4a0: 6563 745f 6964 3a20 5468 6520 6964 656e  ect_id: The iden
-0000a4b0: 7469 6669 6572 206f 6620 7468 6520 6d6c  tifier of the ml
-0000a4c0: 7275 6e20 6f62 6a65 6374 2074 6f20 6465  run object to de
-0000a4d0: 6c65 7465 2069 7473 2072 756e 7469 6d65  lete its runtime
-0000a4e0: 2072 6573 6f75 7263 6573 2e20 666f 7220   resources. for 
-0000a4f0: 6d6f 7374 2066 756e 6374 696f 6e0a 2020  most function.  
-0000a500: 2020 2020 2020 2020 2020 7275 6e74 696d            runtim
-0000a510: 6573 2c20 7275 6e74 696d 6520 7265 736f  es, runtime reso
-0000a520: 7572 6365 7320 6172 6520 7065 7220 5275  urces are per Ru
-0000a530: 6e2c 2066 6f72 2077 6869 6368 2074 6865  n, for which the
-0000a540: 2069 6465 6e74 6966 6965 7220 6973 2074   identifier is t
-0000a550: 6865 2052 756e 2773 2055 4944 2e20 466f  he Run's UID. Fo
-0000a560: 7220 6461 736b 2072 756e 7469 6d65 2c20  r dask runtime, 
-0000a570: 7468 650a 2020 2020 2020 2020 2020 2020  the.            
-0000a580: 7275 6e74 696d 6520 7265 736f 7572 6365  runtime resource
-0000a590: 7320 6172 6520 7065 7220 4675 6e63 7469  s are per Functi
-0000a5a0: 6f6e 2c20 666f 7220 7768 6963 6820 7468  on, for which th
-0000a5b0: 6520 6964 656e 7469 6669 6572 2069 7320  e identifier is 
-0000a5c0: 7468 6520 4675 6e63 7469 6f6e 2773 206e  the Function's n
-0000a5d0: 616d 652e 0a20 2020 2020 2020 203a 7061  ame..        :pa
-0000a5e0: 7261 6d20 666f 7263 653a 2046 6f72 6365  ram force: Force
-0000a5f0: 2064 656c 6574 696f 6e20 2d20 6465 6c65   deletion - dele
-0000a600: 7465 2074 6865 2072 756e 7469 6d65 2072  te the runtime r
-0000a610: 6573 6f75 7263 6520 6576 656e 2069 6620  esource even if 
-0000a620: 6974 2773 206e 6f74 2069 6e20 7465 726d  it's not in term
-0000a630: 696e 616c 2073 7461 7465 206f 7220 6966  inal state or if
-0000a640: 2074 6865 2067 7261 6365 0a20 2020 2020   the grace.     
-0000a650: 2020 2020 2020 2070 6572 696f 6420 6469         period di
-0000a660: 646e 2774 2070 6173 732e 0a20 2020 2020  dn't pass..     
-0000a670: 2020 203a 7061 7261 6d20 6772 6163 655f     :param grace_
-0000a680: 7065 7269 6f64 3a20 4772 6163 6520 7065  period: Grace pe
-0000a690: 7269 6f64 2067 6976 656e 2074 6f20 7468  riod given to th
-0000a6a0: 6520 7275 6e74 696d 6520 7265 736f 7572  e runtime resour
-0000a6b0: 6365 2062 6566 6f72 6520 7468 6579 2061  ce before they a
-0000a6c0: 7265 2061 6374 7561 6c6c 7920 7265 6d6f  re actually remo
-0000a6d0: 7665 642c 2063 6f75 6e74 6564 2066 726f  ved, counted fro
-0000a6e0: 6d0a 2020 2020 2020 2020 2020 2020 7468  m.            th
-0000a6f0: 6520 6d6f 6d65 6e74 2074 6865 7920 6d6f  e moment they mo
-0000a700: 7665 6420 746f 2074 6572 6d69 6e61 6c20  ved to terminal 
-0000a710: 7374 6174 652e 0a0a 2020 2020 2020 2020  state...        
-0000a720: 3a72 6574 7572 6e73 3a20 3a70 793a 636c  :returns: :py:cl
-0000a730: 6173 733a 607e 6d6c 7275 6e2e 6170 692e  ass:`~mlrun.api.
-0000a740: 7363 6865 6d61 732e 4772 6f75 7065 6442  schemas.GroupedB
-0000a750: 7950 726f 6a65 6374 5275 6e74 696d 6552  yProjectRuntimeR
-0000a760: 6573 6f75 7263 6573 4f75 7470 7574 6020  esourcesOutput` 
-0000a770: 6c69 7374 696e 6720 7468 6520 7275 6e74  listing the runt
-0000a780: 696d 6520 7265 736f 7572 6365 730a 2020  ime resources.  
-0000a790: 2020 2020 2020 2020 2020 7468 6174 2077            that w
-0000a7a0: 6572 6520 7265 6d6f 7665 642e 0a20 2020  ere removed..   
-0000a7b0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0000a7c0: 2069 6620 6772 6163 655f 7065 7269 6f64   if grace_period
-0000a7d0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-0000a7e0: 2020 2020 2020 6772 6163 655f 7065 7269        grace_peri
-0000a7f0: 6f64 203d 2063 6f6e 6669 672e 7275 6e74  od = config.runt
-0000a800: 696d 655f 7265 736f 7572 6365 735f 6465  ime_resources_de
-0000a810: 6c65 7469 6f6e 5f67 7261 6365 5f70 6572  letion_grace_per
-0000a820: 696f 640a 0a20 2020 2020 2020 2070 6172  iod..        par
-0000a830: 616d 7320 3d20 7b0a 2020 2020 2020 2020  ams = {.        
-0000a840: 2020 2020 226c 6162 656c 2d73 656c 6563      "label-selec
-0000a850: 746f 7222 3a20 6c61 6265 6c5f 7365 6c65  tor": label_sele
-0000a860: 6374 6f72 2c0a 2020 2020 2020 2020 2020  ctor,.          
-0000a870: 2020 226b 696e 6422 3a20 6b69 6e64 2c0a    "kind": kind,.
-0000a880: 2020 2020 2020 2020 2020 2020 226f 626a              "obj
-0000a890: 6563 742d 6964 223a 206f 626a 6563 745f  ect-id": object_
-0000a8a0: 6964 2c0a 2020 2020 2020 2020 2020 2020  id,.            
-0000a8b0: 2266 6f72 6365 223a 2066 6f72 6365 2c0a  "force": force,.
-0000a8c0: 2020 2020 2020 2020 2020 2020 2267 7261              "gra
-0000a8d0: 6365 2d70 6572 696f 6422 3a20 6772 6163  ce-period": grac
-0000a8e0: 655f 7065 7269 6f64 2c0a 2020 2020 2020  e_period,.      
-0000a8f0: 2020 7d0a 2020 2020 2020 2020 6572 726f    }.        erro
-0000a900: 7220 3d20 2246 6169 6c65 6420 6465 6c65  r = "Failed dele
-0000a910: 7469 6e67 2072 756e 7469 6d65 2072 6573  ting runtime res
-0000a920: 6f75 7263 6573 220a 2020 2020 2020 2020  ources".        
-0000a930: 7072 6f6a 6563 745f 7061 7468 203d 2070  project_path = p
-0000a940: 726f 6a65 6374 2069 6620 7072 6f6a 6563  roject if projec
-0000a950: 7420 656c 7365 2022 2a22 0a20 2020 2020  t else "*".     
-0000a960: 2020 2072 6573 706f 6e73 6520 3d20 7365     response = se
-0000a970: 6c66 2e61 7069 5f63 616c 6c28 0a20 2020  lf.api_call(.   
-0000a980: 2020 2020 2020 2020 2022 4445 4c45 5445           "DELETE
-0000a990: 222c 0a20 2020 2020 2020 2020 2020 2066  ",.            f
-0000a9a0: 2270 726f 6a65 6374 732f 7b70 726f 6a65  "projects/{proje
-0000a9b0: 6374 5f70 6174 687d 2f72 756e 7469 6d65  ct_path}/runtime
-0000a9c0: 2d72 6573 6f75 7263 6573 222c 0a20 2020  -resources",.   
-0000a9d0: 2020 2020 2020 2020 2065 7272 6f72 2c0a           error,.
-0000a9e0: 2020 2020 2020 2020 2020 2020 7061 7261              para
-0000a9f0: 6d73 3d70 6172 616d 732c 0a20 2020 2020  ms=params,.     
-0000aa00: 2020 2029 0a20 2020 2020 2020 2073 7472     ).        str
-0000aa10: 7563 7475 7265 645f 6469 6374 203d 207b  uctured_dict = {
-0000aa20: 7d0a 2020 2020 2020 2020 666f 7220 7072  }.        for pr
-0000aa30: 6f6a 6563 742c 206b 696e 645f 7275 6e74  oject, kind_runt
-0000aa40: 696d 655f 7265 736f 7572 6365 735f 6d61  ime_resources_ma
-0000aa50: 7020 696e 2072 6573 706f 6e73 652e 6a73  p in response.js
-0000aa60: 6f6e 2829 2e69 7465 6d73 2829 3a0a 2020  on().items():.  
-0000aa70: 2020 2020 2020 2020 2020 666f 7220 6b69            for ki
-0000aa80: 6e64 2c20 7275 6e74 696d 655f 7265 736f  nd, runtime_reso
-0000aa90: 7572 6365 7320 696e 206b 696e 645f 7275  urces in kind_ru
-0000aaa0: 6e74 696d 655f 7265 736f 7572 6365 735f  ntime_resources_
-0000aab0: 6d61 702e 6974 656d 7328 293a 0a20 2020  map.items():.   
-0000aac0: 2020 2020 2020 2020 2020 2020 2073 7472               str
-0000aad0: 7563 7475 7265 645f 6469 6374 2e73 6574  uctured_dict.set
-0000aae0: 6465 6661 756c 7428 7072 6f6a 6563 742c  default(project,
-0000aaf0: 207b 7d29 5b0a 2020 2020 2020 2020 2020   {})[.          
-0000ab00: 2020 2020 2020 2020 2020 6b69 6e64 0a20            kind. 
-0000ab10: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
-0000ab20: 203d 206d 6c72 756e 2e61 7069 2e73 6368   = mlrun.api.sch
-0000ab30: 656d 6173 2e52 756e 7469 6d65 5265 736f  emas.RuntimeReso
-0000ab40: 7572 6365 7328 2a2a 7275 6e74 696d 655f  urces(**runtime_
-0000ab50: 7265 736f 7572 6365 7329 0a20 2020 2020  resources).     
-0000ab60: 2020 2072 6574 7572 6e20 7374 7275 6374     return struct
-0000ab70: 7572 6564 5f64 6963 740a 0a20 2020 2064  ured_dict..    d
-0000ab80: 6566 2064 656c 6574 655f 7275 6e74 696d  ef delete_runtim
-0000ab90: 6573 280a 2020 2020 2020 2020 7365 6c66  es(.        self
-0000aba0: 2c0a 2020 2020 2020 2020 6c61 6265 6c5f  ,.        label_
-0000abb0: 7365 6c65 6374 6f72 3a20 7374 7220 3d20  selector: str = 
-0000abc0: 4e6f 6e65 2c0a 2020 2020 2020 2020 666f  None,.        fo
-0000abd0: 7263 653a 2062 6f6f 6c20 3d20 4661 6c73  rce: bool = Fals
-0000abe0: 652c 0a20 2020 2020 2020 2067 7261 6365  e,.        grace
-0000abf0: 5f70 6572 696f 643a 2069 6e74 203d 204e  _period: int = N
-0000ac00: 6f6e 652c 0a20 2020 2029 3a0a 2020 2020  one,.    ):.    
-0000ac10: 2020 2020 2222 2244 6570 7265 6361 7465      """Deprecate
-0000ac20: 6420 7573 6520 3a70 793a 6675 6e63 3a60  d use :py:func:`
-0000ac30: 7e64 656c 6574 655f 7275 6e74 696d 655f  ~delete_runtime_
-0000ac40: 7265 736f 7572 6365 7360 2069 6e73 7465  resources` inste
-0000ac50: 6164 2222 220a 2020 2020 2020 2020 7761  ad""".        wa
-0000ac60: 726e 696e 6773 2e77 6172 6e28 0a20 2020  rnings.warn(.   
-0000ac70: 2020 2020 2020 2020 2022 5468 6973 206d           "This m
-0000ac80: 6574 686f 6420 6973 2064 6570 7265 6361  ethod is depreca
-0000ac90: 7465 642c 2075 7365 2064 656c 6574 655f  ted, use delete_
-0000aca0: 7275 6e74 696d 655f 7265 736f 7572 6365  runtime_resource
-0000acb0: 7320 696e 7374 6561 6422 0a20 2020 2020  s instead".     
-0000acc0: 2020 2020 2020 2022 5468 6973 2077 696c         "This wil
-0000acd0: 6c20 6265 2072 656d 6f76 6564 2069 6e20  l be removed in 
-0000ace0: 302e 392e 3022 2c0a 2020 2020 2020 2020  0.9.0",.        
-0000acf0: 2020 2020 2320 544f 444f 3a20 5265 6d6f      # TODO: Remo
-0000ad00: 7665 2069 6e20 302e 392e 300a 2020 2020  ve in 0.9.0.    
-0000ad10: 2020 2020 2020 2020 4465 7072 6563 6174          Deprecat
-0000ad20: 696f 6e57 6172 6e69 6e67 2c0a 2020 2020  ionWarning,.    
-0000ad30: 2020 2020 290a 2020 2020 2020 2020 6966      ).        if
-0000ad40: 2067 7261 6365 5f70 6572 696f 6420 6973   grace_period is
-0000ad50: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-0000ad60: 2020 2067 7261 6365 5f70 6572 696f 6420     grace_period 
-0000ad70: 3d20 636f 6e66 6967 2e72 756e 7469 6d65  = config.runtime
-0000ad80: 5f72 6573 6f75 7263 6573 5f64 656c 6574  _resources_delet
-0000ad90: 696f 6e5f 6772 6163 655f 7065 7269 6f64  ion_grace_period
-0000ada0: 0a20 2020 2020 2020 2070 6172 616d 7320  .        params 
-0000adb0: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
-0000adc0: 226c 6162 656c 5f73 656c 6563 746f 7222  "label_selector"
-0000add0: 3a20 6c61 6265 6c5f 7365 6c65 6374 6f72  : label_selector
-0000ade0: 2c0a 2020 2020 2020 2020 2020 2020 2266  ,.            "f
-0000adf0: 6f72 6365 223a 2066 6f72 6365 2c0a 2020  orce": force,.  
-0000ae00: 2020 2020 2020 2020 2020 2267 7261 6365            "grace
-0000ae10: 5f70 6572 696f 6422 3a20 6772 6163 655f  _period": grace_
-0000ae20: 7065 7269 6f64 2c0a 2020 2020 2020 2020  period,.        
-0000ae30: 7d0a 2020 2020 2020 2020 6572 726f 7220  }.        error 
-0000ae40: 3d20 2264 656c 6574 6520 7275 6e74 696d  = "delete runtim
-0000ae50: 6573 220a 2020 2020 2020 2020 7365 6c66  es".        self
-0000ae60: 2e61 7069 5f63 616c 6c28 2244 454c 4554  .api_call("DELET
-0000ae70: 4522 2c20 2272 756e 7469 6d65 7322 2c20  E", "runtimes", 
-0000ae80: 6572 726f 722c 2070 6172 616d 733d 7061  error, params=pa
-0000ae90: 7261 6d73 290a 0a20 2020 2064 6566 2064  rams)..    def d
-0000aea0: 656c 6574 655f 7275 6e74 696d 6528 0a20  elete_runtime(. 
-0000aeb0: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-0000aec0: 2020 2020 206b 696e 643a 2073 7472 2c0a       kind: str,.
-0000aed0: 2020 2020 2020 2020 6c61 6265 6c5f 7365          label_se
-0000aee0: 6c65 6374 6f72 3a20 7374 7220 3d20 4e6f  lector: str = No
-0000aef0: 6e65 2c0a 2020 2020 2020 2020 666f 7263  ne,.        forc
-0000af00: 653a 2062 6f6f 6c20 3d20 4661 6c73 652c  e: bool = False,
-0000af10: 0a20 2020 2020 2020 2067 7261 6365 5f70  .        grace_p
-0000af20: 6572 696f 643a 2069 6e74 203d 204e 6f6e  eriod: int = Non
-0000af30: 652c 0a20 2020 2029 3a0a 2020 2020 2020  e,.    ):.      
-0000af40: 2020 2222 2244 6570 7265 6361 7465 6420    """Deprecated 
-0000af50: 7573 6520 3a70 793a 6675 6e63 3a60 7e64  use :py:func:`~d
-0000af60: 656c 6574 655f 7275 6e74 696d 655f 7265  elete_runtime_re
-0000af70: 736f 7572 6365 7360 2028 7769 7468 206b  sources` (with k
-0000af80: 696e 6420 6669 6c74 6572 2920 696e 7374  ind filter) inst
-0000af90: 6561 6422 2222 0a20 2020 2020 2020 2077  ead""".        w
-0000afa0: 6172 6e69 6e67 732e 7761 726e 280a 2020  arnings.warn(.  
-0000afb0: 2020 2020 2020 2020 2020 2254 6869 7320            "This 
-0000afc0: 6d65 7468 6f64 2069 7320 6465 7072 6563  method is deprec
-0000afd0: 6174 6564 2c20 7573 6520 6465 6c65 7465  ated, use delete
-0000afe0: 5f72 756e 7469 6d65 5f72 6573 6f75 7263  _runtime_resourc
-0000aff0: 6573 2028 7769 7468 206b 696e 6420 6669  es (with kind fi
-0000b000: 6c74 6572 2920 696e 7374 6561 6422 0a20  lter) instead". 
-0000b010: 2020 2020 2020 2020 2020 2022 5468 6973             "This
-0000b020: 2077 696c 6c20 6265 2072 656d 6f76 6564   will be removed
-0000b030: 2069 6e20 302e 392e 3022 2c0a 2020 2020   in 0.9.0",.    
-0000b040: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
-0000b050: 5265 6d6f 7665 2069 6e20 302e 392e 300a  Remove in 0.9.0.
-0000b060: 2020 2020 2020 2020 2020 2020 4465 7072              Depr
-0000b070: 6563 6174 696f 6e57 6172 6e69 6e67 2c0a  ecationWarning,.
-0000b080: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
-0000b090: 2020 2069 6620 6772 6163 655f 7065 7269     if grace_peri
-0000b0a0: 6f64 2069 7320 4e6f 6e65 3a0a 2020 2020  od is None:.    
-0000b0b0: 2020 2020 2020 2020 6772 6163 655f 7065          grace_pe
-0000b0c0: 7269 6f64 203d 2063 6f6e 6669 672e 7275  riod = config.ru
-0000b0d0: 6e74 696d 655f 7265 736f 7572 6365 735f  ntime_resources_
-0000b0e0: 6465 6c65 7469 6f6e 5f67 7261 6365 5f70  deletion_grace_p
-0000b0f0: 6572 696f 640a 0a20 2020 2020 2020 2070  eriod..        p
-0000b100: 6172 616d 7320 3d20 7b0a 2020 2020 2020  arams = {.      
-0000b110: 2020 2020 2020 226c 6162 656c 5f73 656c        "label_sel
-0000b120: 6563 746f 7222 3a20 6c61 6265 6c5f 7365  ector": label_se
-0000b130: 6c65 6374 6f72 2c0a 2020 2020 2020 2020  lector,.        
-0000b140: 2020 2020 2266 6f72 6365 223a 2066 6f72      "force": for
-0000b150: 6365 2c0a 2020 2020 2020 2020 2020 2020  ce,.            
-0000b160: 2267 7261 6365 5f70 6572 696f 6422 3a20  "grace_period": 
-0000b170: 6772 6163 655f 7065 7269 6f64 2c0a 2020  grace_period,.  
-0000b180: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
-0000b190: 7061 7468 203d 2066 2272 756e 7469 6d65  path = f"runtime
-0000b1a0: 732f 7b6b 696e 647d 220a 2020 2020 2020  s/{kind}".      
-0000b1b0: 2020 6572 726f 7220 3d20 6622 6465 6c65    error = f"dele
-0000b1c0: 7465 2072 756e 7469 6d65 207b 6b69 6e64  te runtime {kind
-0000b1d0: 7d22 0a20 2020 2020 2020 2073 656c 662e  }".        self.
-0000b1e0: 6170 695f 6361 6c6c 2822 4445 4c45 5445  api_call("DELETE
-0000b1f0: 222c 2070 6174 682c 2065 7272 6f72 2c20  ", path, error, 
-0000b200: 7061 7261 6d73 3d70 6172 616d 7329 0a0a  params=params)..
-0000b210: 2020 2020 6465 6620 6465 6c65 7465 5f72      def delete_r
-0000b220: 756e 7469 6d65 5f6f 626a 6563 7428 0a20  untime_object(. 
-0000b230: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
-0000b240: 2020 2020 206b 696e 643a 2073 7472 2c0a       kind: str,.
-0000b250: 2020 2020 2020 2020 6f62 6a65 6374 5f69          object_i
-0000b260: 643a 2073 7472 2c0a 2020 2020 2020 2020  d: str,.        
-0000b270: 6c61 6265 6c5f 7365 6c65 6374 6f72 3a20  label_selector: 
-0000b280: 7374 7220 3d20 4e6f 6e65 2c0a 2020 2020  str = None,.    
-0000b290: 2020 2020 666f 7263 653a 2062 6f6f 6c20      force: bool 
-0000b2a0: 3d20 4661 6c73 652c 0a20 2020 2020 2020  = False,.       
-0000b2b0: 2067 7261 6365 5f70 6572 696f 643a 2069   grace_period: i
-0000b2c0: 6e74 203d 204e 6f6e 652c 0a20 2020 2029  nt = None,.    )
-0000b2d0: 3a0a 2020 2020 2020 2020 2222 2244 6570  :.        """Dep
-0000b2e0: 7265 6361 7465 6420 7573 6520 3a70 793a  recated use :py:
-0000b2f0: 6675 6e63 3a60 7e64 656c 6574 655f 7275  func:`~delete_ru
-0000b300: 6e74 696d 655f 7265 736f 7572 6365 7360  ntime_resources`
-0000b310: 2028 7769 7468 206b 696e 6420 616e 6420   (with kind and 
-0000b320: 6f62 6a65 6374 5f69 6420 6669 6c74 6572  object_id filter
-0000b330: 2920 696e 7374 6561 6422 2222 0a20 2020  ) instead""".   
-0000b340: 2020 2020 2077 6172 6e69 6e67 732e 7761       warnings.wa
-0000b350: 726e 280a 2020 2020 2020 2020 2020 2020  rn(.            
-0000b360: 2254 6869 7320 6d65 7468 6f64 2069 7320  "This method is 
-0000b370: 6465 7072 6563 6174 6564 2c20 7573 6520  deprecated, use 
-0000b380: 6465 6c65 7465 5f72 756e 7469 6d65 5f72  delete_runtime_r
-0000b390: 6573 6f75 7263 6573 2028 7769 7468 206b  esources (with k
-0000b3a0: 696e 6420 616e 6420 6f62 6a65 6374 5f69  ind and object_i
-0000b3b0: 6420 6669 6c74 6572 2920 696e 7374 6561  d filter) instea
-0000b3c0: 6422 0a20 2020 2020 2020 2020 2020 2022  d".            "
-0000b3d0: 5468 6973 2077 696c 6c20 6265 2072 656d  This will be rem
-0000b3e0: 6f76 6564 2069 6e20 302e 392e 3022 2c0a  oved in 0.9.0",.
-0000b3f0: 2020 2020 2020 2020 2020 2020 2320 544f              # TO
-0000b400: 444f 3a20 5265 6d6f 7665 2069 6e20 302e  DO: Remove in 0.
-0000b410: 392e 300a 2020 2020 2020 2020 2020 2020  9.0.            
-0000b420: 4465 7072 6563 6174 696f 6e57 6172 6e69  DeprecationWarni
-0000b430: 6e67 2c0a 2020 2020 2020 2020 290a 0a20  ng,.        ).. 
-0000b440: 2020 2020 2020 2069 6620 6772 6163 655f         if grace_
-0000b450: 7065 7269 6f64 2069 7320 4e6f 6e65 3a0a  period is None:.
-0000b460: 2020 2020 2020 2020 2020 2020 6772 6163              grac
-0000b470: 655f 7065 7269 6f64 203d 2063 6f6e 6669  e_period = confi
-0000b480: 672e 7275 6e74 696d 655f 7265 736f 7572  g.runtime_resour
-0000b490: 6365 735f 6465 6c65 7469 6f6e 5f67 7261  ces_deletion_gra
-0000b4a0: 6365 5f70 6572 696f 640a 2020 2020 2020  ce_period.      
-0000b4b0: 2020 7061 7261 6d73 203d 207b 0a20 2020    params = {.   
-0000b4c0: 2020 2020 2020 2020 2022 6c61 6265 6c5f           "label_
-0000b4d0: 7365 6c65 6374 6f72 223a 206c 6162 656c  selector": label
-0000b4e0: 5f73 656c 6563 746f 722c 0a20 2020 2020  _selector,.     
-0000b4f0: 2020 2020 2020 2022 666f 7263 6522 3a20         "force": 
-0000b500: 666f 7263 652c 0a20 2020 2020 2020 2020  force,.         
-0000b510: 2020 2022 6772 6163 655f 7065 7269 6f64     "grace_period
-0000b520: 223a 2067 7261 6365 5f70 6572 696f 642c  ": grace_period,
-0000b530: 0a20 2020 2020 2020 207d 0a20 2020 2020  .        }.     
-0000b540: 2020 2070 6174 6820 3d20 6622 7275 6e74     path = f"runt
-0000b550: 696d 6573 2f7b 6b69 6e64 7d2f 7b6f 626a  imes/{kind}/{obj
-0000b560: 6563 745f 6964 7d22 0a20 2020 2020 2020  ect_id}".       
-0000b570: 2065 7272 6f72 203d 2066 2264 656c 6574   error = f"delet
-0000b580: 6520 7275 6e74 696d 6520 6f62 6a65 6374  e runtime object
-0000b590: 207b 6b69 6e64 7d20 7b6f 626a 6563 745f   {kind} {object_
-0000b5a0: 6964 7d22 0a20 2020 2020 2020 2073 656c  id}".        sel
-0000b5b0: 662e 6170 695f 6361 6c6c 2822 4445 4c45  f.api_call("DELE
-0000b5c0: 5445 222c 2070 6174 682c 2065 7272 6f72  TE", path, error
-0000b5d0: 2c20 7061 7261 6d73 3d70 6172 616d 7329  , params=params)
-0000b5e0: 0a0a 2020 2020 6465 6620 6372 6561 7465  ..    def create
-0000b5f0: 5f73 6368 6564 756c 6528 7365 6c66 2c20  _schedule(self, 
-0000b600: 7072 6f6a 6563 743a 2073 7472 2c20 7363  project: str, sc
-0000b610: 6865 6475 6c65 3a20 7363 6865 6d61 732e  hedule: schemas.
-0000b620: 5363 6865 6475 6c65 496e 7075 7429 3a0a  ScheduleInput):.
-0000b630: 2020 2020 2020 2020 2222 2243 7265 6174          """Creat
-0000b640: 6520 6120 6e65 7720 7363 6865 6475 6c65  e a new schedule
-0000b650: 206f 6e20 7468 6520 6769 7665 6e20 7072   on the given pr
-0000b660: 6f6a 6563 742e 2054 6865 2064 6574 6169  oject. The detai
-0000b670: 6c73 206f 6e20 7468 6520 6163 7475 616c  ls on the actual
-0000b680: 206f 626a 6563 7420 746f 2073 6368 6564   object to sched
-0000b690: 756c 6520 6173 2077 656c 6c20 6173 2074  ule as well as t
-0000b6a0: 6865 0a20 2020 2020 2020 2073 6368 6564  he.        sched
-0000b6b0: 756c 6520 6974 7365 6c66 2061 7265 2077  ule itself are w
-0000b6c0: 6974 6869 6e20 7468 6520 7363 6865 6475  ithin the schedu
-0000b6d0: 6c65 206f 626a 6563 7420 7072 6f76 6964  le object provid
-0000b6e0: 6564 2e0a 2020 2020 2020 2020 5468 6520  ed..        The 
-0000b6f0: 3a70 793a 636c 6173 733a 607e 5363 6865  :py:class:`~Sche
-0000b700: 6475 6c65 4372 6f6e 5472 6967 6765 7260  duleCronTrigger`
-0000b710: 2066 6f6c 6c6f 7773 2074 6865 2067 7569   follows the gui
-0000b720: 6465 6c69 6e65 7320 696e 0a20 2020 2020  delines in.     
-0000b730: 2020 2068 7474 7073 3a2f 2f61 7073 6368     https://apsch
-0000b740: 6564 756c 6572 2e72 6561 6474 6865 646f  eduler.readthedo
-0000b750: 6373 2e69 6f2f 656e 2f33 2e78 2f6d 6f64  cs.io/en/3.x/mod
-0000b760: 756c 6573 2f74 7269 6767 6572 732f 6372  ules/triggers/cr
-0000b770: 6f6e 2e68 746d 6c2e 0a20 2020 2020 2020  on.html..       
-0000b780: 2049 7420 616c 736f 2073 7570 706f 7274   It also support
-0000b790: 7320 6120 3a70 793a 6675 6e63 3a60 7e53  s a :py:func:`~S
-0000b7a0: 6368 6564 756c 6543 726f 6e54 7269 6767  cheduleCronTrigg
-0000b7b0: 6572 2e66 726f 6d5f 6372 6f6e 7461 6260  er.from_crontab`
-0000b7c0: 2066 756e 6374 696f 6e20 7468 6174 2061   function that a
-0000b7d0: 6363 6570 7473 2061 0a20 2020 2020 2020  ccepts a.       
-0000b7e0: 2063 726f 6e74 6162 2d66 6f72 6d61 7474   crontab-formatt
-0000b7f0: 6564 2073 7472 696e 6720 2873 6565 2068  ed string (see h
-0000b800: 7474 7073 3a2f 2f65 6e2e 7769 6b69 7065  ttps://en.wikipe
-0000b810: 6469 612e 6f72 672f 7769 6b69 2f43 726f  dia.org/wiki/Cro
-0000b820: 6e20 666f 7220 6d6f 7265 2069 6e66 6f72  n for more infor
-0000b830: 6d61 7469 6f6e 206f 6e20 7468 6520 666f  mation on the fo
-0000b840: 726d 6174 2061 6e64 0a20 2020 2020 2020  rmat and.       
-0000b850: 206e 6f74 6520 7468 6174 2074 6865 2030   note that the 0
-0000b860: 2077 6565 6b64 6179 2069 7320 616c 7761   weekday is alwa
-0000b870: 7973 206d 6f6e 6461 7929 2e0a 0a0a 2020  ys monday)....  
-0000b880: 2020 2020 2020 4578 616d 706c 653a 3a0a        Example::.
-0000b890: 0a20 2020 2020 2020 2020 2020 2066 726f  .            fro
-0000b8a0: 6d20 6d6c 7275 6e2e 6170 6920 696d 706f  m mlrun.api impo
-0000b8b0: 7274 2073 6368 656d 6173 0a0a 2020 2020  rt schemas..    
-0000b8c0: 2020 2020 2020 2020 2320 4578 6563 7574          # Execut
-0000b8d0: 6520 7468 6520 6765 745f 6461 7461 5f66  e the get_data_f
-0000b8e0: 756e 6320 6675 6e63 7469 6f6e 2065 7665  unc function eve
-0000b8f0: 7279 2054 7565 7364 6179 2061 7420 3135  ry Tuesday at 15
-0000b900: 3a33 300a 2020 2020 2020 2020 2020 2020  :30.            
-0000b910: 7363 6865 6475 6c65 203d 2073 6368 656d  schedule = schem
-0000b920: 6173 2e53 6368 6564 756c 6549 6e70 7574  as.ScheduleInput
-0000b930: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000b940: 2020 6e61 6d65 3d22 7275 6e5f 6675 6e63    name="run_func
-0000b950: 5f6f 6e5f 7475 6573 6461 7973 222c 0a20  _on_tuesdays",. 
-0000b960: 2020 2020 2020 2020 2020 2020 2020 206b                 k
-0000b970: 696e 643d 226a 6f62 222c 0a20 2020 2020  ind="job",.     
-0000b980: 2020 2020 2020 2020 2020 2073 6368 6564             sched
-0000b990: 756c 6564 5f6f 626a 6563 743d 6765 745f  uled_object=get_
-0000b9a0: 6461 7461 5f66 756e 632c 0a20 2020 2020  data_func,.     
-0000b9b0: 2020 2020 2020 2020 2020 2063 726f 6e5f             cron_
-0000b9c0: 7472 6967 6765 723d 7363 6865 6d61 732e  trigger=schemas.
-0000b9d0: 5363 6865 6475 6c65 4372 6f6e 5472 6967  ScheduleCronTrig
-0000b9e0: 6765 7228 6461 795f 6f66 5f77 6565 6b3d  ger(day_of_week=
-0000b9f0: 2774 7565 272c 2068 6f75 723d 3135 2c20  'tue', hour=15, 
-0000ba00: 6d69 6e75 7465 3d33 3029 2c0a 2020 2020  minute=30),.    
-0000ba10: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-0000ba20: 2020 2020 2020 6462 2e63 7265 6174 655f        db.create_
-0000ba30: 7363 6865 6475 6c65 2870 726f 6a65 6374  schedule(project
-0000ba40: 5f6e 616d 652c 2073 6368 6564 756c 6529  _name, schedule)
-0000ba50: 0a20 2020 2020 2020 2022 2222 0a0a 2020  .        """..  
-0000ba60: 2020 2020 2020 7072 6f6a 6563 7420 3d20        project = 
-0000ba70: 7072 6f6a 6563 7420 6f72 2063 6f6e 6669  project or confi
-0000ba80: 672e 6465 6661 756c 745f 7072 6f6a 6563  g.default_projec
-0000ba90: 740a 2020 2020 2020 2020 7061 7468 203d  t.        path =
-0000baa0: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
-0000bab0: 6a65 6374 7d2f 7363 6865 6475 6c65 7322  ject}/schedules"
-0000bac0: 0a0a 2020 2020 2020 2020 6572 726f 725f  ..        error_
-0000bad0: 6d65 7373 6167 6520 3d20 6622 4661 696c  message = f"Fail
-0000bae0: 6564 2063 7265 6174 696e 6720 7363 6865  ed creating sche
-0000baf0: 6475 6c65 207b 7072 6f6a 6563 747d 2f7b  dule {project}/{
-0000bb00: 7363 6865 6475 6c65 2e6e 616d 657d 220a  schedule.name}".
-0000bb10: 2020 2020 2020 2020 7365 6c66 2e61 7069          self.api
-0000bb20: 5f63 616c 6c28 2250 4f53 5422 2c20 7061  _call("POST", pa
-0000bb30: 7468 2c20 6572 726f 725f 6d65 7373 6167  th, error_messag
-0000bb40: 652c 2062 6f64 793d 6469 6374 5f74 6f5f  e, body=dict_to_
-0000bb50: 6a73 6f6e 2873 6368 6564 756c 652e 6469  json(schedule.di
-0000bb60: 6374 2829 2929 0a0a 2020 2020 6465 6620  ct()))..    def 
-0000bb70: 7570 6461 7465 5f73 6368 6564 756c 6528  update_schedule(
-0000bb80: 0a20 2020 2020 2020 2073 656c 662c 2070  .        self, p
-0000bb90: 726f 6a65 6374 3a20 7374 722c 206e 616d  roject: str, nam
-0000bba0: 653a 2073 7472 2c20 7363 6865 6475 6c65  e: str, schedule
-0000bbb0: 3a20 7363 6865 6d61 732e 5363 6865 6475  : schemas.Schedu
-0000bbc0: 6c65 5570 6461 7465 0a20 2020 2029 3a0a  leUpdate.    ):.
-0000bbd0: 2020 2020 2020 2020 2222 2255 7064 6174          """Updat
-0000bbe0: 6520 616e 2065 7869 7374 696e 6720 7363  e an existing sc
-0000bbf0: 6865 6475 6c65 2c20 7265 706c 6163 6520  hedule, replace 
-0000bc00: 6974 2077 6974 6820 7468 6520 6465 7461  it with the deta
-0000bc10: 696c 7320 636f 6e74 6169 6e65 6420 696e  ils contained in
-0000bc20: 2074 6865 2073 6368 6564 756c 6520 6f62   the schedule ob
-0000bc30: 6a65 6374 2e22 2222 0a0a 2020 2020 2020  ject."""..      
-0000bc40: 2020 7072 6f6a 6563 7420 3d20 7072 6f6a    project = proj
-0000bc50: 6563 7420 6f72 2063 6f6e 6669 672e 6465  ect or config.de
-0000bc60: 6661 756c 745f 7072 6f6a 6563 740a 2020  fault_project.  
-0000bc70: 2020 2020 2020 7061 7468 203d 2066 2270        path = f"p
-0000bc80: 726f 6a65 6374 732f 7b70 726f 6a65 6374  rojects/{project
-0000bc90: 7d2f 7363 6865 6475 6c65 732f 7b6e 616d  }/schedules/{nam
-0000bca0: 657d 220a 0a20 2020 2020 2020 2065 7272  e}"..        err
-0000bcb0: 6f72 5f6d 6573 7361 6765 203d 2066 2246  or_message = f"F
-0000bcc0: 6169 6c65 6420 7570 6461 7469 6e67 2073  ailed updating s
-0000bcd0: 6368 6564 756c 6520 7b70 726f 6a65 6374  chedule {project
-0000bce0: 7d2f 7b6e 616d 657d 220a 2020 2020 2020  }/{name}".      
-0000bcf0: 2020 7365 6c66 2e61 7069 5f63 616c 6c28    self.api_call(
-0000bd00: 2250 5554 222c 2070 6174 682c 2065 7272  "PUT", path, err
-0000bd10: 6f72 5f6d 6573 7361 6765 2c20 626f 6479  or_message, body
-0000bd20: 3d64 6963 745f 746f 5f6a 736f 6e28 7363  =dict_to_json(sc
-0000bd30: 6865 6475 6c65 2e64 6963 7428 2929 290a  hedule.dict())).
-0000bd40: 0a20 2020 2064 6566 2067 6574 5f73 6368  .    def get_sch
-0000bd50: 6564 756c 6528 0a20 2020 2020 2020 2073  edule(.        s
-0000bd60: 656c 662c 2070 726f 6a65 6374 3a20 7374  elf, project: st
-0000bd70: 722c 206e 616d 653a 2073 7472 2c20 696e  r, name: str, in
-0000bd80: 636c 7564 655f 6c61 7374 5f72 756e 3a20  clude_last_run: 
-0000bd90: 626f 6f6c 203d 2046 616c 7365 0a20 2020  bool = False.   
-0000bda0: 2029 202d 3e20 7363 6865 6d61 732e 5363   ) -> schemas.Sc
-0000bdb0: 6865 6475 6c65 4f75 7470 7574 3a0a 2020  heduleOutput:.  
-0000bdc0: 2020 2020 2020 2222 2252 6574 7269 6576        """Retriev
-0000bdd0: 6520 6465 7461 696c 7320 6f66 2074 6865  e details of the
-0000bde0: 2073 6368 6564 756c 6520 696e 2071 7565   schedule in que
-0000bdf0: 7374 696f 6e2e 2042 6573 6964 6573 2072  stion. Besides r
-0000be00: 6574 7572 6e69 6e67 2074 6865 2064 6574  eturning the det
-0000be10: 6169 6c73 206f 6620 7468 6520 7363 6865  ails of the sche
-0000be20: 6475 6c65 206f 626a 6563 7420 6974 7365  dule object itse
-0000be30: 6c66 2c0a 2020 2020 2020 2020 7468 6973  lf,.        this
-0000be40: 2066 756e 6374 696f 6e20 616c 736f 2072   function also r
-0000be50: 6574 7572 6e73 2074 6865 206e 6578 7420  eturns the next 
-0000be60: 7363 6865 6475 6c65 6420 7275 6e20 666f  scheduled run fo
-0000be70: 7220 7468 6973 2073 7065 6369 6669 6320  r this specific 
-0000be80: 7363 6865 6475 6c65 2c20 6173 2077 656c  schedule, as wel
-0000be90: 6c20 6173 2070 6f74 656e 7469 616c 6c79  l as potentially
-0000bea0: 2074 6865 0a20 2020 2020 2020 2072 6573   the.        res
-0000beb0: 756c 7473 206f 6620 7468 6520 6c61 7374  ults of the last
-0000bec0: 2072 756e 2065 7865 6375 7465 6420 7468   run executed th
-0000bed0: 726f 7567 6820 7468 6973 2073 6368 6564  rough this sched
-0000bee0: 756c 652e 0a0a 2020 2020 2020 2020 3a70  ule...        :p
-0000bef0: 6172 616d 2070 726f 6a65 6374 3a20 5072  aram project: Pr
-0000bf00: 6f6a 6563 7420 6e61 6d65 2e0a 2020 2020  oject name..    
-0000bf10: 2020 2020 3a70 6172 616d 206e 616d 653a      :param name:
-0000bf20: 204e 616d 6520 6f66 2074 6865 2073 6368   Name of the sch
-0000bf30: 6564 756c 6520 6f62 6a65 6374 2074 6f20  edule object to 
-0000bf40: 7175 6572 792e 0a20 2020 2020 2020 203a  query..        :
-0000bf50: 7061 7261 6d20 696e 636c 7564 655f 6c61  param include_la
-0000bf60: 7374 5f72 756e 3a20 5768 6574 6865 7220  st_run: Whether 
-0000bf70: 746f 2069 6e63 6c75 6465 2074 6865 2072  to include the r
-0000bf80: 6573 756c 7473 206f 6620 7468 6520 7363  esults of the sc
-0000bf90: 6865 6475 6c65 2773 206c 6173 7420 7275  hedule's last ru
-0000bfa0: 6e20 696e 2074 6865 2072 6573 706f 6e73  n in the respons
-0000bfb0: 652e 0a20 2020 2020 2020 2022 2222 0a0a  e..        """..
-0000bfc0: 2020 2020 2020 2020 7072 6f6a 6563 7420          project 
-0000bfd0: 3d20 7072 6f6a 6563 7420 6f72 2063 6f6e  = project or con
-0000bfe0: 6669 672e 6465 6661 756c 745f 7072 6f6a  fig.default_proj
-0000bff0: 6563 740a 2020 2020 2020 2020 7061 7468  ect.        path
-0000c000: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
-0000c010: 726f 6a65 6374 7d2f 7363 6865 6475 6c65  roject}/schedule
-0000c020: 732f 7b6e 616d 657d 220a 2020 2020 2020  s/{name}".      
-0000c030: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
-0000c040: 3d20 6622 4661 696c 6564 2067 6574 7469  = f"Failed getti
-0000c050: 6e67 2073 6368 6564 756c 6520 666f 7220  ng schedule for 
-0000c060: 7b70 726f 6a65 6374 7d2f 7b6e 616d 657d  {project}/{name}
-0000c070: 220a 2020 2020 2020 2020 7265 7370 203d  ".        resp =
-0000c080: 2073 656c 662e 6170 695f 6361 6c6c 280a   self.api_call(.
-0000c090: 2020 2020 2020 2020 2020 2020 2247 4554              "GET
-0000c0a0: 222c 2070 6174 682c 2065 7272 6f72 5f6d  ", path, error_m
-0000c0b0: 6573 7361 6765 2c20 7061 7261 6d73 3d7b  essage, params={
-0000c0c0: 2269 6e63 6c75 6465 5f6c 6173 745f 7275  "include_last_ru
-0000c0d0: 6e22 3a20 696e 636c 7564 655f 6c61 7374  n": include_last
-0000c0e0: 5f72 756e 7d0a 2020 2020 2020 2020 290a  _run}.        ).
-0000c0f0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-0000c100: 6368 656d 6173 2e53 6368 6564 756c 654f  chemas.ScheduleO
-0000c110: 7574 7075 7428 2a2a 7265 7370 2e6a 736f  utput(**resp.jso
-0000c120: 6e28 2929 0a0a 2020 2020 6465 6620 6c69  n())..    def li
-0000c130: 7374 5f73 6368 6564 756c 6573 280a 2020  st_schedules(.  
-0000c140: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
-0000c150: 2020 2020 7072 6f6a 6563 743a 2073 7472      project: str
-0000c160: 2c0a 2020 2020 2020 2020 6e61 6d65 3a20  ,.        name: 
-0000c170: 7374 7220 3d20 4e6f 6e65 2c0a 2020 2020  str = None,.    
-0000c180: 2020 2020 6b69 6e64 3a20 7363 6865 6d61      kind: schema
-0000c190: 732e 5363 6865 6475 6c65 4b69 6e64 7320  s.ScheduleKinds 
-0000c1a0: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-0000c1b0: 696e 636c 7564 655f 6c61 7374 5f72 756e  include_last_run
-0000c1c0: 3a20 626f 6f6c 203d 2046 616c 7365 2c0a  : bool = False,.
-0000c1d0: 2020 2020 2920 2d3e 2073 6368 656d 6173      ) -> schemas
-0000c1e0: 2e53 6368 6564 756c 6573 4f75 7470 7574  .SchedulesOutput
-0000c1f0: 3a0a 2020 2020 2020 2020 2222 2252 6574  :.        """Ret
-0000c200: 7269 6576 6520 6c69 7374 206f 6620 7363  rieve list of sc
-0000c210: 6865 6475 6c65 7320 6f66 2073 7065 6369  hedules of speci
-0000c220: 6669 6320 6e61 6d65 206f 7220 6b69 6e64  fic name or kind
-0000c230: 2e0a 0a20 2020 2020 2020 203a 7061 7261  ...        :para
-0000c240: 6d20 7072 6f6a 6563 743a 2050 726f 6a65  m project: Proje
-0000c250: 6374 206e 616d 652e 0a20 2020 2020 2020  ct name..       
-0000c260: 203a 7061 7261 6d20 6e61 6d65 3a20 4e61   :param name: Na
-0000c270: 6d65 206f 6620 7363 6865 6475 6c65 2074  me of schedule t
-0000c280: 6f20 7265 7472 6965 7665 2e20 4361 6e20  o retrieve. Can 
-0000c290: 6265 206f 6d69 7474 6564 2074 6f20 6c69  be omitted to li
-0000c2a0: 7374 2061 6c6c 2073 6368 6564 756c 6573  st all schedules
-0000c2b0: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0000c2c0: 206b 696e 643a 204b 696e 6420 6f66 2073   kind: Kind of s
-0000c2d0: 6368 6564 756c 6520 6f62 6a65 6374 7320  chedule objects 
-0000c2e0: 746f 2072 6574 7269 6576 652c 2063 616e  to retrieve, can
-0000c2f0: 2062 6520 6569 7468 6572 2060 606a 6f62   be either ``job
-0000c300: 6060 206f 7220 6060 7069 7065 6c69 6e65  `` or ``pipeline
-0000c310: 6060 2e0a 2020 2020 2020 2020 3a70 6172  ``..        :par
-0000c320: 616d 2069 6e63 6c75 6465 5f6c 6173 745f  am include_last_
-0000c330: 7275 6e3a 2057 6865 7468 6572 2074 6f20  run: Whether to 
-0000c340: 7265 7475 726e 2066 6f72 2065 6163 6820  return for each 
-0000c350: 7363 6865 6475 6c65 2072 6574 7572 6e65  schedule returne
-0000c360: 6420 616c 736f 2074 6865 2072 6573 756c  d also the resul
-0000c370: 7473 206f 6620 7468 6520 6c61 7374 2072  ts of the last r
-0000c380: 756e 206f 660a 2020 2020 2020 2020 2020  un of.          
-0000c390: 2020 7468 6174 2073 6368 6564 756c 652e    that schedule.
-0000c3a0: 0a20 2020 2020 2020 2022 2222 0a0a 2020  .        """..  
-0000c3b0: 2020 2020 2020 7072 6f6a 6563 7420 3d20        project = 
-0000c3c0: 7072 6f6a 6563 7420 6f72 2063 6f6e 6669  project or confi
-0000c3d0: 672e 6465 6661 756c 745f 7072 6f6a 6563  g.default_projec
-0000c3e0: 740a 2020 2020 2020 2020 7061 7261 6d73  t.        params
-0000c3f0: 203d 207b 226b 696e 6422 3a20 6b69 6e64   = {"kind": kind
-0000c400: 2c20 226e 616d 6522 3a20 6e61 6d65 2c20  , "name": name, 
-0000c410: 2269 6e63 6c75 6465 5f6c 6173 745f 7275  "include_last_ru
-0000c420: 6e22 3a20 696e 636c 7564 655f 6c61 7374  n": include_last
-0000c430: 5f72 756e 7d0a 2020 2020 2020 2020 7061  _run}.        pa
-0000c440: 7468 203d 2066 2270 726f 6a65 6374 732f  th = f"projects/
-0000c450: 7b70 726f 6a65 6374 7d2f 7363 6865 6475  {project}/schedu
-0000c460: 6c65 7322 0a20 2020 2020 2020 2065 7272  les".        err
-0000c470: 6f72 5f6d 6573 7361 6765 203d 2066 2246  or_message = f"F
-0000c480: 6169 6c65 6420 6c69 7374 696e 6720 7363  ailed listing sc
-0000c490: 6865 6475 6c65 7320 666f 7220 7b70 726f  hedules for {pro
-0000c4a0: 6a65 6374 7d20 3f20 7b6b 696e 647d 207b  ject} ? {kind} {
-0000c4b0: 6e61 6d65 7d22 0a20 2020 2020 2020 2072  name}".        r
-0000c4c0: 6573 7020 3d20 7365 6c66 2e61 7069 5f63  esp = self.api_c
-0000c4d0: 616c 6c28 2247 4554 222c 2070 6174 682c  all("GET", path,
-0000c4e0: 2065 7272 6f72 5f6d 6573 7361 6765 2c20   error_message, 
-0000c4f0: 7061 7261 6d73 3d70 6172 616d 7329 0a20  params=params). 
-0000c500: 2020 2020 2020 2072 6574 7572 6e20 7363         return sc
-0000c510: 6865 6d61 732e 5363 6865 6475 6c65 734f  hemas.SchedulesO
-0000c520: 7574 7075 7428 2a2a 7265 7370 2e6a 736f  utput(**resp.jso
-0000c530: 6e28 2929 0a0a 2020 2020 6465 6620 6465  n())..    def de
-0000c540: 6c65 7465 5f73 6368 6564 756c 6528 7365  lete_schedule(se
-0000c550: 6c66 2c20 7072 6f6a 6563 743a 2073 7472  lf, project: str
-0000c560: 2c20 6e61 6d65 3a20 7374 7229 3a0a 2020  , name: str):.  
-0000c570: 2020 2020 2020 2222 2244 656c 6574 6520        """Delete 
-0000c580: 6120 7370 6563 6966 6963 2073 6368 6564  a specific sched
-0000c590: 756c 6520 6279 206e 616d 652e 2222 220a  ule by name.""".
-0000c5a0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-0000c5b0: 203d 2070 726f 6a65 6374 206f 7220 636f   = project or co
-0000c5c0: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
-0000c5d0: 6a65 6374 0a20 2020 2020 2020 2070 6174  ject.        pat
-0000c5e0: 6820 3d20 6622 7072 6f6a 6563 7473 2f7b  h = f"projects/{
-0000c5f0: 7072 6f6a 6563 747d 2f73 6368 6564 756c  project}/schedul
-0000c600: 6573 2f7b 6e61 6d65 7d22 0a20 2020 2020  es/{name}".     
-0000c610: 2020 2065 7272 6f72 5f6d 6573 7361 6765     error_message
-0000c620: 203d 2066 2246 6169 6c65 6420 6465 6c65   = f"Failed dele
-0000c630: 7469 6e67 2073 6368 6564 756c 6520 7b70  ting schedule {p
-0000c640: 726f 6a65 6374 7d2f 7b6e 616d 657d 220a  roject}/{name}".
-0000c650: 2020 2020 2020 2020 7365 6c66 2e61 7069          self.api
-0000c660: 5f63 616c 6c28 2244 454c 4554 4522 2c20  _call("DELETE", 
-0000c670: 7061 7468 2c20 6572 726f 725f 6d65 7373  path, error_mess
-0000c680: 6167 6529 0a0a 2020 2020 6465 6620 696e  age)..    def in
-0000c690: 766f 6b65 5f73 6368 6564 756c 6528 7365  voke_schedule(se
-0000c6a0: 6c66 2c20 7072 6f6a 6563 743a 2073 7472  lf, project: str
-0000c6b0: 2c20 6e61 6d65 3a20 7374 7229 3a0a 2020  , name: str):.  
-0000c6c0: 2020 2020 2020 2222 2245 7865 6375 7465        """Execute
-0000c6d0: 2074 6865 206f 626a 6563 7420 7265 6665   the object refe
-0000c6e0: 7265 6e63 6564 2062 7920 7468 6520 7363  renced by the sc
-0000c6f0: 6865 6475 6c65 2069 6d6d 6564 6961 7465  hedule immediate
-0000c700: 6c79 2e22 2222 0a0a 2020 2020 2020 2020  ly."""..        
-0000c710: 7072 6f6a 6563 7420 3d20 7072 6f6a 6563  project = projec
-0000c720: 7420 6f72 2063 6f6e 6669 672e 6465 6661  t or config.defa
-0000c730: 756c 745f 7072 6f6a 6563 740a 2020 2020  ult_project.    
-0000c740: 2020 2020 7061 7468 203d 2066 2270 726f      path = f"pro
-0000c750: 6a65 6374 732f 7b70 726f 6a65 6374 7d2f  jects/{project}/
-0000c760: 7363 6865 6475 6c65 732f 7b6e 616d 657d  schedules/{name}
-0000c770: 2f69 6e76 6f6b 6522 0a20 2020 2020 2020  /invoke".       
-0000c780: 2065 7272 6f72 5f6d 6573 7361 6765 203d   error_message =
-0000c790: 2066 2246 6169 6c65 6420 696e 766f 6b69   f"Failed invoki
-0000c7a0: 6e67 2073 6368 6564 756c 6520 7b70 726f  ng schedule {pro
-0000c7b0: 6a65 6374 7d2f 7b6e 616d 657d 220a 2020  ject}/{name}".  
-0000c7c0: 2020 2020 2020 7365 6c66 2e61 7069 5f63        self.api_c
-0000c7d0: 616c 6c28 2250 4f53 5422 2c20 7061 7468  all("POST", path
-0000c7e0: 2c20 6572 726f 725f 6d65 7373 6167 6529  , error_message)
-0000c7f0: 0a0a 2020 2020 6465 6620 7265 6d6f 7465  ..    def remote
-0000c800: 5f62 7569 6c64 6572 280a 2020 2020 2020  _builder(.      
-0000c810: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
-0000c820: 6675 6e63 2c0a 2020 2020 2020 2020 7769  func,.        wi
-0000c830: 7468 5f6d 6c72 756e 2c0a 2020 2020 2020  th_mlrun,.      
-0000c840: 2020 6d6c 7275 6e5f 7665 7273 696f 6e5f    mlrun_version_
-0000c850: 7370 6563 6966 6965 723d 4e6f 6e65 2c0a  specifier=None,.
-0000c860: 2020 2020 2020 2020 736b 6970 5f64 6570          skip_dep
-0000c870: 6c6f 7965 643d 4661 6c73 652c 0a20 2020  loyed=False,.   
-0000c880: 2020 2020 2062 7569 6c64 6572 5f65 6e76       builder_env
-0000c890: 3d4e 6f6e 652c 0a20 2020 2029 3a0a 2020  =None,.    ):.  
-0000c8a0: 2020 2020 2020 2222 2242 7569 6c64 2074        """Build t
-0000c8b0: 6865 2070 6f64 2069 6d61 6765 2066 6f72  he pod image for
-0000c8c0: 2061 2066 756e 6374 696f 6e2c 2066 6f72   a function, for
-0000c8d0: 2065 7865 6375 7469 6f6e 206f 6e20 6120   execution on a 
-0000c8e0: 7265 6d6f 7465 2063 6c75 7374 6572 2e20  remote cluster. 
-0000c8f0: 5468 6973 2069 7320 6578 6563 7574 6564  This is executed
-0000c900: 2062 7920 7468 6520 4d4c 5275 6e0a 2020   by the MLRun.  
-0000c910: 2020 2020 2020 4150 4920 7365 7276 6572        API server
-0000c920: 2c20 616e 6420 6372 6561 7465 7320 6120  , and creates a 
-0000c930: 446f 636b 6572 2069 6d61 6765 206f 7574  Docker image out
-0000c940: 206f 6620 7468 6520 6675 6e63 7469 6f6e   of the function
-0000c950: 2070 726f 7669 6465 6420 616e 6420 616e   provided and an
-0000c960: 7920 7370 6563 6966 6963 2062 7569 6c64  y specific build
-0000c970: 0a20 2020 2020 2020 2069 6e73 7472 7563  .        instruc
-0000c980: 7469 6f6e 7320 7072 6f76 6964 6564 2077  tions provided w
-0000c990: 6974 6869 6e2e 2054 6869 7320 6973 2061  ithin. This is a
-0000c9a0: 2070 7265 2d72 6571 7569 7369 7465 2066   pre-requisite f
-0000c9b0: 6f72 2072 656d 6f74 656c 7920 6578 6563  or remotely exec
-0000c9c0: 7574 696e 6720 6120 6675 6e63 7469 6f6e  uting a function
-0000c9d0: 2c20 756e 6c65 7373 2075 7369 6e67 0a20  , unless using. 
-0000c9e0: 2020 2020 2020 2061 2070 7265 2d64 6570         a pre-dep
-0000c9f0: 6c6f 7965 6420 696d 6167 652e 0a0a 2020  loyed image...  
-0000ca00: 2020 2020 2020 3a70 6172 616d 2066 756e        :param fun
-0000ca10: 633a 2046 756e 6374 696f 6e20 746f 2062  c: Function to b
-0000ca20: 7569 6c64 2e0a 2020 2020 2020 2020 3a70  uild..        :p
-0000ca30: 6172 616d 2077 6974 685f 6d6c 7275 6e3a  aram with_mlrun:
-0000ca40: 2057 6865 7468 6572 2074 6f20 6164 6420   Whether to add 
-0000ca50: 4d4c 5275 6e20 7061 636b 6167 6520 746f  MLRun package to
-0000ca60: 2074 6865 2062 7569 6c74 2070 6163 6b61   the built packa
-0000ca70: 6765 2e20 5468 6973 2069 7320 6e6f 7420  ge. This is not 
-0000ca80: 7265 7175 6972 6564 2069 6620 7573 696e  required if usin
-0000ca90: 6720 6120 6261 7365 0a20 2020 2020 2020  g a base.       
-0000caa0: 2020 2020 2069 6d61 6765 2074 6861 7420       image that 
-0000cab0: 616c 7265 6164 7920 6861 7320 4d4c 5275  already has MLRu
-0000cac0: 6e20 696e 2069 742e 0a20 2020 2020 2020  n in it..       
-0000cad0: 203a 7061 7261 6d20 6d6c 7275 6e5f 7665   :param mlrun_ve
-0000cae0: 7273 696f 6e5f 7370 6563 6966 6965 723a  rsion_specifier:
-0000caf0: 2056 6572 7369 6f6e 206f 6620 4d4c 5275   Version of MLRu
-0000cb00: 6e20 746f 2069 6e63 6c75 6465 2069 6e20  n to include in 
-0000cb10: 7468 6520 6275 696c 7420 696d 6167 652e  the built image.
-0000cb20: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0000cb30: 736b 6970 5f64 6570 6c6f 7965 643a 2053  skip_deployed: S
-0000cb40: 6b69 7020 7468 6520 6275 696c 6420 6966  kip the build if
-0000cb50: 2077 6520 616c 7265 6164 7920 6861 7665   we already have
-0000cb60: 2061 6e20 696d 6167 6520 666f 7220 7468   an image for th
-0000cb70: 6520 6675 6e63 7469 6f6e 2e0a 2020 2020  e function..    
-0000cb80: 2020 2020 3a70 6172 616d 2062 7569 6c64      :param build
-0000cb90: 6572 5f65 6e76 3a20 2020 4b61 6e69 6b6f  er_env:   Kaniko
-0000cba0: 2062 7569 6c64 6572 2070 6f64 2065 6e76   builder pod env
-0000cbb0: 2076 6172 7320 6469 6374 2028 666f 7220   vars dict (for 
-0000cbc0: 636f 6e66 6967 2f63 7265 6465 6e74 6961  config/credentia
-0000cbd0: 6c73 290a 2020 2020 2020 2020 2222 220a  ls).        """.
-0000cbe0: 0a20 2020 2020 2020 2074 7279 3a0a 2020  .        try:.  
-0000cbf0: 2020 2020 2020 2020 2020 7265 7120 3d20            req = 
-0000cc00: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
-0000cc10: 2020 2266 756e 6374 696f 6e22 3a20 6675    "function": fu
-0000cc20: 6e63 2e74 6f5f 6469 6374 2829 2c0a 2020  nc.to_dict(),.  
-0000cc30: 2020 2020 2020 2020 2020 2020 2020 2277                "w
-0000cc40: 6974 685f 6d6c 7275 6e22 3a20 626f 6f6c  ith_mlrun": bool
-0000cc50: 3273 7472 2877 6974 685f 6d6c 7275 6e29  2str(with_mlrun)
-0000cc60: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000cc70: 2020 2273 6b69 705f 6465 706c 6f79 6564    "skip_deployed
-0000cc80: 223a 2073 6b69 705f 6465 706c 6f79 6564  ": skip_deployed
-0000cc90: 2c0a 2020 2020 2020 2020 2020 2020 7d0a  ,.            }.
-0000cca0: 2020 2020 2020 2020 2020 2020 6966 206d              if m
-0000ccb0: 6c72 756e 5f76 6572 7369 6f6e 5f73 7065  lrun_version_spe
-0000ccc0: 6369 6669 6572 3a0a 2020 2020 2020 2020  cifier:.        
-0000ccd0: 2020 2020 2020 2020 7265 715b 226d 6c72          req["mlr
-0000cce0: 756e 5f76 6572 7369 6f6e 5f73 7065 6369  un_version_speci
-0000ccf0: 6669 6572 225d 203d 206d 6c72 756e 5f76  fier"] = mlrun_v
-0000cd00: 6572 7369 6f6e 5f73 7065 6369 6669 6572  ersion_specifier
-0000cd10: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0000cd20: 6275 696c 6465 725f 656e 763a 0a20 2020  builder_env:.   
-0000cd30: 2020 2020 2020 2020 2020 2020 2072 6571               req
-0000cd40: 5b22 6275 696c 6465 725f 656e 7622 5d20  ["builder_env"] 
-0000cd50: 3d20 6275 696c 6465 725f 656e 760a 2020  = builder_env.  
-0000cd60: 2020 2020 2020 2020 2020 7265 7370 203d            resp =
-0000cd70: 2073 656c 662e 6170 695f 6361 6c6c 2822   self.api_call("
-0000cd80: 504f 5354 222c 2022 6275 696c 642f 6675  POST", "build/fu
-0000cd90: 6e63 7469 6f6e 222c 206a 736f 6e3d 7265  nction", json=re
-0000cda0: 7129 0a20 2020 2020 2020 2065 7863 6570  q).        excep
-0000cdb0: 7420 4f53 4572 726f 7220 6173 2065 7272  t OSError as err
-0000cdc0: 3a0a 2020 2020 2020 2020 2020 2020 6c6f  :.            lo
-0000cdd0: 6767 6572 2e65 7272 6f72 2866 2265 7272  gger.error(f"err
-0000cde0: 6f72 2073 7562 6d69 7474 696e 6720 6275  or submitting bu
-0000cdf0: 696c 6420 7461 736b 3a20 7b65 7272 5f74  ild task: {err_t
-0000ce00: 6f5f 7374 7228 6572 7229 7d22 290a 2020  o_str(err)}").  
-0000ce10: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0000ce20: 4f53 4572 726f 7228 6622 6572 726f 723a  OSError(f"error:
-0000ce30: 2063 616e 6e6f 7420 7375 626d 6974 2062   cannot submit b
-0000ce40: 7569 6c64 2c20 7b65 7272 5f74 6f5f 7374  uild, {err_to_st
-0000ce50: 7228 6572 7229 7d22 290a 0a20 2020 2020  r(err)}")..     
-0000ce60: 2020 2069 6620 6e6f 7420 7265 7370 2e6f     if not resp.o
-0000ce70: 6b3a 0a20 2020 2020 2020 2020 2020 206c  k:.            l
-0000ce80: 6f67 6765 722e 6572 726f 7228 6622 6261  ogger.error(f"ba
-0000ce90: 6420 7265 7370 2121 5c6e 7b72 6573 702e  d resp!!\n{resp.
-0000cea0: 7465 7874 7d22 290a 2020 2020 2020 2020  text}").        
-0000ceb0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-0000cec0: 7272 6f72 2822 6261 6420 6675 6e63 7469  rror("bad functi
-0000ced0: 6f6e 2072 756e 2072 6573 706f 6e73 6522  on run response"
-0000cee0: 290a 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-0000cef0: 6e20 7265 7370 2e6a 736f 6e28 290a 0a20  n resp.json().. 
-0000cf00: 2020 2064 6566 2067 6574 5f62 7569 6c64     def get_build
-0000cf10: 6572 5f73 7461 7475 7328 0a20 2020 2020  er_status(.     
-0000cf20: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
-0000cf30: 2066 756e 633a 2042 6173 6552 756e 7469   func: BaseRunti
-0000cf40: 6d65 2c0a 2020 2020 2020 2020 6f66 6673  me,.        offs
-0000cf50: 6574 3d30 2c0a 2020 2020 2020 2020 6c6f  et=0,.        lo
-0000cf60: 6773 3d54 7275 652c 0a20 2020 2020 2020  gs=True,.       
-0000cf70: 206c 6173 745f 6c6f 675f 7469 6d65 7374   last_log_timest
-0000cf80: 616d 703d 302c 0a20 2020 2020 2020 2076  amp=0,.        v
-0000cf90: 6572 626f 7365 3d46 616c 7365 2c0a 2020  erbose=False,.  
-0000cfa0: 2020 293a 0a20 2020 2020 2020 2022 2222    ):.        """
-0000cfb0: 5265 7472 6965 7665 2074 6865 2073 7461  Retrieve the sta
-0000cfc0: 7475 7320 6f66 2061 2062 7569 6c64 206f  tus of a build o
-0000cfd0: 7065 7261 7469 6f6e 2063 7572 7265 6e74  peration current
-0000cfe0: 6c79 2069 6e20 7072 6f67 7265 7373 2e0a  ly in progress..
-0000cff0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0000d000: 6675 6e63 3a20 4675 6e63 7469 6f6e 206f  func: Function o
-0000d010: 626a 6563 7420 7468 6174 2069 7320 6265  bject that is be
-0000d020: 696e 6720 6275 696c 742e 0a20 2020 2020  ing built..     
-0000d030: 2020 203a 7061 7261 6d20 6f66 6673 6574     :param offset
-0000d040: 3a20 4f66 6673 6574 2069 6e74 6f20 7468  : Offset into th
-0000d050: 6520 6275 696c 6420 6c6f 6773 2074 6f20  e build logs to 
-0000d060: 7265 7472 6965 7665 206c 6f67 7320 6672  retrieve logs fr
-0000d070: 6f6d 2e0a 2020 2020 2020 2020 3a70 6172  om..        :par
-0000d080: 616d 206c 6f67 733a 2053 686f 756c 6420  am logs: Should 
-0000d090: 6275 696c 6420 6c6f 6773 2062 6520 7265  build logs be re
-0000d0a0: 7472 6965 7665 642e 0a20 2020 2020 2020  trieved..       
-0000d0b0: 203a 7061 7261 6d20 6c61 7374 5f6c 6f67   :param last_log
-0000d0c0: 5f74 696d 6573 7461 6d70 3a20 4c61 7374  _timestamp: Last
-0000d0d0: 2074 696d 6573 7461 6d70 206f 6620 6c6f   timestamp of lo
-0000d0e0: 6773 2074 6861 7420 7765 7265 2061 6c72  gs that were alr
-0000d0f0: 6561 6479 2072 6574 7269 6576 6564 2e20  eady retrieved. 
-0000d100: 4675 6e63 7469 6f6e 2077 696c 6c20 7265  Function will re
-0000d110: 7475 726e 206f 6e6c 7920 6c6f 6773 0a20  turn only logs. 
-0000d120: 2020 2020 2020 2020 2020 206c 6174 6572             later
-0000d130: 2074 6861 6e20 7468 6973 2070 6172 616d   than this param
-0000d140: 6574 6572 2e0a 2020 2020 2020 2020 3a70  eter..        :p
-0000d150: 6172 616d 2076 6572 626f 7365 3a20 4164  aram verbose: Ad
-0000d160: 6420 7665 7262 6f73 6520 6c6f 6773 2069  d verbose logs i
-0000d170: 6e74 6f20 7468 6520 6f75 7470 7574 2e0a  nto the output..
-0000d180: 2020 2020 2020 2020 3a72 6574 7572 6e73          :returns
-0000d190: 3a20 5468 6520 666f 6c6c 6f77 696e 6720  : The following 
-0000d1a0: 7061 7261 6d65 7465 7273 3a0a 0a20 2020  parameters:..   
-0000d1b0: 2020 2020 2020 2020 202d 2054 6578 7420           - Text 
-0000d1c0: 6f66 2062 7569 6c64 6572 206c 6f67 732e  of builder logs.
-0000d1d0: 0a20 2020 2020 2020 2020 2020 202d 2054  .            - T
-0000d1e0: 696d 6573 7461 6d70 206f 6620 6c61 7374  imestamp of last
-0000d1f0: 206c 6f67 2072 6574 7269 6576 6564 2c20   log retrieved, 
-0000d200: 746f 2062 6520 7573 6564 2069 6e20 7375  to be used in su
-0000d210: 6273 6571 7565 6e74 2063 616c 6c73 2074  bsequent calls t
-0000d220: 6f20 7468 6973 2066 756e 6374 696f 6e2e  o this function.
-0000d230: 0a0a 2020 2020 2020 2020 2020 2020 5468  ..            Th
-0000d240: 6520 6675 6e63 7469 6f6e 2061 6c73 6f20  e function also 
-0000d250: 7570 6461 7465 7320 696e 7465 726e 616c  updates internal
-0000d260: 206d 656d 6265 7273 206f 6620 7468 6520   members of the 
-0000d270: 6060 6675 6e63 6060 206f 626a 6563 7420  ``func`` object 
-0000d280: 746f 2072 6566 6c65 6374 2062 7569 6c64  to reflect build
-0000d290: 2070 726f 6365 7373 2069 6e66 6f2e 0a20   process info.. 
-0000d2a0: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-0000d2b0: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-0000d2c0: 2020 2020 2070 6172 616d 7320 3d20 7b0a       params = {.
-0000d2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d2e0: 226e 616d 6522 3a20 6675 6e63 2e6d 6574  "name": func.met
-0000d2f0: 6164 6174 612e 6e61 6d65 2c0a 2020 2020  adata.name,.    
-0000d300: 2020 2020 2020 2020 2020 2020 2270 726f              "pro
-0000d310: 6a65 6374 223a 2066 756e 632e 6d65 7461  ject": func.meta
-0000d320: 6461 7461 2e70 726f 6a65 6374 2c0a 2020  data.project,.  
-0000d330: 2020 2020 2020 2020 2020 2020 2020 2274                "t
-0000d340: 6167 223a 2066 756e 632e 6d65 7461 6461  ag": func.metada
-0000d350: 7461 2e74 6167 2c0a 2020 2020 2020 2020  ta.tag,.        
-0000d360: 2020 2020 2020 2020 226c 6f67 7322 3a20          "logs": 
-0000d370: 626f 6f6c 3273 7472 286c 6f67 7329 2c0a  bool2str(logs),.
-0000d380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d390: 226f 6666 7365 7422 3a20 7374 7228 6f66  "offset": str(of
-0000d3a0: 6673 6574 292c 0a20 2020 2020 2020 2020  fset),.         
-0000d3b0: 2020 2020 2020 2022 6c61 7374 5f6c 6f67         "last_log
-0000d3c0: 5f74 696d 6573 7461 6d70 223a 2073 7472  _timestamp": str
-0000d3d0: 286c 6173 745f 6c6f 675f 7469 6d65 7374  (last_log_timest
-0000d3e0: 616d 7029 2c0a 2020 2020 2020 2020 2020  amp),.          
-0000d3f0: 2020 2020 2020 2276 6572 626f 7365 223a        "verbose":
-0000d400: 2062 6f6f 6c32 7374 7228 7665 7262 6f73   bool2str(verbos
-0000d410: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
-0000d420: 7d0a 2020 2020 2020 2020 2020 2020 7265  }.            re
-0000d430: 7370 203d 2073 656c 662e 6170 695f 6361  sp = self.api_ca
-0000d440: 6c6c 2822 4745 5422 2c20 2262 7569 6c64  ll("GET", "build
-0000d450: 2f73 7461 7475 7322 2c20 7061 7261 6d73  /status", params
-0000d460: 3d70 6172 616d 7329 0a20 2020 2020 2020  =params).       
-0000d470: 2065 7863 6570 7420 4f53 4572 726f 7220   except OSError 
-0000d480: 6173 2065 7272 3a0a 2020 2020 2020 2020  as err:.        
-0000d490: 2020 2020 6c6f 6767 6572 2e65 7272 6f72      logger.error
-0000d4a0: 2866 2265 7272 6f72 2067 6574 7469 6e67  (f"error getting
-0000d4b0: 2062 7569 6c64 2073 7461 7475 733a 207b   build status: {
-0000d4c0: 6572 725f 746f 5f73 7472 2865 7272 297d  err_to_str(err)}
-0000d4d0: 2229 0a20 2020 2020 2020 2020 2020 2072  ").            r
-0000d4e0: 6169 7365 204f 5345 7272 6f72 2866 2265  aise OSError(f"e
-0000d4f0: 7272 6f72 3a20 6361 6e6e 6f74 2067 6574  rror: cannot get
-0000d500: 2062 7569 6c64 2073 7461 7475 732c 207b   build status, {
-0000d510: 6572 725f 746f 5f73 7472 2865 7272 297d  err_to_str(err)}
-0000d520: 2229 0a0a 2020 2020 2020 2020 6966 206e  ")..        if n
-0000d530: 6f74 2072 6573 702e 6f6b 3a0a 2020 2020  ot resp.ok:.    
-0000d540: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
-0000d550: 6172 6e69 6e67 2866 2266 6169 6c65 6420  arning(f"failed 
-0000d560: 7265 7370 2c20 7b72 6573 702e 7465 7874  resp, {resp.text
-0000d570: 7d22 290a 2020 2020 2020 2020 2020 2020  }").            
-0000d580: 7261 6973 6520 5275 6e44 4245 7272 6f72  raise RunDBError
-0000d590: 2822 6261 6420 6675 6e63 7469 6f6e 2062  ("bad function b
-0000d5a0: 7569 6c64 2072 6573 706f 6e73 6522 290a  uild response").
-0000d5b0: 0a20 2020 2020 2020 2069 6620 7265 7370  .        if resp
-0000d5c0: 2e68 6561 6465 7273 3a0a 2020 2020 2020  .headers:.      
-0000d5d0: 2020 2020 2020 6675 6e63 2e73 7461 7475        func.statu
-0000d5e0: 732e 7374 6174 6520 3d20 7265 7370 2e68  s.state = resp.h
-0000d5f0: 6561 6465 7273 2e67 6574 2822 782d 6d6c  eaders.get("x-ml
-0000d600: 7275 6e2d 6675 6e63 7469 6f6e 2d73 7461  run-function-sta
-0000d610: 7475 7322 2c20 2222 290a 2020 2020 2020  tus", "").      
-0000d620: 2020 2020 2020 6c61 7374 5f6c 6f67 5f74        last_log_t
-0000d630: 696d 6573 7461 6d70 203d 2066 6c6f 6174  imestamp = float
-0000d640: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000d650: 2020 7265 7370 2e68 6561 6465 7273 2e67    resp.headers.g
-0000d660: 6574 2822 782d 6d6c 7275 6e2d 6c61 7374  et("x-mlrun-last
-0000d670: 2d74 696d 6573 7461 6d70 222c 2022 302e  -timestamp", "0.
-0000d680: 3022 290a 2020 2020 2020 2020 2020 2020  0").            
-0000d690: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-0000d6a0: 2066 756e 632e 6b69 6e64 2069 6e20 6d6c   func.kind in ml
-0000d6b0: 7275 6e2e 7275 6e74 696d 6573 2e52 756e  run.runtimes.Run
-0000d6c0: 7469 6d65 4b69 6e64 732e 6e75 636c 696f  timeKinds.nuclio
-0000d6d0: 5f72 756e 7469 6d65 7328 293a 0a20 2020  _runtimes():.   
-0000d6e0: 2020 2020 2020 2020 2020 2020 2066 756e               fun
-0000d6f0: 632e 7374 6174 7573 2e61 6464 7265 7373  c.status.address
-0000d700: 203d 2072 6573 702e 6865 6164 6572 732e   = resp.headers.
-0000d710: 6765 7428 2278 2d6d 6c72 756e 2d61 6464  get("x-mlrun-add
-0000d720: 7265 7373 222c 2022 2229 0a20 2020 2020  ress", "").     
-0000d730: 2020 2020 2020 2020 2020 2066 756e 632e             func.
-0000d740: 7374 6174 7573 2e6e 7563 6c69 6f5f 6e61  status.nuclio_na
-0000d750: 6d65 203d 2072 6573 702e 6865 6164 6572  me = resp.header
-0000d760: 732e 6765 7428 2278 2d6d 6c72 756e 2d6e  s.get("x-mlrun-n
-0000d770: 616d 6522 2c20 2222 290a 2020 2020 2020  ame", "").      
-0000d780: 2020 2020 2020 2020 2020 6675 6e63 2e73            func.s
-0000d790: 7461 7475 732e 696e 7465 726e 616c 5f69  tatus.internal_i
-0000d7a0: 6e76 6f63 6174 696f 6e5f 7572 6c73 203d  nvocation_urls =
-0000d7b0: 2072 6573 702e 6865 6164 6572 732e 6765   resp.headers.ge
-0000d7c0: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
-0000d7d0: 2020 2020 2020 2022 782d 6d6c 7275 6e2d         "x-mlrun-
-0000d7e0: 696e 7465 726e 616c 2d69 6e76 6f63 6174  internal-invocat
-0000d7f0: 696f 6e2d 7572 6c73 222c 2022 220a 2020  ion-urls", "".  
-0000d800: 2020 2020 2020 2020 2020 2020 2020 292e                ).
-0000d810: 7370 6c69 7428 222c 2229 0a20 2020 2020  split(",").     
-0000d820: 2020 2020 2020 2020 2020 2066 756e 632e             func.
-0000d830: 7374 6174 7573 2e65 7874 6572 6e61 6c5f  status.external_
-0000d840: 696e 766f 6361 7469 6f6e 5f75 726c 7320  invocation_urls 
-0000d850: 3d20 7265 7370 2e68 6561 6465 7273 2e67  = resp.headers.g
-0000d860: 6574 280a 2020 2020 2020 2020 2020 2020  et(.            
-0000d870: 2020 2020 2020 2020 2278 2d6d 6c72 756e          "x-mlrun
-0000d880: 2d65 7874 6572 6e61 6c2d 696e 766f 6361  -external-invoca
-0000d890: 7469 6f6e 2d75 726c 7322 2c20 2222 0a20  tion-urls", "". 
-0000d8a0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
-0000d8b0: 2e73 706c 6974 2822 2c22 290a 2020 2020  .split(",").    
-0000d8c0: 2020 2020 2020 2020 2020 2020 6675 6e63              func
-0000d8d0: 2e73 7461 7475 732e 636f 6e74 6169 6e65  .status.containe
-0000d8e0: 725f 696d 6167 6520 3d20 7265 7370 2e68  r_image = resp.h
-0000d8f0: 6561 6465 7273 2e67 6574 280a 2020 2020  eaders.get(.    
-0000d900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d910: 2278 2d6d 6c72 756e 2d63 6f6e 7461 696e  "x-mlrun-contain
-0000d920: 6572 2d69 6d61 6765 222c 2022 220a 2020  er-image", "".  
-0000d930: 2020 2020 2020 2020 2020 2020 2020 290a                ).
-0000d940: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0000d950: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000d960: 2020 6675 6e63 2e73 7461 7475 732e 6275    func.status.bu
-0000d970: 696c 645f 706f 6420 3d20 7265 7370 2e68  ild_pod = resp.h
-0000d980: 6561 6465 7273 2e67 6574 2822 6275 696c  eaders.get("buil
-0000d990: 6465 725f 706f 6422 2c20 2222 290a 2020  der_pod", "").  
-0000d9a0: 2020 2020 2020 2020 2020 2020 2020 6675                fu
-0000d9b0: 6e63 2e73 7065 632e 696d 6167 6520 3d20  nc.spec.image = 
-0000d9c0: 7265 7370 2e68 6561 6465 7273 2e67 6574  resp.headers.get
-0000d9d0: 2822 6675 6e63 7469 6f6e 5f69 6d61 6765  ("function_image
-0000d9e0: 222c 2022 2229 0a0a 2020 2020 2020 2020  ", "")..        
-0000d9f0: 7465 7874 203d 2022 220a 2020 2020 2020  text = "".      
-0000da00: 2020 6966 2072 6573 702e 636f 6e74 656e    if resp.conten
-0000da10: 743a 0a20 2020 2020 2020 2020 2020 2074  t:.            t
-0000da20: 6578 7420 3d20 7265 7370 2e63 6f6e 7465  ext = resp.conte
-0000da30: 6e74 2e64 6563 6f64 6528 290a 2020 2020  nt.decode().    
-0000da40: 2020 2020 7265 7475 726e 2074 6578 742c      return text,
-0000da50: 206c 6173 745f 6c6f 675f 7469 6d65 7374   last_log_timest
-0000da60: 616d 700a 0a20 2020 2064 6566 2072 656d  amp..    def rem
-0000da70: 6f74 655f 7374 6172 7428 7365 6c66 2c20  ote_start(self, 
-0000da80: 6675 6e63 5f75 726c 2920 2d3e 2073 6368  func_url) -> sch
-0000da90: 656d 6173 2e42 6163 6b67 726f 756e 6454  emas.BackgroundT
-0000daa0: 6173 6b3a 0a20 2020 2020 2020 2022 2222  ask:.        """
-0000dab0: 4578 6563 7574 6520 6120 6675 6e63 7469  Execute a functi
-0000dac0: 6f6e 2072 656d 6f74 656c 792c 2055 7365  on remotely, Use
-0000dad0: 6420 666f 7220 6060 6461 736b 6060 2066  d for ``dask`` f
-0000dae0: 756e 6374 696f 6e73 2e0a 0a20 2020 2020  unctions...     
-0000daf0: 2020 203a 7061 7261 6d20 6675 6e63 5f75     :param func_u
-0000db00: 726c 3a20 5552 4c20 746f 2074 6865 2066  rl: URL to the f
-0000db10: 756e 6374 696f 6e20 746f 2062 6520 6578  unction to be ex
-0000db20: 6563 7574 6564 2e0a 2020 2020 2020 2020  ecuted..        
-0000db30: 3a72 6574 7572 6e73 3a20 4120 4261 636b  :returns: A Back
-0000db40: 6772 6f75 6e64 5461 736b 206f 626a 6563  groundTask objec
-0000db50: 742c 2077 6974 6820 6465 7461 696c 7320  t, with details 
-0000db60: 6f6e 2065 7865 6375 7469 6f6e 2070 726f  on execution pro
-0000db70: 6365 7373 2061 6e64 2069 7473 2073 7461  cess and its sta
-0000db80: 7475 732e 0a20 2020 2020 2020 2022 2222  tus..        """
-0000db90: 0a0a 2020 2020 2020 2020 7472 793a 0a20  ..        try:. 
-0000dba0: 2020 2020 2020 2020 2020 2072 6571 203d             req =
-0000dbb0: 207b 2266 756e 6374 696f 6e55 726c 223a   {"functionUrl":
-0000dbc0: 2066 756e 635f 7572 6c7d 0a20 2020 2020   func_url}.     
-0000dbd0: 2020 2020 2020 2072 6573 7020 3d20 7365         resp = se
-0000dbe0: 6c66 2e61 7069 5f63 616c 6c28 0a20 2020  lf.api_call(.   
-0000dbf0: 2020 2020 2020 2020 2020 2020 2022 504f               "PO
-0000dc00: 5354 222c 0a20 2020 2020 2020 2020 2020  ST",.           
-0000dc10: 2020 2020 2022 7374 6172 742f 6675 6e63       "start/func
-0000dc20: 7469 6f6e 222c 0a20 2020 2020 2020 2020  tion",.         
-0000dc30: 2020 2020 2020 206a 736f 6e3d 7265 712c         json=req,
-0000dc40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000dc50: 2074 696d 656f 7574 3d69 6e74 2863 6f6e   timeout=int(con
-0000dc60: 6669 672e 7375 626d 6974 5f74 696d 656f  fig.submit_timeo
-0000dc70: 7574 2920 6f72 2036 302c 0a20 2020 2020  ut) or 60,.     
-0000dc80: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-0000dc90: 2065 7863 6570 7420 4f53 4572 726f 7220   except OSError 
-0000dca0: 6173 2065 7272 3a0a 2020 2020 2020 2020  as err:.        
-0000dcb0: 2020 2020 6c6f 6767 6572 2e65 7272 6f72      logger.error
-0000dcc0: 2866 2265 7272 6f72 2073 7461 7274 696e  (f"error startin
-0000dcd0: 6720 6675 6e63 7469 6f6e 3a20 7b65 7272  g function: {err
-0000dce0: 5f74 6f5f 7374 7228 6572 7229 7d22 290a  _to_str(err)}").
-0000dcf0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0000dd00: 6520 4f53 4572 726f 7228 6622 6572 726f  e OSError(f"erro
-0000dd10: 723a 2063 616e 6e6f 7420 7374 6172 7420  r: cannot start 
-0000dd20: 6675 6e63 7469 6f6e 2c20 7b65 7272 5f74  function, {err_t
-0000dd30: 6f5f 7374 7228 6572 7229 7d22 290a 0a20  o_str(err)}").. 
-0000dd40: 2020 2020 2020 2069 6620 6e6f 7420 7265         if not re
-0000dd50: 7370 2e6f 6b3a 0a20 2020 2020 2020 2020  sp.ok:.         
-0000dd60: 2020 206c 6f67 6765 722e 6572 726f 7228     logger.error(
-0000dd70: 6622 6261 6420 7265 7370 2121 5c6e 7b72  f"bad resp!!\n{r
-0000dd80: 6573 702e 7465 7874 7d22 290a 2020 2020  esp.text}").    
-0000dd90: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-0000dda0: 6c75 6545 7272 6f72 2822 6261 6420 6675  lueError("bad fu
-0000ddb0: 6e63 7469 6f6e 2073 7461 7274 2072 6573  nction start res
-0000ddc0: 706f 6e73 6522 290a 0a20 2020 2020 2020  ponse")..       
-0000ddd0: 2072 6574 7572 6e20 7363 6865 6d61 732e   return schemas.
-0000dde0: 4261 636b 6772 6f75 6e64 5461 736b 282a  BackgroundTask(*
-0000ddf0: 2a72 6573 702e 6a73 6f6e 2829 290a 0a20  *resp.json()).. 
-0000de00: 2020 2064 6566 2067 6574 5f70 726f 6a65     def get_proje
-0000de10: 6374 5f62 6163 6b67 726f 756e 645f 7461  ct_background_ta
-0000de20: 736b 280a 2020 2020 2020 2020 7365 6c66  sk(.        self
-0000de30: 2c0a 2020 2020 2020 2020 7072 6f6a 6563  ,.        projec
-0000de40: 743a 2073 7472 2c0a 2020 2020 2020 2020  t: str,.        
-0000de50: 6e61 6d65 3a20 7374 722c 0a20 2020 2029  name: str,.    )
-0000de60: 202d 3e20 7363 6865 6d61 732e 4261 636b   -> schemas.Back
-0000de70: 6772 6f75 6e64 5461 736b 3a0a 2020 2020  groundTask:.    
-0000de80: 2020 2020 2222 2252 6574 7269 6576 6520      """Retrieve 
-0000de90: 7570 6461 7465 6420 696e 666f 726d 6174  updated informat
-0000dea0: 696f 6e20 6f6e 2061 2070 726f 6a65 6374  ion on a project
-0000deb0: 2062 6163 6b67 726f 756e 6420 7461 736b   background task
-0000dec0: 2062 6569 6e67 2065 7865 6375 7465 642e   being executed.
-0000ded0: 2222 220a 0a20 2020 2020 2020 2070 726f  """..        pro
-0000dee0: 6a65 6374 203d 2070 726f 6a65 6374 206f  ject = project o
-0000def0: 7220 636f 6e66 6967 2e64 6566 6175 6c74  r config.default
-0000df00: 5f70 726f 6a65 6374 0a20 2020 2020 2020  _project.       
-0000df10: 2070 6174 6820 3d20 6622 7072 6f6a 6563   path = f"projec
-0000df20: 7473 2f7b 7072 6f6a 6563 747d 2f62 6163  ts/{project}/bac
-0000df30: 6b67 726f 756e 642d 7461 736b 732f 7b6e  kground-tasks/{n
-0000df40: 616d 657d 220a 2020 2020 2020 2020 6572  ame}".        er
-0000df50: 726f 725f 6d65 7373 6167 6520 3d20 280a  ror_message = (.
-0000df60: 2020 2020 2020 2020 2020 2020 6622 4661              f"Fa
-0000df70: 696c 6564 2067 6574 7469 6e67 2070 726f  iled getting pro
-0000df80: 6a65 6374 2062 6163 6b67 726f 756e 6420  ject background 
-0000df90: 7461 736b 2e20 7072 6f6a 6563 743d 7b70  task. project={p
-0000dfa0: 726f 6a65 6374 7d2c 206e 616d 653d 7b6e  roject}, name={n
-0000dfb0: 616d 657d 220a 2020 2020 2020 2020 290a  ame}".        ).
-0000dfc0: 2020 2020 2020 2020 7265 7370 6f6e 7365          response
-0000dfd0: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
-0000dfe0: 2822 4745 5422 2c20 7061 7468 2c20 6572  ("GET", path, er
-0000dff0: 726f 725f 6d65 7373 6167 6529 0a20 2020  ror_message).   
-0000e000: 2020 2020 2072 6574 7572 6e20 7363 6865       return sche
-0000e010: 6d61 732e 4261 636b 6772 6f75 6e64 5461  mas.BackgroundTa
-0000e020: 736b 282a 2a72 6573 706f 6e73 652e 6a73  sk(**response.js
-0000e030: 6f6e 2829 290a 0a20 2020 2064 6566 2067  on())..    def g
-0000e040: 6574 5f62 6163 6b67 726f 756e 645f 7461  et_background_ta
-0000e050: 736b 2873 656c 662c 206e 616d 653a 2073  sk(self, name: s
-0000e060: 7472 2920 2d3e 2073 6368 656d 6173 2e42  tr) -> schemas.B
-0000e070: 6163 6b67 726f 756e 6454 6173 6b3a 0a20  ackgroundTask:. 
-0000e080: 2020 2020 2020 2022 2222 5265 7472 6965         """Retrie
-0000e090: 7665 2075 7064 6174 6564 2069 6e66 6f72  ve updated infor
-0000e0a0: 6d61 7469 6f6e 206f 6e20 6120 6261 636b  mation on a back
-0000e0b0: 6772 6f75 6e64 2074 6173 6b20 6265 696e  ground task bein
-0000e0c0: 6720 6578 6563 7574 6564 2e22 2222 0a0a  g executed."""..
-0000e0d0: 2020 2020 2020 2020 7061 7468 203d 2066          path = f
-0000e0e0: 2262 6163 6b67 726f 756e 642d 7461 736b  "background-task
-0000e0f0: 732f 7b6e 616d 657d 220a 2020 2020 2020  s/{name}".      
-0000e100: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
-0000e110: 3d20 6622 4661 696c 6564 2067 6574 7469  = f"Failed getti
-0000e120: 6e67 2062 6163 6b67 726f 756e 6420 7461  ng background ta
-0000e130: 736b 2e20 6e61 6d65 3d7b 6e61 6d65 7d22  sk. name={name}"
-0000e140: 0a20 2020 2020 2020 2072 6573 706f 6e73  .        respons
-0000e150: 6520 3d20 7365 6c66 2e61 7069 5f63 616c  e = self.api_cal
-0000e160: 6c28 2247 4554 222c 2070 6174 682c 2065  l("GET", path, e
-0000e170: 7272 6f72 5f6d 6573 7361 6765 290a 2020  rror_message).  
-0000e180: 2020 2020 2020 7265 7475 726e 2073 6368        return sch
-0000e190: 656d 6173 2e42 6163 6b67 726f 756e 6454  emas.BackgroundT
-0000e1a0: 6173 6b28 2a2a 7265 7370 6f6e 7365 2e6a  ask(**response.j
-0000e1b0: 736f 6e28 2929 0a0a 2020 2020 6465 6620  son())..    def 
-0000e1c0: 7265 6d6f 7465 5f73 7461 7475 7328 7365  remote_status(se
-0000e1d0: 6c66 2c20 7072 6f6a 6563 742c 206e 616d  lf, project, nam
-0000e1e0: 652c 206b 696e 642c 2073 656c 6563 746f  e, kind, selecto
-0000e1f0: 7229 3a0a 2020 2020 2020 2020 2222 2252  r):.        """R
-0000e200: 6574 7269 6576 6520 7374 6174 7573 206f  etrieve status o
-0000e210: 6620 6120 6675 6e63 7469 6f6e 2062 6569  f a function bei
-0000e220: 6e67 2065 7865 6375 7465 6420 7265 6d6f  ng executed remo
-0000e230: 7465 6c79 2028 7265 6c65 7661 6e74 2074  tely (relevant t
-0000e240: 6f20 6060 6461 736b 6060 2066 756e 6374  o ``dask`` funct
-0000e250: 696f 6e73 292e 0a0a 2020 2020 2020 2020  ions)...        
-0000e260: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
-0000e270: 5468 6520 7072 6f6a 6563 7420 6f66 2074  The project of t
-0000e280: 6865 2066 756e 6374 696f 6e0a 2020 2020  he function.    
-0000e290: 2020 2020 3a70 6172 616d 206e 616d 653a      :param name:
-0000e2a0: 2054 6865 206e 616d 6520 6f66 2074 6865   The name of the
-0000e2b0: 2066 756e 6374 696f 6e0a 2020 2020 2020   function.      
-0000e2c0: 2020 3a70 6172 616d 206b 696e 643a 2054    :param kind: T
-0000e2d0: 6865 206b 696e 6420 6f66 2074 6865 2066  he kind of the f
-0000e2e0: 756e 6374 696f 6e2c 2063 7572 7265 6e74  unction, current
-0000e2f0: 6c79 2060 6064 6173 6b60 6020 6973 2073  ly ``dask`` is s
-0000e300: 7570 706f 7274 6564 2e0a 2020 2020 2020  upported..      
-0000e310: 2020 3a70 6172 616d 2073 656c 6563 746f    :param selecto
-0000e320: 723a 2053 656c 6563 746f 7220 636c 6175  r: Selector clau
-0000e330: 7365 2074 6f20 6265 2061 7070 6c69 6564  se to be applied
-0000e340: 2074 6f20 7468 6520 4b75 6265 726e 6574   to the Kubernet
-0000e350: 6573 2073 7461 7475 7320 7175 6572 7920  es status query 
-0000e360: 746f 2066 696c 7465 7220 7468 6520 7265  to filter the re
-0000e370: 7375 6c74 732e 0a20 2020 2020 2020 2022  sults..        "
-0000e380: 2222 0a0a 2020 2020 2020 2020 7472 793a  ""..        try:
-0000e390: 0a20 2020 2020 2020 2020 2020 2072 6571  .            req
-0000e3a0: 203d 207b 226b 696e 6422 3a20 6b69 6e64   = {"kind": kind
-0000e3b0: 2c20 2273 656c 6563 746f 7222 3a20 7365  , "selector": se
-0000e3c0: 6c65 6374 6f72 2c20 2270 726f 6a65 6374  lector, "project
-0000e3d0: 223a 2070 726f 6a65 6374 2c20 226e 616d  ": project, "nam
-0000e3e0: 6522 3a20 6e61 6d65 7d0a 2020 2020 2020  e": name}.      
-0000e3f0: 2020 2020 2020 7265 7370 203d 2073 656c        resp = sel
-0000e400: 662e 6170 695f 6361 6c6c 2822 504f 5354  f.api_call("POST
-0000e410: 222c 2022 7374 6174 7573 2f66 756e 6374  ", "status/funct
-0000e420: 696f 6e22 2c20 6a73 6f6e 3d72 6571 290a  ion", json=req).
-0000e430: 2020 2020 2020 2020 6578 6365 7074 204f          except O
-0000e440: 5345 7272 6f72 2061 7320 6572 723a 0a20  SError as err:. 
-0000e450: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
-0000e460: 722e 6572 726f 7228 6622 6572 726f 7220  r.error(f"error 
-0000e470: 7374 6172 7469 6e67 2066 756e 6374 696f  starting functio
-0000e480: 6e3a 207b 6572 725f 746f 5f73 7472 2865  n: {err_to_str(e
-0000e490: 7272 297d 2229 0a20 2020 2020 2020 2020  rr)}").         
-0000e4a0: 2020 2072 6169 7365 204f 5345 7272 6f72     raise OSError
-0000e4b0: 2866 2265 7272 6f72 3a20 6361 6e6e 6f74  (f"error: cannot
-0000e4c0: 2073 7461 7274 2066 756e 6374 696f 6e2c   start function,
-0000e4d0: 207b 6572 725f 746f 5f73 7472 2865 7272   {err_to_str(err
-0000e4e0: 297d 2229 0a0a 2020 2020 2020 2020 6966  )}")..        if
-0000e4f0: 206e 6f74 2072 6573 702e 6f6b 3a0a 2020   not resp.ok:.  
-0000e500: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
-0000e510: 2e65 7272 6f72 2866 2262 6164 2072 6573  .error(f"bad res
-0000e520: 7021 215c 6e7b 7265 7370 2e74 6578 747d  p!!\n{resp.text}
-0000e530: 2229 0a20 2020 2020 2020 2020 2020 2072  ").            r
-0000e540: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-0000e550: 2262 6164 2066 756e 6374 696f 6e20 7374  "bad function st
-0000e560: 6174 7573 2072 6573 706f 6e73 6522 290a  atus response").
-0000e570: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000e580: 7265 7370 2e6a 736f 6e28 295b 2264 6174  resp.json()["dat
-0000e590: 6122 5d0a 0a20 2020 2064 6566 2073 7562  a"]..    def sub
-0000e5a0: 6d69 745f 6a6f 6228 0a20 2020 2020 2020  mit_job(.       
-0000e5b0: 2073 656c 662c 2072 756e 7370 6563 2c20   self, runspec, 
-0000e5c0: 7363 6865 6475 6c65 3a20 556e 696f 6e5b  schedule: Union[
-0000e5d0: 7374 722c 2073 6368 656d 6173 2e53 6368  str, schemas.Sch
-0000e5e0: 6564 756c 6543 726f 6e54 7269 6767 6572  eduleCronTrigger
-0000e5f0: 5d20 3d20 4e6f 6e65 0a20 2020 2029 3a0a  ] = None.    ):.
-0000e600: 2020 2020 2020 2020 2222 2253 7562 6d69          """Submi
-0000e610: 7420 6120 6a6f 6220 666f 7220 7265 6d6f  t a job for remo
-0000e620: 7465 2065 7865 6375 7469 6f6e 2e0a 0a20  te execution... 
-0000e630: 2020 2020 2020 203a 7061 7261 6d20 7275         :param ru
-0000e640: 6e73 7065 633a 2054 6865 2072 756e 7469  nspec: The runti
-0000e650: 6d65 206f 626a 6563 7420 7370 6563 2028  me object spec (
-0000e660: 5461 736b 2920 746f 2065 7865 6375 7465  Task) to execute
-0000e670: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0000e680: 2073 6368 6564 756c 653a 2057 6865 7468   schedule: Wheth
-0000e690: 6572 2074 6f20 7363 6865 6475 6c65 2074  er to schedule t
-0000e6a0: 6869 7320 6a6f 6220 7573 696e 6720 6120  his job using a 
-0000e6b0: 4372 6f6e 2074 7269 6767 6572 2e20 4966  Cron trigger. If
-0000e6c0: 206e 6f74 2073 7065 6369 6669 6564 2c20   not specified, 
-0000e6d0: 7468 6520 6a6f 6220 7769 6c6c 2062 6520  the job will be 
-0000e6e0: 7375 626d 6974 7465 640a 2020 2020 2020  submitted.      
-0000e6f0: 2020 2020 2020 696d 6d65 6469 6174 656c        immediatel
-0000e700: 792e 0a20 2020 2020 2020 2022 2222 0a0a  y..        """..
-0000e710: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
-0000e720: 2020 2020 2020 2020 2072 6571 203d 207b           req = {
-0000e730: 2274 6173 6b22 3a20 7275 6e73 7065 632e  "task": runspec.
-0000e740: 746f 5f64 6963 7428 297d 0a20 2020 2020  to_dict()}.     
-0000e750: 2020 2020 2020 2069 6620 7363 6865 6475         if schedu
-0000e760: 6c65 3a0a 2020 2020 2020 2020 2020 2020  le:.            
-0000e770: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
-0000e780: 6528 7363 6865 6475 6c65 2c20 7363 6865  e(schedule, sche
-0000e790: 6d61 732e 5363 6865 6475 6c65 4372 6f6e  mas.ScheduleCron
-0000e7a0: 5472 6967 6765 7229 3a0a 2020 2020 2020  Trigger):.      
-0000e7b0: 2020 2020 2020 2020 2020 2020 2020 7363                sc
-0000e7c0: 6865 6475 6c65 203d 2073 6368 6564 756c  hedule = schedul
-0000e7d0: 652e 6469 6374 2829 0a20 2020 2020 2020  e.dict().       
-0000e7e0: 2020 2020 2020 2020 2072 6571 5b22 7363           req["sc
-0000e7f0: 6865 6475 6c65 225d 203d 2073 6368 6564  hedule"] = sched
-0000e800: 756c 650a 2020 2020 2020 2020 2020 2020  ule.            
-0000e810: 7469 6d65 6f75 7420 3d20 2869 6e74 2863  timeout = (int(c
-0000e820: 6f6e 6669 672e 7375 626d 6974 5f74 696d  onfig.submit_tim
-0000e830: 656f 7574 2920 6f72 2031 3230 2920 2b20  eout) or 120) + 
-0000e840: 3230 0a20 2020 2020 2020 2020 2020 2072  20.            r
-0000e850: 6573 7020 3d20 7365 6c66 2e61 7069 5f63  esp = self.api_c
-0000e860: 616c 6c28 2250 4f53 5422 2c20 2273 7562  all("POST", "sub
-0000e870: 6d69 745f 6a6f 6222 2c20 6a73 6f6e 3d72  mit_job", json=r
-0000e880: 6571 2c20 7469 6d65 6f75 743d 7469 6d65  eq, timeout=time
-0000e890: 6f75 7429 0a0a 2020 2020 2020 2020 6578  out)..        ex
-0000e8a0: 6365 7074 2072 6571 7565 7374 732e 4854  cept requests.HT
-0000e8b0: 5450 4572 726f 7220 6173 2065 7272 3a0a  TPError as err:.
-0000e8c0: 2020 2020 2020 2020 2020 2020 6c6f 6767              logg
-0000e8d0: 6572 2e65 7272 6f72 2866 2265 7272 6f72  er.error(f"error
-0000e8e0: 2073 7562 6d69 7474 696e 6720 7461 736b   submitting task
-0000e8f0: 3a20 7b65 7272 5f74 6f5f 7374 7228 6572  : {err_to_str(er
-0000e900: 7229 7d22 290a 2020 2020 2020 2020 2020  r)}").          
-0000e910: 2020 2320 6e6f 7420 6372 6561 7469 6e67    # not creating
-0000e920: 2061 206e 6577 2065 7863 6570 7469 6f6e   a new exception
-0000e930: 2068 6572 652c 2069 6e20 6f72 6465 7220   here, in order 
-0000e940: 746f 206b 6565 7020 7468 6520 7265 7370  to keep the resp
-0000e950: 6f6e 7365 2061 6e64 2073 7461 7475 7320  onse and status 
-0000e960: 636f 6465 2069 6e20 7468 6520 6578 6365  code in the exce
-0000e970: 7074 696f 6e0a 2020 2020 2020 2020 2020  ption.          
-0000e980: 2020 7261 6973 650a 0a20 2020 2020 2020    raise..       
-0000e990: 2065 7863 6570 7420 4f53 4572 726f 7220   except OSError 
-0000e9a0: 6173 2065 7272 3a0a 2020 2020 2020 2020  as err:.        
-0000e9b0: 2020 2020 6c6f 6767 6572 2e65 7272 6f72      logger.error
-0000e9c0: 2866 2265 7272 6f72 2073 7562 6d69 7474  (f"error submitt
-0000e9d0: 696e 6720 7461 736b 3a20 7b65 7272 5f74  ing task: {err_t
-0000e9e0: 6f5f 7374 7228 6572 7229 7d22 290a 2020  o_str(err)}").  
-0000e9f0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-0000ea00: 4f53 4572 726f 7228 2265 7272 6f72 3a20  OSError("error: 
-0000ea10: 6361 6e6e 6f74 2073 7562 6d69 7420 7461  cannot submit ta
-0000ea20: 736b 2229 2066 726f 6d20 6572 720a 0a20  sk") from err.. 
-0000ea30: 2020 2020 2020 2069 6620 6e6f 7420 7265         if not re
-0000ea40: 7370 2e6f 6b3a 0a20 2020 2020 2020 2020  sp.ok:.         
-0000ea50: 2020 206c 6f67 6765 722e 6572 726f 7228     logger.error(
-0000ea60: 6622 6261 6420 7265 7370 2121 5c6e 7b72  f"bad resp!!\n{r
-0000ea70: 6573 702e 7465 7874 7d22 290a 2020 2020  esp.text}").    
-0000ea80: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-0000ea90: 6c75 6545 7272 6f72 2866 2262 6164 2066  lueError(f"bad f
-0000eaa0: 756e 6374 696f 6e20 7275 6e20 7265 7370  unction run resp
-0000eab0: 6f6e 7365 2c20 7b72 6573 702e 7465 7874  onse, {resp.text
-0000eac0: 7d22 290a 0a20 2020 2020 2020 2072 6573  }")..        res
-0000ead0: 7020 3d20 7265 7370 2e6a 736f 6e28 290a  p = resp.json().
-0000eae0: 2020 2020 2020 2020 7265 7475 726e 2072          return r
-0000eaf0: 6573 705b 2264 6174 6122 5d0a 0a20 2020  esp["data"]..   
-0000eb00: 2064 6566 2073 7562 6d69 745f 7069 7065   def submit_pipe
-0000eb10: 6c69 6e65 280a 2020 2020 2020 2020 7365  line(.        se
-0000eb20: 6c66 2c0a 2020 2020 2020 2020 7072 6f6a  lf,.        proj
-0000eb30: 6563 742c 0a20 2020 2020 2020 2070 6970  ect,.        pip
-0000eb40: 656c 696e 652c 0a20 2020 2020 2020 2061  eline,.        a
-0000eb50: 7267 756d 656e 7473 3d4e 6f6e 652c 0a20  rguments=None,. 
-0000eb60: 2020 2020 2020 2065 7870 6572 696d 656e         experimen
-0000eb70: 743d 4e6f 6e65 2c0a 2020 2020 2020 2020  t=None,.        
-0000eb80: 7275 6e3d 4e6f 6e65 2c0a 2020 2020 2020  run=None,.      
-0000eb90: 2020 6e61 6d65 7370 6163 653d 4e6f 6e65    namespace=None
-0000eba0: 2c0a 2020 2020 2020 2020 6172 7469 6661  ,.        artifa
-0000ebb0: 6374 5f70 6174 683d 4e6f 6e65 2c0a 2020  ct_path=None,.  
-0000ebc0: 2020 2020 2020 6f70 733d 4e6f 6e65 2c0a        ops=None,.
-0000ebd0: 2020 2020 2020 2020 7474 6c3d 4e6f 6e65          ttl=None
-0000ebe0: 2c0a 2020 2020 293a 0a20 2020 2020 2020  ,.    ):.       
-0000ebf0: 2022 2222 5375 626d 6974 2061 204b 4650   """Submit a KFP
-0000ec00: 2070 6970 656c 696e 6520 666f 7220 6578   pipeline for ex
-0000ec10: 6563 7574 696f 6e2e 0a0a 2020 2020 2020  ecution...      
-0000ec20: 2020 3a70 6172 616d 2070 726f 6a65 6374    :param project
-0000ec30: 3a20 5468 6520 7072 6f6a 6563 7420 6f66  : The project of
-0000ec40: 2074 6865 2070 6970 656c 696e 650a 2020   the pipeline.  
-0000ec50: 2020 2020 2020 3a70 6172 616d 2070 6970        :param pip
-0000ec60: 656c 696e 653a 2050 6970 656c 696e 6520  eline: Pipeline 
-0000ec70: 6675 6e63 7469 6f6e 206f 7220 7061 7468  function or path
-0000ec80: 2074 6f20 2e79 616d 6c2f 2e7a 6970 2070   to .yaml/.zip p
-0000ec90: 6970 656c 696e 6520 6669 6c65 2e0a 2020  ipeline file..  
-0000eca0: 2020 2020 2020 3a70 6172 616d 2061 7267        :param arg
-0000ecb0: 756d 656e 7473 3a20 4120 6469 6374 696f  uments: A dictio
-0000ecc0: 6e61 7279 206f 6620 6172 6775 6d65 6e74  nary of argument
-0000ecd0: 7320 746f 2070 6173 7320 746f 2074 6865  s to pass to the
-0000ece0: 2070 6970 656c 696e 652e 0a20 2020 2020   pipeline..     
-0000ecf0: 2020 203a 7061 7261 6d20 6578 7065 7269     :param experi
-0000ed00: 6d65 6e74 3a20 4120 6e61 6d65 2074 6f20  ment: A name to 
-0000ed10: 6173 7369 676e 2066 6f72 2074 6865 2073  assign for the s
-0000ed20: 7065 6369 6669 6320 6578 7065 7269 6d65  pecific experime
-0000ed30: 6e74 2e0a 2020 2020 2020 2020 3a70 6172  nt..        :par
-0000ed40: 616d 2072 756e 3a20 4120 6e61 6d65 2066  am run: A name f
-0000ed50: 6f72 2074 6869 7320 7370 6563 6966 6963  or this specific
-0000ed60: 2072 756e 2e0a 2020 2020 2020 2020 3a70   run..        :p
-0000ed70: 6172 616d 206e 616d 6573 7061 6365 3a20  aram namespace: 
-0000ed80: 4b75 6265 726e 6574 6573 206e 616d 6573  Kubernetes names
-0000ed90: 7061 6365 2074 6f20 6578 6563 7574 6520  pace to execute 
-0000eda0: 7468 6520 7069 7065 6c69 6e65 2069 6e2e  the pipeline in.
-0000edb0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0000edc0: 6172 7469 6661 6374 5f70 6174 683a 2041  artifact_path: A
-0000edd0: 2070 6174 6820 746f 2061 7274 6966 6163   path to artifac
-0000ede0: 7473 2075 7365 6420 6279 2074 6869 7320  ts used by this 
-0000edf0: 7069 7065 6c69 6e65 2e0a 2020 2020 2020  pipeline..      
-0000ee00: 2020 3a70 6172 616d 206f 7073 3a20 5472    :param ops: Tr
-0000ee10: 616e 7366 6f72 6d65 7273 2074 6f20 6170  ansformers to ap
-0000ee20: 706c 7920 6f6e 2061 6c6c 206f 7073 2069  ply on all ops i
-0000ee30: 6e20 7468 6520 7069 7065 6c69 6e65 2e0a  n the pipeline..
-0000ee40: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
-0000ee50: 746c 3a20 5365 7420 7468 6520 5454 4c20  tl: Set the TTL 
-0000ee60: 666f 7220 7468 6520 7069 7065 6c69 6e65  for the pipeline
-0000ee70: 2061 6674 6572 2069 7473 2063 6f6d 706c   after its compl
-0000ee80: 6574 696f 6e2e 0a20 2020 2020 2020 2022  etion..        "
-0000ee90: 2222 0a0a 2020 2020 2020 2020 6966 2069  ""..        if i
-0000eea0: 7369 6e73 7461 6e63 6528 7069 7065 6c69  sinstance(pipeli
-0000eeb0: 6e65 2c20 7374 7229 3a0a 2020 2020 2020  ne, str):.      
-0000eec0: 2020 2020 2020 7069 7065 5f66 696c 6520        pipe_file 
-0000eed0: 3d20 7069 7065 6c69 6e65 0a20 2020 2020  = pipeline.     
-0000eee0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0000eef0: 2020 2020 2070 6970 655f 6669 6c65 203d       pipe_file =
-0000ef00: 2074 656d 7066 696c 652e 4e61 6d65 6454   tempfile.NamedT
-0000ef10: 656d 706f 7261 7279 4669 6c65 2873 7566  emporaryFile(suf
-0000ef20: 6669 783d 222e 7961 6d6c 222c 2064 656c  fix=".yaml", del
-0000ef30: 6574 653d 4661 6c73 6529 2e6e 616d 650a  ete=False).name.
-0000ef40: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
-0000ef50: 203d 206e 6577 5f70 6970 655f 6d65 7461   = new_pipe_meta
-0000ef60: 2861 7274 6966 6163 745f 7061 7468 2c20  (artifact_path, 
-0000ef70: 7474 6c2c 206f 7073 290a 2020 2020 2020  ttl, ops).      
-0000ef80: 2020 2020 2020 6b66 702e 636f 6d70 696c        kfp.compil
-0000ef90: 6572 2e43 6f6d 7069 6c65 7228 292e 636f  er.Compiler().co
-0000efa0: 6d70 696c 6528 0a20 2020 2020 2020 2020  mpile(.         
-0000efb0: 2020 2020 2020 2070 6970 656c 696e 652c         pipeline,
-0000efc0: 2070 6970 655f 6669 6c65 2c20 7479 7065   pipe_file, type
-0000efd0: 5f63 6865 636b 3d46 616c 7365 2c20 7069  _check=False, pi
-0000efe0: 7065 6c69 6e65 5f63 6f6e 663d 636f 6e66  peline_conf=conf
-0000eff0: 0a20 2020 2020 2020 2020 2020 2029 0a0a  .            )..
-0000f000: 2020 2020 2020 2020 6966 2070 6970 655f          if pipe_
-0000f010: 6669 6c65 2e65 6e64 7377 6974 6828 222e  file.endswith(".
-0000f020: 7961 6d6c 2229 3a0a 2020 2020 2020 2020  yaml"):.        
-0000f030: 2020 2020 6865 6164 6572 7320 3d20 7b22      headers = {"
-0000f040: 636f 6e74 656e 742d 7479 7065 223a 2022  content-type": "
-0000f050: 6170 706c 6963 6174 696f 6e2f 7961 6d6c  application/yaml
-0000f060: 227d 0a20 2020 2020 2020 2065 6c69 6620  "}.        elif 
-0000f070: 7069 7065 5f66 696c 652e 656e 6473 7769  pipe_file.endswi
-0000f080: 7468 2822 2e7a 6970 2229 3a0a 2020 2020  th(".zip"):.    
-0000f090: 2020 2020 2020 2020 6865 6164 6572 7320          headers 
-0000f0a0: 3d20 7b22 636f 6e74 656e 742d 7479 7065  = {"content-type
-0000f0b0: 223a 2022 6170 706c 6963 6174 696f 6e2f  ": "application/
-0000f0c0: 7a69 7022 7d0a 2020 2020 2020 2020 656c  zip"}.        el
-0000f0d0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0000f0e0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-0000f0f0: 2822 7069 7065 6c69 6e65 2066 696c 6520  ("pipeline file 
-0000f100: 6d75 7374 2062 6520 2e79 616d 6c20 6f72  must be .yaml or
-0000f110: 202e 7a69 7022 290a 2020 2020 2020 2020   .zip").        
-0000f120: 6966 2061 7267 756d 656e 7473 3a0a 2020  if arguments:.  
-0000f130: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
-0000f140: 2069 7369 6e73 7461 6e63 6528 6172 6775   isinstance(argu
-0000f150: 6d65 6e74 732c 2064 6963 7429 3a0a 2020  ments, dict):.  
-0000f160: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-0000f170: 6973 6520 5661 6c75 6545 7272 6f72 2822  ise ValueError("
-0000f180: 6172 6775 6d65 6e74 7320 6d75 7374 2062  arguments must b
-0000f190: 6520 6469 6374 2074 7970 6522 290a 2020  e dict type").  
-0000f1a0: 2020 2020 2020 2020 2020 6865 6164 6572            header
-0000f1b0: 735b 7363 6865 6d61 732e 4865 6164 6572  s[schemas.Header
-0000f1c0: 4e61 6d65 732e 7069 7065 6c69 6e65 5f61  Names.pipeline_a
-0000f1d0: 7267 756d 656e 7473 5d20 3d20 7374 7228  rguments] = str(
-0000f1e0: 6172 6775 6d65 6e74 7329 0a0a 2020 2020  arguments)..    
-0000f1f0: 2020 2020 6966 206e 6f74 2070 6174 682e      if not path.
-0000f200: 6973 6669 6c65 2870 6970 655f 6669 6c65  isfile(pipe_file
-0000f210: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
-0000f220: 6169 7365 204f 5345 7272 6f72 2866 2266  aise OSError(f"f
-0000f230: 696c 6520 7b70 6970 655f 6669 6c65 7d20  ile {pipe_file} 
-0000f240: 646f 6573 6e74 2065 7869 7374 2229 0a20  doesnt exist"). 
-0000f250: 2020 2020 2020 2077 6974 6820 6f70 656e         with open
-0000f260: 2870 6970 655f 6669 6c65 2c20 2272 6222  (pipe_file, "rb"
-0000f270: 2920 6173 2066 703a 0a20 2020 2020 2020  ) as fp:.       
-0000f280: 2020 2020 2064 6174 6120 3d20 6670 2e72       data = fp.r
-0000f290: 6561 6428 290a 2020 2020 2020 2020 6966  ead().        if
-0000f2a0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
-0000f2b0: 7069 7065 6c69 6e65 2c20 7374 7229 3a0a  pipeline, str):.
-0000f2c0: 2020 2020 2020 2020 2020 2020 7265 6d6f              remo
-0000f2d0: 7665 2870 6970 655f 6669 6c65 290a 0a20  ve(pipe_file).. 
-0000f2e0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000f2f0: 2020 2020 2020 2020 7061 7261 6d73 203d          params =
-0000f300: 207b 226e 616d 6573 7061 6365 223a 206e   {"namespace": n
-0000f310: 616d 6573 7061 6365 2c20 2265 7870 6572  amespace, "exper
-0000f320: 696d 656e 7422 3a20 6578 7065 7269 6d65  iment": experime
-0000f330: 6e74 2c20 2272 756e 223a 2072 756e 7d0a  nt, "run": run}.
-0000f340: 2020 2020 2020 2020 2020 2020 7265 7370              resp
-0000f350: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
-0000f360: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0000f370: 2020 2250 4f53 5422 2c0a 2020 2020 2020    "POST",.      
-0000f380: 2020 2020 2020 2020 2020 6622 7072 6f6a            f"proj
-0000f390: 6563 7473 2f7b 7072 6f6a 6563 747d 2f70  ects/{project}/p
-0000f3a0: 6970 656c 696e 6573 222c 0a20 2020 2020  ipelines",.     
-0000f3b0: 2020 2020 2020 2020 2020 2070 6172 616d             param
-0000f3c0: 733d 7061 7261 6d73 2c0a 2020 2020 2020  s=params,.      
-0000f3d0: 2020 2020 2020 2020 2020 7469 6d65 6f75            timeou
-0000f3e0: 743d 3230 2c0a 2020 2020 2020 2020 2020  t=20,.          
-0000f3f0: 2020 2020 2020 626f 6479 3d64 6174 612c        body=data,
-0000f400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f410: 2068 6561 6465 7273 3d68 6561 6465 7273   headers=headers
-0000f420: 2c0a 2020 2020 2020 2020 2020 2020 290a  ,.            ).
-0000f430: 2020 2020 2020 2020 6578 6365 7074 204f          except O
-0000f440: 5345 7272 6f72 2061 7320 6572 723a 0a20  SError as err:. 
-0000f450: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
-0000f460: 722e 6572 726f 7228 6622 6572 726f 7220  r.error(f"error 
-0000f470: 6361 6e6e 6f74 2073 7562 6d69 7420 7069  cannot submit pi
-0000f480: 7065 6c69 6e65 3a20 7b65 7272 5f74 6f5f  peline: {err_to_
-0000f490: 7374 7228 6572 7229 7d22 290a 2020 2020  str(err)}").    
-0000f4a0: 2020 2020 2020 2020 7261 6973 6520 4f53          raise OS
-0000f4b0: 4572 726f 7228 6622 6572 726f 723a 2063  Error(f"error: c
-0000f4c0: 616e 6e6f 7420 6361 6e6e 6f74 2073 7562  annot cannot sub
-0000f4d0: 6d69 7420 7069 7065 6c69 6e65 2c20 7b65  mit pipeline, {e
-0000f4e0: 7272 5f74 6f5f 7374 7228 6572 7229 7d22  rr_to_str(err)}"
-0000f4f0: 290a 0a20 2020 2020 2020 2069 6620 6e6f  )..        if no
-0000f500: 7420 7265 7370 2e6f 6b3a 0a20 2020 2020  t resp.ok:.     
-0000f510: 2020 2020 2020 206c 6f67 6765 722e 6572         logger.er
-0000f520: 726f 7228 6622 6261 6420 7265 7370 2121  ror(f"bad resp!!
-0000f530: 5c6e 7b72 6573 702e 7465 7874 7d22 290a  \n{resp.text}").
-0000f540: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0000f550: 6520 5661 6c75 6545 7272 6f72 2866 2262  e ValueError(f"b
-0000f560: 6164 2073 7562 6d69 7420 7069 7065 6c69  ad submit pipeli
-0000f570: 6e65 2072 6573 706f 6e73 652c 207b 7265  ne response, {re
-0000f580: 7370 2e74 6578 747d 2229 0a0a 2020 2020  sp.text}")..    
-0000f590: 2020 2020 7265 7370 203d 2072 6573 702e      resp = resp.
-0000f5a0: 6a73 6f6e 2829 0a20 2020 2020 2020 206c  json().        l
-0000f5b0: 6f67 6765 722e 696e 666f 2866 2273 7562  ogger.info(f"sub
-0000f5c0: 6d69 7474 6564 2070 6970 656c 696e 6520  mitted pipeline 
-0000f5d0: 7b72 6573 705b 276e 616d 6527 5d7d 2069  {resp['name']} i
-0000f5e0: 643d 7b72 6573 705b 2769 6427 5d7d 2229  d={resp['id']}")
-0000f5f0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000f600: 7265 7370 5b22 6964 225d 0a0a 2020 2020  resp["id"]..    
-0000f610: 6465 6620 6c69 7374 5f70 6970 656c 696e  def list_pipelin
-0000f620: 6573 280a 2020 2020 2020 2020 7365 6c66  es(.        self
-0000f630: 2c0a 2020 2020 2020 2020 7072 6f6a 6563  ,.        projec
-0000f640: 743a 2073 7472 2c0a 2020 2020 2020 2020  t: str,.        
-0000f650: 6e61 6d65 7370 6163 653a 2073 7472 203d  namespace: str =
-0000f660: 204e 6f6e 652c 0a20 2020 2020 2020 2073   None,.        s
-0000f670: 6f72 745f 6279 3a20 7374 7220 3d20 2222  ort_by: str = ""
-0000f680: 2c0a 2020 2020 2020 2020 7061 6765 5f74  ,.        page_t
-0000f690: 6f6b 656e 3a20 7374 7220 3d20 2222 2c0a  oken: str = "",.
-0000f6a0: 2020 2020 2020 2020 6669 6c74 6572 5f3a          filter_:
-0000f6b0: 2073 7472 203d 2022 222c 0a20 2020 2020   str = "",.     
-0000f6c0: 2020 2066 6f72 6d61 745f 3a20 556e 696f     format_: Unio
-0000f6d0: 6e5b 0a20 2020 2020 2020 2020 2020 2073  n[.            s
-0000f6e0: 7472 2c20 6d6c 7275 6e2e 6170 692e 7363  tr, mlrun.api.sc
-0000f6f0: 6865 6d61 732e 5069 7065 6c69 6e65 7346  hemas.PipelinesF
-0000f700: 6f72 6d61 740a 2020 2020 2020 2020 5d20  ormat.        ] 
-0000f710: 3d20 6d6c 7275 6e2e 6170 692e 7363 6865  = mlrun.api.sche
-0000f720: 6d61 732e 5069 7065 6c69 6e65 7346 6f72  mas.PipelinesFor
-0000f730: 6d61 742e 6d65 7461 6461 7461 5f6f 6e6c  mat.metadata_onl
-0000f740: 792c 0a20 2020 2020 2020 2070 6167 655f  y,.        page_
-0000f750: 7369 7a65 3a20 696e 7420 3d20 4e6f 6e65  size: int = None
-0000f760: 2c0a 2020 2020 2920 2d3e 206d 6c72 756e  ,.    ) -> mlrun
-0000f770: 2e61 7069 2e73 6368 656d 6173 2e50 6970  .api.schemas.Pip
-0000f780: 656c 696e 6573 4f75 7470 7574 3a0a 2020  elinesOutput:.  
-0000f790: 2020 2020 2020 2222 2252 6574 7269 6576        """Retriev
-0000f7a0: 6520 6120 6c69 7374 206f 6620 4b46 5020  e a list of KFP 
-0000f7b0: 7069 7065 6c69 6e65 732e 2054 6869 7320  pipelines. This 
-0000f7c0: 6675 6e63 7469 6f6e 2063 616e 2062 6520  function can be 
-0000f7d0: 696e 766f 6b65 6420 746f 2067 6574 2061  invoked to get a
-0000f7e0: 6c6c 2070 6970 656c 696e 6573 2066 726f  ll pipelines fro
-0000f7f0: 6d20 616c 6c20 7072 6f6a 6563 7473 2c0a  m all projects,.
-0000f800: 2020 2020 2020 2020 6279 2073 7065 6369          by speci
-0000f810: 6679 696e 6720 6060 7072 6f6a 6563 743d  fying ``project=
-0000f820: 2a60 602c 2069 6e20 7768 6963 6820 6361  *``, in which ca
-0000f830: 7365 2070 6167 696e 6174 696f 6e20 6361  se pagination ca
-0000f840: 6e20 6265 2075 7365 6420 616e 6420 7468  n be used and th
-0000f850: 6520 7661 7269 6f75 7320 736f 7274 696e  e various sortin
-0000f860: 6720 616e 6420 7061 6769 6e61 7469 6f6e  g and pagination
-0000f870: 0a20 2020 2020 2020 2070 726f 7065 7274  .        propert
-0000f880: 6965 7320 6361 6e20 6265 2061 7070 6c69  ies can be appli
-0000f890: 6564 2e20 4966 2061 2073 7065 6369 6669  ed. If a specifi
-0000f8a0: 6320 7072 6f6a 6563 7420 6973 2072 6571  c project is req
-0000f8b0: 7565 7374 6564 2c20 7468 656e 2074 6865  uested, then the
-0000f8c0: 2070 6167 696e 6174 696f 6e20 6f70 7469   pagination opti
-0000f8d0: 6f6e 7320 6361 6e6e 6f74 2062 650a 2020  ons cannot be.  
-0000f8e0: 2020 2020 2020 7573 6564 2061 6e64 2070        used and p
-0000f8f0: 6167 696e 6174 696f 6e20 6973 206e 6f74  agination is not
-0000f900: 2061 7070 6c69 6564 2e0a 0a20 2020 2020   applied...     
-0000f910: 2020 203a 7061 7261 6d20 7072 6f6a 6563     :param projec
-0000f920: 743a 2050 726f 6a65 6374 206e 616d 652e  t: Project name.
-0000f930: 2043 616e 2062 6520 6060 2a60 6020 666f   Can be ``*`` fo
-0000f940: 7220 7175 6572 7920 6163 726f 7373 2061  r query across a
-0000f950: 6c6c 2070 726f 6a65 6374 732e 0a20 2020  ll projects..   
-0000f960: 2020 2020 203a 7061 7261 6d20 6e61 6d65       :param name
-0000f970: 7370 6163 653a 204b 7562 6572 6e65 7465  space: Kubernete
-0000f980: 7320 6e61 6d65 7370 6163 6520 696e 2077  s namespace in w
-0000f990: 6869 6368 2074 6865 2070 6970 656c 696e  hich the pipelin
-0000f9a0: 6573 2061 7265 2065 7865 6375 7469 6e67  es are executing
-0000f9b0: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0000f9c0: 2073 6f72 745f 6279 3a20 4669 656c 6420   sort_by: Field 
-0000f9d0: 746f 2073 6f72 7420 7468 6520 7265 7375  to sort the resu
-0000f9e0: 6c74 7320 6279 2e0a 2020 2020 2020 2020  lts by..        
-0000f9f0: 3a70 6172 616d 2070 6167 655f 746f 6b65  :param page_toke
-0000fa00: 6e3a 2055 7365 2066 6f72 2070 6167 696e  n: Use for pagin
-0000fa10: 6174 696f 6e2c 2074 6f20 7265 7472 6965  ation, to retrie
-0000fa20: 7665 206e 6578 7420 7061 6765 2e0a 2020  ve next page..  
-0000fa30: 2020 2020 2020 3a70 6172 616d 2066 696c        :param fil
-0000fa40: 7465 725f 3a20 4b75 6265 726e 6574 6573  ter_: Kubernetes
-0000fa50: 2066 696c 7465 7220 746f 2061 7070 6c79   filter to apply
-0000fa60: 2074 6f20 7468 6520 7175 6572 792c 2063   to the query, c
-0000fa70: 616e 2062 6520 7573 6564 2074 6f20 6669  an be used to fi
-0000fa80: 6c74 6572 206f 6e20 7370 6563 6966 6963  lter on specific
-0000fa90: 206f 626a 6563 7420 6669 656c 6473 2e0a   object fields..
-0000faa0: 2020 2020 2020 2020 3a70 6172 616d 2066          :param f
-0000fab0: 6f72 6d61 745f 3a20 5265 7375 6c74 2066  ormat_: Result f
-0000fac0: 6f72 6d61 742e 2043 616e 2062 6520 6f6e  ormat. Can be on
-0000fad0: 6520 6f66 3a0a 0a20 2020 2020 2020 2020  e of:..         
-0000fae0: 2020 202d 2060 6066 756c 6c60 6020 2d20     - ``full`` - 
-0000faf0: 7265 7475 726e 2074 6865 2066 756c 6c20  return the full 
-0000fb00: 6f62 6a65 6374 732e 0a20 2020 2020 2020  objects..       
-0000fb10: 2020 2020 202d 2060 606d 6574 6164 6174       - ``metadat
-0000fb20: 615f 6f6e 6c79 6060 2028 6465 6661 756c  a_only`` (defaul
-0000fb30: 7429 202d 2072 6574 7572 6e20 6a75 7374  t) - return just
-0000fb40: 206d 6574 6164 6174 6120 6f66 2074 6865   metadata of the
-0000fb50: 2070 6970 656c 696e 6573 206f 626a 6563   pipelines objec
-0000fb60: 7473 2e0a 2020 2020 2020 2020 2020 2020  ts..            
-0000fb70: 2d20 6060 6e61 6d65 5f6f 6e6c 7960 6020  - ``name_only`` 
-0000fb80: 2d20 7265 7475 726e 206a 7573 7420 7468  - return just th
-0000fb90: 6520 6e61 6d65 7320 6f66 2074 6865 2070  e names of the p
-0000fba0: 6970 656c 696e 6520 6f62 6a65 6374 732e  ipeline objects.
-0000fbb0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0000fbc0: 7061 6765 5f73 697a 653a 2053 697a 6520  page_size: Size 
-0000fbd0: 6f66 2061 2073 696e 676c 6520 7061 6765  of a single page
-0000fbe0: 2077 6865 6e20 6170 706c 7969 6e67 2070   when applying p
-0000fbf0: 6167 696e 6174 696f 6e2e 0a20 2020 2020  agination..     
-0000fc00: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
-0000fc10: 6966 2070 726f 6a65 6374 2021 3d20 222a  if project != "*
-0000fc20: 2220 616e 6420 2870 6167 655f 746f 6b65  " and (page_toke
-0000fc30: 6e20 6f72 2070 6167 655f 7369 7a65 206f  n or page_size o
-0000fc40: 7220 736f 7274 5f62 7929 3a0a 2020 2020  r sort_by):.    
-0000fc50: 2020 2020 2020 2020 7261 6973 6520 6d6c          raise ml
-0000fc60: 7275 6e2e 6572 726f 7273 2e4d 4c52 756e  run.errors.MLRun
-0000fc70: 496e 7661 6c69 6441 7267 756d 656e 7445  InvalidArgumentE
-0000fc80: 7272 6f72 280a 2020 2020 2020 2020 2020  rror(.          
-0000fc90: 2020 2020 2020 2246 696c 7465 7269 6e67        "Filtering
-0000fca0: 2062 7920 7072 6f6a 6563 7420 6361 6e20   by project can 
-0000fcb0: 6e6f 7420 6265 2075 7365 6420 746f 6765  not be used toge
-0000fcc0: 7468 6572 2077 6974 6820 7061 6769 6e61  ther with pagina
-0000fcd0: 7469 6f6e 2c20 6f72 2073 6f72 7469 6e67  tion, or sorting
-0000fce0: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
-0000fcf0: 2020 2020 2020 2020 7061 7261 6d73 203d          params =
-0000fd00: 207b 0a20 2020 2020 2020 2020 2020 2022   {.            "
-0000fd10: 6e61 6d65 7370 6163 6522 3a20 6e61 6d65  namespace": name
-0000fd20: 7370 6163 652c 0a20 2020 2020 2020 2020  space,.         
-0000fd30: 2020 2022 736f 7274 5f62 7922 3a20 736f     "sort_by": so
-0000fd40: 7274 5f62 792c 0a20 2020 2020 2020 2020  rt_by,.         
-0000fd50: 2020 2022 7061 6765 5f74 6f6b 656e 223a     "page_token":
-0000fd60: 2070 6167 655f 746f 6b65 6e2c 0a20 2020   page_token,.   
-0000fd70: 2020 2020 2020 2020 2022 6669 6c74 6572           "filter
-0000fd80: 223a 2066 696c 7465 725f 2c0a 2020 2020  ": filter_,.    
-0000fd90: 2020 2020 2020 2020 2266 6f72 6d61 7422          "format"
-0000fda0: 3a20 666f 726d 6174 5f2c 0a20 2020 2020  : format_,.     
-0000fdb0: 2020 2020 2020 2022 7061 6765 5f73 697a         "page_siz
-0000fdc0: 6522 3a20 7061 6765 5f73 697a 652c 0a20  e": page_size,. 
-0000fdd0: 2020 2020 2020 207d 0a0a 2020 2020 2020         }..      
-0000fde0: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
-0000fdf0: 3d20 6622 4661 696c 6564 206c 6973 7469  = f"Failed listi
-0000fe00: 6e67 2070 6970 656c 696e 6573 2c20 7175  ng pipelines, qu
-0000fe10: 6572 793a 207b 7061 7261 6d73 7d22 0a20  ery: {params}". 
-0000fe20: 2020 2020 2020 2072 6573 706f 6e73 6520         response 
-0000fe30: 3d20 7365 6c66 2e61 7069 5f63 616c 6c28  = self.api_call(
-0000fe40: 0a20 2020 2020 2020 2020 2020 2022 4745  .            "GE
-0000fe50: 5422 2c20 6622 7072 6f6a 6563 7473 2f7b  T", f"projects/{
-0000fe60: 7072 6f6a 6563 747d 2f70 6970 656c 696e  project}/pipelin
-0000fe70: 6573 222c 2065 7272 6f72 5f6d 6573 7361  es", error_messa
-0000fe80: 6765 2c20 7061 7261 6d73 3d70 6172 616d  ge, params=param
-0000fe90: 730a 2020 2020 2020 2020 290a 2020 2020  s.        ).    
-0000fea0: 2020 2020 7265 7475 726e 206d 6c72 756e      return mlrun
-0000feb0: 2e61 7069 2e73 6368 656d 6173 2e50 6970  .api.schemas.Pip
-0000fec0: 656c 696e 6573 4f75 7470 7574 282a 2a72  elinesOutput(**r
-0000fed0: 6573 706f 6e73 652e 6a73 6f6e 2829 290a  esponse.json()).
-0000fee0: 0a20 2020 2064 6566 2067 6574 5f70 6970  .    def get_pip
-0000fef0: 656c 696e 6528 0a20 2020 2020 2020 2073  eline(.        s
-0000ff00: 656c 662c 0a20 2020 2020 2020 2072 756e  elf,.        run
-0000ff10: 5f69 643a 2073 7472 2c0a 2020 2020 2020  _id: str,.      
-0000ff20: 2020 6e61 6d65 7370 6163 653a 2073 7472    namespace: str
-0000ff30: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0000ff40: 2074 696d 656f 7574 3a20 696e 7420 3d20   timeout: int = 
-0000ff50: 3130 2c0a 2020 2020 2020 2020 666f 726d  10,.        form
-0000ff60: 6174 5f3a 2055 6e69 6f6e 5b0a 2020 2020  at_: Union[.    
-0000ff70: 2020 2020 2020 2020 7374 722c 206d 6c72          str, mlr
-0000ff80: 756e 2e61 7069 2e73 6368 656d 6173 2e50  un.api.schemas.P
-0000ff90: 6970 656c 696e 6573 466f 726d 6174 0a20  ipelinesFormat. 
-0000ffa0: 2020 2020 2020 205d 203d 206d 6c72 756e         ] = mlrun
-0000ffb0: 2e61 7069 2e73 6368 656d 6173 2e50 6970  .api.schemas.Pip
-0000ffc0: 656c 696e 6573 466f 726d 6174 2e73 756d  elinesFormat.sum
-0000ffd0: 6d61 7279 2c0a 2020 2020 2020 2020 7072  mary,.        pr
-0000ffe0: 6f6a 6563 743a 2073 7472 203d 204e 6f6e  oject: str = Non
-0000fff0: 652c 0a20 2020 2029 3a0a 2020 2020 2020  e,.    ):.      
-00010000: 2020 2222 2252 6574 7269 6576 6520 6465    """Retrieve de
-00010010: 7461 696c 7320 6f66 2061 2073 7065 6369  tails of a speci
-00010020: 6669 6320 7069 7065 6c69 6e65 2075 7369  fic pipeline usi
-00010030: 6e67 2069 7473 2072 756e 2049 4420 2861  ng its run ID (a
-00010040: 7320 7072 6f76 6964 6564 2077 6865 6e20  s provided when 
-00010050: 7468 6520 7069 7065 6c69 6e65 2077 6173  the pipeline was
-00010060: 2065 7865 6375 7465 6429 2e22 2222 0a0a   executed)."""..
-00010070: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
-00010080: 2020 2020 2020 2020 2070 6172 616d 7320           params 
-00010090: 3d20 7b7d 0a20 2020 2020 2020 2020 2020  = {}.           
-000100a0: 2069 6620 6e61 6d65 7370 6163 653a 0a20   if namespace:. 
-000100b0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-000100c0: 6172 616d 735b 226e 616d 6573 7061 6365  arams["namespace
-000100d0: 225d 203d 206e 616d 6573 7061 6365 0a20  "] = namespace. 
-000100e0: 2020 2020 2020 2020 2020 2070 6172 616d             param
-000100f0: 735b 2266 6f72 6d61 7422 5d20 3d20 666f  s["format"] = fo
-00010100: 726d 6174 5f0a 2020 2020 2020 2020 2020  rmat_.          
-00010110: 2020 7072 6f6a 6563 745f 7061 7468 203d    project_path =
-00010120: 2070 726f 6a65 6374 2069 6620 7072 6f6a   project if proj
-00010130: 6563 7420 656c 7365 2022 2a22 0a20 2020  ect else "*".   
-00010140: 2020 2020 2020 2020 2072 6573 7020 3d20           resp = 
-00010150: 7365 6c66 2e61 7069 5f63 616c 6c28 0a20  self.api_call(. 
-00010160: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00010170: 4745 5422 2c0a 2020 2020 2020 2020 2020  GET",.          
-00010180: 2020 2020 2020 6622 7072 6f6a 6563 7473        f"projects
-00010190: 2f7b 7072 6f6a 6563 745f 7061 7468 7d2f  /{project_path}/
-000101a0: 7069 7065 6c69 6e65 732f 7b72 756e 5f69  pipelines/{run_i
-000101b0: 647d 222c 0a20 2020 2020 2020 2020 2020  d}",.           
-000101c0: 2020 2020 2070 6172 616d 733d 7061 7261       params=para
-000101d0: 6d73 2c0a 2020 2020 2020 2020 2020 2020  ms,.            
-000101e0: 2020 2020 7469 6d65 6f75 743d 7469 6d65      timeout=time
-000101f0: 6f75 742c 0a20 2020 2020 2020 2020 2020  out,.           
-00010200: 2029 0a20 2020 2020 2020 2065 7863 6570   ).        excep
-00010210: 7420 4f53 4572 726f 7220 6173 2065 7272  t OSError as err
-00010220: 3a0a 2020 2020 2020 2020 2020 2020 6c6f  :.            lo
-00010230: 6767 6572 2e65 7272 6f72 2866 2265 7272  gger.error(f"err
-00010240: 6f72 2063 616e 6e6f 7420 6765 7420 7069  or cannot get pi
-00010250: 7065 6c69 6e65 3a20 7b65 7272 5f74 6f5f  peline: {err_to_
-00010260: 7374 7228 6572 7229 7d22 290a 2020 2020  str(err)}").    
-00010270: 2020 2020 2020 2020 7261 6973 6520 4f53          raise OS
-00010280: 4572 726f 7228 6622 6572 726f 723a 2063  Error(f"error: c
-00010290: 616e 6e6f 7420 6765 7420 7069 7065 6c69  annot get pipeli
-000102a0: 6e65 2c20 7b65 7272 5f74 6f5f 7374 7228  ne, {err_to_str(
-000102b0: 6572 7229 7d22 290a 0a20 2020 2020 2020  err)}")..       
-000102c0: 2069 6620 6e6f 7420 7265 7370 2e6f 6b3a   if not resp.ok:
-000102d0: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
-000102e0: 6765 722e 6572 726f 7228 6622 6261 6420  ger.error(f"bad 
-000102f0: 7265 7370 2121 5c6e 7b72 6573 702e 7465  resp!!\n{resp.te
-00010300: 7874 7d22 290a 2020 2020 2020 2020 2020  xt}").          
-00010310: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00010320: 6f72 2866 2262 6164 2067 6574 2070 6970  or(f"bad get pip
-00010330: 656c 696e 6520 7265 7370 6f6e 7365 2c20  eline response, 
-00010340: 7b72 6573 702e 7465 7874 7d22 290a 0a20  {resp.text}").. 
-00010350: 2020 2020 2020 2072 6574 7572 6e20 7265         return re
-00010360: 7370 2e6a 736f 6e28 290a 0a20 2020 2040  sp.json()..    @
-00010370: 7374 6174 6963 6d65 7468 6f64 0a20 2020  staticmethod.   
-00010380: 2064 6566 205f 7265 736f 6c76 655f 7265   def _resolve_re
-00010390: 6665 7265 6e63 6528 7461 672c 2075 6964  ference(tag, uid
-000103a0: 293a 0a20 2020 2020 2020 2069 6620 7569  ):.        if ui
-000103b0: 6420 616e 6420 7461 673a 0a20 2020 2020  d and tag:.     
-000103c0: 2020 2020 2020 2072 6169 7365 204d 4c52         raise MLR
-000103d0: 756e 496e 7661 6c69 6441 7267 756d 656e  unInvalidArgumen
-000103e0: 7445 7272 6f72 2822 626f 7468 2075 6964  tError("both uid
-000103f0: 2061 6e64 2074 6167 2077 6572 6520 7072   and tag were pr
-00010400: 6f76 6964 6564 2229 0a20 2020 2020 2020  ovided").       
-00010410: 2072 6574 7572 6e20 7569 6420 6f72 2074   return uid or t
-00010420: 6167 206f 7220 226c 6174 6573 7422 0a0a  ag or "latest"..
-00010430: 2020 2020 6465 6620 6372 6561 7465 5f66      def create_f
-00010440: 6561 7475 7265 5f73 6574 280a 2020 2020  eature_set(.    
-00010450: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
-00010460: 2020 6665 6174 7572 655f 7365 743a 2055    feature_set: U
-00010470: 6e69 6f6e 5b64 6963 742c 2073 6368 656d  nion[dict, schem
-00010480: 6173 2e46 6561 7475 7265 5365 742c 2046  as.FeatureSet, F
-00010490: 6561 7475 7265 5365 745d 2c0a 2020 2020  eatureSet],.    
-000104a0: 2020 2020 7072 6f6a 6563 743d 2222 2c0a      project="",.
-000104b0: 2020 2020 2020 2020 7665 7273 696f 6e65          versione
-000104c0: 643d 5472 7565 2c0a 2020 2020 2920 2d3e  d=True,.    ) ->
-000104d0: 2064 6963 743a 0a20 2020 2020 2020 2022   dict:.        "
-000104e0: 2222 4372 6561 7465 2061 206e 6577 203a  ""Create a new :
-000104f0: 7079 3a63 6c61 7373 3a60 7e6d 6c72 756e  py:class:`~mlrun
-00010500: 2e66 6561 7475 7265 5f73 746f 7265 2e46  .feature_store.F
-00010510: 6561 7475 7265 5365 7460 2061 6e64 2073  eatureSet` and s
-00010520: 6176 6520 696e 2074 6865 203a 7079 3a6d  ave in the :py:m
-00010530: 6f64 3a60 6d6c 7275 6e60 2044 422e 2054  od:`mlrun` DB. T
-00010540: 6865 0a20 2020 2020 2020 2066 6561 7475  he.        featu
-00010550: 7265 2d73 6574 206d 7573 7420 6e6f 7420  re-set must not 
-00010560: 7072 6576 696f 7573 6c79 2065 7869 7374  previously exist
-00010570: 2069 6e20 7468 6520 4442 2e0a 0a20 2020   in the DB...   
-00010580: 2020 2020 203a 7061 7261 6d20 6665 6174       :param feat
-00010590: 7572 655f 7365 743a 2054 6865 206e 6577  ure_set: The new
-000105a0: 203a 7079 3a63 6c61 7373 3a60 7e6d 6c72   :py:class:`~mlr
-000105b0: 756e 2e66 6561 7475 7265 5f73 746f 7265  un.feature_store
-000105c0: 2e46 6561 7475 7265 5365 7460 2074 6f20  .FeatureSet` to 
-000105d0: 6372 6561 7465 2e0a 2020 2020 2020 2020  create..        
-000105e0: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
-000105f0: 4e61 6d65 206f 6620 7072 6f6a 6563 7420  Name of project 
-00010600: 7468 6973 2066 6561 7475 7265 2d73 6574  this feature-set
-00010610: 2062 656c 6f6e 6773 2074 6f2e 0a20 2020   belongs to..   
-00010620: 2020 2020 203a 7061 7261 6d20 7665 7273       :param vers
-00010630: 696f 6e65 643a 2057 6865 7468 6572 2074  ioned: Whether t
-00010640: 6f20 6d61 696e 7461 696e 2076 6572 7369  o maintain versi
-00010650: 6f6e 7320 666f 7220 7468 6973 2066 6561  ons for this fea
-00010660: 7475 7265 2d73 6574 2e20 416c 6c20 7665  ture-set. All ve
-00010670: 7273 696f 6e73 206f 6620 6120 7665 7273  rsions of a vers
-00010680: 696f 6e65 6420 6f62 6a65 6374 0a20 2020  ioned object.   
-00010690: 2020 2020 2020 2020 2077 696c 6c20 6265           will be
-000106a0: 206b 6570 7420 696e 2074 6865 2044 4220   kept in the DB 
-000106b0: 616e 6420 6361 6e20 6265 2072 6574 7269  and can be retri
-000106c0: 6576 6564 2075 6e74 696c 2065 7870 6c69  eved until expli
-000106d0: 6369 746c 7920 6465 6c65 7465 642e 0a20  citly deleted.. 
-000106e0: 2020 2020 2020 203a 7265 7475 726e 733a         :returns:
-000106f0: 2054 6865 203a 7079 3a63 6c61 7373 3a60   The :py:class:`
-00010700: 7e6d 6c72 756e 2e66 6561 7475 7265 5f73  ~mlrun.feature_s
-00010710: 746f 7265 2e46 6561 7475 7265 5365 7460  tore.FeatureSet`
-00010720: 206f 626a 6563 7420 2861 7320 6469 6374   object (as dict
-00010730: 292e 0a20 2020 2020 2020 2022 2222 0a20  )..        """. 
-00010740: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-00010750: 616e 6365 2866 6561 7475 7265 5f73 6574  ance(feature_set
-00010760: 2c20 7363 6865 6d61 732e 4665 6174 7572  , schemas.Featur
-00010770: 6553 6574 293a 0a20 2020 2020 2020 2020  eSet):.         
-00010780: 2020 2066 6561 7475 7265 5f73 6574 203d     feature_set =
-00010790: 2066 6561 7475 7265 5f73 6574 2e64 6963   feature_set.dic
-000107a0: 7428 290a 2020 2020 2020 2020 656c 6966  t().        elif
-000107b0: 2069 7369 6e73 7461 6e63 6528 6665 6174   isinstance(feat
-000107c0: 7572 655f 7365 742c 2046 6561 7475 7265  ure_set, Feature
-000107d0: 5365 7429 3a0a 2020 2020 2020 2020 2020  Set):.          
-000107e0: 2020 6665 6174 7572 655f 7365 7420 3d20    feature_set = 
-000107f0: 6665 6174 7572 655f 7365 742e 746f 5f64  feature_set.to_d
-00010800: 6963 7428 290a 0a20 2020 2020 2020 2070  ict()..        p
-00010810: 726f 6a65 6374 203d 2028 0a20 2020 2020  roject = (.     
-00010820: 2020 2020 2020 2070 726f 6a65 6374 0a20         project. 
-00010830: 2020 2020 2020 2020 2020 206f 7220 6665             or fe
-00010840: 6174 7572 655f 7365 745b 226d 6574 6164  ature_set["metad
-00010850: 6174 6122 5d2e 6765 7428 2270 726f 6a65  ata"].get("proje
-00010860: 6374 222c 204e 6f6e 6529 0a20 2020 2020  ct", None).     
-00010870: 2020 2020 2020 206f 7220 636f 6e66 6967         or config
-00010880: 2e64 6566 6175 6c74 5f70 726f 6a65 6374  .default_project
-00010890: 0a20 2020 2020 2020 2029 0a20 2020 2020  .        ).     
-000108a0: 2020 2070 6174 6820 3d20 6622 7072 6f6a     path = f"proj
-000108b0: 6563 7473 2f7b 7072 6f6a 6563 747d 2f66  ects/{project}/f
-000108c0: 6561 7475 7265 2d73 6574 7322 0a20 2020  eature-sets".   
-000108d0: 2020 2020 2070 6172 616d 7320 3d20 7b22       params = {"
-000108e0: 7665 7273 696f 6e65 6422 3a20 7665 7273  versioned": vers
-000108f0: 696f 6e65 647d 0a0a 2020 2020 2020 2020  ioned}..        
-00010900: 6e61 6d65 203d 2066 6561 7475 7265 5f73  name = feature_s
-00010910: 6574 5b22 6d65 7461 6461 7461 225d 5b22  et["metadata"]["
-00010920: 6e61 6d65 225d 0a20 2020 2020 2020 2065  name"].        e
-00010930: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
-00010940: 2246 6169 6c65 6420 6372 6561 7469 6e67  "Failed creating
-00010950: 2066 6561 7475 7265 2d73 6574 207b 7072   feature-set {pr
-00010960: 6f6a 6563 747d 2f7b 6e61 6d65 7d22 0a20  oject}/{name}". 
-00010970: 2020 2020 2020 2072 6573 7020 3d20 7365         resp = se
-00010980: 6c66 2e61 7069 5f63 616c 6c28 0a20 2020  lf.api_call(.   
-00010990: 2020 2020 2020 2020 2022 504f 5354 222c           "POST",
-000109a0: 0a20 2020 2020 2020 2020 2020 2070 6174  .            pat
-000109b0: 682c 0a20 2020 2020 2020 2020 2020 2065  h,.            e
-000109c0: 7272 6f72 5f6d 6573 7361 6765 2c0a 2020  rror_message,.  
-000109d0: 2020 2020 2020 2020 2020 7061 7261 6d73            params
-000109e0: 3d70 6172 616d 732c 0a20 2020 2020 2020  =params,.       
-000109f0: 2020 2020 2062 6f64 793d 6469 6374 5f74       body=dict_t
-00010a00: 6f5f 6a73 6f6e 2866 6561 7475 7265 5f73  o_json(feature_s
-00010a10: 6574 292c 0a20 2020 2020 2020 2029 0a20  et),.        ). 
-00010a20: 2020 2020 2020 2072 6574 7572 6e20 7265         return re
-00010a30: 7370 2e6a 736f 6e28 290a 0a20 2020 2064  sp.json()..    d
-00010a40: 6566 2067 6574 5f66 6561 7475 7265 5f73  ef get_feature_s
-00010a50: 6574 280a 2020 2020 2020 2020 7365 6c66  et(.        self
-00010a60: 2c20 6e61 6d65 3a20 7374 722c 2070 726f  , name: str, pro
-00010a70: 6a65 6374 3a20 7374 7220 3d20 2222 2c20  ject: str = "", 
-00010a80: 7461 673a 2073 7472 203d 204e 6f6e 652c  tag: str = None,
-00010a90: 2075 6964 3a20 7374 7220 3d20 4e6f 6e65   uid: str = None
-00010aa0: 0a20 2020 2029 202d 3e20 4665 6174 7572  .    ) -> Featur
-00010ab0: 6553 6574 3a0a 2020 2020 2020 2020 2222  eSet:.        ""
-00010ac0: 2252 6574 7269 6576 6520 6120 7e6d 6c72  "Retrieve a ~mlr
-00010ad0: 756e 2e66 6561 7475 7265 5f73 746f 7265  un.feature_store
-00010ae0: 2e46 6561 7475 7265 5365 7460 206f 626a  .FeatureSet` obj
-00010af0: 6563 742e 2049 6620 626f 7468 2060 6074  ect. If both ``t
-00010b00: 6167 6060 2061 6e64 2060 6075 6964 6060  ag`` and ``uid``
-00010b10: 2061 7265 206e 6f74 2073 7065 6369 6669   are not specifi
-00010b20: 6564 2c20 7468 656e 0a20 2020 2020 2020  ed, then.       
-00010b30: 2074 6865 206f 626a 6563 7420 7461 6767   the object tagg
-00010b40: 6564 2060 606c 6174 6573 7460 6020 7769  ed ``latest`` wi
-00010b50: 6c6c 2062 6520 7265 7472 6965 7665 642e  ll be retrieved.
-00010b60: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-00010b70: 206e 616d 653a 204e 616d 6520 6f66 206f   name: Name of o
-00010b80: 626a 6563 7420 746f 2072 6574 7269 6576  bject to retriev
-00010b90: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
-00010ba0: 6d20 7072 6f6a 6563 743a 2050 726f 6a65  m project: Proje
-00010bb0: 6374 2074 6865 2046 6561 7475 7265 5365  ct the FeatureSe
-00010bc0: 7420 6265 6c6f 6e67 7320 746f 2e0a 2020  t belongs to..  
-00010bd0: 2020 2020 2020 3a70 6172 616d 2074 6167        :param tag
-00010be0: 3a20 5461 6720 6f66 2074 6865 2073 7065  : Tag of the spe
-00010bf0: 6369 6669 6320 6f62 6a65 6374 2076 6572  cific object ver
-00010c00: 7369 6f6e 2074 6f20 7265 7472 6965 7665  sion to retrieve
-00010c10: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-00010c20: 2075 6964 3a20 7569 6420 6f66 2074 6865   uid: uid of the
-00010c30: 206f 626a 6563 7420 746f 2072 6574 7269   object to retri
-00010c40: 6576 6520 2863 616e 206f 6e6c 7920 6265  eve (can only be
-00010c50: 2075 7365 6420 666f 7220 7665 7273 696f   used for versio
-00010c60: 6e65 6420 6f62 6a65 6374 7329 2e0a 2020  ned objects)..  
-00010c70: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
-00010c80: 2020 2070 726f 6a65 6374 203d 2070 726f     project = pro
-00010c90: 6a65 6374 206f 7220 636f 6e66 6967 2e64  ject or config.d
-00010ca0: 6566 6175 6c74 5f70 726f 6a65 6374 0a20  efault_project. 
-00010cb0: 2020 2020 2020 2072 6566 6572 656e 6365         reference
-00010cc0: 203d 2073 656c 662e 5f72 6573 6f6c 7665   = self._resolve
-00010cd0: 5f72 6566 6572 656e 6365 2874 6167 2c20  _reference(tag, 
-00010ce0: 7569 6429 0a20 2020 2020 2020 2070 6174  uid).        pat
-00010cf0: 6820 3d20 6622 7072 6f6a 6563 7473 2f7b  h = f"projects/{
-00010d00: 7072 6f6a 6563 747d 2f66 6561 7475 7265  project}/feature
-00010d10: 2d73 6574 732f 7b6e 616d 657d 2f72 6566  -sets/{name}/ref
-00010d20: 6572 656e 6365 732f 7b72 6566 6572 656e  erences/{referen
-00010d30: 6365 7d22 0a20 2020 2020 2020 2065 7272  ce}".        err
-00010d40: 6f72 5f6d 6573 7361 6765 203d 2066 2246  or_message = f"F
-00010d50: 6169 6c65 6420 7265 7472 6965 7669 6e67  ailed retrieving
-00010d60: 2066 6561 7475 7265 2d73 6574 207b 7072   feature-set {pr
-00010d70: 6f6a 6563 747d 2f7b 6e61 6d65 7d22 0a20  oject}/{name}". 
-00010d80: 2020 2020 2020 2072 6573 7020 3d20 7365         resp = se
-00010d90: 6c66 2e61 7069 5f63 616c 6c28 2247 4554  lf.api_call("GET
-00010da0: 222c 2070 6174 682c 2065 7272 6f72 5f6d  ", path, error_m
-00010db0: 6573 7361 6765 290a 2020 2020 2020 2020  essage).        
-00010dc0: 7265 7475 726e 2046 6561 7475 7265 5365  return FeatureSe
-00010dd0: 742e 6672 6f6d 5f64 6963 7428 7265 7370  t.from_dict(resp
-00010de0: 2e6a 736f 6e28 2929 0a0a 2020 2020 6465  .json())..    de
-00010df0: 6620 6c69 7374 5f66 6561 7475 7265 7328  f list_features(
-00010e00: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
-00010e10: 2020 2020 2020 2070 726f 6a65 6374 3a20         project: 
-00010e20: 7374 722c 0a20 2020 2020 2020 206e 616d  str,.        nam
-00010e30: 653a 2073 7472 203d 204e 6f6e 652c 0a20  e: str = None,. 
-00010e40: 2020 2020 2020 2074 6167 3a20 7374 7220         tag: str 
-00010e50: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-00010e60: 656e 7469 7469 6573 3a20 4c69 7374 5b73  entities: List[s
-00010e70: 7472 5d20 3d20 4e6f 6e65 2c0a 2020 2020  tr] = None,.    
-00010e80: 2020 2020 6c61 6265 6c73 3a20 4c69 7374      labels: List
-00010e90: 5b73 7472 5d20 3d20 4e6f 6e65 2c0a 2020  [str] = None,.  
-00010ea0: 2020 2920 2d3e 204c 6973 745b 6469 6374    ) -> List[dict
-00010eb0: 5d3a 0a20 2020 2020 2020 2022 2222 4c69  ]:.        """Li
-00010ec0: 7374 2066 6561 7475 7265 2d73 6574 7320  st feature-sets 
-00010ed0: 7768 6963 6820 636f 6e74 6169 6e20 7370  which contain sp
-00010ee0: 6563 6966 6963 2066 6561 7475 7265 732e  ecific features.
-00010ef0: 2054 6869 7320 6675 6e63 7469 6f6e 206d   This function m
-00010f00: 6179 2072 6574 7572 6e20 6d75 6c74 6970  ay return multip
-00010f10: 6c65 2076 6572 7369 6f6e 7320 6f66 2074  le versions of t
-00010f20: 6865 2073 616d 650a 2020 2020 2020 2020  he same.        
-00010f30: 6665 6174 7572 652d 7365 7420 6966 2061  feature-set if a
-00010f40: 2073 7065 6369 6669 6320 7461 6720 6973   specific tag is
-00010f50: 206e 6f74 2072 6571 7565 7374 6564 2e20   not requested. 
-00010f60: 4e6f 7465 2074 6861 7420 7468 6520 7661  Note that the va
-00010f70: 7269 6f75 7320 6669 6c74 6572 7320 6f66  rious filters of
-00010f80: 2074 6869 7320 6675 6e63 7469 6f6e 2061   this function a
-00010f90: 6374 7561 6c6c 790a 2020 2020 2020 2020  ctually.        
-00010fa0: 7265 6665 7220 746f 2074 6865 2066 6561  refer to the fea
-00010fb0: 7475 7265 2d73 6574 206f 626a 6563 7420  ture-set object 
-00010fc0: 636f 6e74 6169 6e69 6e67 2074 6865 2066  containing the f
-00010fd0: 6561 7475 7265 732c 206e 6f74 2074 6f20  eatures, not to 
-00010fe0: 7468 6520 6665 6174 7572 6573 2074 6865  the features the
-00010ff0: 6d73 656c 7665 732e 0a0a 2020 2020 2020  mselves...      
-00011000: 2020 3a70 6172 616d 2070 726f 6a65 6374    :param project
-00011010: 3a20 5072 6f6a 6563 7420 7768 6963 6820  : Project which 
-00011020: 636f 6e74 6169 6e73 2074 6865 7365 2066  contains these f
-00011030: 6561 7475 7265 732e 0a20 2020 2020 2020  eatures..       
-00011040: 203a 7061 7261 6d20 6e61 6d65 3a20 4e61   :param name: Na
-00011050: 6d65 206f 6620 7468 6520 6665 6174 7572  me of the featur
-00011060: 6520 746f 206c 6f6f 6b20 666f 722e 2054  e to look for. T
-00011070: 6865 206e 616d 6520 6973 2075 7365 6420  he name is used 
-00011080: 696e 2061 206c 696b 6520 7175 6572 792c  in a like query,
-00011090: 2061 6e64 2069 7320 6e6f 7420 6361 7365   and is not case
-000110a0: 2d73 656e 7369 7469 7665 2e20 466f 720a  -sensitive. For.
-000110b0: 2020 2020 2020 2020 2020 2020 6578 616d              exam
-000110c0: 706c 652c 206c 6f6f 6b69 6e67 2066 6f72  ple, looking for
-000110d0: 2060 6066 6561 7460 6020 7769 6c6c 2072   ``feat`` will r
-000110e0: 6574 7572 6e20 6665 6174 7572 6573 2077  eturn features w
-000110f0: 6869 6368 2061 7265 206e 616d 6564 2060  hich are named `
-00011100: 604d 7946 6561 7475 7265 6060 2061 7320  `MyFeature`` as 
-00011110: 7765 6c6c 2061 7320 6060 6465 6665 6174  well as ``defeat
-00011120: 6060 2e0a 2020 2020 2020 2020 3a70 6172  ``..        :par
-00011130: 616d 2074 6167 3a20 5265 7475 726e 2066  am tag: Return f
-00011140: 6561 7475 7265 2d73 6574 7320 7768 6963  eature-sets whic
-00011150: 6820 636f 6e74 6169 6e20 7468 6520 6665  h contain the fe
-00011160: 6174 7572 6573 206c 6f6f 6b65 6420 666f  atures looked fo
-00011170: 722c 2061 6e64 2061 7265 2074 6167 6765  r, and are tagge
-00011180: 6420 7769 7468 2074 6865 2073 7065 6369  d with the speci
-00011190: 6669 6320 7461 672e 0a20 2020 2020 2020  fic tag..       
-000111a0: 203a 7061 7261 6d20 656e 7469 7469 6573   :param entities
-000111b0: 3a20 5265 7475 726e 206f 6e6c 7920 6665  : Return only fe
-000111c0: 6174 7572 652d 7365 7473 2077 6869 6368  ature-sets which
-000111d0: 2063 6f6e 7461 696e 2061 6e20 656e 7469   contain an enti
-000111e0: 7479 2077 686f 7365 206e 616d 6520 6973  ty whose name is
-000111f0: 2063 6f6e 7461 696e 6564 2069 6e20 7468   contained in th
-00011200: 6973 206c 6973 742e 0a20 2020 2020 2020  is list..       
-00011210: 203a 7061 7261 6d20 6c61 6265 6c73 3a20   :param labels: 
-00011220: 5265 7475 726e 206f 6e6c 7920 6665 6174  Return only feat
-00011230: 7572 652d 7365 7473 2077 6869 6368 2061  ure-sets which a
-00011240: 7265 206c 6162 656c 6564 2061 7320 7265  re labeled as re
-00011250: 7175 6573 7465 642e 0a20 2020 2020 2020  quested..       
-00011260: 203a 7265 7475 726e 733a 2041 206c 6973   :returns: A lis
-00011270: 7420 6f66 206d 6170 7069 6e67 2066 726f  t of mapping fro
-00011280: 6d20 6665 6174 7572 6520 746f 2061 2064  m feature to a d
-00011290: 6967 6573 7420 6f66 2074 6865 2066 6561  igest of the fea
-000112a0: 7475 7265 2d73 6574 2c20 7768 6963 6820  ture-set, which 
-000112b0: 636f 6e74 6169 6e73 2074 6865 2066 6561  contains the fea
-000112c0: 7475 7265 2d73 6574 0a20 2020 2020 2020  ture-set.       
-000112d0: 2020 2020 206d 6574 612d 6461 7461 2e20       meta-data. 
-000112e0: 4d75 6c74 6970 6c65 2065 6e74 7269 6573  Multiple entries
-000112f0: 206d 6179 2062 6520 7265 7475 726e 6564   may be returned
-00011300: 2066 6f72 2061 6e79 2073 7065 6369 6669   for any specifi
-00011310: 6320 6665 6174 7572 6520 6475 6520 746f  c feature due to
-00011320: 206d 756c 7469 706c 6520 7461 6773 206f   multiple tags o
-00011330: 7220 7665 7273 696f 6e73 0a20 2020 2020  r versions.     
-00011340: 2020 2020 2020 206f 6620 7468 6520 6665         of the fe
-00011350: 6174 7572 652d 7365 742e 0a20 2020 2020  ature-set..     
-00011360: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
-00011370: 7072 6f6a 6563 7420 3d20 7072 6f6a 6563  project = projec
-00011380: 7420 6f72 2063 6f6e 6669 672e 6465 6661  t or config.defa
-00011390: 756c 745f 7072 6f6a 6563 740a 2020 2020  ult_project.    
-000113a0: 2020 2020 7061 7261 6d73 203d 207b 0a20      params = {. 
-000113b0: 2020 2020 2020 2020 2020 2022 6e61 6d65             "name
-000113c0: 223a 206e 616d 652c 0a20 2020 2020 2020  ": name,.       
-000113d0: 2020 2020 2022 7461 6722 3a20 7461 672c       "tag": tag,
-000113e0: 0a20 2020 2020 2020 2020 2020 2022 656e  .            "en
-000113f0: 7469 7479 223a 2065 6e74 6974 6965 7320  tity": entities 
-00011400: 6f72 205b 5d2c 0a20 2020 2020 2020 2020  or [],.         
-00011410: 2020 2022 6c61 6265 6c22 3a20 6c61 6265     "label": labe
-00011420: 6c73 206f 7220 5b5d 2c0a 2020 2020 2020  ls or [],.      
-00011430: 2020 7d0a 0a20 2020 2020 2020 2070 6174    }..        pat
-00011440: 6820 3d20 6622 7072 6f6a 6563 7473 2f7b  h = f"projects/{
-00011450: 7072 6f6a 6563 747d 2f66 6561 7475 7265  project}/feature
-00011460: 7322 0a0a 2020 2020 2020 2020 6572 726f  s"..        erro
-00011470: 725f 6d65 7373 6167 6520 3d20 6622 4661  r_message = f"Fa
-00011480: 696c 6564 206c 6973 7469 6e67 2066 6561  iled listing fea
-00011490: 7475 7265 732c 2070 726f 6a65 6374 3a20  tures, project: 
-000114a0: 7b70 726f 6a65 6374 7d2c 2071 7565 7279  {project}, query
-000114b0: 3a20 7b70 6172 616d 737d 220a 2020 2020  : {params}".    
-000114c0: 2020 2020 7265 7370 203d 2073 656c 662e      resp = self.
-000114d0: 6170 695f 6361 6c6c 2822 4745 5422 2c20  api_call("GET", 
-000114e0: 7061 7468 2c20 6572 726f 725f 6d65 7373  path, error_mess
-000114f0: 6167 652c 2070 6172 616d 733d 7061 7261  age, params=para
-00011500: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-00011510: 726e 2072 6573 702e 6a73 6f6e 2829 5b22  rn resp.json()["
-00011520: 6665 6174 7572 6573 225d 0a0a 2020 2020  features"]..    
-00011530: 6465 6620 6c69 7374 5f65 6e74 6974 6965  def list_entitie
-00011540: 7328 0a20 2020 2020 2020 2073 656c 662c  s(.        self,
-00011550: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-00011560: 3a20 7374 722c 0a20 2020 2020 2020 206e  : str,.        n
-00011570: 616d 653a 2073 7472 203d 204e 6f6e 652c  ame: str = None,
-00011580: 0a20 2020 2020 2020 2074 6167 3a20 7374  .        tag: st
-00011590: 7220 3d20 4e6f 6e65 2c0a 2020 2020 2020  r = None,.      
-000115a0: 2020 6c61 6265 6c73 3a20 4c69 7374 5b73    labels: List[s
-000115b0: 7472 5d20 3d20 4e6f 6e65 2c0a 2020 2020  tr] = None,.    
-000115c0: 2920 2d3e 204c 6973 745b 6469 6374 5d3a  ) -> List[dict]:
-000115d0: 0a20 2020 2020 2020 2022 2222 5265 7472  .        """Retr
-000115e0: 6965 7665 2061 206c 6973 7420 6f66 2065  ieve a list of e
-000115f0: 6e74 6974 6965 7320 616e 6420 7468 6569  ntities and thei
-00011600: 7220 6d61 7070 696e 6720 746f 2074 6865  r mapping to the
-00011610: 2063 6f6e 7461 696e 696e 6720 6665 6174   containing feat
-00011620: 7572 652d 7365 7473 2e20 5468 6973 2066  ure-sets. This f
-00011630: 756e 6374 696f 6e20 6973 2073 696d 696c  unction is simil
-00011640: 6172 0a20 2020 2020 2020 2074 6f20 7468  ar.        to th
-00011650: 6520 3a70 793a 6675 6e63 3a60 7e6c 6973  e :py:func:`~lis
-00011660: 745f 6665 6174 7572 6573 6020 6675 6e63  t_features` func
-00011670: 7469 6f6e 2c20 616e 6420 7573 6573 2074  tion, and uses t
-00011680: 6865 2073 616d 6520 6c6f 6769 632e 2048  he same logic. H
-00011690: 6f77 6576 6572 2c20 7468 6520 656e 7469  owever, the enti
-000116a0: 7469 6573 2061 7265 206d 6174 6368 6564  ties are matched
-000116b0: 0a20 2020 2020 2020 2061 6761 696e 7374  .        against
-000116c0: 2074 6865 206e 616d 6520 7261 7468 6572   the name rather
-000116d0: 2074 6861 6e20 7468 6520 6665 6174 7572   than the featur
-000116e0: 6573 2e0a 2020 2020 2020 2020 2222 220a  es..        """.
-000116f0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-00011700: 203d 2070 726f 6a65 6374 206f 7220 636f   = project or co
-00011710: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
-00011720: 6a65 6374 0a20 2020 2020 2020 2070 6172  ject.        par
-00011730: 616d 7320 3d20 7b0a 2020 2020 2020 2020  ams = {.        
-00011740: 2020 2020 226e 616d 6522 3a20 6e61 6d65      "name": name
-00011750: 2c0a 2020 2020 2020 2020 2020 2020 2274  ,.            "t
-00011760: 6167 223a 2074 6167 2c0a 2020 2020 2020  ag": tag,.      
-00011770: 2020 2020 2020 226c 6162 656c 223a 206c        "label": l
-00011780: 6162 656c 7320 6f72 205b 5d2c 0a20 2020  abels or [],.   
-00011790: 2020 2020 207d 0a0a 2020 2020 2020 2020       }..        
-000117a0: 7061 7468 203d 2066 2270 726f 6a65 6374  path = f"project
-000117b0: 732f 7b70 726f 6a65 6374 7d2f 656e 7469  s/{project}/enti
-000117c0: 7469 6573 220a 0a20 2020 2020 2020 2065  ties"..        e
-000117d0: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
-000117e0: 2246 6169 6c65 6420 6c69 7374 696e 6720  "Failed listing 
-000117f0: 656e 7469 7469 6573 2c20 7072 6f6a 6563  entities, projec
-00011800: 743a 207b 7072 6f6a 6563 747d 2c20 7175  t: {project}, qu
-00011810: 6572 793a 207b 7061 7261 6d73 7d22 0a20  ery: {params}". 
-00011820: 2020 2020 2020 2072 6573 7020 3d20 7365         resp = se
-00011830: 6c66 2e61 7069 5f63 616c 6c28 2247 4554  lf.api_call("GET
-00011840: 222c 2070 6174 682c 2065 7272 6f72 5f6d  ", path, error_m
-00011850: 6573 7361 6765 2c20 7061 7261 6d73 3d70  essage, params=p
-00011860: 6172 616d 7329 0a20 2020 2020 2020 2072  arams).        r
-00011870: 6574 7572 6e20 7265 7370 2e6a 736f 6e28  eturn resp.json(
-00011880: 295b 2265 6e74 6974 6965 7322 5d0a 0a20  )["entities"].. 
-00011890: 2020 2040 7374 6174 6963 6d65 7468 6f64     @staticmethod
-000118a0: 0a20 2020 2064 6566 205f 6765 6e65 7261  .    def _genera
-000118b0: 7465 5f70 6172 7469 7469 6f6e 5f62 795f  te_partition_by_
-000118c0: 7061 7261 6d73 280a 2020 2020 2020 2020  params(.        
-000118d0: 7061 7274 6974 696f 6e5f 6279 5f63 6c73  partition_by_cls
-000118e0: 2c0a 2020 2020 2020 2020 7061 7274 6974  ,.        partit
-000118f0: 696f 6e5f 6279 2c0a 2020 2020 2020 2020  ion_by,.        
-00011900: 726f 7773 5f70 6572 5f70 6172 7469 7469  rows_per_partiti
-00011910: 6f6e 2c0a 2020 2020 2020 2020 736f 7274  on,.        sort
-00011920: 5f62 792c 0a20 2020 2020 2020 206f 7264  _by,.        ord
-00011930: 6572 2c0a 2020 2020 2020 2020 6d61 785f  er,.        max_
-00011940: 7061 7274 6974 696f 6e73 3d4e 6f6e 652c  partitions=None,
-00011950: 0a20 2020 2029 3a0a 0a20 2020 2020 2020  .    ):..       
-00011960: 2070 6172 7469 7469 6f6e 5f70 6172 616d   partition_param
-00011970: 7320 3d20 7b0a 2020 2020 2020 2020 2020  s = {.          
-00011980: 2020 2270 6172 7469 7469 6f6e 2d62 7922    "partition-by"
-00011990: 3a20 7061 7274 6974 696f 6e5f 6279 2c0a  : partition_by,.
-000119a0: 2020 2020 2020 2020 2020 2020 2272 6f77              "row
-000119b0: 732d 7065 722d 7061 7274 6974 696f 6e22  s-per-partition"
-000119c0: 3a20 726f 7773 5f70 6572 5f70 6172 7469  : rows_per_parti
-000119d0: 7469 6f6e 2c0a 2020 2020 2020 2020 2020  tion,.          
-000119e0: 2020 2270 6172 7469 7469 6f6e 2d73 6f72    "partition-sor
-000119f0: 742d 6279 223a 2073 6f72 745f 6279 2c0a  t-by": sort_by,.
-00011a00: 2020 2020 2020 2020 2020 2020 2270 6172              "par
-00011a10: 7469 7469 6f6e 2d6f 7264 6572 223a 206f  tition-order": o
-00011a20: 7264 6572 2c0a 2020 2020 2020 2020 7d0a  rder,.        }.
-00011a30: 2020 2020 2020 2020 6966 206d 6178 5f70          if max_p
-00011a40: 6172 7469 7469 6f6e 7320 6973 206e 6f74  artitions is not
-00011a50: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-00011a60: 2020 2070 6172 7469 7469 6f6e 5f70 6172     partition_par
-00011a70: 616d 735b 226d 6178 2d70 6172 7469 7469  ams["max-partiti
-00011a80: 6f6e 7322 5d20 3d20 6d61 785f 7061 7274  ons"] = max_part
-00011a90: 6974 696f 6e73 0a20 2020 2020 2020 2072  itions.        r
-00011aa0: 6574 7572 6e20 7061 7274 6974 696f 6e5f  eturn partition_
-00011ab0: 7061 7261 6d73 0a0a 2020 2020 6465 6620  params..    def 
-00011ac0: 6c69 7374 5f66 6561 7475 7265 5f73 6574  list_feature_set
-00011ad0: 7328 0a20 2020 2020 2020 2073 656c 662c  s(.        self,
-00011ae0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-00011af0: 3a20 7374 7220 3d20 2222 2c0a 2020 2020  : str = "",.    
-00011b00: 2020 2020 6e61 6d65 3a20 7374 7220 3d20      name: str = 
-00011b10: 4e6f 6e65 2c0a 2020 2020 2020 2020 7461  None,.        ta
-00011b20: 673a 2073 7472 203d 204e 6f6e 652c 0a20  g: str = None,. 
-00011b30: 2020 2020 2020 2073 7461 7465 3a20 7374         state: st
-00011b40: 7220 3d20 4e6f 6e65 2c0a 2020 2020 2020  r = None,.      
-00011b50: 2020 656e 7469 7469 6573 3a20 4c69 7374    entities: List
-00011b60: 5b73 7472 5d20 3d20 4e6f 6e65 2c0a 2020  [str] = None,.  
-00011b70: 2020 2020 2020 6665 6174 7572 6573 3a20        features: 
-00011b80: 4c69 7374 5b73 7472 5d20 3d20 4e6f 6e65  List[str] = None
-00011b90: 2c0a 2020 2020 2020 2020 6c61 6265 6c73  ,.        labels
-00011ba0: 3a20 4c69 7374 5b73 7472 5d20 3d20 4e6f  : List[str] = No
-00011bb0: 6e65 2c0a 2020 2020 2020 2020 7061 7274  ne,.        part
-00011bc0: 6974 696f 6e5f 6279 3a20 556e 696f 6e5b  ition_by: Union[
-00011bd0: 7363 6865 6d61 732e 4665 6174 7572 6553  schemas.FeatureS
-00011be0: 746f 7265 5061 7274 6974 696f 6e42 7946  torePartitionByF
-00011bf0: 6965 6c64 2c20 7374 725d 203d 204e 6f6e  ield, str] = Non
-00011c00: 652c 0a20 2020 2020 2020 2072 6f77 735f  e,.        rows_
-00011c10: 7065 725f 7061 7274 6974 696f 6e3a 2069  per_partition: i
-00011c20: 6e74 203d 2031 2c0a 2020 2020 2020 2020  nt = 1,.        
-00011c30: 7061 7274 6974 696f 6e5f 736f 7274 5f62  partition_sort_b
-00011c40: 793a 2055 6e69 6f6e 5b73 6368 656d 6173  y: Union[schemas
-00011c50: 2e53 6f72 7446 6965 6c64 2c20 7374 725d  .SortField, str]
-00011c60: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-00011c70: 2070 6172 7469 7469 6f6e 5f6f 7264 6572   partition_order
-00011c80: 3a20 556e 696f 6e5b 7363 6865 6d61 732e  : Union[schemas.
-00011c90: 4f72 6465 7254 7970 652c 2073 7472 5d20  OrderType, str] 
-00011ca0: 3d20 7363 6865 6d61 732e 4f72 6465 7254  = schemas.OrderT
-00011cb0: 7970 652e 6465 7363 2c0a 2020 2020 2920  ype.desc,.    ) 
-00011cc0: 2d3e 204c 6973 745b 4665 6174 7572 6553  -> List[FeatureS
-00011cd0: 6574 5d3a 0a20 2020 2020 2020 2022 2222  et]:.        """
-00011ce0: 5265 7472 6965 7665 2061 206c 6973 7420  Retrieve a list 
-00011cf0: 6f66 2066 6561 7475 7265 2d73 6574 7320  of feature-sets 
-00011d00: 6d61 7463 6869 6e67 2074 6865 2063 7269  matching the cri
-00011d10: 7465 7269 6120 7072 6f76 6964 6564 2e0a  teria provided..
-00011d20: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00011d30: 7072 6f6a 6563 743a 2050 726f 6a65 6374  project: Project
-00011d40: 206e 616d 652e 0a20 2020 2020 2020 203a   name..        :
-00011d50: 7061 7261 6d20 6e61 6d65 3a20 4e61 6d65  param name: Name
-00011d60: 206f 6620 6665 6174 7572 652d 7365 7420   of feature-set 
-00011d70: 746f 206d 6174 6368 2e20 5468 6973 2069  to match. This i
-00011d80: 7320 6120 6c69 6b65 2071 7565 7279 2c20  s a like query, 
-00011d90: 616e 6420 6973 2063 6173 652d 696e 7365  and is case-inse
-00011da0: 6e73 6974 6976 652e 0a20 2020 2020 2020  nsitive..       
-00011db0: 203a 7061 7261 6d20 7461 673a 204d 6174   :param tag: Mat
-00011dc0: 6368 2066 6561 7475 7265 2d73 6574 7320  ch feature-sets 
-00011dd0: 7769 7468 2073 7065 6369 6669 6320 7461  with specific ta
-00011de0: 672e 0a20 2020 2020 2020 203a 7061 7261  g..        :para
-00011df0: 6d20 7374 6174 653a 204d 6174 6368 2066  m state: Match f
-00011e00: 6561 7475 7265 2d73 6574 7320 7769 7468  eature-sets with
-00011e10: 2061 2073 7065 6369 6669 6320 7374 6174   a specific stat
-00011e20: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
-00011e30: 6d20 656e 7469 7469 6573 3a20 4d61 7463  m entities: Matc
-00011e40: 6820 6665 6174 7572 652d 7365 7473 2077  h feature-sets w
-00011e50: 6869 6368 2063 6f6e 7461 696e 2065 6e74  hich contain ent
-00011e60: 6974 6965 7320 7768 6f73 6520 6e61 6d65  ities whose name
-00011e70: 2069 7320 696e 2074 6869 7320 6c69 7374   is in this list
-00011e80: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-00011e90: 2066 6561 7475 7265 733a 204d 6174 6368   features: Match
-00011ea0: 2066 6561 7475 7265 2d73 6574 7320 7768   feature-sets wh
-00011eb0: 6963 6820 636f 6e74 6169 6e20 6665 6174  ich contain feat
-00011ec0: 7572 6573 2077 686f 7365 206e 616d 6520  ures whose name 
-00011ed0: 6973 2069 6e20 7468 6973 206c 6973 742e  is in this list.
-00011ee0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00011ef0: 6c61 6265 6c73 3a20 4d61 7463 6820 6665  labels: Match fe
-00011f00: 6174 7572 652d 7365 7473 2077 6869 6368  ature-sets which
-00011f10: 2068 6176 6520 7468 6573 6520 6c61 6265   have these labe
-00011f20: 6c73 2e0a 2020 2020 2020 2020 3a70 6172  ls..        :par
-00011f30: 616d 2070 6172 7469 7469 6f6e 5f62 793a  am partition_by:
-00011f40: 2046 6965 6c64 2074 6f20 6772 6f75 7020   Field to group 
-00011f50: 7265 7375 6c74 7320 6279 2e20 4f6e 6c79  results by. Only
-00011f60: 2061 6c6c 6f77 6564 2076 616c 7565 2069   allowed value i
-00011f70: 7320 606e 616d 6560 2e20 5768 656e 2060  s `name`. When `
-00011f80: 7061 7274 6974 696f 6e5f 6279 6020 6973  partition_by` is
-00011f90: 2073 7065 6369 6669 6564 2c0a 2020 2020   specified,.    
-00011fa0: 2020 2020 2020 2020 7468 6520 6070 6172          the `par
-00011fb0: 7469 7469 6f6e 5f73 6f72 745f 6279 6020  tition_sort_by` 
-00011fc0: 7061 7261 6d65 7465 7220 6d75 7374 2062  parameter must b
-00011fd0: 6520 7072 6f76 6964 6564 2061 7320 7765  e provided as we
-00011fe0: 6c6c 2e0a 2020 2020 2020 2020 3a70 6172  ll..        :par
-00011ff0: 616d 2072 6f77 735f 7065 725f 7061 7274  am rows_per_part
-00012000: 6974 696f 6e3a 2048 6f77 206d 616e 7920  ition: How many 
-00012010: 746f 7020 726f 7773 2028 7065 7220 736f  top rows (per so
-00012020: 7274 696e 6720 6465 6669 6e65 6420 6279  rting defined by
-00012030: 2060 7061 7274 6974 696f 6e5f 736f 7274   `partition_sort
-00012040: 5f62 7960 2061 6e64 2060 7061 7274 6974  _by` and `partit
-00012050: 696f 6e5f 6f72 6465 7260 290a 2020 2020  ion_order`).    
-00012060: 2020 2020 2020 2020 746f 2072 6574 7572          to retur
-00012070: 6e20 7065 7220 6772 6f75 702e 2044 6566  n per group. Def
-00012080: 6175 6c74 2076 616c 7565 2069 7320 312e  ault value is 1.
-00012090: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-000120a0: 7061 7274 6974 696f 6e5f 736f 7274 5f62  partition_sort_b
-000120b0: 793a 2057 6861 7420 6669 656c 6420 746f  y: What field to
-000120c0: 2073 6f72 7420 7468 6520 7265 7375 6c74   sort the result
-000120d0: 7320 6279 2c20 7769 7468 696e 2065 6163  s by, within eac
-000120e0: 6820 7061 7274 6974 696f 6e20 6465 6669  h partition defi
-000120f0: 6e65 6420 6279 2060 7061 7274 6974 696f  ned by `partitio
-00012100: 6e5f 6279 602e 0a20 2020 2020 2020 2020  n_by`..         
-00012110: 2020 2043 7572 7265 6e74 6c79 2074 6865     Currently the
-00012120: 206f 6e6c 7920 616c 6c6f 7765 6420 7661   only allowed va
-00012130: 6c75 6520 6172 6520 6063 7265 6174 6564  lue are `created
-00012140: 6020 616e 6420 6075 7064 6174 6564 602e  ` and `updated`.
-00012150: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00012160: 7061 7274 6974 696f 6e5f 6f72 6465 723a  partition_order:
-00012170: 204f 7264 6572 206f 6620 736f 7274 696e   Order of sortin
-00012180: 6720 7769 7468 696e 2070 6172 7469 7469  g within partiti
-00012190: 6f6e 7320 2d20 6061 7363 6020 6f72 2060  ons - `asc` or `
-000121a0: 6465 7363 602e 2044 6566 6175 6c74 2069  desc`. Default i
-000121b0: 7320 6064 6573 6360 2e0a 2020 2020 2020  s `desc`..      
-000121c0: 2020 3a72 6574 7572 6e73 3a20 4c69 7374    :returns: List
-000121d0: 206f 6620 6d61 7463 6869 6e67 203a 7079   of matching :py
-000121e0: 3a63 6c61 7373 3a60 7e6d 6c72 756e 2e66  :class:`~mlrun.f
-000121f0: 6561 7475 7265 5f73 746f 7265 2e46 6561  eature_store.Fea
-00012200: 7475 7265 5365 7460 206f 626a 6563 7473  tureSet` objects
-00012210: 2e0a 2020 2020 2020 2020 2222 220a 0a20  ..        """.. 
-00012220: 2020 2020 2020 2070 726f 6a65 6374 203d         project =
-00012230: 2070 726f 6a65 6374 206f 7220 636f 6e66   project or conf
-00012240: 6967 2e64 6566 6175 6c74 5f70 726f 6a65  ig.default_proje
-00012250: 6374 0a0a 2020 2020 2020 2020 7061 7261  ct..        para
-00012260: 6d73 203d 207b 0a20 2020 2020 2020 2020  ms = {.         
-00012270: 2020 2022 6e61 6d65 223a 206e 616d 652c     "name": name,
-00012280: 0a20 2020 2020 2020 2020 2020 2022 7374  .            "st
-00012290: 6174 6522 3a20 7374 6174 652c 0a20 2020  ate": state,.   
-000122a0: 2020 2020 2020 2020 2022 7461 6722 3a20           "tag": 
-000122b0: 7461 672c 0a20 2020 2020 2020 2020 2020  tag,.           
-000122c0: 2022 656e 7469 7479 223a 2065 6e74 6974   "entity": entit
-000122d0: 6965 7320 6f72 205b 5d2c 0a20 2020 2020  ies or [],.     
-000122e0: 2020 2020 2020 2022 6665 6174 7572 6522         "feature"
-000122f0: 3a20 6665 6174 7572 6573 206f 7220 5b5d  : features or []
-00012300: 2c0a 2020 2020 2020 2020 2020 2020 226c  ,.            "l
-00012310: 6162 656c 223a 206c 6162 656c 7320 6f72  abel": labels or
-00012320: 205b 5d2c 0a20 2020 2020 2020 207d 0a20   [],.        }. 
-00012330: 2020 2020 2020 2069 6620 7061 7274 6974         if partit
-00012340: 696f 6e5f 6279 3a0a 2020 2020 2020 2020  ion_by:.        
-00012350: 2020 2020 7061 7261 6d73 2e75 7064 6174      params.updat
-00012360: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
-00012370: 2020 2073 656c 662e 5f67 656e 6572 6174     self._generat
-00012380: 655f 7061 7274 6974 696f 6e5f 6279 5f70  e_partition_by_p
-00012390: 6172 616d 7328 0a20 2020 2020 2020 2020  arams(.         
-000123a0: 2020 2020 2020 2020 2020 2073 6368 656d             schem
-000123b0: 6173 2e46 6561 7475 7265 5374 6f72 6550  as.FeatureStoreP
-000123c0: 6172 7469 7469 6f6e 4279 4669 656c 642c  artitionByField,
-000123d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000123e0: 2020 2020 2070 6172 7469 7469 6f6e 5f62       partition_b
-000123f0: 792c 0a20 2020 2020 2020 2020 2020 2020  y,.             
-00012400: 2020 2020 2020 2072 6f77 735f 7065 725f         rows_per_
-00012410: 7061 7274 6974 696f 6e2c 0a20 2020 2020  partition,.     
-00012420: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-00012430: 6172 7469 7469 6f6e 5f73 6f72 745f 6279  artition_sort_by
-00012440: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00012450: 2020 2020 2020 7061 7274 6974 696f 6e5f        partition_
-00012460: 6f72 6465 722c 0a20 2020 2020 2020 2020  order,.         
-00012470: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-00012480: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
-00012490: 7061 7468 203d 2066 2270 726f 6a65 6374  path = f"project
-000124a0: 732f 7b70 726f 6a65 6374 7d2f 6665 6174  s/{project}/feat
-000124b0: 7572 652d 7365 7473 220a 0a20 2020 2020  ure-sets"..     
-000124c0: 2020 2065 7272 6f72 5f6d 6573 7361 6765     error_message
-000124d0: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
-000124e0: 2066 2246 6169 6c65 6420 6c69 7374 696e   f"Failed listin
-000124f0: 6720 6665 6174 7572 652d 7365 7473 2c20  g feature-sets, 
-00012500: 7072 6f6a 6563 743a 207b 7072 6f6a 6563  project: {projec
-00012510: 747d 2c20 7175 6572 793a 207b 7061 7261  t}, query: {para
-00012520: 6d73 7d22 0a20 2020 2020 2020 2029 0a20  ms}".        ). 
-00012530: 2020 2020 2020 2072 6573 7020 3d20 7365         resp = se
-00012540: 6c66 2e61 7069 5f63 616c 6c28 2247 4554  lf.api_call("GET
-00012550: 222c 2070 6174 682c 2065 7272 6f72 5f6d  ", path, error_m
-00012560: 6573 7361 6765 2c20 7061 7261 6d73 3d70  essage, params=p
-00012570: 6172 616d 7329 0a20 2020 2020 2020 2066  arams).        f
-00012580: 6561 7475 7265 5f73 6574 7320 3d20 7265  eature_sets = re
-00012590: 7370 2e6a 736f 6e28 295b 2266 6561 7475  sp.json()["featu
-000125a0: 7265 5f73 6574 7322 5d0a 2020 2020 2020  re_sets"].      
-000125b0: 2020 6966 2066 6561 7475 7265 5f73 6574    if feature_set
-000125c0: 733a 0a20 2020 2020 2020 2020 2020 2072  s:.            r
-000125d0: 6574 7572 6e20 5b46 6561 7475 7265 5365  eturn [FeatureSe
-000125e0: 742e 6672 6f6d 5f64 6963 7428 6f62 6a29  t.from_dict(obj)
-000125f0: 2066 6f72 206f 626a 2069 6e20 6665 6174   for obj in feat
-00012600: 7572 655f 7365 7473 5d0a 0a20 2020 2064  ure_sets]..    d
-00012610: 6566 2073 746f 7265 5f66 6561 7475 7265  ef store_feature
-00012620: 5f73 6574 280a 2020 2020 2020 2020 7365  _set(.        se
-00012630: 6c66 2c0a 2020 2020 2020 2020 6665 6174  lf,.        feat
-00012640: 7572 655f 7365 743a 2055 6e69 6f6e 5b64  ure_set: Union[d
-00012650: 6963 742c 2073 6368 656d 6173 2e46 6561  ict, schemas.Fea
-00012660: 7475 7265 5365 742c 2046 6561 7475 7265  tureSet, Feature
-00012670: 5365 745d 2c0a 2020 2020 2020 2020 6e61  Set],.        na
-00012680: 6d65 3d4e 6f6e 652c 0a20 2020 2020 2020  me=None,.       
-00012690: 2070 726f 6a65 6374 3d22 222c 0a20 2020   project="",.   
-000126a0: 2020 2020 2074 6167 3d4e 6f6e 652c 0a20       tag=None,. 
-000126b0: 2020 2020 2020 2075 6964 3d4e 6f6e 652c         uid=None,
-000126c0: 0a20 2020 2020 2020 2076 6572 7369 6f6e  .        version
-000126d0: 6564 3d54 7275 652c 0a20 2020 2029 202d  ed=True,.    ) -
-000126e0: 3e20 6469 6374 3a0a 2020 2020 2020 2020  > dict:.        
-000126f0: 2222 2253 6176 6520 6120 3a70 793a 636c  """Save a :py:cl
-00012700: 6173 733a 607e 6d6c 7275 6e2e 6665 6174  ass:`~mlrun.feat
-00012710: 7572 655f 7374 6f72 652e 4665 6174 7572  ure_store.Featur
-00012720: 6553 6574 6020 6f62 6a65 6374 2069 6e20  eSet` object in 
-00012730: 7468 6520 3a70 793a 6d6f 643a 606d 6c72  the :py:mod:`mlr
-00012740: 756e 6020 4442 2e20 5468 650a 2020 2020  un` DB. The.    
-00012750: 2020 2020 6665 6174 7572 652d 7365 7420      feature-set 
-00012760: 6361 6e20 6265 2065 6974 6865 7220 6120  can be either a 
-00012770: 6e65 7720 6f62 6a65 6374 206f 7220 6120  new object or a 
-00012780: 6d6f 6469 6669 6361 7469 6f6e 2074 6f20  modification to 
-00012790: 6578 6973 7469 6e67 206f 626a 6563 7420  existing object 
-000127a0: 7265 6665 7265 6e63 6564 2062 7920 7468  referenced by th
-000127b0: 6520 7061 7261 6d73 206f 660a 2020 2020  e params of.    
-000127c0: 2020 2020 7468 6520 6675 6e63 7469 6f6e      the function
-000127d0: 2e0a 0a20 2020 2020 2020 203a 7061 7261  ...        :para
-000127e0: 6d20 6665 6174 7572 655f 7365 743a 2054  m feature_set: T
-000127f0: 6865 203a 7079 3a63 6c61 7373 3a60 7e6d  he :py:class:`~m
-00012800: 6c72 756e 2e66 6561 7475 7265 5f73 746f  lrun.feature_sto
-00012810: 7265 2e46 6561 7475 7265 5365 7460 2074  re.FeatureSet` t
-00012820: 6f20 7374 6f72 652e 0a20 2020 2020 2020  o store..       
-00012830: 203a 7061 7261 6d20 6e61 6d65 3a20 2020   :param name:   
-00012840: 204e 616d 6520 6f66 2066 6561 7475 7265   Name of feature
-00012850: 2073 6574 2e0a 2020 2020 2020 2020 3a70   set..        :p
-00012860: 6172 616d 2070 726f 6a65 6374 3a20 4e61  aram project: Na
-00012870: 6d65 206f 6620 7072 6f6a 6563 7420 7468  me of project th
-00012880: 6973 2066 6561 7475 7265 2d73 6574 2062  is feature-set b
-00012890: 656c 6f6e 6773 2074 6f2e 0a20 2020 2020  elongs to..     
-000128a0: 2020 203a 7061 7261 6d20 7461 673a 2054     :param tag: T
-000128b0: 6865 2060 6074 6167 6060 206f 6620 7468  he ``tag`` of th
-000128c0: 6520 6f62 6a65 6374 2074 6f20 7265 706c  e object to repl
-000128d0: 6163 6520 696e 2074 6865 2044 422c 2066  ace in the DB, f
-000128e0: 6f72 2065 7861 6d70 6c65 2060 606c 6174  or example ``lat
-000128f0: 6573 7460 602e 0a20 2020 2020 2020 203a  est``..        :
-00012900: 7061 7261 6d20 7569 643a 2054 6865 2060  param uid: The `
-00012910: 6075 6964 6060 206f 6620 7468 6520 6f62  `uid`` of the ob
-00012920: 6a65 6374 2074 6f20 7265 706c 6163 6520  ject to replace 
-00012930: 696e 2074 6865 2044 422e 2049 6620 7573  in the DB. If us
-00012940: 696e 6720 7468 6973 2070 6172 616d 6574  ing this paramet
-00012950: 6572 2c20 7468 6520 6d6f 6469 6669 6564  er, the modified
-00012960: 206f 626a 6563 740a 2020 2020 2020 2020   object.        
-00012970: 2020 2020 6d75 7374 2068 6176 6520 7468      must have th
-00012980: 6520 7361 6d65 2060 6075 6964 6060 206f  e same ``uid`` o
-00012990: 6620 7468 6520 7072 6576 696f 7573 6c79  f the previously
-000129a0: 2d65 7869 7374 696e 6720 6f62 6a65 6374  -existing object
-000129b0: 2e20 5468 6973 2063 616e 6e6f 7420 6265  . This cannot be
-000129c0: 2075 7365 6420 666f 7220 6e6f 6e2d 7665   used for non-ve
-000129d0: 7273 696f 6e65 6420 6f62 6a65 6374 732e  rsioned objects.
-000129e0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-000129f0: 7665 7273 696f 6e65 643a 2057 6865 7468  versioned: Wheth
-00012a00: 6572 2074 6f20 6d61 696e 7461 696e 2076  er to maintain v
-00012a10: 6572 7369 6f6e 7320 666f 7220 7468 6973  ersions for this
-00012a20: 2066 6561 7475 7265 2d73 6574 2e20 416c   feature-set. Al
-00012a30: 6c20 7665 7273 696f 6e73 206f 6620 6120  l versions of a 
-00012a40: 7665 7273 696f 6e65 6420 6f62 6a65 6374  versioned object
-00012a50: 0a20 2020 2020 2020 2020 2020 2077 696c  .            wil
-00012a60: 6c20 6265 206b 6570 7420 696e 2074 6865  l be kept in the
-00012a70: 2044 4220 616e 6420 6361 6e20 6265 2072   DB and can be r
-00012a80: 6574 7269 6576 6564 2075 6e74 696c 2065  etrieved until e
-00012a90: 7870 6c69 6369 746c 7920 6465 6c65 7465  xplicitly delete
-00012aa0: 642e 0a20 2020 2020 2020 203a 7265 7475  d..        :retu
-00012ab0: 726e 733a 2054 6865 203a 7079 3a63 6c61  rns: The :py:cla
-00012ac0: 7373 3a60 7e6d 6c72 756e 2e66 6561 7475  ss:`~mlrun.featu
-00012ad0: 7265 5f73 746f 7265 2e46 6561 7475 7265  re_store.Feature
-00012ae0: 5365 7460 206f 626a 6563 7420 2861 7320  Set` object (as 
-00012af0: 6469 6374 292e 0a20 2020 2020 2020 2022  dict)..        "
-00012b00: 2222 0a0a 2020 2020 2020 2020 7265 6665  ""..        refe
-00012b10: 7265 6e63 6520 3d20 7365 6c66 2e5f 7265  rence = self._re
-00012b20: 736f 6c76 655f 7265 6665 7265 6e63 6528  solve_reference(
-00012b30: 7461 672c 2075 6964 290a 2020 2020 2020  tag, uid).      
-00012b40: 2020 7061 7261 6d73 203d 207b 2276 6572    params = {"ver
-00012b50: 7369 6f6e 6564 223a 2076 6572 7369 6f6e  sioned": version
-00012b60: 6564 7d0a 0a20 2020 2020 2020 2069 6620  ed}..        if 
-00012b70: 6973 696e 7374 616e 6365 2866 6561 7475  isinstance(featu
-00012b80: 7265 5f73 6574 2c20 7363 6865 6d61 732e  re_set, schemas.
-00012b90: 4665 6174 7572 6553 6574 293a 0a20 2020  FeatureSet):.   
-00012ba0: 2020 2020 2020 2020 2066 6561 7475 7265           feature
-00012bb0: 5f73 6574 203d 2066 6561 7475 7265 5f73  _set = feature_s
-00012bc0: 6574 2e64 6963 7428 290a 2020 2020 2020  et.dict().      
-00012bd0: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
-00012be0: 6528 6665 6174 7572 655f 7365 742c 2046  e(feature_set, F
-00012bf0: 6561 7475 7265 5365 7429 3a0a 2020 2020  eatureSet):.    
-00012c00: 2020 2020 2020 2020 6665 6174 7572 655f          feature_
-00012c10: 7365 7420 3d20 6665 6174 7572 655f 7365  set = feature_se
-00012c20: 742e 746f 5f64 6963 7428 290a 0a20 2020  t.to_dict()..   
-00012c30: 2020 2020 206e 616d 6520 3d20 6e61 6d65       name = name
-00012c40: 206f 7220 6665 6174 7572 655f 7365 745b   or feature_set[
-00012c50: 226d 6574 6164 6174 6122 5d5b 226e 616d  "metadata"]["nam
-00012c60: 6522 5d0a 2020 2020 2020 2020 7072 6f6a  e"].        proj
-00012c70: 6563 7420 3d20 280a 2020 2020 2020 2020  ect = (.        
-00012c80: 2020 2020 7072 6f6a 6563 7420 6f72 2066      project or f
-00012c90: 6561 7475 7265 5f73 6574 5b22 6d65 7461  eature_set["meta
-00012ca0: 6461 7461 225d 2e67 6574 2822 7072 6f6a  data"].get("proj
-00012cb0: 6563 7422 2920 6f72 2063 6f6e 6669 672e  ect") or config.
-00012cc0: 6465 6661 756c 745f 7072 6f6a 6563 740a  default_project.
-00012cd0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-00012ce0: 2020 7061 7468 203d 2066 2270 726f 6a65    path = f"proje
-00012cf0: 6374 732f 7b70 726f 6a65 6374 7d2f 6665  cts/{project}/fe
-00012d00: 6174 7572 652d 7365 7473 2f7b 6e61 6d65  ature-sets/{name
-00012d10: 7d2f 7265 6665 7265 6e63 6573 2f7b 7265  }/references/{re
-00012d20: 6665 7265 6e63 657d 220a 2020 2020 2020  ference}".      
-00012d30: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
-00012d40: 3d20 6622 4661 696c 6564 2073 746f 7269  = f"Failed stori
-00012d50: 6e67 2066 6561 7475 7265 2d73 6574 207b  ng feature-set {
-00012d60: 7072 6f6a 6563 747d 2f7b 6e61 6d65 7d22  project}/{name}"
-00012d70: 0a20 2020 2020 2020 2072 6573 7020 3d20  .        resp = 
-00012d80: 7365 6c66 2e61 7069 5f63 616c 6c28 0a20  self.api_call(. 
-00012d90: 2020 2020 2020 2020 2020 2022 5055 5422             "PUT"
-00012da0: 2c20 7061 7468 2c20 6572 726f 725f 6d65  , path, error_me
-00012db0: 7373 6167 652c 2070 6172 616d 733d 7061  ssage, params=pa
-00012dc0: 7261 6d73 2c20 626f 6479 3d64 6963 745f  rams, body=dict_
-00012dd0: 746f 5f6a 736f 6e28 6665 6174 7572 655f  to_json(feature_
-00012de0: 7365 7429 0a20 2020 2020 2020 2029 0a20  set).        ). 
-00012df0: 2020 2020 2020 2072 6574 7572 6e20 7265         return re
-00012e00: 7370 2e6a 736f 6e28 290a 0a20 2020 2064  sp.json()..    d
-00012e10: 6566 2070 6174 6368 5f66 6561 7475 7265  ef patch_feature
-00012e20: 5f73 6574 280a 2020 2020 2020 2020 7365  _set(.        se
-00012e30: 6c66 2c0a 2020 2020 2020 2020 6e61 6d65  lf,.        name
-00012e40: 2c0a 2020 2020 2020 2020 6665 6174 7572  ,.        featur
-00012e50: 655f 7365 745f 7570 6461 7465 3a20 6469  e_set_update: di
-00012e60: 6374 2c0a 2020 2020 2020 2020 7072 6f6a  ct,.        proj
-00012e70: 6563 743d 2222 2c0a 2020 2020 2020 2020  ect="",.        
-00012e80: 7461 673d 4e6f 6e65 2c0a 2020 2020 2020  tag=None,.      
-00012e90: 2020 7569 643d 4e6f 6e65 2c0a 2020 2020    uid=None,.    
-00012ea0: 2020 2020 7061 7463 685f 6d6f 6465 3a20      patch_mode: 
-00012eb0: 556e 696f 6e5b 7374 722c 2073 6368 656d  Union[str, schem
-00012ec0: 6173 2e50 6174 6368 4d6f 6465 5d20 3d20  as.PatchMode] = 
-00012ed0: 7363 6865 6d61 732e 5061 7463 684d 6f64  schemas.PatchMod
-00012ee0: 652e 7265 706c 6163 652c 0a20 2020 2029  e.replace,.    )
-00012ef0: 3a0a 2020 2020 2020 2020 2222 224d 6f64  :.        """Mod
-00012f00: 6966 7920 2870 6174 6368 2920 616e 2065  ify (patch) an e
-00012f10: 7869 7374 696e 6720 3a70 793a 636c 6173  xisting :py:clas
-00012f20: 733a 607e 6d6c 7275 6e2e 6665 6174 7572  s:`~mlrun.featur
-00012f30: 655f 7374 6f72 652e 4665 6174 7572 6553  e_store.FeatureS
-00012f40: 6574 6020 6f62 6a65 6374 2e0a 2020 2020  et` object..    
-00012f50: 2020 2020 5468 6520 6f62 6a65 6374 2069      The object i
-00012f60: 7320 6964 656e 7469 6669 6564 2062 7920  s identified by 
-00012f70: 6974 7320 6e61 6d65 2028 616e 6420 7072  its name (and pr
-00012f80: 6f6a 6563 7420 6974 2062 656c 6f6e 6773  oject it belongs
-00012f90: 2074 6f29 2c20 6173 2077 656c 6c20 6173   to), as well as
-00012fa0: 206f 7074 696f 6e61 6c6c 7920 6120 6060   optionally a ``
-00012fb0: 7461 6760 6020 6f72 2069 7473 0a20 2020  tag`` or its.   
-00012fc0: 2020 2020 2060 6075 6964 6060 2028 666f       ``uid`` (fo
-00012fd0: 7220 7665 7273 696f 6e65 6420 6f62 6a65  r versioned obje
-00012fe0: 6374 292e 2049 6620 626f 7468 2060 6074  ct). If both ``t
-00012ff0: 6167 6060 2061 6e64 2060 6075 6964 6060  ag`` and ``uid``
-00013000: 2061 7265 206f 6d69 7474 6564 2074 6865   are omitted the
-00013010: 6e20 7468 6520 6f62 6a65 6374 2077 6974  n the object wit
-00013020: 6820 7461 6720 6060 6c61 7465 7374 6060  h tag ``latest``
-00013030: 0a20 2020 2020 2020 2069 7320 6d6f 6469  .        is modi
-00013040: 6669 6564 2e0a 0a20 2020 2020 2020 203a  fied...        :
-00013050: 7061 7261 6d20 6e61 6d65 3a20 4e61 6d65  param name: Name
-00013060: 206f 6620 7468 6520 6f62 6a65 6374 2074   of the object t
-00013070: 6f20 7061 7463 682e 0a20 2020 2020 2020  o patch..       
-00013080: 203a 7061 7261 6d20 6665 6174 7572 655f   :param feature_
-00013090: 7365 745f 7570 6461 7465 3a20 5468 6520  set_update: The 
-000130a0: 6d6f 6469 6669 6361 7469 6f6e 7320 6e65  modifications ne
-000130b0: 6564 6564 2069 6e20 7468 6520 6f62 6a65  eded in the obje
-000130c0: 6374 2e20 5468 6973 2070 6172 616d 6574  ct. This paramet
-000130d0: 6572 206f 6e6c 7920 6861 7320 7468 6520  er only has the 
-000130e0: 6368 616e 6765 7320 696e 2069 742c 0a20  changes in it,. 
-000130f0: 2020 2020 2020 2020 2020 206e 6f74 2061             not a
-00013100: 2066 756c 6c20 6f62 6a65 6374 2e0a 2020   full object..  
-00013110: 2020 2020 2020 2020 2020 4578 616d 706c            Exampl
-00013120: 653a 3a0a 0a20 2020 2020 2020 2020 2020  e::..           
-00013130: 2020 2020 2066 6561 7475 7265 5f73 6574       feature_set
-00013140: 5f75 7064 6174 6520 3d20 7b22 7374 6174  _update = {"stat
-00013150: 7573 223a 207b 2270 726f 6365 7373 6564  us": {"processed
-00013160: 2220 3a20 5472 7565 7d7d 0a0a 2020 2020  " : True}}..    
-00013170: 2020 2020 2020 2020 5769 6c6c 2061 7070          Will app
-00013180: 6c79 2074 6865 2066 6965 6c64 2060 6073  ly the field ``s
-00013190: 7461 7475 732e 7072 6f63 6573 7365 6460  tatus.processed`
-000131a0: 6020 746f 2074 6865 2065 7869 7374 696e  ` to the existin
-000131b0: 6720 6f62 6a65 6374 2e0a 2020 2020 2020  g object..      
-000131c0: 2020 3a70 6172 616d 2070 726f 6a65 6374    :param project
-000131d0: 3a20 5072 6f6a 6563 7420 7768 6963 6820  : Project which 
-000131e0: 636f 6e74 6169 6e73 2074 6865 206d 6f64  contains the mod
-000131f0: 6966 6965 6420 6f62 6a65 6374 2e0a 2020  ified object..  
-00013200: 2020 2020 2020 3a70 6172 616d 2074 6167        :param tag
-00013210: 3a20 5468 6520 7461 6720 6f66 2074 6865  : The tag of the
-00013220: 206f 626a 6563 7420 746f 206d 6f64 6966   object to modif
-00013230: 792e 0a20 2020 2020 2020 203a 7061 7261  y..        :para
-00013240: 6d20 7569 643a 2075 6964 206f 6620 7468  m uid: uid of th
-00013250: 6520 6f62 6a65 6374 2074 6f20 6d6f 6469  e object to modi
-00013260: 6679 2e0a 2020 2020 2020 2020 3a70 6172  fy..        :par
-00013270: 616d 2070 6174 6368 5f6d 6f64 653a 2054  am patch_mode: T
-00013280: 6865 2073 7472 6174 6567 7920 666f 7220  he strategy for 
-00013290: 6d65 7267 696e 6720 7468 6520 6368 616e  merging the chan
-000132a0: 6765 7320 7769 7468 2074 6865 2065 7869  ges with the exi
-000132b0: 7374 696e 6720 6f62 6a65 6374 2e20 4361  sting object. Ca
-000132c0: 6e20 6265 2065 6974 6865 7220 6060 7265  n be either ``re
-000132d0: 706c 6163 6560 600a 2020 2020 2020 2020  place``.        
-000132e0: 2020 2020 6f72 2060 6061 6464 6974 6976      or ``additiv
-000132f0: 6560 602e 0a20 2020 2020 2020 2022 2222  e``..        """
-00013300: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-00013310: 203d 2070 726f 6a65 6374 206f 7220 636f   = project or co
-00013320: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
-00013330: 6a65 6374 0a20 2020 2020 2020 2072 6566  ject.        ref
-00013340: 6572 656e 6365 203d 2073 656c 662e 5f72  erence = self._r
-00013350: 6573 6f6c 7665 5f72 6566 6572 656e 6365  esolve_reference
-00013360: 2874 6167 2c20 7569 6429 0a20 2020 2020  (tag, uid).     
-00013370: 2020 2068 6561 6465 7273 203d 207b 7363     headers = {sc
-00013380: 6865 6d61 732e 4865 6164 6572 4e61 6d65  hemas.HeaderName
-00013390: 732e 7061 7463 685f 6d6f 6465 3a20 7061  s.patch_mode: pa
-000133a0: 7463 685f 6d6f 6465 7d0a 2020 2020 2020  tch_mode}.      
-000133b0: 2020 7061 7468 203d 2066 2270 726f 6a65    path = f"proje
-000133c0: 6374 732f 7b70 726f 6a65 6374 7d2f 6665  cts/{project}/fe
-000133d0: 6174 7572 652d 7365 7473 2f7b 6e61 6d65  ature-sets/{name
-000133e0: 7d2f 7265 6665 7265 6e63 6573 2f7b 7265  }/references/{re
-000133f0: 6665 7265 6e63 657d 220a 2020 2020 2020  ference}".      
-00013400: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
-00013410: 3d20 6622 4661 696c 6564 2075 7064 6174  = f"Failed updat
-00013420: 696e 6720 6665 6174 7572 652d 7365 7420  ing feature-set 
-00013430: 7b70 726f 6a65 6374 7d2f 7b6e 616d 657d  {project}/{name}
-00013440: 220a 2020 2020 2020 2020 7365 6c66 2e61  ".        self.a
-00013450: 7069 5f63 616c 6c28 0a20 2020 2020 2020  pi_call(.       
-00013460: 2020 2020 2022 5041 5443 4822 2c0a 2020       "PATCH",.  
-00013470: 2020 2020 2020 2020 2020 7061 7468 2c0a            path,.
-00013480: 2020 2020 2020 2020 2020 2020 6572 726f              erro
-00013490: 725f 6d65 7373 6167 652c 0a20 2020 2020  r_message,.     
-000134a0: 2020 2020 2020 2062 6f64 793d 6469 6374         body=dict
-000134b0: 5f74 6f5f 6a73 6f6e 2866 6561 7475 7265  _to_json(feature
-000134c0: 5f73 6574 5f75 7064 6174 6529 2c0a 2020  _set_update),.  
-000134d0: 2020 2020 2020 2020 2020 6865 6164 6572            header
-000134e0: 733d 6865 6164 6572 732c 0a20 2020 2020  s=headers,.     
-000134f0: 2020 2029 0a0a 2020 2020 6465 6620 6465     )..    def de
-00013500: 6c65 7465 5f66 6561 7475 7265 5f73 6574  lete_feature_set
-00013510: 2873 656c 662c 206e 616d 652c 2070 726f  (self, name, pro
-00013520: 6a65 6374 3d22 222c 2074 6167 3d4e 6f6e  ject="", tag=Non
-00013530: 652c 2075 6964 3d4e 6f6e 6529 3a0a 2020  e, uid=None):.  
-00013540: 2020 2020 2020 2222 2244 656c 6574 6520        """Delete 
-00013550: 6120 3a70 793a 636c 6173 733a 607e 6d6c  a :py:class:`~ml
-00013560: 7275 6e2e 6665 6174 7572 655f 7374 6f72  run.feature_stor
-00013570: 652e 4665 6174 7572 6553 6574 6020 6f62  e.FeatureSet` ob
-00013580: 6a65 6374 2066 726f 6d20 7468 6520 4442  ject from the DB
-00013590: 2e0a 2020 2020 2020 2020 4966 2060 6074  ..        If ``t
-000135a0: 6167 6060 206f 7220 6060 7569 6460 6020  ag`` or ``uid`` 
-000135b0: 6172 6520 7370 6563 6966 6965 642c 2074  are specified, t
-000135c0: 6865 6e20 6a75 7374 2074 6865 2076 6572  hen just the ver
-000135d0: 7369 6f6e 2072 6566 6572 656e 6365 6420  sion referenced 
-000135e0: 6279 2074 6865 6d20 7769 6c6c 2062 6520  by them will be 
-000135f0: 6465 6c65 7465 642e 2055 7369 6e67 2062  deleted. Using b
-00013600: 6f74 680a 2020 2020 2020 2020 6973 206e  oth.        is n
-00013610: 6f74 2061 6c6c 6f77 6564 2e0a 2020 2020  ot allowed..    
-00013620: 2020 2020 4966 206e 6f6e 6520 6172 6520      If none are 
-00013630: 7370 6563 6966 6965 642c 2074 6865 6e20  specified, then 
-00013640: 616c 6c20 696e 7374 616e 6365 7320 6f66  all instances of
-00013650: 2074 6865 206f 626a 6563 7420 7768 6f73   the object whos
-00013660: 6520 6e61 6d65 2069 7320 6060 6e61 6d65  e name is ``name
-00013670: 6060 2077 696c 6c20 6265 2064 656c 6574  `` will be delet
-00013680: 6564 2e0a 2020 2020 2020 2020 2222 220a  ed..        """.
-00013690: 2020 2020 2020 2020 7072 6f6a 6563 7420          project 
-000136a0: 3d20 7072 6f6a 6563 7420 6f72 2063 6f6e  = project or con
-000136b0: 6669 672e 6465 6661 756c 745f 7072 6f6a  fig.default_proj
-000136c0: 6563 740a 2020 2020 2020 2020 7061 7468  ect.        path
-000136d0: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
-000136e0: 726f 6a65 6374 7d2f 6665 6174 7572 652d  roject}/feature-
-000136f0: 7365 7473 2f7b 6e61 6d65 7d22 0a0a 2020  sets/{name}"..  
-00013700: 2020 2020 2020 6966 2074 6167 206f 7220        if tag or 
-00013710: 7569 643a 0a20 2020 2020 2020 2020 2020  uid:.           
-00013720: 2072 6566 6572 656e 6365 203d 2073 656c   reference = sel
-00013730: 662e 5f72 6573 6f6c 7665 5f72 6566 6572  f._resolve_refer
-00013740: 656e 6365 2874 6167 2c20 7569 6429 0a20  ence(tag, uid). 
-00013750: 2020 2020 2020 2020 2020 2070 6174 6820             path 
-00013760: 3d20 7061 7468 202b 2066 222f 7265 6665  = path + f"/refe
-00013770: 7265 6e63 6573 2f7b 7265 6665 7265 6e63  rences/{referenc
-00013780: 657d 220a 0a20 2020 2020 2020 2065 7272  e}"..        err
-00013790: 6f72 5f6d 6573 7361 6765 203d 2066 2246  or_message = f"F
-000137a0: 6169 6c65 6420 6465 6c65 7469 6e67 2066  ailed deleting f
-000137b0: 6561 7475 7265 2d73 6574 207b 6e61 6d65  eature-set {name
-000137c0: 7d22 0a20 2020 2020 2020 2073 656c 662e  }".        self.
-000137d0: 6170 695f 6361 6c6c 2822 4445 4c45 5445  api_call("DELETE
-000137e0: 222c 2070 6174 682c 2065 7272 6f72 5f6d  ", path, error_m
-000137f0: 6573 7361 6765 290a 0a20 2020 2064 6566  essage)..    def
-00013800: 2063 7265 6174 655f 6665 6174 7572 655f   create_feature_
-00013810: 7665 6374 6f72 280a 2020 2020 2020 2020  vector(.        
-00013820: 7365 6c66 2c0a 2020 2020 2020 2020 6665  self,.        fe
-00013830: 6174 7572 655f 7665 6374 6f72 3a20 556e  ature_vector: Un
-00013840: 696f 6e5b 6469 6374 2c20 7363 6865 6d61  ion[dict, schema
-00013850: 732e 4665 6174 7572 6556 6563 746f 722c  s.FeatureVector,
-00013860: 2046 6561 7475 7265 5665 6374 6f72 5d2c   FeatureVector],
-00013870: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-00013880: 3d22 222c 0a20 2020 2020 2020 2076 6572  ="",.        ver
-00013890: 7369 6f6e 6564 3d54 7275 652c 0a20 2020  sioned=True,.   
-000138a0: 2029 202d 3e20 6469 6374 3a0a 2020 2020   ) -> dict:.    
-000138b0: 2020 2020 2222 2243 7265 6174 6520 6120      """Create a 
-000138c0: 6e65 7720 3a70 793a 636c 6173 733a 607e  new :py:class:`~
-000138d0: 6d6c 7275 6e2e 6665 6174 7572 655f 7374  mlrun.feature_st
-000138e0: 6f72 652e 4665 6174 7572 6556 6563 746f  ore.FeatureVecto
-000138f0: 7260 2061 6e64 2073 6176 6520 696e 2074  r` and save in t
-00013900: 6865 203a 7079 3a6d 6f64 3a60 6d6c 7275  he :py:mod:`mlru
-00013910: 6e60 2044 422e 0a0a 2020 2020 2020 2020  n` DB...        
-00013920: 3a70 6172 616d 2066 6561 7475 7265 5f76  :param feature_v
-00013930: 6563 746f 723a 2054 6865 206e 6577 203a  ector: The new :
-00013940: 7079 3a63 6c61 7373 3a60 7e6d 6c72 756e  py:class:`~mlrun
-00013950: 2e66 6561 7475 7265 5f73 746f 7265 2e46  .feature_store.F
-00013960: 6561 7475 7265 5665 6374 6f72 6020 746f  eatureVector` to
-00013970: 2063 7265 6174 652e 0a20 2020 2020 2020   create..       
-00013980: 203a 7061 7261 6d20 7072 6f6a 6563 743a   :param project:
-00013990: 204e 616d 6520 6f66 2070 726f 6a65 6374   Name of project
-000139a0: 2074 6869 7320 6665 6174 7572 652d 7665   this feature-ve
-000139b0: 6374 6f72 2062 656c 6f6e 6773 2074 6f2e  ctor belongs to.
-000139c0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-000139d0: 7665 7273 696f 6e65 643a 2057 6865 7468  versioned: Wheth
-000139e0: 6572 2074 6f20 6d61 696e 7461 696e 2076  er to maintain v
-000139f0: 6572 7369 6f6e 7320 666f 7220 7468 6973  ersions for this
-00013a00: 2066 6561 7475 7265 2d76 6563 746f 722e   feature-vector.
-00013a10: 2041 6c6c 2076 6572 7369 6f6e 7320 6f66   All versions of
-00013a20: 2061 2076 6572 7369 6f6e 6564 206f 626a   a versioned obj
-00013a30: 6563 740a 2020 2020 2020 2020 2020 2020  ect.            
-00013a40: 7769 6c6c 2062 6520 6b65 7074 2069 6e20  will be kept in 
-00013a50: 7468 6520 4442 2061 6e64 2063 616e 2062  the DB and can b
-00013a60: 6520 7265 7472 6965 7665 6420 756e 7469  e retrieved unti
-00013a70: 6c20 6578 706c 6963 6974 6c79 2064 656c  l explicitly del
-00013a80: 6574 6564 2e0a 2020 2020 2020 2020 3a72  eted..        :r
-00013a90: 6574 7572 6e73 3a20 5468 6520 3a70 793a  eturns: The :py:
-00013aa0: 636c 6173 733a 607e 6d6c 7275 6e2e 6665  class:`~mlrun.fe
-00013ab0: 6174 7572 655f 7374 6f72 652e 4665 6174  ature_store.Feat
-00013ac0: 7572 6556 6563 746f 7260 206f 626a 6563  ureVector` objec
-00013ad0: 7420 2861 7320 6469 6374 292e 0a20 2020  t (as dict)..   
-00013ae0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-00013af0: 2069 6620 6973 696e 7374 616e 6365 2866   if isinstance(f
-00013b00: 6561 7475 7265 5f76 6563 746f 722c 2073  eature_vector, s
-00013b10: 6368 656d 6173 2e46 6561 7475 7265 5665  chemas.FeatureVe
-00013b20: 6374 6f72 293a 0a20 2020 2020 2020 2020  ctor):.         
-00013b30: 2020 2066 6561 7475 7265 5f76 6563 746f     feature_vecto
-00013b40: 7220 3d20 6665 6174 7572 655f 7665 6374  r = feature_vect
-00013b50: 6f72 2e64 6963 7428 290a 2020 2020 2020  or.dict().      
-00013b60: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
-00013b70: 6528 6665 6174 7572 655f 7665 6374 6f72  e(feature_vector
-00013b80: 2c20 4665 6174 7572 6556 6563 746f 7229  , FeatureVector)
-00013b90: 3a0a 2020 2020 2020 2020 2020 2020 6665  :.            fe
-00013ba0: 6174 7572 655f 7665 6374 6f72 203d 2066  ature_vector = f
-00013bb0: 6561 7475 7265 5f76 6563 746f 722e 746f  eature_vector.to
-00013bc0: 5f64 6963 7428 290a 0a20 2020 2020 2020  _dict()..       
-00013bd0: 2070 726f 6a65 6374 203d 2028 0a20 2020   project = (.   
-00013be0: 2020 2020 2020 2020 2070 726f 6a65 6374           project
-00013bf0: 0a20 2020 2020 2020 2020 2020 206f 7220  .            or 
-00013c00: 6665 6174 7572 655f 7665 6374 6f72 5b22  feature_vector["
-00013c10: 6d65 7461 6461 7461 225d 2e67 6574 2822  metadata"].get("
-00013c20: 7072 6f6a 6563 7422 2c20 4e6f 6e65 290a  project", None).
-00013c30: 2020 2020 2020 2020 2020 2020 6f72 2063              or c
-00013c40: 6f6e 6669 672e 6465 6661 756c 745f 7072  onfig.default_pr
-00013c50: 6f6a 6563 740a 2020 2020 2020 2020 290a  oject.        ).
-00013c60: 2020 2020 2020 2020 7061 7468 203d 2066          path = f
-00013c70: 2270 726f 6a65 6374 732f 7b70 726f 6a65  "projects/{proje
-00013c80: 6374 7d2f 6665 6174 7572 652d 7665 6374  ct}/feature-vect
-00013c90: 6f72 7322 0a20 2020 2020 2020 2070 6172  ors".        par
-00013ca0: 616d 7320 3d20 7b22 7665 7273 696f 6e65  ams = {"versione
-00013cb0: 6422 3a20 7665 7273 696f 6e65 647d 0a0a  d": versioned}..
-00013cc0: 2020 2020 2020 2020 6e61 6d65 203d 2066          name = f
-00013cd0: 6561 7475 7265 5f76 6563 746f 725b 226d  eature_vector["m
-00013ce0: 6574 6164 6174 6122 5d5b 226e 616d 6522  etadata"]["name"
-00013cf0: 5d0a 2020 2020 2020 2020 6572 726f 725f  ].        error_
-00013d00: 6d65 7373 6167 6520 3d20 6622 4661 696c  message = f"Fail
-00013d10: 6564 2063 7265 6174 696e 6720 6665 6174  ed creating feat
-00013d20: 7572 652d 7665 6374 6f72 207b 7072 6f6a  ure-vector {proj
-00013d30: 6563 747d 2f7b 6e61 6d65 7d22 0a20 2020  ect}/{name}".   
-00013d40: 2020 2020 2072 6573 7020 3d20 7365 6c66       resp = self
-00013d50: 2e61 7069 5f63 616c 6c28 0a20 2020 2020  .api_call(.     
-00013d60: 2020 2020 2020 2022 504f 5354 222c 0a20         "POST",. 
-00013d70: 2020 2020 2020 2020 2020 2070 6174 682c             path,
-00013d80: 0a20 2020 2020 2020 2020 2020 2065 7272  .            err
-00013d90: 6f72 5f6d 6573 7361 6765 2c0a 2020 2020  or_message,.    
-00013da0: 2020 2020 2020 2020 7061 7261 6d73 3d70          params=p
-00013db0: 6172 616d 732c 0a20 2020 2020 2020 2020  arams,.         
-00013dc0: 2020 2062 6f64 793d 6469 6374 5f74 6f5f     body=dict_to_
-00013dd0: 6a73 6f6e 2866 6561 7475 7265 5f76 6563  json(feature_vec
-00013de0: 746f 7229 2c0a 2020 2020 2020 2020 290a  tor),.        ).
-00013df0: 2020 2020 2020 2020 7265 7475 726e 2072          return r
-00013e00: 6573 702e 6a73 6f6e 2829 0a0a 2020 2020  esp.json()..    
-00013e10: 6465 6620 6765 745f 6665 6174 7572 655f  def get_feature_
-00013e20: 7665 6374 6f72 280a 2020 2020 2020 2020  vector(.        
-00013e30: 7365 6c66 2c20 6e61 6d65 3a20 7374 722c  self, name: str,
-00013e40: 2070 726f 6a65 6374 3a20 7374 7220 3d20   project: str = 
-00013e50: 2222 2c20 7461 673a 2073 7472 203d 204e  "", tag: str = N
-00013e60: 6f6e 652c 2075 6964 3a20 7374 7220 3d20  one, uid: str = 
-00013e70: 4e6f 6e65 0a20 2020 2029 202d 3e20 4665  None.    ) -> Fe
-00013e80: 6174 7572 6556 6563 746f 723a 0a20 2020  atureVector:.   
-00013e90: 2020 2020 2022 2222 5265 7475 726e 2061       """Return a
-00013ea0: 2073 7065 6369 6669 6320 6665 6174 7572   specific featur
-00013eb0: 652d 7665 6374 6f72 2072 6566 6572 656e  e-vector referen
-00013ec0: 6365 6420 6279 2069 7473 2074 6167 206f  ced by its tag o
-00013ed0: 7220 7569 642e 2049 6620 6e6f 6e65 2061  r uid. If none a
-00013ee0: 7265 2070 726f 7669 6465 642c 2060 606c  re provided, ``l
-00013ef0: 6174 6573 7460 6020 7461 6720 7769 6c6c  atest`` tag will
-00013f00: 0a20 2020 2020 2020 2062 6520 7573 6564  .        be used
-00013f10: 2e22 2222 0a0a 2020 2020 2020 2020 7072  ."""..        pr
-00013f20: 6f6a 6563 7420 3d20 7072 6f6a 6563 7420  oject = project 
-00013f30: 6f72 2063 6f6e 6669 672e 6465 6661 756c  or config.defaul
-00013f40: 745f 7072 6f6a 6563 740a 2020 2020 2020  t_project.      
-00013f50: 2020 7265 6665 7265 6e63 6520 3d20 7365    reference = se
-00013f60: 6c66 2e5f 7265 736f 6c76 655f 7265 6665  lf._resolve_refe
-00013f70: 7265 6e63 6528 7461 672c 2075 6964 290a  rence(tag, uid).
-00013f80: 2020 2020 2020 2020 7061 7468 203d 2066          path = f
-00013f90: 2270 726f 6a65 6374 732f 7b70 726f 6a65  "projects/{proje
-00013fa0: 6374 7d2f 6665 6174 7572 652d 7665 6374  ct}/feature-vect
-00013fb0: 6f72 732f 7b6e 616d 657d 2f72 6566 6572  ors/{name}/refer
-00013fc0: 656e 6365 732f 7b72 6566 6572 656e 6365  ences/{reference
-00013fd0: 7d22 0a20 2020 2020 2020 2065 7272 6f72  }".        error
-00013fe0: 5f6d 6573 7361 6765 203d 2066 2246 6169  _message = f"Fai
-00013ff0: 6c65 6420 7265 7472 6965 7669 6e67 2066  led retrieving f
-00014000: 6561 7475 7265 2d76 6563 746f 7220 7b70  eature-vector {p
-00014010: 726f 6a65 6374 7d2f 7b6e 616d 657d 220a  roject}/{name}".
-00014020: 2020 2020 2020 2020 7265 7370 203d 2073          resp = s
-00014030: 656c 662e 6170 695f 6361 6c6c 2822 4745  elf.api_call("GE
-00014040: 5422 2c20 7061 7468 2c20 6572 726f 725f  T", path, error_
-00014050: 6d65 7373 6167 6529 0a20 2020 2020 2020  message).       
-00014060: 2072 6574 7572 6e20 4665 6174 7572 6556   return FeatureV
-00014070: 6563 746f 722e 6672 6f6d 5f64 6963 7428  ector.from_dict(
-00014080: 7265 7370 2e6a 736f 6e28 2929 0a0a 2020  resp.json())..  
-00014090: 2020 6465 6620 6c69 7374 5f66 6561 7475    def list_featu
-000140a0: 7265 5f76 6563 746f 7273 280a 2020 2020  re_vectors(.    
-000140b0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
-000140c0: 2020 7072 6f6a 6563 743a 2073 7472 203d    project: str =
-000140d0: 2022 222c 0a20 2020 2020 2020 206e 616d   "",.        nam
-000140e0: 653a 2073 7472 203d 204e 6f6e 652c 0a20  e: str = None,. 
-000140f0: 2020 2020 2020 2074 6167 3a20 7374 7220         tag: str 
-00014100: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
-00014110: 7374 6174 653a 2073 7472 203d 204e 6f6e  state: str = Non
-00014120: 652c 0a20 2020 2020 2020 206c 6162 656c  e,.        label
-00014130: 733a 204c 6973 745b 7374 725d 203d 204e  s: List[str] = N
-00014140: 6f6e 652c 0a20 2020 2020 2020 2070 6172  one,.        par
-00014150: 7469 7469 6f6e 5f62 793a 2055 6e69 6f6e  tition_by: Union
-00014160: 5b73 6368 656d 6173 2e46 6561 7475 7265  [schemas.Feature
-00014170: 5374 6f72 6550 6172 7469 7469 6f6e 4279  StorePartitionBy
-00014180: 4669 656c 642c 2073 7472 5d20 3d20 4e6f  Field, str] = No
-00014190: 6e65 2c0a 2020 2020 2020 2020 726f 7773  ne,.        rows
-000141a0: 5f70 6572 5f70 6172 7469 7469 6f6e 3a20  _per_partition: 
-000141b0: 696e 7420 3d20 312c 0a20 2020 2020 2020  int = 1,.       
-000141c0: 2070 6172 7469 7469 6f6e 5f73 6f72 745f   partition_sort_
-000141d0: 6279 3a20 556e 696f 6e5b 7363 6865 6d61  by: Union[schema
-000141e0: 732e 536f 7274 4669 656c 642c 2073 7472  s.SortField, str
-000141f0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
-00014200: 2020 7061 7274 6974 696f 6e5f 6f72 6465    partition_orde
-00014210: 723a 2055 6e69 6f6e 5b73 6368 656d 6173  r: Union[schemas
-00014220: 2e4f 7264 6572 5479 7065 2c20 7374 725d  .OrderType, str]
-00014230: 203d 2073 6368 656d 6173 2e4f 7264 6572   = schemas.Order
-00014240: 5479 7065 2e64 6573 632c 0a20 2020 2029  Type.desc,.    )
-00014250: 202d 3e20 4c69 7374 5b46 6561 7475 7265   -> List[Feature
-00014260: 5665 6374 6f72 5d3a 0a20 2020 2020 2020  Vector]:.       
-00014270: 2022 2222 5265 7472 6965 7665 2061 206c   """Retrieve a l
-00014280: 6973 7420 6f66 2066 6561 7475 7265 2d76  ist of feature-v
-00014290: 6563 746f 7273 206d 6174 6368 696e 6720  ectors matching 
-000142a0: 7468 6520 6372 6974 6572 6961 2070 726f  the criteria pro
-000142b0: 7669 6465 642e 0a0a 2020 2020 2020 2020  vided...        
-000142c0: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
-000142d0: 5072 6f6a 6563 7420 6e61 6d65 2e0a 2020  Project name..  
-000142e0: 2020 2020 2020 3a70 6172 616d 206e 616d        :param nam
-000142f0: 653a 204e 616d 6520 6f66 2066 6561 7475  e: Name of featu
-00014300: 7265 2d76 6563 746f 7220 746f 206d 6174  re-vector to mat
-00014310: 6368 2e20 5468 6973 2069 7320 6120 6c69  ch. This is a li
-00014320: 6b65 2071 7565 7279 2c20 616e 6420 6973  ke query, and is
-00014330: 2063 6173 652d 696e 7365 6e73 6974 6976   case-insensitiv
-00014340: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
-00014350: 6d20 7461 673a 204d 6174 6368 2066 6561  m tag: Match fea
-00014360: 7475 7265 2d76 6563 746f 7273 2077 6974  ture-vectors wit
-00014370: 6820 7370 6563 6966 6963 2074 6167 2e0a  h specific tag..
-00014380: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
-00014390: 7461 7465 3a20 4d61 7463 6820 6665 6174  tate: Match feat
-000143a0: 7572 652d 7665 6374 6f72 7320 7769 7468  ure-vectors with
-000143b0: 2061 2073 7065 6369 6669 6320 7374 6174   a specific stat
-000143c0: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
-000143d0: 6d20 6c61 6265 6c73 3a20 4d61 7463 6820  m labels: Match 
-000143e0: 6665 6174 7572 652d 7665 6374 6f72 7320  feature-vectors 
-000143f0: 7768 6963 6820 6861 7665 2074 6865 7365  which have these
-00014400: 206c 6162 656c 732e 0a20 2020 2020 2020   labels..       
-00014410: 203a 7061 7261 6d20 7061 7274 6974 696f   :param partitio
-00014420: 6e5f 6279 3a20 4669 656c 6420 746f 2067  n_by: Field to g
-00014430: 726f 7570 2072 6573 756c 7473 2062 792e  roup results by.
-00014440: 204f 6e6c 7920 616c 6c6f 7765 6420 7661   Only allowed va
-00014450: 6c75 6520 6973 2060 6e61 6d65 602e 2057  lue is `name`. W
-00014460: 6865 6e20 6070 6172 7469 7469 6f6e 5f62  hen `partition_b
-00014470: 7960 2069 7320 7370 6563 6966 6965 642c  y` is specified,
-00014480: 0a20 2020 2020 2020 2020 2020 2074 6865  .            the
-00014490: 2060 7061 7274 6974 696f 6e5f 736f 7274   `partition_sort
-000144a0: 5f62 7960 2070 6172 616d 6574 6572 206d  _by` parameter m
-000144b0: 7573 7420 6265 2070 726f 7669 6465 6420  ust be provided 
-000144c0: 6173 2077 656c 6c2e 0a20 2020 2020 2020  as well..       
-000144d0: 203a 7061 7261 6d20 726f 7773 5f70 6572   :param rows_per
-000144e0: 5f70 6172 7469 7469 6f6e 3a20 486f 7720  _partition: How 
-000144f0: 6d61 6e79 2074 6f70 2072 6f77 7320 2870  many top rows (p
-00014500: 6572 2073 6f72 7469 6e67 2064 6566 696e  er sorting defin
-00014510: 6564 2062 7920 6070 6172 7469 7469 6f6e  ed by `partition
-00014520: 5f73 6f72 745f 6279 6020 616e 6420 6070  _sort_by` and `p
-00014530: 6172 7469 7469 6f6e 5f6f 7264 6572 6029  artition_order`)
-00014540: 0a20 2020 2020 2020 2020 2020 2074 6f20  .            to 
-00014550: 7265 7475 726e 2070 6572 2067 726f 7570  return per group
-00014560: 2e20 4465 6661 756c 7420 7661 6c75 6520  . Default value 
-00014570: 6973 2031 2e0a 2020 2020 2020 2020 3a70  is 1..        :p
-00014580: 6172 616d 2070 6172 7469 7469 6f6e 5f73  aram partition_s
-00014590: 6f72 745f 6279 3a20 5768 6174 2066 6965  ort_by: What fie
-000145a0: 6c64 2074 6f20 736f 7274 2074 6865 2072  ld to sort the r
-000145b0: 6573 756c 7473 2062 792c 2077 6974 6869  esults by, withi
-000145c0: 6e20 6561 6368 2070 6172 7469 7469 6f6e  n each partition
-000145d0: 2064 6566 696e 6564 2062 7920 6070 6172   defined by `par
-000145e0: 7469 7469 6f6e 5f62 7960 2e0a 2020 2020  tition_by`..    
-000145f0: 2020 2020 2020 2020 4375 7272 656e 746c          Currentl
-00014600: 7920 7468 6520 6f6e 6c79 2061 6c6c 6f77  y the only allow
-00014610: 6564 2076 616c 7565 7320 6172 6520 6063  ed values are `c
-00014620: 7265 6174 6564 6020 616e 6420 6075 7064  reated` and `upd
-00014630: 6174 6564 602e 0a20 2020 2020 2020 203a  ated`..        :
-00014640: 7061 7261 6d20 7061 7274 6974 696f 6e5f  param partition_
-00014650: 6f72 6465 723a 204f 7264 6572 206f 6620  order: Order of 
-00014660: 736f 7274 696e 6720 7769 7468 696e 2070  sorting within p
-00014670: 6172 7469 7469 6f6e 7320 2d20 6061 7363  artitions - `asc
-00014680: 6020 6f72 2060 6465 7363 602e 2044 6566  ` or `desc`. Def
-00014690: 6175 6c74 2069 7320 6064 6573 6360 2e0a  ault is `desc`..
-000146a0: 2020 2020 2020 2020 3a72 6574 7572 6e73          :returns
-000146b0: 3a20 4c69 7374 206f 6620 6d61 7463 6869  : List of matchi
-000146c0: 6e67 203a 7079 3a63 6c61 7373 3a60 7e6d  ng :py:class:`~m
-000146d0: 6c72 756e 2e66 6561 7475 7265 5f73 746f  lrun.feature_sto
-000146e0: 7265 2e46 6561 7475 7265 5665 6374 6f72  re.FeatureVector
-000146f0: 6020 6f62 6a65 6374 732e 0a20 2020 2020  ` objects..     
-00014700: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
-00014710: 7072 6f6a 6563 7420 3d20 7072 6f6a 6563  project = projec
-00014720: 7420 6f72 2063 6f6e 6669 672e 6465 6661  t or config.defa
-00014730: 756c 745f 7072 6f6a 6563 740a 0a20 2020  ult_project..   
-00014740: 2020 2020 2070 6172 616d 7320 3d20 7b0a       params = {.
-00014750: 2020 2020 2020 2020 2020 2020 226e 616d              "nam
-00014760: 6522 3a20 6e61 6d65 2c0a 2020 2020 2020  e": name,.      
-00014770: 2020 2020 2020 2273 7461 7465 223a 2073        "state": s
-00014780: 7461 7465 2c0a 2020 2020 2020 2020 2020  tate,.          
-00014790: 2020 2274 6167 223a 2074 6167 2c0a 2020    "tag": tag,.  
-000147a0: 2020 2020 2020 2020 2020 226c 6162 656c            "label
-000147b0: 223a 206c 6162 656c 7320 6f72 205b 5d2c  ": labels or [],
-000147c0: 0a20 2020 2020 2020 207d 0a20 2020 2020  .        }.     
-000147d0: 2020 2069 6620 7061 7274 6974 696f 6e5f     if partition_
-000147e0: 6279 3a0a 2020 2020 2020 2020 2020 2020  by:.            
-000147f0: 7061 7261 6d73 2e75 7064 6174 6528 0a20  params.update(. 
-00014800: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00014810: 656c 662e 5f67 656e 6572 6174 655f 7061  elf._generate_pa
-00014820: 7274 6974 696f 6e5f 6279 5f70 6172 616d  rtition_by_param
-00014830: 7328 0a20 2020 2020 2020 2020 2020 2020  s(.             
-00014840: 2020 2020 2020 2073 6368 656d 6173 2e46         schemas.F
-00014850: 6561 7475 7265 5374 6f72 6550 6172 7469  eatureStoreParti
-00014860: 7469 6f6e 4279 4669 656c 642c 0a20 2020  tionByField,.   
-00014870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014880: 2070 6172 7469 7469 6f6e 5f62 792c 0a20   partition_by,. 
-00014890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000148a0: 2020 2072 6f77 735f 7065 725f 7061 7274     rows_per_part
-000148b0: 6974 696f 6e2c 0a20 2020 2020 2020 2020  ition,.         
-000148c0: 2020 2020 2020 2020 2020 2070 6172 7469             parti
-000148d0: 7469 6f6e 5f73 6f72 745f 6279 2c0a 2020  tion_sort_by,.  
-000148e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000148f0: 2020 7061 7274 6974 696f 6e5f 6f72 6465    partition_orde
-00014900: 722c 0a20 2020 2020 2020 2020 2020 2020  r,.             
-00014910: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
-00014920: 2029 0a0a 2020 2020 2020 2020 7061 7468   )..        path
-00014930: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
-00014940: 726f 6a65 6374 7d2f 6665 6174 7572 652d  roject}/feature-
-00014950: 7665 6374 6f72 7322 0a0a 2020 2020 2020  vectors"..      
-00014960: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
-00014970: 3d20 280a 2020 2020 2020 2020 2020 2020  = (.            
-00014980: 6622 4661 696c 6564 206c 6973 7469 6e67  f"Failed listing
-00014990: 2066 6561 7475 7265 2d76 6563 746f 7273   feature-vectors
-000149a0: 2c20 7072 6f6a 6563 743a 207b 7072 6f6a  , project: {proj
-000149b0: 6563 747d 2c20 7175 6572 793a 207b 7061  ect}, query: {pa
-000149c0: 7261 6d73 7d22 0a20 2020 2020 2020 2029  rams}".        )
-000149d0: 0a20 2020 2020 2020 2072 6573 7020 3d20  .        resp = 
-000149e0: 7365 6c66 2e61 7069 5f63 616c 6c28 2247  self.api_call("G
-000149f0: 4554 222c 2070 6174 682c 2065 7272 6f72  ET", path, error
-00014a00: 5f6d 6573 7361 6765 2c20 7061 7261 6d73  _message, params
-00014a10: 3d70 6172 616d 7329 0a20 2020 2020 2020  =params).       
-00014a20: 2066 6561 7475 7265 5f76 6563 746f 7273   feature_vectors
-00014a30: 203d 2072 6573 702e 6a73 6f6e 2829 5b22   = resp.json()["
-00014a40: 6665 6174 7572 655f 7665 6374 6f72 7322  feature_vectors"
-00014a50: 5d0a 2020 2020 2020 2020 6966 2066 6561  ].        if fea
-00014a60: 7475 7265 5f76 6563 746f 7273 3a0a 2020  ture_vectors:.  
-00014a70: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00014a80: 205b 4665 6174 7572 6556 6563 746f 722e   [FeatureVector.
-00014a90: 6672 6f6d 5f64 6963 7428 6f62 6a29 2066  from_dict(obj) f
-00014aa0: 6f72 206f 626a 2069 6e20 6665 6174 7572  or obj in featur
-00014ab0: 655f 7665 6374 6f72 735d 0a0a 2020 2020  e_vectors]..    
-00014ac0: 6465 6620 7374 6f72 655f 6665 6174 7572  def store_featur
-00014ad0: 655f 7665 6374 6f72 280a 2020 2020 2020  e_vector(.      
-00014ae0: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
-00014af0: 6665 6174 7572 655f 7665 6374 6f72 3a20  feature_vector: 
-00014b00: 556e 696f 6e5b 6469 6374 2c20 7363 6865  Union[dict, sche
-00014b10: 6d61 732e 4665 6174 7572 6556 6563 746f  mas.FeatureVecto
-00014b20: 722c 2046 6561 7475 7265 5665 6374 6f72  r, FeatureVector
-00014b30: 5d2c 0a20 2020 2020 2020 206e 616d 653d  ],.        name=
-00014b40: 4e6f 6e65 2c0a 2020 2020 2020 2020 7072  None,.        pr
-00014b50: 6f6a 6563 743d 2222 2c0a 2020 2020 2020  oject="",.      
-00014b60: 2020 7461 673d 4e6f 6e65 2c0a 2020 2020    tag=None,.    
-00014b70: 2020 2020 7569 643d 4e6f 6e65 2c0a 2020      uid=None,.  
-00014b80: 2020 2020 2020 7665 7273 696f 6e65 643d        versioned=
-00014b90: 5472 7565 2c0a 2020 2020 2920 2d3e 2064  True,.    ) -> d
-00014ba0: 6963 743a 0a20 2020 2020 2020 2022 2222  ict:.        """
-00014bb0: 5374 6f72 6520 6120 3a70 793a 636c 6173  Store a :py:clas
-00014bc0: 733a 607e 6d6c 7275 6e2e 6665 6174 7572  s:`~mlrun.featur
-00014bd0: 655f 7374 6f72 652e 4665 6174 7572 6556  e_store.FeatureV
-00014be0: 6563 746f 7260 206f 626a 6563 7420 696e  ector` object in
-00014bf0: 2074 6865 203a 7079 3a6d 6f64 3a60 6d6c   the :py:mod:`ml
-00014c00: 7275 6e60 2044 422e 2054 6865 0a20 2020  run` DB. The.   
-00014c10: 2020 2020 2066 6561 7475 7265 2d76 6563       feature-vec
-00014c20: 746f 7220 6361 6e20 6265 2065 6974 6865  tor can be eithe
-00014c30: 7220 6120 6e65 7720 6f62 6a65 6374 206f  r a new object o
-00014c40: 7220 6120 6d6f 6469 6669 6361 7469 6f6e  r a modification
-00014c50: 2074 6f20 6578 6973 7469 6e67 206f 626a   to existing obj
-00014c60: 6563 7420 7265 6665 7265 6e63 6564 2062  ect referenced b
-00014c70: 7920 7468 6520 7061 7261 6d73 0a20 2020  y the params.   
-00014c80: 2020 2020 206f 6620 7468 6520 6675 6e63       of the func
-00014c90: 7469 6f6e 2e0a 0a20 2020 2020 2020 203a  tion...        :
-00014ca0: 7061 7261 6d20 6665 6174 7572 655f 7665  param feature_ve
-00014cb0: 6374 6f72 3a20 5468 6520 3a70 793a 636c  ctor: The :py:cl
-00014cc0: 6173 733a 607e 6d6c 7275 6e2e 6665 6174  ass:`~mlrun.feat
-00014cd0: 7572 655f 7374 6f72 652e 4665 6174 7572  ure_store.Featur
-00014ce0: 6556 6563 746f 7260 2074 6f20 7374 6f72  eVector` to stor
-00014cf0: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
-00014d00: 6d20 6e61 6d65 3a20 2020 204e 616d 6520  m name:    Name 
-00014d10: 6f66 2066 6561 7475 7265 2076 6563 746f  of feature vecto
-00014d20: 722e 0a20 2020 2020 2020 203a 7061 7261  r..        :para
-00014d30: 6d20 7072 6f6a 6563 743a 204e 616d 6520  m project: Name 
-00014d40: 6f66 2070 726f 6a65 6374 2074 6869 7320  of project this 
-00014d50: 6665 6174 7572 652d 7665 6374 6f72 2062  feature-vector b
-00014d60: 656c 6f6e 6773 2074 6f2e 0a20 2020 2020  elongs to..     
-00014d70: 2020 203a 7061 7261 6d20 7461 673a 2054     :param tag: T
-00014d80: 6865 2060 6074 6167 6060 206f 6620 7468  he ``tag`` of th
-00014d90: 6520 6f62 6a65 6374 2074 6f20 7265 706c  e object to repl
-00014da0: 6163 6520 696e 2074 6865 2044 422c 2066  ace in the DB, f
-00014db0: 6f72 2065 7861 6d70 6c65 2060 606c 6174  or example ``lat
-00014dc0: 6573 7460 602e 0a20 2020 2020 2020 203a  est``..        :
-00014dd0: 7061 7261 6d20 7569 643a 2054 6865 2060  param uid: The `
-00014de0: 6075 6964 6060 206f 6620 7468 6520 6f62  `uid`` of the ob
-00014df0: 6a65 6374 2074 6f20 7265 706c 6163 6520  ject to replace 
-00014e00: 696e 2074 6865 2044 422e 2049 6620 7573  in the DB. If us
-00014e10: 696e 6720 7468 6973 2070 6172 616d 6574  ing this paramet
-00014e20: 6572 2c20 7468 6520 6d6f 6469 6669 6564  er, the modified
-00014e30: 206f 626a 6563 740a 2020 2020 2020 2020   object.        
-00014e40: 2020 2020 6d75 7374 2068 6176 6520 7468      must have th
-00014e50: 6520 7361 6d65 2060 6075 6964 6060 206f  e same ``uid`` o
-00014e60: 6620 7468 6520 7072 6576 696f 7573 6c79  f the previously
-00014e70: 2d65 7869 7374 696e 6720 6f62 6a65 6374  -existing object
-00014e80: 2e20 5468 6973 2063 616e 6e6f 7420 6265  . This cannot be
-00014e90: 2075 7365 6420 666f 7220 6e6f 6e2d 7665   used for non-ve
-00014ea0: 7273 696f 6e65 6420 6f62 6a65 6374 732e  rsioned objects.
-00014eb0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00014ec0: 7665 7273 696f 6e65 643a 2057 6865 7468  versioned: Wheth
-00014ed0: 6572 2074 6f20 6d61 696e 7461 696e 2076  er to maintain v
-00014ee0: 6572 7369 6f6e 7320 666f 7220 7468 6973  ersions for this
-00014ef0: 2066 6561 7475 7265 2d76 6563 746f 722e   feature-vector.
-00014f00: 2041 6c6c 2076 6572 7369 6f6e 7320 6f66   All versions of
-00014f10: 2061 2076 6572 7369 6f6e 6564 206f 626a   a versioned obj
-00014f20: 6563 740a 2020 2020 2020 2020 2020 2020  ect.            
-00014f30: 7769 6c6c 2062 6520 6b65 7074 2069 6e20  will be kept in 
-00014f40: 7468 6520 4442 2061 6e64 2063 616e 2062  the DB and can b
-00014f50: 6520 7265 7472 6965 7665 6420 756e 7469  e retrieved unti
-00014f60: 6c20 6578 706c 6963 6974 6c79 2064 656c  l explicitly del
-00014f70: 6574 6564 2e0a 2020 2020 2020 2020 3a72  eted..        :r
-00014f80: 6574 7572 6e73 3a20 5468 6520 3a70 793a  eturns: The :py:
-00014f90: 636c 6173 733a 607e 6d6c 7275 6e2e 6665  class:`~mlrun.fe
-00014fa0: 6174 7572 655f 7374 6f72 652e 4665 6174  ature_store.Feat
-00014fb0: 7572 6556 6563 746f 7260 206f 626a 6563  ureVector` objec
-00014fc0: 7420 2861 7320 6469 6374 292e 0a20 2020  t (as dict)..   
-00014fd0: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
-00014fe0: 2020 7265 6665 7265 6e63 6520 3d20 7365    reference = se
-00014ff0: 6c66 2e5f 7265 736f 6c76 655f 7265 6665  lf._resolve_refe
-00015000: 7265 6e63 6528 7461 672c 2075 6964 290a  rence(tag, uid).
-00015010: 2020 2020 2020 2020 7061 7261 6d73 203d          params =
-00015020: 207b 2276 6572 7369 6f6e 6564 223a 2076   {"versioned": v
-00015030: 6572 7369 6f6e 6564 7d0a 0a20 2020 2020  ersioned}..     
-00015040: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-00015050: 2866 6561 7475 7265 5f76 6563 746f 722c  (feature_vector,
-00015060: 2073 6368 656d 6173 2e46 6561 7475 7265   schemas.Feature
-00015070: 5665 6374 6f72 293a 0a20 2020 2020 2020  Vector):.       
-00015080: 2020 2020 2066 6561 7475 7265 5f76 6563       feature_vec
-00015090: 746f 7220 3d20 6665 6174 7572 655f 7665  tor = feature_ve
-000150a0: 6374 6f72 2e64 6963 7428 290a 2020 2020  ctor.dict().    
-000150b0: 2020 2020 656c 6966 2069 7369 6e73 7461      elif isinsta
-000150c0: 6e63 6528 6665 6174 7572 655f 7665 6374  nce(feature_vect
-000150d0: 6f72 2c20 4665 6174 7572 6556 6563 746f  or, FeatureVecto
-000150e0: 7229 3a0a 2020 2020 2020 2020 2020 2020  r):.            
-000150f0: 6665 6174 7572 655f 7665 6374 6f72 203d  feature_vector =
-00015100: 2066 6561 7475 7265 5f76 6563 746f 722e   feature_vector.
-00015110: 746f 5f64 6963 7428 290a 0a20 2020 2020  to_dict()..     
-00015120: 2020 206e 616d 6520 3d20 6e61 6d65 206f     name = name o
-00015130: 7220 6665 6174 7572 655f 7665 6374 6f72  r feature_vector
-00015140: 5b22 6d65 7461 6461 7461 225d 5b22 6e61  ["metadata"]["na
-00015150: 6d65 225d 0a20 2020 2020 2020 2070 726f  me"].        pro
-00015160: 6a65 6374 203d 2028 0a20 2020 2020 2020  ject = (.       
-00015170: 2020 2020 2070 726f 6a65 6374 0a20 2020       project.   
-00015180: 2020 2020 2020 2020 206f 7220 6665 6174           or feat
-00015190: 7572 655f 7665 6374 6f72 5b22 6d65 7461  ure_vector["meta
-000151a0: 6461 7461 225d 2e67 6574 2822 7072 6f6a  data"].get("proj
-000151b0: 6563 7422 290a 2020 2020 2020 2020 2020  ect").          
-000151c0: 2020 6f72 2063 6f6e 6669 672e 6465 6661    or config.defa
-000151d0: 756c 745f 7072 6f6a 6563 740a 2020 2020  ult_project.    
-000151e0: 2020 2020 290a 2020 2020 2020 2020 7061      ).        pa
-000151f0: 7468 203d 2066 2270 726f 6a65 6374 732f  th = f"projects/
-00015200: 7b70 726f 6a65 6374 7d2f 6665 6174 7572  {project}/featur
-00015210: 652d 7665 6374 6f72 732f 7b6e 616d 657d  e-vectors/{name}
-00015220: 2f72 6566 6572 656e 6365 732f 7b72 6566  /references/{ref
-00015230: 6572 656e 6365 7d22 0a20 2020 2020 2020  erence}".       
-00015240: 2065 7272 6f72 5f6d 6573 7361 6765 203d   error_message =
-00015250: 2066 2246 6169 6c65 6420 7374 6f72 696e   f"Failed storin
-00015260: 6720 6665 6174 7572 652d 7665 6374 6f72  g feature-vector
-00015270: 207b 7072 6f6a 6563 747d 2f7b 6e61 6d65   {project}/{name
-00015280: 7d22 0a20 2020 2020 2020 2072 6573 7020  }".        resp 
-00015290: 3d20 7365 6c66 2e61 7069 5f63 616c 6c28  = self.api_call(
-000152a0: 0a20 2020 2020 2020 2020 2020 2022 5055  .            "PU
-000152b0: 5422 2c20 7061 7468 2c20 6572 726f 725f  T", path, error_
-000152c0: 6d65 7373 6167 652c 2070 6172 616d 733d  message, params=
-000152d0: 7061 7261 6d73 2c20 626f 6479 3d64 6963  params, body=dic
-000152e0: 745f 746f 5f6a 736f 6e28 6665 6174 7572  t_to_json(featur
-000152f0: 655f 7665 6374 6f72 290a 2020 2020 2020  e_vector).      
-00015300: 2020 290a 2020 2020 2020 2020 7265 7475    ).        retu
-00015310: 726e 2072 6573 702e 6a73 6f6e 2829 0a0a  rn resp.json()..
-00015320: 2020 2020 6465 6620 7061 7463 685f 6665      def patch_fe
-00015330: 6174 7572 655f 7665 6374 6f72 280a 2020  ature_vector(.  
-00015340: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
-00015350: 2020 2020 6e61 6d65 2c0a 2020 2020 2020      name,.      
-00015360: 2020 6665 6174 7572 655f 7665 6374 6f72    feature_vector
-00015370: 5f75 7064 6174 653a 2064 6963 742c 0a20  _update: dict,. 
-00015380: 2020 2020 2020 2070 726f 6a65 6374 3d22         project="
-00015390: 222c 0a20 2020 2020 2020 2074 6167 3d4e  ",.        tag=N
-000153a0: 6f6e 652c 0a20 2020 2020 2020 2075 6964  one,.        uid
-000153b0: 3d4e 6f6e 652c 0a20 2020 2020 2020 2070  =None,.        p
-000153c0: 6174 6368 5f6d 6f64 653a 2055 6e69 6f6e  atch_mode: Union
-000153d0: 5b73 7472 2c20 7363 6865 6d61 732e 5061  [str, schemas.Pa
-000153e0: 7463 684d 6f64 655d 203d 2073 6368 656d  tchMode] = schem
-000153f0: 6173 2e50 6174 6368 4d6f 6465 2e72 6570  as.PatchMode.rep
-00015400: 6c61 6365 2c0a 2020 2020 293a 0a20 2020  lace,.    ):.   
-00015410: 2020 2020 2022 2222 4d6f 6469 6679 2028       """Modify (
-00015420: 7061 7463 6829 2061 6e20 6578 6973 7469  patch) an existi
-00015430: 6e67 203a 7079 3a63 6c61 7373 3a60 7e6d  ng :py:class:`~m
-00015440: 6c72 756e 2e66 6561 7475 7265 5f73 746f  lrun.feature_sto
-00015450: 7265 2e46 6561 7475 7265 5665 6374 6f72  re.FeatureVector
-00015460: 6020 6f62 6a65 6374 2e0a 2020 2020 2020  ` object..      
-00015470: 2020 5468 6520 6f62 6a65 6374 2069 7320    The object is 
-00015480: 6964 656e 7469 6669 6564 2062 7920 6974  identified by it
-00015490: 7320 6e61 6d65 2028 616e 6420 7072 6f6a  s name (and proj
-000154a0: 6563 7420 6974 2062 656c 6f6e 6773 2074  ect it belongs t
-000154b0: 6f29 2c20 6173 2077 656c 6c20 6173 206f  o), as well as o
-000154c0: 7074 696f 6e61 6c6c 7920 6120 6060 7461  ptionally a ``ta
-000154d0: 6760 6020 6f72 2069 7473 0a20 2020 2020  g`` or its.     
-000154e0: 2020 2060 6075 6964 6060 2028 666f 7220     ``uid`` (for 
-000154f0: 7665 7273 696f 6e65 6420 6f62 6a65 6374  versioned object
-00015500: 292e 2049 6620 626f 7468 2060 6074 6167  ). If both ``tag
-00015510: 6060 2061 6e64 2060 6075 6964 6060 2061  `` and ``uid`` a
-00015520: 7265 206f 6d69 7474 6564 2074 6865 6e20  re omitted then 
-00015530: 7468 6520 6f62 6a65 6374 2077 6974 6820  the object with 
-00015540: 7461 6720 6060 6c61 7465 7374 6060 0a20  tag ``latest``. 
-00015550: 2020 2020 2020 2069 7320 6d6f 6469 6669         is modifi
-00015560: 6564 2e0a 0a20 2020 2020 2020 203a 7061  ed...        :pa
-00015570: 7261 6d20 6e61 6d65 3a20 4e61 6d65 206f  ram name: Name o
-00015580: 6620 7468 6520 6f62 6a65 6374 2074 6f20  f the object to 
-00015590: 7061 7463 682e 0a20 2020 2020 2020 203a  patch..        :
-000155a0: 7061 7261 6d20 6665 6174 7572 655f 7665  param feature_ve
-000155b0: 6374 6f72 5f75 7064 6174 653a 2054 6865  ctor_update: The
-000155c0: 206d 6f64 6966 6963 6174 696f 6e73 206e   modifications n
-000155d0: 6565 6465 6420 696e 2074 6865 206f 626a  eeded in the obj
-000155e0: 6563 742e 2054 6869 7320 7061 7261 6d65  ect. This parame
-000155f0: 7465 7220 6f6e 6c79 2068 6173 2074 6865  ter only has the
-00015600: 2063 6861 6e67 6573 2069 6e20 6974 2c0a   changes in it,.
-00015610: 2020 2020 2020 2020 2020 2020 6e6f 7420              not 
-00015620: 6120 6675 6c6c 206f 626a 6563 742e 0a20  a full object.. 
-00015630: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
-00015640: 6f6a 6563 743a 2050 726f 6a65 6374 2077  oject: Project w
-00015650: 6869 6368 2063 6f6e 7461 696e 7320 7468  hich contains th
-00015660: 6520 6d6f 6469 6669 6564 206f 626a 6563  e modified objec
-00015670: 742e 0a20 2020 2020 2020 203a 7061 7261  t..        :para
-00015680: 6d20 7461 673a 2054 6865 2074 6167 206f  m tag: The tag o
-00015690: 6620 7468 6520 6f62 6a65 6374 2074 6f20  f the object to 
-000156a0: 6d6f 6469 6679 2e0a 2020 2020 2020 2020  modify..        
-000156b0: 3a70 6172 616d 2075 6964 3a20 7569 6420  :param uid: uid 
-000156c0: 6f66 2074 6865 206f 626a 6563 7420 746f  of the object to
-000156d0: 206d 6f64 6966 792e 0a20 2020 2020 2020   modify..       
-000156e0: 203a 7061 7261 6d20 7061 7463 685f 6d6f   :param patch_mo
-000156f0: 6465 3a20 5468 6520 7374 7261 7465 6779  de: The strategy
-00015700: 2066 6f72 206d 6572 6769 6e67 2074 6865   for merging the
-00015710: 2063 6861 6e67 6573 2077 6974 6820 7468   changes with th
-00015720: 6520 6578 6973 7469 6e67 206f 626a 6563  e existing objec
-00015730: 742e 2043 616e 2062 6520 6569 7468 6572  t. Can be either
-00015740: 2060 6072 6570 6c61 6365 6060 0a20 2020   ``replace``.   
-00015750: 2020 2020 2020 2020 206f 7220 6060 6164           or ``ad
-00015760: 6469 7469 7665 6060 2e0a 2020 2020 2020  ditive``..      
-00015770: 2020 2222 220a 2020 2020 2020 2020 7265    """.        re
-00015780: 6665 7265 6e63 6520 3d20 7365 6c66 2e5f  ference = self._
-00015790: 7265 736f 6c76 655f 7265 6665 7265 6e63  resolve_referenc
-000157a0: 6528 7461 672c 2075 6964 290a 2020 2020  e(tag, uid).    
-000157b0: 2020 2020 7072 6f6a 6563 7420 3d20 7072      project = pr
-000157c0: 6f6a 6563 7420 6f72 2063 6f6e 6669 672e  oject or config.
-000157d0: 6465 6661 756c 745f 7072 6f6a 6563 740a  default_project.
-000157e0: 2020 2020 2020 2020 6865 6164 6572 7320          headers 
-000157f0: 3d20 7b73 6368 656d 6173 2e48 6561 6465  = {schemas.Heade
-00015800: 724e 616d 6573 2e70 6174 6368 5f6d 6f64  rNames.patch_mod
-00015810: 653a 2070 6174 6368 5f6d 6f64 657d 0a20  e: patch_mode}. 
-00015820: 2020 2020 2020 2070 6174 6820 3d20 6622         path = f"
-00015830: 7072 6f6a 6563 7473 2f7b 7072 6f6a 6563  projects/{projec
-00015840: 747d 2f66 6561 7475 7265 2d76 6563 746f  t}/feature-vecto
-00015850: 7273 2f7b 6e61 6d65 7d2f 7265 6665 7265  rs/{name}/refere
-00015860: 6e63 6573 2f7b 7265 6665 7265 6e63 657d  nces/{reference}
-00015870: 220a 2020 2020 2020 2020 6572 726f 725f  ".        error_
-00015880: 6d65 7373 6167 6520 3d20 6622 4661 696c  message = f"Fail
-00015890: 6564 2075 7064 6174 696e 6720 6665 6174  ed updating feat
-000158a0: 7572 652d 7665 6374 6f72 207b 7072 6f6a  ure-vector {proj
-000158b0: 6563 747d 2f7b 6e61 6d65 7d22 0a20 2020  ect}/{name}".   
-000158c0: 2020 2020 2073 656c 662e 6170 695f 6361       self.api_ca
-000158d0: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
-000158e0: 2250 4154 4348 222c 0a20 2020 2020 2020  "PATCH",.       
-000158f0: 2020 2020 2070 6174 682c 0a20 2020 2020       path,.     
-00015900: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
-00015910: 7361 6765 2c0a 2020 2020 2020 2020 2020  sage,.          
-00015920: 2020 626f 6479 3d64 6963 745f 746f 5f6a    body=dict_to_j
-00015930: 736f 6e28 6665 6174 7572 655f 7665 6374  son(feature_vect
-00015940: 6f72 5f75 7064 6174 6529 2c0a 2020 2020  or_update),.    
-00015950: 2020 2020 2020 2020 6865 6164 6572 733d          headers=
-00015960: 6865 6164 6572 732c 0a20 2020 2020 2020  headers,.       
-00015970: 2029 0a0a 2020 2020 6465 6620 6465 6c65   )..    def dele
-00015980: 7465 5f66 6561 7475 7265 5f76 6563 746f  te_feature_vecto
-00015990: 7228 7365 6c66 2c20 6e61 6d65 2c20 7072  r(self, name, pr
-000159a0: 6f6a 6563 743d 2222 2c20 7461 673d 4e6f  oject="", tag=No
-000159b0: 6e65 2c20 7569 643d 4e6f 6e65 293a 0a20  ne, uid=None):. 
-000159c0: 2020 2020 2020 2022 2222 4465 6c65 7465         """Delete
-000159d0: 2061 203a 7079 3a63 6c61 7373 3a60 7e6d   a :py:class:`~m
-000159e0: 6c72 756e 2e66 6561 7475 7265 5f73 746f  lrun.feature_sto
-000159f0: 7265 2e46 6561 7475 7265 5665 6374 6f72  re.FeatureVector
-00015a00: 6020 6f62 6a65 6374 2066 726f 6d20 7468  ` object from th
-00015a10: 6520 4442 2e0a 2020 2020 2020 2020 4966  e DB..        If
-00015a20: 2060 6074 6167 6060 206f 7220 6060 7569   ``tag`` or ``ui
-00015a30: 6460 6020 6172 6520 7370 6563 6966 6965  d`` are specifie
-00015a40: 642c 2074 6865 6e20 6a75 7374 2074 6865  d, then just the
-00015a50: 2076 6572 7369 6f6e 2072 6566 6572 656e   version referen
-00015a60: 6365 6420 6279 2074 6865 6d20 7769 6c6c  ced by them will
-00015a70: 2062 6520 6465 6c65 7465 642e 2055 7369   be deleted. Usi
-00015a80: 6e67 2062 6f74 680a 2020 2020 2020 2020  ng both.        
-00015a90: 6973 206e 6f74 2061 6c6c 6f77 6564 2e0a  is not allowed..
-00015aa0: 2020 2020 2020 2020 4966 206e 6f6e 6520          If none 
-00015ab0: 6172 6520 7370 6563 6966 6965 642c 2074  are specified, t
-00015ac0: 6865 6e20 616c 6c20 696e 7374 616e 6365  hen all instance
-00015ad0: 7320 6f66 2074 6865 206f 626a 6563 7420  s of the object 
-00015ae0: 7768 6f73 6520 6e61 6d65 2069 7320 6060  whose name is ``
-00015af0: 6e61 6d65 6060 2077 696c 6c20 6265 2064  name`` will be d
-00015b00: 656c 6574 6564 2e0a 2020 2020 2020 2020  eleted..        
-00015b10: 2222 220a 2020 2020 2020 2020 7072 6f6a  """.        proj
-00015b20: 6563 7420 3d20 7072 6f6a 6563 7420 6f72  ect = project or
-00015b30: 2063 6f6e 6669 672e 6465 6661 756c 745f   config.default_
-00015b40: 7072 6f6a 6563 740a 2020 2020 2020 2020  project.        
-00015b50: 7061 7468 203d 2066 2270 726f 6a65 6374  path = f"project
-00015b60: 732f 7b70 726f 6a65 6374 7d2f 6665 6174  s/{project}/feat
-00015b70: 7572 652d 7665 6374 6f72 732f 7b6e 616d  ure-vectors/{nam
-00015b80: 657d 220a 2020 2020 2020 2020 6966 2074  e}".        if t
-00015b90: 6167 206f 7220 7569 643a 0a20 2020 2020  ag or uid:.     
-00015ba0: 2020 2020 2020 2072 6566 6572 656e 6365         reference
-00015bb0: 203d 2073 656c 662e 5f72 6573 6f6c 7665   = self._resolve
-00015bc0: 5f72 6566 6572 656e 6365 2874 6167 2c20  _reference(tag, 
-00015bd0: 7569 6429 0a20 2020 2020 2020 2020 2020  uid).           
-00015be0: 2070 6174 6820 3d20 7061 7468 202b 2066   path = path + f
-00015bf0: 222f 7265 6665 7265 6e63 6573 2f7b 7265  "/references/{re
-00015c00: 6665 7265 6e63 657d 220a 0a20 2020 2020  ference}"..     
-00015c10: 2020 2065 7272 6f72 5f6d 6573 7361 6765     error_message
-00015c20: 203d 2066 2246 6169 6c65 6420 6465 6c65   = f"Failed dele
-00015c30: 7469 6e67 2066 6561 7475 7265 2d76 6563  ting feature-vec
-00015c40: 746f 7220 7b6e 616d 657d 220a 2020 2020  tor {name}".    
-00015c50: 2020 2020 7365 6c66 2e61 7069 5f63 616c      self.api_cal
-00015c60: 6c28 2244 454c 4554 4522 2c20 7061 7468  l("DELETE", path
-00015c70: 2c20 6572 726f 725f 6d65 7373 6167 6529  , error_message)
-00015c80: 0a0a 2020 2020 6465 6620 7461 675f 6f62  ..    def tag_ob
-00015c90: 6a65 6374 7328 0a20 2020 2020 2020 2073  jects(.        s
-00015ca0: 656c 662c 0a20 2020 2020 2020 2070 726f  elf,.        pro
-00015cb0: 6a65 6374 3a20 7374 722c 0a20 2020 2020  ject: str,.     
-00015cc0: 2020 2074 6167 5f6e 616d 653a 2073 7472     tag_name: str
-00015cd0: 2c0a 2020 2020 2020 2020 6f62 6a65 6374  ,.        object
-00015ce0: 733a 2055 6e69 6f6e 5b6d 6c72 756e 2e61  s: Union[mlrun.a
-00015cf0: 7069 2e73 6368 656d 6173 2e54 6167 4f62  pi.schemas.TagOb
-00015d00: 6a65 6374 732c 2064 6963 745d 2c0a 2020  jects, dict],.  
-00015d10: 2020 2020 2020 7265 706c 6163 653a 2062        replace: b
-00015d20: 6f6f 6c20 3d20 4661 6c73 652c 0a20 2020  ool = False,.   
-00015d30: 2029 3a0a 2020 2020 2020 2020 2222 2254   ):.        """T
-00015d40: 6167 2061 206c 6973 7420 6f66 206f 626a  ag a list of obj
-00015d50: 6563 7473 2e0a 0a20 2020 2020 2020 203a  ects...        :
-00015d60: 7061 7261 6d20 7072 6f6a 6563 743a 2050  param project: P
-00015d70: 726f 6a65 6374 2077 6869 6368 2063 6f6e  roject which con
-00015d80: 7461 696e 7320 7468 6520 6f62 6a65 6374  tains the object
-00015d90: 732e 0a20 2020 2020 2020 203a 7061 7261  s..        :para
-00015da0: 6d20 7461 675f 6e61 6d65 3a20 5468 6520  m tag_name: The 
-00015db0: 7461 6720 746f 2073 6574 206f 6e20 7468  tag to set on th
-00015dc0: 6520 6f62 6a65 6374 732e 0a20 2020 2020  e objects..     
-00015dd0: 2020 203a 7061 7261 6d20 6f62 6a65 6374     :param object
-00015de0: 733a 2054 6865 206f 626a 6563 7473 2074  s: The objects t
-00015df0: 6f20 7461 672e 0a20 2020 2020 2020 203a  o tag..        :
-00015e00: 7061 7261 6d20 7265 706c 6163 653a 2057  param replace: W
-00015e10: 6865 7468 6572 2074 6f20 7265 706c 6163  hether to replac
-00015e20: 6520 7468 6520 6578 6973 7469 6e67 2074  e the existing t
-00015e30: 6167 7320 6f66 2074 6865 206f 626a 6563  ags of the objec
-00015e40: 7473 206f 7220 746f 2061 6464 2074 6865  ts or to add the
-00015e50: 206e 6577 2074 6167 2074 6f20 7468 656d   new tag to them
-00015e60: 2e0a 2020 2020 2020 2020 2222 220a 0a20  ..        """.. 
-00015e70: 2020 2020 2020 2070 6174 6820 3d20 6622         path = f"
-00015e80: 7072 6f6a 6563 7473 2f7b 7072 6f6a 6563  projects/{projec
-00015e90: 747d 2f74 6167 732f 7b74 6167 5f6e 616d  t}/tags/{tag_nam
-00015ea0: 657d 220a 2020 2020 2020 2020 6572 726f  e}".        erro
-00015eb0: 725f 6d65 7373 6167 6520 3d20 6622 4661  r_message = f"Fa
-00015ec0: 696c 6564 2074 6f20 7461 6720 7b74 6167  iled to tag {tag
-00015ed0: 5f6e 616d 657d 206f 6e20 6f62 6a65 6374  _name} on object
-00015ee0: 7320 7b6f 626a 6563 7473 7d22 0a20 2020  s {objects}".   
-00015ef0: 2020 2020 206d 6574 686f 6420 3d20 2250       method = "P
-00015f00: 4f53 5422 2069 6620 7265 706c 6163 6520  OST" if replace 
-00015f10: 656c 7365 2022 5055 5422 0a20 2020 2020  else "PUT".     
-00015f20: 2020 2073 656c 662e 6170 695f 6361 6c6c     self.api_call
-00015f30: 280a 2020 2020 2020 2020 2020 2020 6d65  (.            me
-00015f40: 7468 6f64 2c0a 2020 2020 2020 2020 2020  thod,.          
-00015f50: 2020 7061 7468 2c0a 2020 2020 2020 2020    path,.        
-00015f60: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
-00015f70: 652c 0a20 2020 2020 2020 2020 2020 2062  e,.            b
-00015f80: 6f64 793d 6469 6374 5f74 6f5f 6a73 6f6e  ody=dict_to_json
-00015f90: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-00015fa0: 2020 6f62 6a65 6374 732e 6469 6374 2829    objects.dict()
-00015fb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015fc0: 2069 6620 6973 696e 7374 616e 6365 286f   if isinstance(o
-00015fd0: 626a 6563 7473 2c20 6d6c 7275 6e2e 6170  bjects, mlrun.ap
-00015fe0: 692e 7363 6865 6d61 732e 5461 674f 626a  i.schemas.TagObj
-00015ff0: 6563 7473 290a 2020 2020 2020 2020 2020  ects).          
-00016000: 2020 2020 2020 656c 7365 206f 626a 6563        else objec
-00016010: 7473 0a20 2020 2020 2020 2020 2020 2029  ts.            )
-00016020: 2c0a 2020 2020 2020 2020 290a 0a20 2020  ,.        )..   
-00016030: 2064 6566 2064 656c 6574 655f 6f62 6a65   def delete_obje
-00016040: 6374 735f 7461 6728 0a20 2020 2020 2020  cts_tag(.       
-00016050: 2073 656c 662c 0a20 2020 2020 2020 2070   self,.        p
-00016060: 726f 6a65 6374 3a20 7374 722c 0a20 2020  roject: str,.   
-00016070: 2020 2020 2074 6167 5f6e 616d 653a 2073       tag_name: s
-00016080: 7472 2c0a 2020 2020 2020 2020 7461 675f  tr,.        tag_
-00016090: 6f62 6a65 6374 733a 2055 6e69 6f6e 5b6d  objects: Union[m
-000160a0: 6c72 756e 2e61 7069 2e73 6368 656d 6173  lrun.api.schemas
-000160b0: 2e54 6167 4f62 6a65 6374 732c 2064 6963  .TagObjects, dic
-000160c0: 745d 2c0a 2020 2020 293a 0a20 2020 2020  t],.    ):.     
-000160d0: 2020 2022 2222 4465 6c65 7465 2061 2074     """Delete a t
-000160e0: 6167 2066 726f 6d20 6120 6c69 7374 206f  ag from a list o
-000160f0: 6620 6f62 6a65 6374 732e 0a0a 2020 2020  f objects...    
-00016100: 2020 2020 3a70 6172 616d 2070 726f 6a65      :param proje
-00016110: 6374 3a20 5072 6f6a 6563 7420 7768 6963  ct: Project whic
-00016120: 6820 636f 6e74 6169 6e73 2074 6865 206f  h contains the o
-00016130: 626a 6563 7473 2e0a 2020 2020 2020 2020  bjects..        
-00016140: 3a70 6172 616d 2074 6167 5f6e 616d 653a  :param tag_name:
-00016150: 2054 6865 2074 6167 2074 6f20 6465 6c65   The tag to dele
-00016160: 7465 2066 726f 6d20 7468 6520 6f62 6a65  te from the obje
-00016170: 6374 732e 0a20 2020 2020 2020 203a 7061  cts..        :pa
-00016180: 7261 6d20 7461 675f 6f62 6a65 6374 733a  ram tag_objects:
-00016190: 2054 6865 206f 626a 6563 7473 2074 6f20   The objects to 
-000161a0: 6465 6c65 7465 2074 6865 2074 6167 2066  delete the tag f
-000161b0: 726f 6d2e 0a0a 2020 2020 2020 2020 2222  rom...        ""
-000161c0: 220a 2020 2020 2020 2020 7061 7468 203d  ".        path =
-000161d0: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
-000161e0: 6a65 6374 7d2f 7461 6773 2f7b 7461 675f  ject}/tags/{tag_
-000161f0: 6e61 6d65 7d22 0a20 2020 2020 2020 2065  name}".        e
-00016200: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
-00016210: 2246 6169 6c65 6420 6465 6c65 7469 6e67  "Failed deleting
-00016220: 2074 6167 2066 726f 6d20 7b74 6167 5f6e   tag from {tag_n
-00016230: 616d 657d 220a 2020 2020 2020 2020 7365  ame}".        se
-00016240: 6c66 2e61 7069 5f63 616c 6c28 0a20 2020  lf.api_call(.   
-00016250: 2020 2020 2020 2020 2022 4445 4c45 5445           "DELETE
-00016260: 222c 0a20 2020 2020 2020 2020 2020 2070  ",.            p
-00016270: 6174 682c 0a20 2020 2020 2020 2020 2020  ath,.           
-00016280: 2065 7272 6f72 5f6d 6573 7361 6765 2c0a   error_message,.
-00016290: 2020 2020 2020 2020 2020 2020 626f 6479              body
-000162a0: 3d64 6963 745f 746f 5f6a 736f 6e28 0a20  =dict_to_json(. 
-000162b0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-000162c0: 6167 5f6f 626a 6563 7473 2e64 6963 7428  ag_objects.dict(
-000162d0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-000162e0: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-000162f0: 7461 675f 6f62 6a65 6374 732c 206d 6c72  tag_objects, mlr
-00016300: 756e 2e61 7069 2e73 6368 656d 6173 2e54  un.api.schemas.T
-00016310: 6167 4f62 6a65 6374 7329 0a20 2020 2020  agObjects).     
-00016320: 2020 2020 2020 2020 2020 2065 6c73 6520             else 
-00016330: 7461 675f 6f62 6a65 6374 730a 2020 2020  tag_objects.    
-00016340: 2020 2020 2020 2020 292c 0a20 2020 2020          ),.     
-00016350: 2020 2029 0a0a 2020 2020 6465 6620 7461     )..    def ta
-00016360: 675f 6172 7469 6661 6374 7328 0a20 2020  g_artifacts(.   
-00016370: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
-00016380: 2020 2061 7274 6966 6163 7473 3a20 556e     artifacts: Un
-00016390: 696f 6e5b 4c69 7374 5b41 7274 6966 6163  ion[List[Artifac
-000163a0: 745d 2c20 4c69 7374 5b64 6963 745d 2c20  t], List[dict], 
-000163b0: 4172 7469 6661 6374 2c20 6469 6374 5d2c  Artifact, dict],
-000163c0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-000163d0: 3a20 7374 722c 0a20 2020 2020 2020 2074  : str,.        t
-000163e0: 6167 5f6e 616d 653a 2073 7472 2c0a 2020  ag_name: str,.  
-000163f0: 2020 2020 2020 7265 706c 6163 653a 2062        replace: b
-00016400: 6f6f 6c20 3d20 4661 6c73 652c 0a20 2020  ool = False,.   
-00016410: 2029 3a0a 2020 2020 2020 2020 2222 2254   ):.        """T
-00016420: 6167 2061 206c 6973 7420 6f66 2061 7274  ag a list of art
-00016430: 6966 6163 7473 2e0a 0a20 2020 2020 2020  ifacts...       
-00016440: 203a 7061 7261 6d20 6172 7469 6661 6374   :param artifact
-00016450: 733a 2054 6865 2061 7274 6966 6163 7473  s: The artifacts
-00016460: 2074 6f20 7461 672e 2043 616e 2062 6520   to tag. Can be 
-00016470: 6120 6c69 7374 206f 6620 3a70 793a 636c  a list of :py:cl
-00016480: 6173 733a 607e 6d6c 7275 6e2e 6172 7469  ass:`~mlrun.arti
-00016490: 6661 6374 732e 4172 7469 6661 6374 6020  facts.Artifact` 
-000164a0: 6f62 6a65 6374 7320 6f72 0a20 2020 2020  objects or.     
-000164b0: 2020 2020 2020 2064 6963 7469 6f6e 6172         dictionar
-000164c0: 6965 732c 206f 7220 6120 7369 6e67 6c65  ies, or a single
-000164d0: 206f 626a 6563 742e 0a20 2020 2020 2020   object..       
-000164e0: 203a 7061 7261 6d20 7072 6f6a 6563 743a   :param project:
-000164f0: 2050 726f 6a65 6374 2077 6869 6368 2063   Project which c
-00016500: 6f6e 7461 696e 7320 7468 6520 6172 7469  ontains the arti
-00016510: 6661 6374 732e 0a20 2020 2020 2020 203a  facts..        :
-00016520: 7061 7261 6d20 7461 675f 6e61 6d65 3a20  param tag_name: 
-00016530: 5468 6520 7461 6720 746f 2073 6574 206f  The tag to set o
-00016540: 6e20 7468 6520 6172 7469 6661 6374 732e  n the artifacts.
-00016550: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-00016560: 7265 706c 6163 653a 2049 6620 5472 7565  replace: If True
-00016570: 2c20 7265 706c 6163 6520 6578 6973 7469  , replace existi
-00016580: 6e67 2074 6167 732c 206f 7468 6572 7769  ng tags, otherwi
-00016590: 7365 2061 7070 656e 6420 746f 2065 7869  se append to exi
-000165a0: 7374 696e 6720 7461 6773 2e0a 2020 2020  sting tags..    
-000165b0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-000165c0: 7461 675f 6f62 6a65 6374 7320 3d20 7365  tag_objects = se
-000165d0: 6c66 2e5f 7265 736f 6c76 655f 6172 7469  lf._resolve_arti
-000165e0: 6661 6374 735f 746f 5f74 6167 5f6f 626a  facts_to_tag_obj
-000165f0: 6563 7473 2861 7274 6966 6163 7473 290a  ects(artifacts).
-00016600: 2020 2020 2020 2020 7365 6c66 2e74 6167          self.tag
-00016610: 5f6f 626a 6563 7473 2870 726f 6a65 6374  _objects(project
-00016620: 2c20 7461 675f 6e61 6d65 2c20 6f62 6a65  , tag_name, obje
-00016630: 6374 733d 7461 675f 6f62 6a65 6374 732c  cts=tag_objects,
-00016640: 2072 6570 6c61 6365 3d72 6570 6c61 6365   replace=replace
-00016650: 290a 0a20 2020 2064 6566 2064 656c 6574  )..    def delet
-00016660: 655f 6172 7469 6661 6374 735f 7461 6773  e_artifacts_tags
-00016670: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
-00016680: 2020 2020 2020 2020 6172 7469 6661 6374          artifact
-00016690: 732c 0a20 2020 2020 2020 2070 726f 6a65  s,.        proje
-000166a0: 6374 3a20 7374 722c 0a20 2020 2020 2020  ct: str,.       
-000166b0: 2074 6167 5f6e 616d 653a 2073 7472 2c0a   tag_name: str,.
-000166c0: 2020 2020 293a 0a20 2020 2020 2020 2022      ):.        "
-000166d0: 2222 4465 6c65 7465 2074 6167 2066 726f  ""Delete tag fro
-000166e0: 6d20 6120 6c69 7374 206f 6620 6172 7469  m a list of arti
-000166f0: 6661 6374 732e 0a0a 2020 2020 2020 2020  facts...        
-00016700: 3a70 6172 616d 2061 7274 6966 6163 7473  :param artifacts
-00016710: 3a20 5468 6520 6172 7469 6661 6374 7320  : The artifacts 
-00016720: 746f 2064 656c 6574 6520 7468 6520 7461  to delete the ta
-00016730: 6720 6672 6f6d 2e20 4361 6e20 6265 2061  g from. Can be a
-00016740: 206c 6973 7420 6f66 203a 7079 3a63 6c61   list of :py:cla
-00016750: 7373 3a60 7e6d 6c72 756e 2e61 7274 6966  ss:`~mlrun.artif
-00016760: 6163 7473 2e41 7274 6966 6163 7460 0a20  acts.Artifact`. 
-00016770: 2020 2020 2020 2020 2020 206f 626a 6563             objec
-00016780: 7473 206f 7220 6469 6374 696f 6e61 7269  ts or dictionari
-00016790: 6573 2c20 6f72 2061 2073 696e 676c 6520  es, or a single 
-000167a0: 6f62 6a65 6374 2e0a 2020 2020 2020 2020  object..        
-000167b0: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
-000167c0: 5072 6f6a 6563 7420 7768 6963 6820 636f  Project which co
-000167d0: 6e74 6169 6e73 2074 6865 2061 7274 6966  ntains the artif
-000167e0: 6163 7473 2e0a 2020 2020 2020 2020 3a70  acts..        :p
-000167f0: 6172 616d 2074 6167 5f6e 616d 653a 2054  aram tag_name: T
-00016800: 6865 2074 6167 2074 6f20 7365 7420 6f6e  he tag to set on
-00016810: 2074 6865 2061 7274 6966 6163 7473 2e0a   the artifacts..
-00016820: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-00016830: 2020 2020 7461 675f 6f62 6a65 6374 7320      tag_objects 
-00016840: 3d20 7365 6c66 2e5f 7265 736f 6c76 655f  = self._resolve_
-00016850: 6172 7469 6661 6374 735f 746f 5f74 6167  artifacts_to_tag
-00016860: 5f6f 626a 6563 7473 2861 7274 6966 6163  _objects(artifac
-00016870: 7473 290a 2020 2020 2020 2020 7365 6c66  ts).        self
-00016880: 2e64 656c 6574 655f 6f62 6a65 6374 735f  .delete_objects_
-00016890: 7461 6728 7072 6f6a 6563 742c 2074 6167  tag(project, tag
-000168a0: 5f6e 616d 652c 2074 6167 5f6f 626a 6563  _name, tag_objec
-000168b0: 7473 290a 0a20 2020 2064 6566 206c 6973  ts)..    def lis
-000168c0: 745f 7072 6f6a 6563 7473 280a 2020 2020  t_projects(.    
-000168d0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
-000168e0: 2020 6f77 6e65 723a 2073 7472 203d 204e    owner: str = N
-000168f0: 6f6e 652c 0a20 2020 2020 2020 2066 6f72  one,.        for
-00016900: 6d61 745f 3a20 556e 696f 6e5b 0a20 2020  mat_: Union[.   
-00016910: 2020 2020 2020 2020 2073 7472 2c20 6d6c           str, ml
-00016920: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
-00016930: 5072 6f6a 6563 7473 466f 726d 6174 0a20  ProjectsFormat. 
-00016940: 2020 2020 2020 205d 203d 206d 6c72 756e         ] = mlrun
-00016950: 2e61 7069 2e73 6368 656d 6173 2e50 726f  .api.schemas.Pro
-00016960: 6a65 6374 7346 6f72 6d61 742e 6675 6c6c  jectsFormat.full
-00016970: 2c0a 2020 2020 2020 2020 6c61 6265 6c73  ,.        labels
-00016980: 3a20 4c69 7374 5b73 7472 5d20 3d20 4e6f  : List[str] = No
-00016990: 6e65 2c0a 2020 2020 2020 2020 7374 6174  ne,.        stat
-000169a0: 653a 2055 6e69 6f6e 5b73 7472 2c20 6d6c  e: Union[str, ml
-000169b0: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
-000169c0: 5072 6f6a 6563 7453 7461 7465 5d20 3d20  ProjectState] = 
-000169d0: 4e6f 6e65 2c0a 2020 2020 2920 2d3e 204c  None,.    ) -> L
-000169e0: 6973 745b 556e 696f 6e5b 6d6c 7275 6e2e  ist[Union[mlrun.
-000169f0: 7072 6f6a 6563 7473 2e4d 6c72 756e 5072  projects.MlrunPr
-00016a00: 6f6a 6563 742c 2073 7472 5d5d 3a0a 2020  oject, str]]:.  
-00016a10: 2020 2020 2020 2222 2252 6574 7572 6e20        """Return 
-00016a20: 6120 6c69 7374 206f 6620 7468 6520 6578  a list of the ex
-00016a30: 6973 7469 6e67 2070 726f 6a65 6374 732c  isting projects,
-00016a40: 2070 6f74 656e 7469 616c 6c79 2066 696c   potentially fil
-00016a50: 7465 7265 6420 6279 2073 7065 6369 6669  tered by specifi
-00016a60: 6320 6372 6974 6572 6961 2e0a 0a20 2020  c criteria...   
-00016a70: 2020 2020 203a 7061 7261 6d20 6f77 6e65       :param owne
-00016a80: 723a 204c 6973 7420 6f6e 6c79 2070 726f  r: List only pro
-00016a90: 6a65 6374 7320 6265 6c6f 6e67 696e 6720  jects belonging 
-00016aa0: 746f 2074 6869 7320 7370 6563 6966 6963  to this specific
-00016ab0: 206f 776e 6572 2e0a 2020 2020 2020 2020   owner..        
-00016ac0: 3a70 6172 616d 2066 6f72 6d61 745f 3a20  :param format_: 
-00016ad0: 466f 726d 6174 206f 6620 7468 6520 7265  Format of the re
-00016ae0: 7375 6c74 732e 2050 6f73 7369 626c 6520  sults. Possible 
-00016af0: 7661 6c75 6573 2061 7265 3a0a 0a20 2020  values are:..   
-00016b00: 2020 2020 2020 2020 202d 2060 6066 756c           - ``ful
-00016b10: 6c60 6020 2864 6566 6175 6c74 2076 616c  l`` (default val
-00016b20: 7565 2920 2d20 5265 7475 726e 2066 756c  ue) - Return ful
-00016b30: 6c20 7072 6f6a 6563 7420 6f62 6a65 6374  l project object
-00016b40: 732e 0a20 2020 2020 2020 2020 2020 202d  s..            -
-00016b50: 2060 606e 616d 655f 6f6e 6c79 6060 202d   ``name_only`` -
-00016b60: 2052 6574 7572 6e20 6a75 7374 2074 6865   Return just the
-00016b70: 206e 616d 6573 206f 6620 7468 6520 7072   names of the pr
-00016b80: 6f6a 6563 7473 2e0a 0a20 2020 2020 2020  ojects...       
-00016b90: 203a 7061 7261 6d20 6c61 6265 6c73 3a20   :param labels: 
-00016ba0: 4669 6c74 6572 2062 7920 6c61 6265 6c73  Filter by labels
-00016bb0: 2061 7474 6163 6865 6420 746f 2074 6865   attached to the
-00016bc0: 2070 726f 6a65 6374 2e0a 2020 2020 2020   project..      
-00016bd0: 2020 3a70 6172 616d 2073 7461 7465 3a20    :param state: 
-00016be0: 4669 6c74 6572 2062 7920 7072 6f6a 6563  Filter by projec
-00016bf0: 7427 7320 7374 6174 652e 2043 616e 2062  t's state. Can b
-00016c00: 6520 6569 7468 6572 2060 606f 6e6c 696e  e either ``onlin
-00016c10: 6560 6020 6f72 2060 6061 7263 6869 7665  e`` or ``archive
-00016c20: 6460 602e 0a20 2020 2020 2020 2022 2222  d``..        """
-00016c30: 0a0a 2020 2020 2020 2020 7061 7261 6d73  ..        params
-00016c40: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
-00016c50: 2022 6f77 6e65 7222 3a20 6f77 6e65 722c   "owner": owner,
-00016c60: 0a20 2020 2020 2020 2020 2020 2022 7374  .            "st
-00016c70: 6174 6522 3a20 7374 6174 652c 0a20 2020  ate": state,.   
-00016c80: 2020 2020 2020 2020 2022 666f 726d 6174           "format
-00016c90: 223a 2066 6f72 6d61 745f 2c0a 2020 2020  ": format_,.    
-00016ca0: 2020 2020 2020 2020 226c 6162 656c 223a          "label":
-00016cb0: 206c 6162 656c 7320 6f72 205b 5d2c 0a20   labels or [],. 
-00016cc0: 2020 2020 2020 207d 0a0a 2020 2020 2020         }..      
-00016cd0: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
-00016ce0: 3d20 6622 4661 696c 6564 206c 6973 7469  = f"Failed listi
-00016cf0: 6e67 2070 726f 6a65 6374 732c 2071 7565  ng projects, que
-00016d00: 7279 3a20 7b70 6172 616d 737d 220a 2020  ry: {params}".  
-00016d10: 2020 2020 2020 7265 7370 6f6e 7365 203d        response =
-00016d20: 2073 656c 662e 6170 695f 6361 6c6c 2822   self.api_call("
-00016d30: 4745 5422 2c20 2270 726f 6a65 6374 7322  GET", "projects"
-00016d40: 2c20 6572 726f 725f 6d65 7373 6167 652c  , error_message,
-00016d50: 2070 6172 616d 733d 7061 7261 6d73 290a   params=params).
-00016d60: 2020 2020 2020 2020 6966 2066 6f72 6d61          if forma
-00016d70: 745f 203d 3d20 6d6c 7275 6e2e 6170 692e  t_ == mlrun.api.
-00016d80: 7363 6865 6d61 732e 5072 6f6a 6563 7473  schemas.Projects
-00016d90: 466f 726d 6174 2e6e 616d 655f 6f6e 6c79  Format.name_only
-00016da0: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
-00016db0: 7475 726e 2072 6573 706f 6e73 652e 6a73  turn response.js
-00016dc0: 6f6e 2829 5b22 7072 6f6a 6563 7473 225d  on()["projects"]
-00016dd0: 0a20 2020 2020 2020 2065 6c69 6620 666f  .        elif fo
-00016de0: 726d 6174 5f20 3d3d 206d 6c72 756e 2e61  rmat_ == mlrun.a
-00016df0: 7069 2e73 6368 656d 6173 2e50 726f 6a65  pi.schemas.Proje
-00016e00: 6374 7346 6f72 6d61 742e 6675 6c6c 3a0a  ctsFormat.full:.
-00016e10: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00016e20: 726e 205b 0a20 2020 2020 2020 2020 2020  rn [.           
-00016e30: 2020 2020 206d 6c72 756e 2e70 726f 6a65       mlrun.proje
-00016e40: 6374 732e 4d6c 7275 6e50 726f 6a65 6374  cts.MlrunProject
-00016e50: 2e66 726f 6d5f 6469 6374 2870 726f 6a65  .from_dict(proje
-00016e60: 6374 5f64 6963 7429 0a20 2020 2020 2020  ct_dict).       
-00016e70: 2020 2020 2020 2020 2066 6f72 2070 726f           for pro
-00016e80: 6a65 6374 5f64 6963 7420 696e 2072 6573  ject_dict in res
-00016e90: 706f 6e73 652e 6a73 6f6e 2829 5b22 7072  ponse.json()["pr
-00016ea0: 6f6a 6563 7473 225d 0a20 2020 2020 2020  ojects"].       
-00016eb0: 2020 2020 205d 0a20 2020 2020 2020 2065       ].        e
-00016ec0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00016ed0: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-00016ee0: 656e 7465 6445 7272 6f72 280a 2020 2020  entedError(.    
-00016ef0: 2020 2020 2020 2020 2020 2020 6622 5072              f"Pr
-00016f00: 6f76 6964 6564 2066 6f72 6d61 7420 6973  ovided format is
-00016f10: 206e 6f74 2073 7570 706f 7274 6564 2e20   not supported. 
-00016f20: 666f 726d 6174 3d7b 666f 726d 6174 5f7d  format={format_}
-00016f30: 220a 2020 2020 2020 2020 2020 2020 290a  ".            ).
-00016f40: 0a20 2020 2064 6566 2067 6574 5f70 726f  .    def get_pro
-00016f50: 6a65 6374 2873 656c 662c 206e 616d 653a  ject(self, name:
-00016f60: 2073 7472 2920 2d3e 206d 6c72 756e 2e70   str) -> mlrun.p
-00016f70: 726f 6a65 6374 732e 4d6c 7275 6e50 726f  rojects.MlrunPro
-00016f80: 6a65 6374 3a0a 2020 2020 2020 2020 2222  ject:.        ""
-00016f90: 2247 6574 2064 6574 6169 6c73 2066 6f72  "Get details for
-00016fa0: 2061 2073 7065 6369 6669 6320 7072 6f6a   a specific proj
-00016fb0: 6563 742e 2222 220a 0a20 2020 2020 2020  ect."""..       
-00016fc0: 2069 6620 6e6f 7420 6e61 6d65 3a0a 2020   if not name:.  
-00016fd0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00016fe0: 4d4c 5275 6e49 6e76 616c 6964 4172 6775  MLRunInvalidArgu
-00016ff0: 6d65 6e74 4572 726f 7228 224e 616d 6520  mentError("Name 
-00017000: 6d75 7374 2062 6520 7072 6f76 6964 6564  must be provided
-00017010: 2229 0a0a 2020 2020 2020 2020 7061 7468  ")..        path
-00017020: 203d 2066 2270 726f 6a65 6374 732f 7b6e   = f"projects/{n
-00017030: 616d 657d 220a 2020 2020 2020 2020 6572  ame}".        er
-00017040: 726f 725f 6d65 7373 6167 6520 3d20 6622  ror_message = f"
-00017050: 4661 696c 6564 2072 6574 7269 6576 696e  Failed retrievin
-00017060: 6720 7072 6f6a 6563 7420 7b6e 616d 657d  g project {name}
-00017070: 220a 2020 2020 2020 2020 7265 7370 6f6e  ".        respon
-00017080: 7365 203d 2073 656c 662e 6170 695f 6361  se = self.api_ca
-00017090: 6c6c 2822 4745 5422 2c20 7061 7468 2c20  ll("GET", path, 
-000170a0: 6572 726f 725f 6d65 7373 6167 6529 0a20  error_message). 
-000170b0: 2020 2020 2020 2072 6574 7572 6e20 6d6c         return ml
-000170c0: 7275 6e2e 7072 6f6a 6563 7473 2e4d 6c72  run.projects.Mlr
-000170d0: 756e 5072 6f6a 6563 742e 6672 6f6d 5f64  unProject.from_d
-000170e0: 6963 7428 7265 7370 6f6e 7365 2e6a 736f  ict(response.jso
-000170f0: 6e28 2929 0a0a 2020 2020 6465 6620 6465  n())..    def de
-00017100: 6c65 7465 5f70 726f 6a65 6374 280a 2020  lete_project(.  
-00017110: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
-00017120: 2020 2020 6e61 6d65 3a20 7374 722c 0a20      name: str,. 
-00017130: 2020 2020 2020 2064 656c 6574 696f 6e5f         deletion_
-00017140: 7374 7261 7465 6779 3a20 556e 696f 6e5b  strategy: Union[
-00017150: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
-00017160: 2c20 6d6c 7275 6e2e 6170 692e 7363 6865  , mlrun.api.sche
-00017170: 6d61 732e 4465 6c65 7469 6f6e 5374 7261  mas.DeletionStra
-00017180: 7465 6779 0a20 2020 2020 2020 205d 203d  tegy.        ] =
-00017190: 206d 6c72 756e 2e61 7069 2e73 6368 656d   mlrun.api.schem
-000171a0: 6173 2e44 656c 6574 696f 6e53 7472 6174  as.DeletionStrat
-000171b0: 6567 792e 6465 6661 756c 7428 292c 0a20  egy.default(),. 
-000171c0: 2020 2029 3a0a 2020 2020 2020 2020 2222     ):.        ""
-000171d0: 2244 656c 6574 6520 6120 7072 6f6a 6563  "Delete a projec
-000171e0: 742e 0a0a 2020 2020 2020 2020 3a70 6172  t...        :par
-000171f0: 616d 206e 616d 653a 204e 616d 6520 6f66  am name: Name of
-00017200: 2074 6865 2070 726f 6a65 6374 2074 6f20   the project to 
-00017210: 6465 6c65 7465 2e0a 2020 2020 2020 2020  delete..        
-00017220: 3a70 6172 616d 2064 656c 6574 696f 6e5f  :param deletion_
-00017230: 7374 7261 7465 6779 3a20 486f 7720 746f  strategy: How to
-00017240: 2074 7265 6174 2063 6869 6c64 206f 626a   treat child obj
-00017250: 6563 7473 206f 6620 7468 6520 7072 6f6a  ects of the proj
-00017260: 6563 742e 2050 6f73 7369 626c 6520 7661  ect. Possible va
-00017270: 6c75 6573 2061 7265 3a0a 0a20 2020 2020  lues are:..     
-00017280: 2020 2020 2020 202d 2060 6072 6573 7472         - ``restr
-00017290: 6963 7460 6020 2864 6566 6175 6c74 2920  ict`` (default) 
-000172a0: 2d20 5072 6f6a 6563 7420 6d75 7374 206e  - Project must n
-000172b0: 6f74 2068 6176 6520 616e 7920 6368 696c  ot have any chil
-000172c0: 6420 6f62 6a65 6374 7320 7768 656e 2064  d objects when d
-000172d0: 656c 6574 6564 2e20 4966 2075 7369 6e67  eleted. If using
-000172e0: 2074 6869 7320 6d6f 6465 2077 6869 6c65   this mode while
-000172f0: 0a20 2020 2020 2020 2020 2020 2020 2063  .              c
-00017300: 6869 6c64 206f 626a 6563 7473 2065 7869  hild objects exi
-00017310: 7374 2c20 7468 6520 6f70 6572 6174 696f  st, the operatio
-00017320: 6e20 7769 6c6c 2066 6169 6c2e 0a20 2020  n will fail..   
-00017330: 2020 2020 2020 2020 202d 2060 6063 6173           - ``cas
-00017340: 6361 6465 6060 202d 2041 7574 6f6d 6174  cade`` - Automat
-00017350: 6963 616c 6c79 2064 656c 6574 6520 616c  ically delete al
-00017360: 6c20 6368 696c 6420 6f62 6a65 6374 7320  l child objects 
-00017370: 7768 656e 2064 656c 6574 696e 6720 7468  when deleting th
-00017380: 6520 7072 6f6a 6563 742e 0a20 2020 2020  e project..     
-00017390: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
-000173a0: 7061 7468 203d 2066 2270 726f 6a65 6374  path = f"project
-000173b0: 732f 7b6e 616d 657d 220a 2020 2020 2020  s/{name}".      
-000173c0: 2020 6865 6164 6572 7320 3d20 7b73 6368    headers = {sch
-000173d0: 656d 6173 2e48 6561 6465 724e 616d 6573  emas.HeaderNames
-000173e0: 2e64 656c 6574 696f 6e5f 7374 7261 7465  .deletion_strate
-000173f0: 6779 3a20 6465 6c65 7469 6f6e 5f73 7472  gy: deletion_str
-00017400: 6174 6567 797d 0a20 2020 2020 2020 2065  ategy}.        e
-00017410: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
-00017420: 2246 6169 6c65 6420 6465 6c65 7469 6e67  "Failed deleting
-00017430: 2070 726f 6a65 6374 207b 6e61 6d65 7d22   project {name}"
-00017440: 0a20 2020 2020 2020 2072 6573 706f 6e73  .        respons
-00017450: 6520 3d20 7365 6c66 2e61 7069 5f63 616c  e = self.api_cal
-00017460: 6c28 2244 454c 4554 4522 2c20 7061 7468  l("DELETE", path
-00017470: 2c20 6572 726f 725f 6d65 7373 6167 652c  , error_message,
-00017480: 2068 6561 6465 7273 3d68 6561 6465 7273   headers=headers
-00017490: 290a 2020 2020 2020 2020 6966 2072 6573  ).        if res
-000174a0: 706f 6e73 652e 7374 6174 7573 5f63 6f64  ponse.status_cod
-000174b0: 6520 3d3d 2068 7474 702e 4854 5450 5374  e == http.HTTPSt
-000174c0: 6174 7573 2e41 4343 4550 5445 443a 0a20  atus.ACCEPTED:. 
-000174d0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-000174e0: 6e20 7365 6c66 2e5f 7761 6974 5f66 6f72  n self._wait_for
-000174f0: 5f70 726f 6a65 6374 5f74 6f5f 6265 5f64  _project_to_be_d
-00017500: 656c 6574 6564 286e 616d 6529 0a0a 2020  eleted(name)..  
-00017510: 2020 6465 6620 7374 6f72 655f 7072 6f6a    def store_proj
-00017520: 6563 7428 0a20 2020 2020 2020 2073 656c  ect(.        sel
-00017530: 662c 0a20 2020 2020 2020 206e 616d 653a  f,.        name:
-00017540: 2073 7472 2c0a 2020 2020 2020 2020 7072   str,.        pr
-00017550: 6f6a 6563 743a 2055 6e69 6f6e 5b64 6963  oject: Union[dic
-00017560: 742c 206d 6c72 756e 2e70 726f 6a65 6374  t, mlrun.project
-00017570: 732e 4d6c 7275 6e50 726f 6a65 6374 2c20  s.MlrunProject, 
-00017580: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
-00017590: 732e 5072 6f6a 6563 745d 2c0a 2020 2020  s.Project],.    
-000175a0: 2920 2d3e 206d 6c72 756e 2e70 726f 6a65  ) -> mlrun.proje
-000175b0: 6374 732e 4d6c 7275 6e50 726f 6a65 6374  cts.MlrunProject
-000175c0: 3a0a 2020 2020 2020 2020 2222 2253 746f  :.        """Sto
-000175d0: 7265 2061 2070 726f 6a65 6374 2069 6e20  re a project in 
-000175e0: 7468 6520 4442 2e20 5468 6973 206f 7065  the DB. This ope
-000175f0: 7261 7469 6f6e 2077 696c 6c20 6f76 6572  ration will over
-00017600: 7772 6974 6520 6578 6973 7469 6e67 2070  write existing p
-00017610: 726f 6a65 6374 206f 6620 7468 6520 7361  roject of the sa
-00017620: 6d65 206e 616d 6520 6966 2065 7869 7374  me name if exist
-00017630: 732e 2222 220a 0a20 2020 2020 2020 2070  s."""..        p
-00017640: 6174 6820 3d20 6622 7072 6f6a 6563 7473  ath = f"projects
-00017650: 2f7b 6e61 6d65 7d22 0a20 2020 2020 2020  /{name}".       
-00017660: 2065 7272 6f72 5f6d 6573 7361 6765 203d   error_message =
-00017670: 2066 2246 6169 6c65 6420 7374 6f72 696e   f"Failed storin
-00017680: 6720 7072 6f6a 6563 7420 7b6e 616d 657d  g project {name}
-00017690: 220a 2020 2020 2020 2020 6966 2069 7369  ".        if isi
-000176a0: 6e73 7461 6e63 6528 7072 6f6a 6563 742c  nstance(project,
-000176b0: 206d 6c72 756e 2e61 7069 2e73 6368 656d   mlrun.api.schem
-000176c0: 6173 2e50 726f 6a65 6374 293a 0a20 2020  as.Project):.   
-000176d0: 2020 2020 2020 2020 2070 726f 6a65 6374           project
-000176e0: 203d 2070 726f 6a65 6374 2e64 6963 7428   = project.dict(
-000176f0: 290a 2020 2020 2020 2020 656c 6966 2069  ).        elif i
-00017700: 7369 6e73 7461 6e63 6528 7072 6f6a 6563  sinstance(projec
-00017710: 742c 206d 6c72 756e 2e70 726f 6a65 6374  t, mlrun.project
-00017720: 732e 4d6c 7275 6e50 726f 6a65 6374 293a  s.MlrunProject):
-00017730: 0a20 2020 2020 2020 2020 2020 2070 726f  .            pro
-00017740: 6a65 6374 203d 2070 726f 6a65 6374 2e74  ject = project.t
-00017750: 6f5f 6469 6374 2829 0a20 2020 2020 2020  o_dict().       
-00017760: 2072 6573 706f 6e73 6520 3d20 7365 6c66   response = self
-00017770: 2e61 7069 5f63 616c 6c28 0a20 2020 2020  .api_call(.     
-00017780: 2020 2020 2020 2022 5055 5422 2c0a 2020         "PUT",.  
-00017790: 2020 2020 2020 2020 2020 7061 7468 2c0a            path,.
-000177a0: 2020 2020 2020 2020 2020 2020 6572 726f              erro
-000177b0: 725f 6d65 7373 6167 652c 0a20 2020 2020  r_message,.     
-000177c0: 2020 2020 2020 2062 6f64 793d 6469 6374         body=dict
-000177d0: 5f74 6f5f 6a73 6f6e 2870 726f 6a65 6374  _to_json(project
-000177e0: 292c 0a20 2020 2020 2020 2029 0a20 2020  ),.        ).   
-000177f0: 2020 2020 2069 6620 7265 7370 6f6e 7365       if response
-00017800: 2e73 7461 7475 735f 636f 6465 203d 3d20  .status_code == 
-00017810: 6874 7470 2e48 5454 5053 7461 7475 732e  http.HTTPStatus.
-00017820: 4143 4345 5054 4544 3a0a 2020 2020 2020  ACCEPTED:.      
-00017830: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-00017840: 662e 5f77 6169 745f 666f 725f 7072 6f6a  f._wait_for_proj
-00017850: 6563 745f 746f 5f72 6561 6368 5f74 6572  ect_to_reach_ter
-00017860: 6d69 6e61 6c5f 7374 6174 6528 6e61 6d65  minal_state(name
-00017870: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00017880: 206d 6c72 756e 2e70 726f 6a65 6374 732e   mlrun.projects.
-00017890: 4d6c 7275 6e50 726f 6a65 6374 2e66 726f  MlrunProject.fro
-000178a0: 6d5f 6469 6374 2872 6573 706f 6e73 652e  m_dict(response.
-000178b0: 6a73 6f6e 2829 290a 0a20 2020 2064 6566  json())..    def
-000178c0: 2070 6174 6368 5f70 726f 6a65 6374 280a   patch_project(.
-000178d0: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-000178e0: 2020 2020 2020 6e61 6d65 3a20 7374 722c        name: str,
-000178f0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-00017900: 3a20 6469 6374 2c0a 2020 2020 2020 2020  : dict,.        
-00017910: 7061 7463 685f 6d6f 6465 3a20 556e 696f  patch_mode: Unio
-00017920: 6e5b 7374 722c 2073 6368 656d 6173 2e50  n[str, schemas.P
-00017930: 6174 6368 4d6f 6465 5d20 3d20 7363 6865  atchMode] = sche
-00017940: 6d61 732e 5061 7463 684d 6f64 652e 7265  mas.PatchMode.re
-00017950: 706c 6163 652c 0a20 2020 2029 202d 3e20  place,.    ) -> 
-00017960: 6d6c 7275 6e2e 7072 6f6a 6563 7473 2e4d  mlrun.projects.M
-00017970: 6c72 756e 5072 6f6a 6563 743a 0a20 2020  lrunProject:.   
-00017980: 2020 2020 2022 2222 5061 7463 6820 616e       """Patch an
-00017990: 2065 7869 7374 696e 6720 7072 6f6a 6563   existing projec
-000179a0: 7420 6f62 6a65 6374 2e0a 0a20 2020 2020  t object...     
-000179b0: 2020 203a 7061 7261 6d20 6e61 6d65 3a20     :param name: 
-000179c0: 4e61 6d65 206f 6620 7072 6f6a 6563 7420  Name of project 
-000179d0: 746f 2070 6174 6368 2e0a 2020 2020 2020  to patch..      
-000179e0: 2020 3a70 6172 616d 2070 726f 6a65 6374    :param project
-000179f0: 3a20 5468 6520 6163 7475 616c 2063 6861  : The actual cha
-00017a00: 6e67 6573 2074 6f20 7468 6520 7072 6f6a  nges to the proj
-00017a10: 6563 7420 6f62 6a65 6374 2e0a 2020 2020  ect object..    
-00017a20: 2020 2020 3a70 6172 616d 2070 6174 6368      :param patch
-00017a30: 5f6d 6f64 653a 2054 6865 2073 7472 6174  _mode: The strat
-00017a40: 6567 7920 666f 7220 6d65 7267 696e 6720  egy for merging 
-00017a50: 7468 6520 6368 616e 6765 7320 7769 7468  the changes with
-00017a60: 2074 6865 2065 7869 7374 696e 6720 6f62   the existing ob
-00017a70: 6a65 6374 2e20 4361 6e20 6265 2065 6974  ject. Can be eit
-00017a80: 6865 7220 6060 7265 706c 6163 6560 600a  her ``replace``.
-00017a90: 2020 2020 2020 2020 2020 2020 6f72 2060              or `
-00017aa0: 6061 6464 6974 6976 6560 602e 0a20 2020  `additive``..   
-00017ab0: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
-00017ac0: 2020 7061 7468 203d 2066 2270 726f 6a65    path = f"proje
-00017ad0: 6374 732f 7b6e 616d 657d 220a 2020 2020  cts/{name}".    
-00017ae0: 2020 2020 6865 6164 6572 7320 3d20 7b73      headers = {s
-00017af0: 6368 656d 6173 2e48 6561 6465 724e 616d  chemas.HeaderNam
-00017b00: 6573 2e70 6174 6368 5f6d 6f64 653a 2070  es.patch_mode: p
-00017b10: 6174 6368 5f6d 6f64 657d 0a20 2020 2020  atch_mode}.     
-00017b20: 2020 2065 7272 6f72 5f6d 6573 7361 6765     error_message
-00017b30: 203d 2066 2246 6169 6c65 6420 7061 7463   = f"Failed patc
-00017b40: 6869 6e67 2070 726f 6a65 6374 207b 6e61  hing project {na
-00017b50: 6d65 7d22 0a20 2020 2020 2020 2072 6573  me}".        res
-00017b60: 706f 6e73 6520 3d20 7365 6c66 2e61 7069  ponse = self.api
-00017b70: 5f63 616c 6c28 0a20 2020 2020 2020 2020  _call(.         
-00017b80: 2020 2022 5041 5443 4822 2c20 7061 7468     "PATCH", path
-00017b90: 2c20 6572 726f 725f 6d65 7373 6167 652c  , error_message,
-00017ba0: 2062 6f64 793d 6469 6374 5f74 6f5f 6a73   body=dict_to_js
-00017bb0: 6f6e 2870 726f 6a65 6374 292c 2068 6561  on(project), hea
-00017bc0: 6465 7273 3d68 6561 6465 7273 0a20 2020  ders=headers.   
-00017bd0: 2020 2020 2029 0a20 2020 2020 2020 2072       ).        r
-00017be0: 6574 7572 6e20 6d6c 7275 6e2e 7072 6f6a  eturn mlrun.proj
-00017bf0: 6563 7473 2e4d 6c72 756e 5072 6f6a 6563  ects.MlrunProjec
-00017c00: 742e 6672 6f6d 5f64 6963 7428 7265 7370  t.from_dict(resp
-00017c10: 6f6e 7365 2e6a 736f 6e28 2929 0a0a 2020  onse.json())..  
-00017c20: 2020 6465 6620 6372 6561 7465 5f70 726f    def create_pro
-00017c30: 6a65 6374 280a 2020 2020 2020 2020 7365  ject(.        se
-00017c40: 6c66 2c0a 2020 2020 2020 2020 7072 6f6a  lf,.        proj
-00017c50: 6563 743a 2055 6e69 6f6e 5b64 6963 742c  ect: Union[dict,
-00017c60: 206d 6c72 756e 2e70 726f 6a65 6374 732e   mlrun.projects.
-00017c70: 4d6c 7275 6e50 726f 6a65 6374 2c20 6d6c  MlrunProject, ml
-00017c80: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
-00017c90: 5072 6f6a 6563 745d 2c0a 2020 2020 2920  Project],.    ) 
-00017ca0: 2d3e 206d 6c72 756e 2e70 726f 6a65 6374  -> mlrun.project
-00017cb0: 732e 4d6c 7275 6e50 726f 6a65 6374 3a0a  s.MlrunProject:.
-00017cc0: 2020 2020 2020 2020 2222 2243 7265 6174          """Creat
-00017cd0: 6520 6120 6e65 7720 7072 6f6a 6563 742e  e a new project.
-00017ce0: 2041 2070 726f 6a65 6374 2077 6974 6820   A project with 
-00017cf0: 7468 6520 7361 6d65 206e 616d 6520 6d75  the same name mu
-00017d00: 7374 206e 6f74 2065 7869 7374 2070 7269  st not exist pri
-00017d10: 6f72 2074 6f20 6372 6561 7469 6f6e 2e22  or to creation."
-00017d20: 2222 0a0a 2020 2020 2020 2020 6966 2069  ""..        if i
-00017d30: 7369 6e73 7461 6e63 6528 7072 6f6a 6563  sinstance(projec
-00017d40: 742c 206d 6c72 756e 2e61 7069 2e73 6368  t, mlrun.api.sch
-00017d50: 656d 6173 2e50 726f 6a65 6374 293a 0a20  emas.Project):. 
-00017d60: 2020 2020 2020 2020 2020 2070 726f 6a65             proje
-00017d70: 6374 203d 2070 726f 6a65 6374 2e64 6963  ct = project.dic
-00017d80: 7428 290a 2020 2020 2020 2020 656c 6966  t().        elif
-00017d90: 2069 7369 6e73 7461 6e63 6528 7072 6f6a   isinstance(proj
-00017da0: 6563 742c 206d 6c72 756e 2e70 726f 6a65  ect, mlrun.proje
-00017db0: 6374 732e 4d6c 7275 6e50 726f 6a65 6374  cts.MlrunProject
-00017dc0: 293a 0a20 2020 2020 2020 2020 2020 2070  ):.            p
-00017dd0: 726f 6a65 6374 203d 2070 726f 6a65 6374  roject = project
-00017de0: 2e74 6f5f 6469 6374 2829 0a20 2020 2020  .to_dict().     
-00017df0: 2020 2070 726f 6a65 6374 5f6e 616d 6520     project_name 
-00017e00: 3d20 7072 6f6a 6563 745b 226d 6574 6164  = project["metad
-00017e10: 6174 6122 5d5b 226e 616d 6522 5d0a 2020  ata"]["name"].  
-00017e20: 2020 2020 2020 6572 726f 725f 6d65 7373        error_mess
-00017e30: 6167 6520 3d20 6622 4661 696c 6564 2063  age = f"Failed c
-00017e40: 7265 6174 696e 6720 7072 6f6a 6563 7420  reating project 
-00017e50: 7b70 726f 6a65 6374 5f6e 616d 657d 220a  {project_name}".
-00017e60: 2020 2020 2020 2020 7265 7370 6f6e 7365          response
-00017e70: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
-00017e80: 280a 2020 2020 2020 2020 2020 2020 2250  (.            "P
-00017e90: 4f53 5422 2c0a 2020 2020 2020 2020 2020  OST",.          
-00017ea0: 2020 2270 726f 6a65 6374 7322 2c0a 2020    "projects",.  
-00017eb0: 2020 2020 2020 2020 2020 6572 726f 725f            error_
-00017ec0: 6d65 7373 6167 652c 0a20 2020 2020 2020  message,.       
-00017ed0: 2020 2020 2062 6f64 793d 6469 6374 5f74       body=dict_t
-00017ee0: 6f5f 6a73 6f6e 2870 726f 6a65 6374 292c  o_json(project),
-00017ef0: 0a20 2020 2020 2020 2029 0a20 2020 2020  .        ).     
-00017f00: 2020 2069 6620 7265 7370 6f6e 7365 2e73     if response.s
-00017f10: 7461 7475 735f 636f 6465 203d 3d20 6874  tatus_code == ht
-00017f20: 7470 2e48 5454 5053 7461 7475 732e 4143  tp.HTTPStatus.AC
-00017f30: 4345 5054 4544 3a0a 2020 2020 2020 2020  CEPTED:.        
-00017f40: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-00017f50: 5f77 6169 745f 666f 725f 7072 6f6a 6563  _wait_for_projec
-00017f60: 745f 746f 5f72 6561 6368 5f74 6572 6d69  t_to_reach_termi
-00017f70: 6e61 6c5f 7374 6174 6528 7072 6f6a 6563  nal_state(projec
-00017f80: 745f 6e61 6d65 290a 2020 2020 2020 2020  t_name).        
-00017f90: 7265 7475 726e 206d 6c72 756e 2e70 726f  return mlrun.pro
-00017fa0: 6a65 6374 732e 4d6c 7275 6e50 726f 6a65  jects.MlrunProje
-00017fb0: 6374 2e66 726f 6d5f 6469 6374 2872 6573  ct.from_dict(res
-00017fc0: 706f 6e73 652e 6a73 6f6e 2829 290a 0a20  ponse.json()).. 
-00017fd0: 2020 2064 6566 205f 7761 6974 5f66 6f72     def _wait_for
-00017fe0: 5f70 726f 6a65 6374 5f74 6f5f 7265 6163  _project_to_reac
-00017ff0: 685f 7465 726d 696e 616c 5f73 7461 7465  h_terminal_state
-00018000: 280a 2020 2020 2020 2020 7365 6c66 2c20  (.        self, 
-00018010: 7072 6f6a 6563 745f 6e61 6d65 3a20 7374  project_name: st
-00018020: 720a 2020 2020 2920 2d3e 206d 6c72 756e  r.    ) -> mlrun
-00018030: 2e70 726f 6a65 6374 732e 4d6c 7275 6e50  .projects.MlrunP
-00018040: 726f 6a65 6374 3a0a 2020 2020 2020 2020  roject:.        
-00018050: 6465 6620 5f76 6572 6966 795f 7072 6f6a  def _verify_proj
-00018060: 6563 745f 696e 5f74 6572 6d69 6e61 6c5f  ect_in_terminal_
-00018070: 7374 6174 6528 293a 0a20 2020 2020 2020  state():.       
-00018080: 2020 2020 2070 726f 6a65 6374 203d 2073       project = s
-00018090: 656c 662e 6765 745f 7072 6f6a 6563 7428  elf.get_project(
-000180a0: 7072 6f6a 6563 745f 6e61 6d65 290a 2020  project_name).  
-000180b0: 2020 2020 2020 2020 2020 6966 2028 0a20            if (. 
-000180c0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-000180d0: 726f 6a65 6374 2e73 7461 7475 732e 7374  roject.status.st
-000180e0: 6174 650a 2020 2020 2020 2020 2020 2020  ate.            
-000180f0: 2020 2020 6e6f 7420 696e 206d 6c72 756e      not in mlrun
-00018100: 2e61 7069 2e73 6368 656d 6173 2e50 726f  .api.schemas.Pro
-00018110: 6a65 6374 5374 6174 652e 7465 726d 696e  jectState.termin
-00018120: 616c 5f73 7461 7465 7328 290a 2020 2020  al_states().    
-00018130: 2020 2020 2020 2020 293a 0a20 2020 2020          ):.     
-00018140: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00018150: 2045 7863 6570 7469 6f6e 280a 2020 2020   Exception(.    
-00018160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018170: 6622 5072 6f6a 6563 7420 6e6f 7420 696e  f"Project not in
-00018180: 2074 6572 6d69 6e61 6c20 7374 6174 652e   terminal state.
-00018190: 2053 7461 7465 3a20 7b70 726f 6a65 6374   State: {project
-000181a0: 2e73 7461 7475 732e 7374 6174 657d 220a  .status.state}".
-000181b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000181c0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
-000181d0: 7475 726e 2070 726f 6a65 6374 0a0a 2020  turn project..  
-000181e0: 2020 2020 2020 7265 7475 726e 206d 6c72        return mlr
-000181f0: 756e 2e75 7469 6c73 2e68 656c 7065 7273  un.utils.helpers
-00018200: 2e72 6574 7279 5f75 6e74 696c 5f73 7563  .retry_until_suc
-00018210: 6365 7373 6675 6c28 0a20 2020 2020 2020  cessful(.       
-00018220: 2020 2020 2073 656c 662e 5f77 6169 745f       self._wait_
-00018230: 666f 725f 7072 6f6a 6563 745f 7465 726d  for_project_term
-00018240: 696e 616c 5f73 7461 7465 5f72 6574 7279  inal_state_retry
-00018250: 5f69 6e74 6572 7661 6c2c 0a20 2020 2020  _interval,.     
-00018260: 2020 2020 2020 2031 3230 2c0a 2020 2020         120,.    
-00018270: 2020 2020 2020 2020 6c6f 6767 6572 2c0a          logger,.
-00018280: 2020 2020 2020 2020 2020 2020 4661 6c73              Fals
-00018290: 652c 0a20 2020 2020 2020 2020 2020 205f  e,.            _
-000182a0: 7665 7269 6679 5f70 726f 6a65 6374 5f69  verify_project_i
-000182b0: 6e5f 7465 726d 696e 616c 5f73 7461 7465  n_terminal_state
-000182c0: 2c0a 2020 2020 2020 2020 290a 0a20 2020  ,.        )..   
-000182d0: 2064 6566 205f 7761 6974 5f66 6f72 5f62   def _wait_for_b
-000182e0: 6163 6b67 726f 756e 645f 7461 736b 5f74  ackground_task_t
-000182f0: 6f5f 7265 6163 685f 7465 726d 696e 616c  o_reach_terminal
-00018300: 5f73 7461 7465 280a 2020 2020 2020 2020  _state(.        
-00018310: 7365 6c66 2c20 6e61 6d65 3a20 7374 720a  self, name: str.
-00018320: 2020 2020 2920 2d3e 2073 6368 656d 6173      ) -> schemas
-00018330: 2e42 6163 6b67 726f 756e 6454 6173 6b3a  .BackgroundTask:
-00018340: 0a20 2020 2020 2020 2064 6566 205f 7665  .        def _ve
-00018350: 7269 6679 5f62 6163 6b67 726f 756e 645f  rify_background_
-00018360: 7461 736b 5f69 6e5f 7465 726d 696e 616c  task_in_terminal
-00018370: 5f73 7461 7465 2829 3a0a 2020 2020 2020  _state():.      
-00018380: 2020 2020 2020 6261 636b 6772 6f75 6e64        background
-00018390: 5f74 6173 6b20 3d20 7365 6c66 2e67 6574  _task = self.get
-000183a0: 5f62 6163 6b67 726f 756e 645f 7461 736b  _background_task
-000183b0: 286e 616d 6529 0a20 2020 2020 2020 2020  (name).         
-000183c0: 2020 2073 7461 7465 203d 2062 6163 6b67     state = backg
-000183d0: 726f 756e 645f 7461 736b 2e73 7461 7475  round_task.statu
-000183e0: 732e 7374 6174 650a 2020 2020 2020 2020  s.state.        
-000183f0: 2020 2020 6966 2073 7461 7465 206e 6f74      if state not
-00018400: 2069 6e20 6d6c 7275 6e2e 6170 692e 7363   in mlrun.api.sc
-00018410: 6865 6d61 732e 4261 636b 6772 6f75 6e64  hemas.Background
-00018420: 5461 736b 5374 6174 652e 7465 726d 696e  TaskState.termin
-00018430: 616c 5f73 7461 7465 7328 293a 0a20 2020  al_states():.   
-00018440: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-00018450: 7365 2045 7863 6570 7469 6f6e 280a 2020  se Exception(.  
-00018460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018470: 2020 6622 4261 636b 6772 6f75 6e64 2074    f"Background t
-00018480: 6173 6b20 6e6f 7420 696e 2074 6572 6d69  ask not in termi
-00018490: 6e61 6c20 7374 6174 652e 206e 616d 653d  nal state. name=
-000184a0: 7b6e 616d 657d 2c20 7374 6174 653d 7b73  {name}, state={s
-000184b0: 7461 7465 7d22 0a20 2020 2020 2020 2020  tate}".         
-000184c0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
-000184d0: 2020 2020 2072 6574 7572 6e20 6261 636b       return back
-000184e0: 6772 6f75 6e64 5f74 6173 6b0a 0a20 2020  ground_task..   
-000184f0: 2020 2020 2072 6574 7572 6e20 6d6c 7275       return mlru
-00018500: 6e2e 7574 696c 732e 6865 6c70 6572 732e  n.utils.helpers.
-00018510: 7265 7472 795f 756e 7469 6c5f 7375 6363  retry_until_succ
-00018520: 6573 7366 756c 280a 2020 2020 2020 2020  essful(.        
-00018530: 2020 2020 7365 6c66 2e5f 7761 6974 5f66      self._wait_f
-00018540: 6f72 5f62 6163 6b67 726f 756e 645f 7461  or_background_ta
-00018550: 736b 5f74 6572 6d69 6e61 6c5f 7374 6174  sk_terminal_stat
-00018560: 655f 7265 7472 795f 696e 7465 7276 616c  e_retry_interval
-00018570: 2c0a 2020 2020 2020 2020 2020 2020 3630  ,.            60
-00018580: 202a 2036 302c 0a20 2020 2020 2020 2020   * 60,.         
-00018590: 2020 206c 6f67 6765 722c 0a20 2020 2020     logger,.     
-000185a0: 2020 2020 2020 2046 616c 7365 2c0a 2020         False,.  
-000185b0: 2020 2020 2020 2020 2020 5f76 6572 6966            _verif
-000185c0: 795f 6261 636b 6772 6f75 6e64 5f74 6173  y_background_tas
-000185d0: 6b5f 696e 5f74 6572 6d69 6e61 6c5f 7374  k_in_terminal_st
-000185e0: 6174 652c 0a20 2020 2020 2020 2029 0a0a  ate,.        )..
-000185f0: 2020 2020 6465 6620 5f77 6169 745f 666f      def _wait_fo
-00018600: 725f 7072 6f6a 6563 745f 746f 5f62 655f  r_project_to_be_
-00018610: 6465 6c65 7465 6428 7365 6c66 2c20 7072  deleted(self, pr
-00018620: 6f6a 6563 745f 6e61 6d65 3a20 7374 7229  oject_name: str)
-00018630: 3a0a 2020 2020 2020 2020 6465 6620 5f76  :.        def _v
-00018640: 6572 6966 795f 7072 6f6a 6563 745f 6465  erify_project_de
-00018650: 6c65 7465 6428 293a 0a20 2020 2020 2020  leted():.       
-00018660: 2020 2020 2070 726f 6a65 6374 7320 3d20       projects = 
-00018670: 7365 6c66 2e6c 6973 745f 7072 6f6a 6563  self.list_projec
-00018680: 7473 280a 2020 2020 2020 2020 2020 2020  ts(.            
-00018690: 2020 2020 666f 726d 6174 5f3d 6d6c 7275      format_=mlru
-000186a0: 6e2e 6170 692e 7363 6865 6d61 732e 5072  n.api.schemas.Pr
-000186b0: 6f6a 6563 7473 466f 726d 6174 2e6e 616d  ojectsFormat.nam
-000186c0: 655f 6f6e 6c79 0a20 2020 2020 2020 2020  e_only.         
-000186d0: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
-000186e0: 2069 6620 7072 6f6a 6563 745f 6e61 6d65   if project_name
-000186f0: 2069 6e20 7072 6f6a 6563 7473 3a0a 2020   in projects:.  
-00018700: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-00018710: 6973 6520 4578 6365 7074 696f 6e28 2250  ise Exception("P
-00018720: 726f 6a65 6374 2073 7469 6c6c 2065 7869  roject still exi
-00018730: 7374 7322 290a 0a20 2020 2020 2020 2072  sts")..        r
-00018740: 6574 7572 6e20 6d6c 7275 6e2e 7574 696c  eturn mlrun.util
-00018750: 732e 6865 6c70 6572 732e 7265 7472 795f  s.helpers.retry_
-00018760: 756e 7469 6c5f 7375 6363 6573 7366 756c  until_successful
-00018770: 280a 2020 2020 2020 2020 2020 2020 7365  (.            se
-00018780: 6c66 2e5f 7761 6974 5f66 6f72 5f70 726f  lf._wait_for_pro
-00018790: 6a65 6374 5f64 656c 6574 696f 6e5f 696e  ject_deletion_in
-000187a0: 7465 7276 616c 2c0a 2020 2020 2020 2020  terval,.        
-000187b0: 2020 2020 3132 302c 0a20 2020 2020 2020      120,.       
-000187c0: 2020 2020 206c 6f67 6765 722c 0a20 2020       logger,.   
-000187d0: 2020 2020 2020 2020 2046 616c 7365 2c0a           False,.
-000187e0: 2020 2020 2020 2020 2020 2020 5f76 6572              _ver
-000187f0: 6966 795f 7072 6f6a 6563 745f 6465 6c65  ify_project_dele
-00018800: 7465 642c 0a20 2020 2020 2020 2029 0a0a  ted,.        )..
-00018810: 2020 2020 6465 6620 6372 6561 7465 5f70      def create_p
-00018820: 726f 6a65 6374 5f73 6563 7265 7473 280a  roject_secrets(.
-00018830: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
-00018840: 2020 2020 2020 7072 6f6a 6563 743a 2073        project: s
-00018850: 7472 2c0a 2020 2020 2020 2020 7072 6f76  tr,.        prov
-00018860: 6964 6572 3a20 556e 696f 6e5b 0a20 2020  ider: Union[.   
-00018870: 2020 2020 2020 2020 2073 7472 2c20 7363           str, sc
-00018880: 6865 6d61 732e 5365 6372 6574 5072 6f76  hemas.SecretProv
-00018890: 6964 6572 4e61 6d65 0a20 2020 2020 2020  iderName.       
-000188a0: 205d 203d 2073 6368 656d 6173 2e53 6563   ] = schemas.Sec
-000188b0: 7265 7450 726f 7669 6465 724e 616d 652e  retProviderName.
-000188c0: 6b75 6265 726e 6574 6573 2c0a 2020 2020  kubernetes,.    
-000188d0: 2020 2020 7365 6372 6574 733a 2064 6963      secrets: dic
-000188e0: 7420 3d20 4e6f 6e65 2c0a 2020 2020 293a  t = None,.    ):
-000188f0: 0a20 2020 2020 2020 2022 2222 4372 6561  .        """Crea
-00018900: 7465 2070 726f 6a65 6374 2d63 6f6e 7465  te project-conte
-00018910: 7874 2073 6563 7265 7473 2075 7369 6e67  xt secrets using
-00018920: 2065 6974 6865 7220 6060 7661 756c 7460   either ``vault`
-00018930: 6020 6f72 2060 606b 7562 6572 6e65 7465  ` or ``kubernete
-00018940: 7360 6020 7072 6f76 6964 6572 2e0a 2020  s`` provider..  
-00018950: 2020 2020 2020 5768 656e 2075 7369 6e67        When using
-00018960: 2077 6974 6820 5661 756c 742c 2074 6869   with Vault, thi
-00018970: 7320 7769 6c6c 2063 7265 6174 6520 6e65  s will create ne
-00018980: 6564 6564 2056 6175 6c74 2073 7472 7563  eded Vault struc
-00018990: 7475 7265 7320 666f 7220 7374 6f72 696e  tures for storin
-000189a0: 6720 7365 6372 6574 7320 696e 2070 726f  g secrets in pro
-000189b0: 6a65 6374 2d63 6f6e 7465 7874 2c20 616e  ject-context, an
-000189c0: 640a 2020 2020 2020 2020 7374 6f72 6520  d.        store 
-000189d0: 6120 7365 7420 6f66 2073 6563 7265 7420  a set of secret 
-000189e0: 7661 6c75 6573 2e20 5468 6520 6d65 7468  values. The meth
-000189f0: 6f64 2067 656e 6572 6174 6573 204b 7562  od generates Kub
-00018a00: 6572 6e65 7465 7320 7365 7276 6963 652d  ernetes service-
-00018a10: 6163 636f 756e 7420 616e 6420 7468 6520  account and the 
-00018a20: 5661 756c 7420 6175 7468 656e 7469 6361  Vault authentica
-00018a30: 7469 6f6e 0a20 2020 2020 2020 2073 7472  tion.        str
-00018a40: 7563 7475 7265 7320 7468 6174 2061 7265  uctures that are
-00018a50: 2072 6571 7569 7265 6420 666f 7220 6675   required for fu
-00018a60: 6e63 7469 6f6e 2050 6f64 7320 746f 2061  nction Pods to a
-00018a70: 7574 6865 6e74 6963 6174 6520 7769 7468  uthenticate with
-00018a80: 2056 6175 6c74 2061 6e64 2062 6520 6162   Vault and be ab
-00018a90: 6c65 2074 6f20 6578 7472 6163 7420 7365  le to extract se
-00018aa0: 6372 6574 2076 616c 7565 730a 2020 2020  cret values.    
-00018ab0: 2020 2020 7061 7373 6564 2061 7320 7061      passed as pa
-00018ac0: 7274 206f 6620 7468 6569 7220 636f 6e74  rt of their cont
-00018ad0: 6578 742e 0a0a 2020 2020 2020 2020 4e6f  ext...        No
-00018ae0: 7465 3a0a 2020 2020 2020 2020 2020 2020  te:.            
-00018af0: 2020 2020 5468 6973 206d 6574 686f 6420      This method 
-00018b00: 7573 6564 2077 6974 6820 5661 756c 7420  used with Vault 
-00018b10: 6973 2063 7572 7265 6e74 6c79 2069 6e20  is currently in 
-00018b20: 7465 6368 6e69 6361 6c20 7072 6576 6965  technical previe
-00018b30: 772c 2061 6e64 2072 6571 7569 7265 7320  w, and requires 
-00018b40: 6120 4861 7368 6943 6f72 7020 5661 756c  a HashiCorp Vaul
-00018b50: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-00018b60: 2020 696e 6672 6173 7472 7563 7475 7265    infrastructure
-00018b70: 2070 726f 7065 726c 7920 7365 7420 7570   properly set up
-00018b80: 2061 6e64 2063 6f6e 6e65 6374 6564 2074   and connected t
-00018b90: 6f20 7468 6520 4d4c 5275 6e20 4150 4920  o the MLRun API 
-00018ba0: 7365 7276 6572 2e0a 0a20 2020 2020 2020  server...       
-00018bb0: 2057 6865 6e20 7573 6564 2077 6974 6820   When used with 
-00018bc0: 4b75 6265 726e 6574 6573 2c20 7468 6973  Kubernetes, this
-00018bd0: 2077 696c 6c20 6d61 6b65 2073 7572 6520   will make sure 
-00018be0: 7468 6174 2074 6865 2070 726f 6a65 6374  that the project
-00018bf0: 2d73 7065 6369 6669 6320 6b38 7320 7365  -specific k8s se
-00018c00: 6372 6574 2069 7320 6372 6561 7465 642c  cret is created,
-00018c10: 2061 6e64 2077 696c 6c0a 2020 2020 2020   and will.      
-00018c20: 2020 706f 7075 6c61 7465 2069 7420 7769    populate it wi
-00018c30: 7468 2074 6865 2073 6563 7265 7473 2070  th the secrets p
-00018c40: 726f 7669 6465 642c 2072 6570 6c61 6369  rovided, replaci
-00018c50: 6e67 2074 6865 6972 2076 616c 7565 7320  ng their values 
-00018c60: 6966 2074 6865 7920 6578 6973 742e 0a0a  if they exist...
-00018c70: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
-00018c80: 726f 6a65 6374 3a20 5468 6520 7072 6f6a  roject: The proj
-00018c90: 6563 7420 636f 6e74 6578 7420 666f 7220  ect context for 
-00018ca0: 7768 6963 6820 746f 2067 656e 6572 6174  which to generat
-00018cb0: 6520 7468 6520 696e 6672 6120 616e 6420  e the infra and 
-00018cc0: 7374 6f72 6520 7365 6372 6574 732e 0a20  store secrets.. 
-00018cd0: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
-00018ce0: 6f76 6964 6572 3a20 5468 6520 6e61 6d65  ovider: The name
-00018cf0: 206f 6620 7468 6520 7365 6372 6574 732d   of the secrets-
-00018d00: 7072 6f76 6964 6572 2074 6f20 776f 726b  provider to work
-00018d10: 2077 6974 682e 2041 6363 6570 7473 2061   with. Accepts a
-00018d20: 0a20 2020 2020 2020 2020 2020 203a 7079  .            :py
-00018d30: 3a63 6c61 7373 3a60 7e6d 6c72 756e 2e61  :class:`~mlrun.a
-00018d40: 7069 2e73 6368 656d 6173 2e73 6563 7265  pi.schemas.secre
-00018d50: 742e 5365 6372 6574 5072 6f76 6964 6572  t.SecretProvider
-00018d60: 4e61 6d65 6020 656e 756d 2e0a 2020 2020  Name` enum..    
-00018d70: 2020 2020 3a70 6172 616d 2073 6563 7265      :param secre
-00018d80: 7473 3a20 4120 7365 7420 6f66 2073 6563  ts: A set of sec
-00018d90: 7265 7420 7661 6c75 6573 2074 6f20 7374  ret values to st
-00018da0: 6f72 652e 0a20 2020 2020 2020 2020 2020  ore..           
-00018db0: 2045 7861 6d70 6c65 3a3a 0a0a 2020 2020   Example::..    
-00018dc0: 2020 2020 2020 2020 2020 2020 7365 6372              secr
-00018dd0: 6574 7320 3d20 7b27 7061 7373 776f 7264  ets = {'password
-00018de0: 273a 2027 6d79 5061 7373 7730 7264 272c  ': 'myPassw0rd',
-00018df0: 2027 6177 735f 6b65 7927 3a20 2731 3131   'aws_key': '111
-00018e00: 3232 3233 3333 277d 0a20 2020 2020 2020  222333'}.       
-00018e10: 2020 2020 2020 2020 2064 622e 6372 6561           db.crea
-00018e20: 7465 5f70 726f 6a65 6374 5f73 6563 7265  te_project_secre
-00018e30: 7473 280a 2020 2020 2020 2020 2020 2020  ts(.            
-00018e40: 2020 2020 2020 2020 2270 726f 6a65 6374          "project
-00018e50: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
-00018e60: 2020 2020 2020 2020 7072 6f76 6964 6572          provider
-00018e70: 3d6d 6c72 756e 2e61 7069 2e73 6368 656d  =mlrun.api.schem
-00018e80: 6173 2e53 6563 7265 7450 726f 7669 6465  as.SecretProvide
-00018e90: 724e 616d 652e 6b75 6265 726e 6574 6573  rName.kubernetes
-00018ea0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00018eb0: 2020 2020 2020 7365 6372 6574 733d 7365        secrets=se
-00018ec0: 6372 6574 730a 2020 2020 2020 2020 2020  crets.          
-00018ed0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-00018ee0: 2222 220a 2020 2020 2020 2020 7061 7468  """.        path
-00018ef0: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
-00018f00: 726f 6a65 6374 7d2f 7365 6372 6574 7322  roject}/secrets"
-00018f10: 0a20 2020 2020 2020 2073 6563 7265 7473  .        secrets
-00018f20: 5f69 6e70 7574 203d 2073 6368 656d 6173  _input = schemas
-00018f30: 2e53 6563 7265 7473 4461 7461 2873 6563  .SecretsData(sec
-00018f40: 7265 7473 3d73 6563 7265 7473 2c20 7072  rets=secrets, pr
-00018f50: 6f76 6964 6572 3d70 726f 7669 6465 7229  ovider=provider)
-00018f60: 0a20 2020 2020 2020 2062 6f64 7920 3d20  .        body = 
-00018f70: 7365 6372 6574 735f 696e 7075 742e 6469  secrets_input.di
-00018f80: 6374 2829 0a20 2020 2020 2020 2065 7272  ct().        err
-00018f90: 6f72 5f6d 6573 7361 6765 203d 2066 2246  or_message = f"F
-00018fa0: 6169 6c65 6420 6372 6561 7469 6e67 2073  ailed creating s
-00018fb0: 6563 7265 7420 7072 6f76 6964 6572 207b  ecret provider {
-00018fc0: 7072 6f6a 6563 747d 2f7b 7072 6f76 6964  project}/{provid
-00018fd0: 6572 7d22 0a20 2020 2020 2020 2073 656c  er}".        sel
-00018fe0: 662e 6170 695f 6361 6c6c 280a 2020 2020  f.api_call(.    
-00018ff0: 2020 2020 2020 2020 2250 4f53 5422 2c0a          "POST",.
-00019000: 2020 2020 2020 2020 2020 2020 7061 7468              path
-00019010: 2c0a 2020 2020 2020 2020 2020 2020 6572  ,.            er
-00019020: 726f 725f 6d65 7373 6167 652c 0a20 2020  ror_message,.   
-00019030: 2020 2020 2020 2020 2062 6f64 793d 6469           body=di
-00019040: 6374 5f74 6f5f 6a73 6f6e 2862 6f64 7929  ct_to_json(body)
-00019050: 2c0a 2020 2020 2020 2020 290a 0a20 2020  ,.        )..   
-00019060: 2064 6566 206c 6973 745f 7072 6f6a 6563   def list_projec
-00019070: 745f 7365 6372 6574 7328 0a20 2020 2020  t_secrets(.     
-00019080: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
-00019090: 2070 726f 6a65 6374 3a20 7374 722c 0a20   project: str,. 
-000190a0: 2020 2020 2020 2074 6f6b 656e 3a20 7374         token: st
-000190b0: 7220 3d20 4e6f 6e65 2c0a 2020 2020 2020  r = None,.      
-000190c0: 2020 7072 6f76 6964 6572 3a20 556e 696f    provider: Unio
-000190d0: 6e5b 0a20 2020 2020 2020 2020 2020 2073  n[.            s
-000190e0: 7472 2c20 7363 6865 6d61 732e 5365 6372  tr, schemas.Secr
-000190f0: 6574 5072 6f76 6964 6572 4e61 6d65 0a20  etProviderName. 
-00019100: 2020 2020 2020 205d 203d 2073 6368 656d         ] = schem
-00019110: 6173 2e53 6563 7265 7450 726f 7669 6465  as.SecretProvide
-00019120: 724e 616d 652e 6b75 6265 726e 6574 6573  rName.kubernetes
-00019130: 2c0a 2020 2020 2020 2020 7365 6372 6574  ,.        secret
-00019140: 733a 204c 6973 745b 7374 725d 203d 204e  s: List[str] = N
-00019150: 6f6e 652c 0a20 2020 2029 202d 3e20 7363  one,.    ) -> sc
-00019160: 6865 6d61 732e 5365 6372 6574 7344 6174  hemas.SecretsDat
-00019170: 613a 0a20 2020 2020 2020 2022 2222 5265  a:.        """Re
-00019180: 7472 6965 7665 2070 726f 6a65 6374 2d63  trieve project-c
-00019190: 6f6e 7465 7874 2073 6563 7265 7473 2066  ontext secrets f
-000191a0: 726f 6d20 5661 756c 742e 0a0a 2020 2020  rom Vault...    
-000191b0: 2020 2020 4e6f 7465 3a0a 2020 2020 2020      Note:.      
-000191c0: 2020 2020 2020 2020 2020 5468 6973 206d            This m
-000191d0: 6574 686f 6420 666f 7220 5661 756c 7420  ethod for Vault 
-000191e0: 6675 6e63 7469 6f6e 616c 6974 7920 6973  functionality is
-000191f0: 2063 7572 7265 6e74 6c79 2069 6e20 7465   currently in te
-00019200: 6368 6e69 6361 6c20 7072 6576 6965 772c  chnical preview,
-00019210: 2061 6e64 2072 6571 7569 7265 7320 6120   and requires a 
-00019220: 4861 7368 6943 6f72 7020 5661 756c 740a  HashiCorp Vault.
-00019230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019240: 696e 6672 6173 7472 7563 7475 7265 2070  infrastructure p
-00019250: 726f 7065 726c 7920 7365 7420 7570 2061  roperly set up a
-00019260: 6e64 2063 6f6e 6e65 6374 6564 2074 6f20  nd connected to 
-00019270: 7468 6520 4d4c 5275 6e20 4150 4920 7365  the MLRun API se
-00019280: 7276 6572 2e0a 0a20 2020 2020 2020 203a  rver...        :
-00019290: 7061 7261 6d20 7072 6f6a 6563 743a 2054  param project: T
-000192a0: 6865 2070 726f 6a65 6374 206e 616d 652e  he project name.
-000192b0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-000192c0: 746f 6b65 6e3a 2056 6175 6c74 2074 6f6b  token: Vault tok
-000192d0: 656e 2074 6f20 7573 6520 666f 7220 7265  en to use for re
-000192e0: 7472 6965 7669 6e67 2073 6563 7265 7473  trieving secrets
-000192f0: 2e0a 2020 2020 2020 2020 2020 2020 4d75  ..            Mu
-00019300: 7374 2062 6520 6120 7661 6c69 6420 5661  st be a valid Va
-00019310: 756c 7420 746f 6b65 6e2c 2077 6974 6820  ult token, with 
-00019320: 7065 726d 6973 7369 6f6e 7320 746f 2072  permissions to r
-00019330: 6574 7269 6576 6520 7365 6372 6574 7320  etrieve secrets 
-00019340: 6f66 2074 6865 2070 726f 6a65 6374 2069  of the project i
-00019350: 6e20 7175 6573 7469 6f6e 2e0a 2020 2020  n question..    
-00019360: 2020 2020 3a70 6172 616d 2070 726f 7669      :param provi
-00019370: 6465 723a 2054 6865 206e 616d 6520 6f66  der: The name of
-00019380: 2074 6865 2073 6563 7265 7473 2d70 726f   the secrets-pro
-00019390: 7669 6465 7220 746f 2077 6f72 6b20 7769  vider to work wi
-000193a0: 7468 2e20 4375 7272 656e 746c 7920 6f6e  th. Currently on
-000193b0: 6c79 2060 6076 6175 6c74 6060 2069 7320  ly ``vault`` is 
-000193c0: 6163 6365 7074 6564 2e0a 2020 2020 2020  accepted..      
-000193d0: 2020 3a70 6172 616d 2073 6563 7265 7473    :param secrets
-000193e0: 3a20 4120 6c69 7374 206f 6620 7365 6372  : A list of secr
-000193f0: 6574 206e 616d 6573 2074 6f20 7265 7472  et names to retr
-00019400: 6965 7665 2e20 416e 2065 6d70 7479 206c  ieve. An empty l
-00019410: 6973 7420 6060 5b5d 6060 2077 696c 6c20  ist ``[]`` will 
-00019420: 7265 7472 6965 7665 2061 6c6c 2073 6563  retrieve all sec
-00019430: 7265 7473 2061 7373 6967 6e65 640a 2020  rets assigned.  
-00019440: 2020 2020 2020 2020 2020 746f 2074 6869            to thi
-00019450: 7320 7370 6563 6966 6963 2070 726f 6a65  s specific proje
-00019460: 6374 2e20 6060 6b75 6265 726e 6574 6573  ct. ``kubernetes
-00019470: 6060 2070 726f 7669 6465 7220 6f6e 6c79  `` provider only
-00019480: 2073 7570 706f 7274 7320 616e 2065 6d70   supports an emp
-00019490: 7479 206c 6973 742e 0a20 2020 2020 2020  ty list..       
-000194a0: 2022 2222 0a0a 2020 2020 2020 2020 6966   """..        if
-000194b0: 2070 726f 7669 6465 7220 3d3d 2073 6368   provider == sch
-000194c0: 656d 6173 2e53 6563 7265 7450 726f 7669  emas.SecretProvi
-000194d0: 6465 724e 616d 652e 7661 756c 742e 7661  derName.vault.va
-000194e0: 6c75 6520 616e 6420 6e6f 7420 746f 6b65  lue and not toke
-000194f0: 6e3a 0a20 2020 2020 2020 2020 2020 2072  n:.            r
-00019500: 6169 7365 204d 4c52 756e 496e 7661 6c69  aise MLRunInvali
-00019510: 6441 7267 756d 656e 7445 7272 6f72 280a  dArgumentError(.
-00019520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019530: 2241 2076 6175 6c74 2074 6f6b 656e 206d  "A vault token m
-00019540: 7573 7420 6265 2070 726f 7669 6465 6420  ust be provided 
-00019550: 7768 656e 2061 6363 6573 7369 6e67 2076  when accessing v
-00019560: 6175 6c74 2073 6563 7265 7473 220a 2020  ault secrets".  
-00019570: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
-00019580: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
-00019590: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
-000195a0: 2f73 6563 7265 7473 220a 2020 2020 2020  /secrets".      
-000195b0: 2020 7061 7261 6d73 203d 207b 2270 726f    params = {"pro
-000195c0: 7669 6465 7222 3a20 7072 6f76 6964 6572  vider": provider
-000195d0: 2c20 2273 6563 7265 7422 3a20 7365 6372  , "secret": secr
-000195e0: 6574 737d 0a20 2020 2020 2020 2068 6561  ets}.        hea
-000195f0: 6465 7273 203d 207b 7363 6865 6d61 732e  ders = {schemas.
-00019600: 4865 6164 6572 4e61 6d65 732e 7365 6372  HeaderNames.secr
-00019610: 6574 5f73 746f 7265 5f74 6f6b 656e 3a20  et_store_token: 
-00019620: 746f 6b65 6e7d 0a20 2020 2020 2020 2065  token}.        e
-00019630: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
-00019640: 2246 6169 6c65 6420 7265 7472 6965 7669  "Failed retrievi
-00019650: 6e67 2073 6563 7265 7473 207b 7072 6f6a  ng secrets {proj
-00019660: 6563 747d 2f7b 7072 6f76 6964 6572 7d22  ect}/{provider}"
-00019670: 0a20 2020 2020 2020 2072 6573 756c 7420  .        result 
-00019680: 3d20 7365 6c66 2e61 7069 5f63 616c 6c28  = self.api_call(
-00019690: 0a20 2020 2020 2020 2020 2020 2022 4745  .            "GE
-000196a0: 5422 2c0a 2020 2020 2020 2020 2020 2020  T",.            
-000196b0: 7061 7468 2c0a 2020 2020 2020 2020 2020  path,.          
-000196c0: 2020 6572 726f 725f 6d65 7373 6167 652c    error_message,
-000196d0: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
-000196e0: 616d 733d 7061 7261 6d73 2c0a 2020 2020  ams=params,.    
-000196f0: 2020 2020 2020 2020 6865 6164 6572 733d          headers=
-00019700: 6865 6164 6572 732c 0a20 2020 2020 2020  headers,.       
-00019710: 2029 0a20 2020 2020 2020 2072 6574 7572   ).        retur
-00019720: 6e20 7363 6865 6d61 732e 5365 6372 6574  n schemas.Secret
-00019730: 7344 6174 6128 2a2a 7265 7375 6c74 2e6a  sData(**result.j
-00019740: 736f 6e28 2929 0a0a 2020 2020 6465 6620  son())..    def 
-00019750: 6c69 7374 5f70 726f 6a65 6374 5f73 6563  list_project_sec
-00019760: 7265 745f 6b65 7973 280a 2020 2020 2020  ret_keys(.      
-00019770: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
-00019780: 7072 6f6a 6563 743a 2073 7472 2c0a 2020  project: str,.  
-00019790: 2020 2020 2020 7072 6f76 6964 6572 3a20        provider: 
-000197a0: 556e 696f 6e5b 0a20 2020 2020 2020 2020  Union[.         
-000197b0: 2020 2073 7472 2c20 7363 6865 6d61 732e     str, schemas.
-000197c0: 5365 6372 6574 5072 6f76 6964 6572 4e61  SecretProviderNa
-000197d0: 6d65 0a20 2020 2020 2020 205d 203d 2073  me.        ] = s
-000197e0: 6368 656d 6173 2e53 6563 7265 7450 726f  chemas.SecretPro
-000197f0: 7669 6465 724e 616d 652e 6b75 6265 726e  viderName.kubern
-00019800: 6574 6573 2c0a 2020 2020 2020 2020 746f  etes,.        to
-00019810: 6b65 6e3a 2073 7472 203d 204e 6f6e 652c  ken: str = None,
-00019820: 0a20 2020 2029 202d 3e20 7363 6865 6d61  .    ) -> schema
-00019830: 732e 5365 6372 6574 4b65 7973 4461 7461  s.SecretKeysData
-00019840: 3a0a 2020 2020 2020 2020 2222 2252 6574  :.        """Ret
-00019850: 7269 6576 6520 7072 6f6a 6563 742d 636f  rieve project-co
-00019860: 6e74 6578 7420 7365 6372 6574 206b 6579  ntext secret key
-00019870: 7320 6672 6f6d 2056 6175 6c74 206f 7220  s from Vault or 
-00019880: 4b75 6265 726e 6574 6573 2e0a 0a20 2020  Kubernetes...   
-00019890: 2020 2020 204e 6f74 653a 0a20 2020 2020       Note:.     
-000198a0: 2020 2020 2020 2020 2020 2054 6869 7320             This 
-000198b0: 6d65 7468 6f64 2066 6f72 2056 6175 6c74  method for Vault
-000198c0: 2066 756e 6374 696f 6e61 6c69 7479 2069   functionality i
-000198d0: 7320 6375 7272 656e 746c 7920 696e 2074  s currently in t
-000198e0: 6563 686e 6963 616c 2070 7265 7669 6577  echnical preview
-000198f0: 2c20 616e 6420 7265 7175 6972 6573 2061  , and requires a
-00019900: 2048 6173 6869 436f 7270 2056 6175 6c74   HashiCorp Vault
-00019910: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019920: 2069 6e66 7261 7374 7275 6374 7572 6520   infrastructure 
-00019930: 7072 6f70 6572 6c79 2073 6574 2075 7020  properly set up 
-00019940: 616e 6420 636f 6e6e 6563 7465 6420 746f  and connected to
-00019950: 2074 6865 204d 4c52 756e 2041 5049 2073   the MLRun API s
-00019960: 6572 7665 722e 0a0a 2020 2020 2020 2020  erver...        
-00019970: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
-00019980: 5468 6520 7072 6f6a 6563 7420 6e61 6d65  The project name
-00019990: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-000199a0: 2070 726f 7669 6465 723a 2054 6865 206e   provider: The n
-000199b0: 616d 6520 6f66 2074 6865 2073 6563 7265  ame of the secre
-000199c0: 7473 2d70 726f 7669 6465 7220 746f 2077  ts-provider to w
-000199d0: 6f72 6b20 7769 7468 2e20 4163 6365 7074  ork with. Accept
-000199e0: 7320 610a 2020 2020 2020 2020 2020 2020  s a.            
-000199f0: 3a70 793a 636c 6173 733a 607e 6d6c 7275  :py:class:`~mlru
-00019a00: 6e2e 6170 692e 7363 6865 6d61 732e 7365  n.api.schemas.se
-00019a10: 6372 6574 2e53 6563 7265 7450 726f 7669  cret.SecretProvi
-00019a20: 6465 724e 616d 6560 2065 6e75 6d2e 0a20  derName` enum.. 
-00019a30: 2020 2020 2020 203a 7061 7261 6d20 746f         :param to
-00019a40: 6b65 6e3a 2056 6175 6c74 2074 6f6b 656e  ken: Vault token
-00019a50: 2074 6f20 7573 6520 666f 7220 7265 7472   to use for retr
-00019a60: 6965 7669 6e67 2073 6563 7265 7473 2e20  ieving secrets. 
-00019a70: 4f6e 6c79 2069 6e20 7573 6520 6966 2060  Only in use if `
-00019a80: 6070 726f 7669 6465 7260 6020 6973 2060  `provider`` is `
-00019a90: 6076 6175 6c74 6060 2e0a 2020 2020 2020  `vault``..      
-00019aa0: 2020 2020 2020 4d75 7374 2062 6520 6120        Must be a 
-00019ab0: 7661 6c69 6420 5661 756c 7420 746f 6b65  valid Vault toke
-00019ac0: 6e2c 2077 6974 6820 7065 726d 6973 7369  n, with permissi
-00019ad0: 6f6e 7320 746f 2072 6574 7269 6576 6520  ons to retrieve 
-00019ae0: 7365 6372 6574 7320 6f66 2074 6865 2070  secrets of the p
-00019af0: 726f 6a65 6374 2069 6e20 7175 6573 7469  roject in questi
-00019b00: 6f6e 2e0a 2020 2020 2020 2020 2222 220a  on..        """.
-00019b10: 0a20 2020 2020 2020 2069 6620 7072 6f76  .        if prov
-00019b20: 6964 6572 203d 3d20 7363 6865 6d61 732e  ider == schemas.
-00019b30: 5365 6372 6574 5072 6f76 6964 6572 4e61  SecretProviderNa
-00019b40: 6d65 2e76 6175 6c74 2e76 616c 7565 2061  me.vault.value a
-00019b50: 6e64 206e 6f74 2074 6f6b 656e 3a0a 2020  nd not token:.  
-00019b60: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00019b70: 4d4c 5275 6e49 6e76 616c 6964 4172 6775  MLRunInvalidArgu
-00019b80: 6d65 6e74 4572 726f 7228 0a20 2020 2020  mentError(.     
-00019b90: 2020 2020 2020 2020 2020 2022 4120 7661             "A va
-00019ba0: 756c 7420 746f 6b65 6e20 6d75 7374 2062  ult token must b
-00019bb0: 6520 7072 6f76 6964 6564 2077 6865 6e20  e provided when 
-00019bc0: 6163 6365 7373 696e 6720 7661 756c 7420  accessing vault 
-00019bd0: 7365 6372 6574 7322 0a20 2020 2020 2020  secrets".       
-00019be0: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
-00019bf0: 7061 7468 203d 2066 2270 726f 6a65 6374  path = f"project
-00019c00: 732f 7b70 726f 6a65 6374 7d2f 7365 6372  s/{project}/secr
-00019c10: 6574 2d6b 6579 7322 0a20 2020 2020 2020  et-keys".       
-00019c20: 2070 6172 616d 7320 3d20 7b22 7072 6f76   params = {"prov
-00019c30: 6964 6572 223a 2070 726f 7669 6465 727d  ider": provider}
-00019c40: 0a20 2020 2020 2020 2068 6561 6465 7273  .        headers
-00019c50: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
-00019c60: 207b 7363 6865 6d61 732e 4865 6164 6572   {schemas.Header
-00019c70: 4e61 6d65 732e 7365 6372 6574 5f73 746f  Names.secret_sto
-00019c80: 7265 5f74 6f6b 656e 3a20 746f 6b65 6e7d  re_token: token}
-00019c90: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00019ca0: 7072 6f76 6964 6572 203d 3d20 7363 6865  provider == sche
-00019cb0: 6d61 732e 5365 6372 6574 5072 6f76 6964  mas.SecretProvid
-00019cc0: 6572 4e61 6d65 2e76 6175 6c74 2e76 616c  erName.vault.val
-00019cd0: 7565 0a20 2020 2020 2020 2020 2020 2065  ue.            e
-00019ce0: 6c73 6520 4e6f 6e65 0a20 2020 2020 2020  lse None.       
-00019cf0: 2029 0a20 2020 2020 2020 2065 7272 6f72   ).        error
-00019d00: 5f6d 6573 7361 6765 203d 2066 2246 6169  _message = f"Fai
-00019d10: 6c65 6420 7265 7472 6965 7669 6e67 2073  led retrieving s
-00019d20: 6563 7265 7420 6b65 7973 207b 7072 6f6a  ecret keys {proj
-00019d30: 6563 747d 2f7b 7072 6f76 6964 6572 7d22  ect}/{provider}"
-00019d40: 0a20 2020 2020 2020 2072 6573 756c 7420  .        result 
-00019d50: 3d20 7365 6c66 2e61 7069 5f63 616c 6c28  = self.api_call(
-00019d60: 0a20 2020 2020 2020 2020 2020 2022 4745  .            "GE
-00019d70: 5422 2c0a 2020 2020 2020 2020 2020 2020  T",.            
-00019d80: 7061 7468 2c0a 2020 2020 2020 2020 2020  path,.          
-00019d90: 2020 6572 726f 725f 6d65 7373 6167 652c    error_message,
-00019da0: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
-00019db0: 616d 733d 7061 7261 6d73 2c0a 2020 2020  ams=params,.    
-00019dc0: 2020 2020 2020 2020 6865 6164 6572 733d          headers=
-00019dd0: 6865 6164 6572 732c 0a20 2020 2020 2020  headers,.       
-00019de0: 2029 0a20 2020 2020 2020 2072 6574 7572   ).        retur
-00019df0: 6e20 7363 6865 6d61 732e 5365 6372 6574  n schemas.Secret
-00019e00: 4b65 7973 4461 7461 282a 2a72 6573 756c  KeysData(**resul
-00019e10: 742e 6a73 6f6e 2829 290a 0a20 2020 2064  t.json())..    d
-00019e20: 6566 2064 656c 6574 655f 7072 6f6a 6563  ef delete_projec
-00019e30: 745f 7365 6372 6574 7328 0a20 2020 2020  t_secrets(.     
-00019e40: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
-00019e50: 2070 726f 6a65 6374 3a20 7374 722c 0a20   project: str,. 
-00019e60: 2020 2020 2020 2070 726f 7669 6465 723a         provider:
-00019e70: 2055 6e69 6f6e 5b0a 2020 2020 2020 2020   Union[.        
-00019e80: 2020 2020 7374 722c 2073 6368 656d 6173      str, schemas
-00019e90: 2e53 6563 7265 7450 726f 7669 6465 724e  .SecretProviderN
-00019ea0: 616d 650a 2020 2020 2020 2020 5d20 3d20  ame.        ] = 
-00019eb0: 7363 6865 6d61 732e 5365 6372 6574 5072  schemas.SecretPr
-00019ec0: 6f76 6964 6572 4e61 6d65 2e6b 7562 6572  oviderName.kuber
-00019ed0: 6e65 7465 732c 0a20 2020 2020 2020 2073  netes,.        s
-00019ee0: 6563 7265 7473 3a20 4c69 7374 5b73 7472  ecrets: List[str
-00019ef0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 293a  ] = None,.    ):
-00019f00: 0a20 2020 2020 2020 2022 2222 4465 6c65  .        """Dele
-00019f10: 7465 2070 726f 6a65 6374 2d63 6f6e 7465  te project-conte
-00019f20: 7874 2073 6563 7265 7473 2066 726f 6d20  xt secrets from 
-00019f30: 4b75 6265 726e 6574 6573 2e0a 0a20 2020  Kubernetes...   
-00019f40: 2020 2020 203a 7061 7261 6d20 7072 6f6a       :param proj
-00019f50: 6563 743a 2054 6865 2070 726f 6a65 6374  ect: The project
-00019f60: 206e 616d 652e 0a20 2020 2020 2020 203a   name..        :
-00019f70: 7061 7261 6d20 7072 6f76 6964 6572 3a20  param provider: 
-00019f80: 5468 6520 6e61 6d65 206f 6620 7468 6520  The name of the 
-00019f90: 7365 6372 6574 732d 7072 6f76 6964 6572  secrets-provider
-00019fa0: 2074 6f20 776f 726b 2077 6974 682e 2043   to work with. C
-00019fb0: 7572 7265 6e74 6c79 206f 6e6c 7920 6060  urrently only ``
-00019fc0: 6b75 6265 726e 6574 6573 6060 2069 7320  kubernetes`` is 
-00019fd0: 7375 7070 6f72 7465 642e 0a20 2020 2020  supported..     
-00019fe0: 2020 203a 7061 7261 6d20 7365 6372 6574     :param secret
-00019ff0: 733a 2041 206c 6973 7420 6f66 2073 6563  s: A list of sec
-0001a000: 7265 7420 6e61 6d65 7320 746f 2064 656c  ret names to del
-0001a010: 6574 652e 2041 6e20 656d 7074 7920 6c69  ete. An empty li
-0001a020: 7374 2077 696c 6c20 6465 6c65 7465 2061  st will delete a
-0001a030: 6c6c 2073 6563 7265 7473 2061 7373 6967  ll secrets assig
-0001a040: 6e65 640a 2020 2020 2020 2020 2020 2020  ned.            
-0001a050: 746f 2074 6869 7320 7370 6563 6966 6963  to this specific
-0001a060: 2070 726f 6a65 6374 2e0a 2020 2020 2020   project..      
-0001a070: 2020 2222 220a 0a20 2020 2020 2020 2070    """..        p
-0001a080: 6174 6820 3d20 6622 7072 6f6a 6563 7473  ath = f"projects
-0001a090: 2f7b 7072 6f6a 6563 747d 2f73 6563 7265  /{project}/secre
-0001a0a0: 7473 220a 2020 2020 2020 2020 7061 7261  ts".        para
-0001a0b0: 6d73 203d 207b 2270 726f 7669 6465 7222  ms = {"provider"
-0001a0c0: 3a20 7072 6f76 6964 6572 2c20 2273 6563  : provider, "sec
-0001a0d0: 7265 7422 3a20 7365 6372 6574 737d 0a20  ret": secrets}. 
-0001a0e0: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
-0001a0f0: 7361 6765 203d 2066 2246 6169 6c65 6420  sage = f"Failed 
-0001a100: 6465 6c65 7469 6e67 2073 6563 7265 7473  deleting secrets
-0001a110: 207b 7072 6f6a 6563 747d 2f7b 7072 6f76   {project}/{prov
-0001a120: 6964 6572 7d22 0a20 2020 2020 2020 2073  ider}".        s
-0001a130: 656c 662e 6170 695f 6361 6c6c 280a 2020  elf.api_call(.  
-0001a140: 2020 2020 2020 2020 2020 2244 454c 4554            "DELET
-0001a150: 4522 2c0a 2020 2020 2020 2020 2020 2020  E",.            
-0001a160: 7061 7468 2c0a 2020 2020 2020 2020 2020  path,.          
-0001a170: 2020 6572 726f 725f 6d65 7373 6167 652c    error_message,
-0001a180: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
-0001a190: 616d 733d 7061 7261 6d73 2c0a 2020 2020  ams=params,.    
-0001a1a0: 2020 2020 290a 0a20 2020 2064 6566 2063      )..    def c
-0001a1b0: 7265 6174 655f 7573 6572 5f73 6563 7265  reate_user_secre
-0001a1c0: 7473 280a 2020 2020 2020 2020 7365 6c66  ts(.        self
-0001a1d0: 2c0a 2020 2020 2020 2020 7573 6572 3a20  ,.        user: 
-0001a1e0: 7374 722c 0a20 2020 2020 2020 2070 726f  str,.        pro
-0001a1f0: 7669 6465 723a 2055 6e69 6f6e 5b0a 2020  vider: Union[.  
-0001a200: 2020 2020 2020 2020 2020 7374 722c 2073            str, s
-0001a210: 6368 656d 6173 2e53 6563 7265 7450 726f  chemas.SecretPro
-0001a220: 7669 6465 724e 616d 650a 2020 2020 2020  viderName.      
-0001a230: 2020 5d20 3d20 7363 6865 6d61 732e 5365    ] = schemas.Se
-0001a240: 6372 6574 5072 6f76 6964 6572 4e61 6d65  cretProviderName
-0001a250: 2e76 6175 6c74 2c0a 2020 2020 2020 2020  .vault,.        
-0001a260: 7365 6372 6574 733a 2064 6963 7420 3d20  secrets: dict = 
-0001a270: 4e6f 6e65 2c0a 2020 2020 293a 0a20 2020  None,.    ):.   
-0001a280: 2020 2020 2022 2222 4372 6561 7465 2075       """Create u
-0001a290: 7365 722d 636f 6e74 6578 7420 7365 6372  ser-context secr
-0001a2a0: 6574 2069 6e20 5661 756c 742e 2050 6c65  et in Vault. Ple
-0001a2b0: 6173 6520 7265 6665 7220 746f 203a 7079  ase refer to :py
-0001a2c0: 3a66 756e 633a 6063 7265 6174 655f 7072  :func:`create_pr
-0001a2d0: 6f6a 6563 745f 7365 6372 6574 7360 2066  oject_secrets` f
-0001a2e0: 6f72 206d 6f72 6520 6465 7461 696c 730a  or more details.
-0001a2f0: 2020 2020 2020 2020 616e 6420 7374 6174          and stat
-0001a300: 7573 206f 6620 7468 6973 2066 756e 6374  us of this funct
-0001a310: 696f 6e61 6c69 7479 2e0a 0a20 2020 2020  ionality...     
-0001a320: 2020 204e 6f74 653a 0a20 2020 2020 2020     Note:.       
-0001a330: 2020 2020 2020 2020 2054 6869 7320 6d65           This me
-0001a340: 7468 6f64 2069 7320 6375 7272 656e 746c  thod is currentl
-0001a350: 7920 696e 2074 6563 686e 6963 616c 2070  y in technical p
-0001a360: 7265 7669 6577 2c20 616e 6420 7265 7175  review, and requ
-0001a370: 6972 6573 2061 2048 6173 6869 436f 7270  ires a HashiCorp
-0001a380: 2056 6175 6c74 2069 6e66 7261 7374 7275   Vault infrastru
-0001a390: 6374 7572 650a 2020 2020 2020 2020 2020  cture.          
-0001a3a0: 2020 2020 2020 7072 6f70 6572 6c79 2073        properly s
-0001a3b0: 6574 2075 7020 616e 6420 636f 6e6e 6563  et up and connec
-0001a3c0: 7465 6420 746f 2074 6865 204d 4c52 756e  ted to the MLRun
-0001a3d0: 2041 5049 2073 6572 7665 722e 0a0a 2020   API server...  
-0001a3e0: 2020 2020 2020 3a70 6172 616d 2075 7365        :param use
-0001a3f0: 723a 2054 6865 2075 7365 7220 636f 6e74  r: The user cont
-0001a400: 6578 7420 666f 7220 7768 6963 6820 746f  ext for which to
-0001a410: 2067 656e 6572 6174 6520 7468 6520 696e   generate the in
-0001a420: 6672 6120 616e 6420 7374 6f72 6520 7365  fra and store se
-0001a430: 6372 6574 732e 0a20 2020 2020 2020 203a  crets..        :
-0001a440: 7061 7261 6d20 7072 6f76 6964 6572 3a20  param provider: 
-0001a450: 5468 6520 6e61 6d65 206f 6620 7468 6520  The name of the 
-0001a460: 7365 6372 6574 732d 7072 6f76 6964 6572  secrets-provider
-0001a470: 2074 6f20 776f 726b 2077 6974 682e 2043   to work with. C
-0001a480: 7572 7265 6e74 6c79 206f 6e6c 7920 6060  urrently only ``
-0001a490: 7661 756c 7460 6020 6973 2073 7570 706f  vault`` is suppo
-0001a4a0: 7274 6564 2e0a 2020 2020 2020 2020 3a70  rted..        :p
-0001a4b0: 6172 616d 2073 6563 7265 7473 3a20 4120  aram secrets: A 
-0001a4c0: 7365 7420 6f66 2073 6563 7265 7420 7661  set of secret va
-0001a4d0: 6c75 6573 2074 6f20 7374 6f72 6520 7769  lues to store wi
-0001a4e0: 7468 696e 2074 6865 2056 6175 6c74 2e0a  thin the Vault..
-0001a4f0: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
-0001a500: 2020 2020 7061 7468 203d 2022 7573 6572      path = "user
-0001a510: 2d73 6563 7265 7473 220a 2020 2020 2020  -secrets".      
-0001a520: 2020 7365 6372 6574 735f 6372 6561 7469    secrets_creati
-0001a530: 6f6e 5f72 6571 7565 7374 203d 2073 6368  on_request = sch
-0001a540: 656d 6173 2e55 7365 7253 6563 7265 7443  emas.UserSecretC
-0001a550: 7265 6174 696f 6e52 6571 7565 7374 280a  reationRequest(.
-0001a560: 2020 2020 2020 2020 2020 2020 7573 6572              user
-0001a570: 3d75 7365 722c 0a20 2020 2020 2020 2020  =user,.         
-0001a580: 2020 2070 726f 7669 6465 723d 7072 6f76     provider=prov
-0001a590: 6964 6572 2c0a 2020 2020 2020 2020 2020  ider,.          
-0001a5a0: 2020 7365 6372 6574 733d 7365 6372 6574    secrets=secret
-0001a5b0: 732c 0a20 2020 2020 2020 2029 0a20 2020  s,.        ).   
-0001a5c0: 2020 2020 2062 6f64 7920 3d20 7365 6372       body = secr
-0001a5d0: 6574 735f 6372 6561 7469 6f6e 5f72 6571  ets_creation_req
-0001a5e0: 7565 7374 2e64 6963 7428 290a 2020 2020  uest.dict().    
-0001a5f0: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
-0001a600: 6520 3d20 6622 4661 696c 6564 2063 7265  e = f"Failed cre
-0001a610: 6174 696e 6720 7573 6572 2073 6563 7265  ating user secre
-0001a620: 7473 202d 207b 7573 6572 7d22 0a20 2020  ts - {user}".   
-0001a630: 2020 2020 2073 656c 662e 6170 695f 6361       self.api_ca
-0001a640: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
-0001a650: 2250 4f53 5422 2c0a 2020 2020 2020 2020  "POST",.        
-0001a660: 2020 2020 7061 7468 2c0a 2020 2020 2020      path,.      
-0001a670: 2020 2020 2020 6572 726f 725f 6d65 7373        error_mess
-0001a680: 6167 652c 0a20 2020 2020 2020 2020 2020  age,.           
-0001a690: 2062 6f64 793d 6469 6374 5f74 6f5f 6a73   body=dict_to_js
-0001a6a0: 6f6e 2862 6f64 7929 2c0a 2020 2020 2020  on(body),.      
-0001a6b0: 2020 290a 0a20 2020 2040 7374 6174 6963    )..    @static
-0001a6c0: 6d65 7468 6f64 0a20 2020 2064 6566 205f  method.    def _
-0001a6d0: 7661 6c69 6461 7465 5f76 6572 7369 6f6e  validate_version
-0001a6e0: 5f63 6f6d 7061 7469 6269 6c69 7479 2873  _compatibility(s
-0001a6f0: 6572 7665 725f 7665 7273 696f 6e2c 2063  erver_version, c
-0001a700: 6c69 656e 745f 7665 7273 696f 6e29 202d  lient_version) -
-0001a710: 3e20 626f 6f6c 3a0a 2020 2020 2020 2020  > bool:.        
-0001a720: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
-0001a730: 2070 6172 7365 645f 7365 7276 6572 5f76   parsed_server_v
-0001a740: 6572 7369 6f6e 203d 2073 656d 7665 722e  ersion = semver.
-0001a750: 5665 7273 696f 6e49 6e66 6f2e 7061 7273  VersionInfo.pars
-0001a760: 6528 7365 7276 6572 5f76 6572 7369 6f6e  e(server_version
-0001a770: 290a 2020 2020 2020 2020 2020 2020 7061  ).            pa
-0001a780: 7273 6564 5f63 6c69 656e 745f 7665 7273  rsed_client_vers
-0001a790: 696f 6e20 3d20 7365 6d76 6572 2e56 6572  ion = semver.Ver
-0001a7a0: 7369 6f6e 496e 666f 2e70 6172 7365 2863  sionInfo.parse(c
-0001a7b0: 6c69 656e 745f 7665 7273 696f 6e29 0a20  lient_version). 
-0001a7c0: 2020 2020 2020 2065 7863 6570 7420 5661         except Va
-0001a7d0: 6c75 6545 7272 6f72 3a0a 2020 2020 2020  lueError:.      
-0001a7e0: 2020 2020 2020 2320 5468 6973 2077 696c        # This wil
-0001a7f0: 6c20 6d6f 7374 6c79 2068 6170 7065 6e20  l mostly happen 
-0001a800: 696e 2064 6576 2073 6365 6e61 7269 6f73  in dev scenarios
-0001a810: 2077 6865 6e20 7468 6520 7665 7273 696f   when the versio
-0001a820: 6e20 6973 2075 6e73 7461 626c 6520 616e  n is unstable an
-0001a830: 6420 7375 6368 202d 2074 6865 7265 666f  d such - therefo
-0001a840: 7265 2077 6527 7265 2069 676e 6f72 696e  re we're ignorin
-0001a850: 670a 2020 2020 2020 2020 2020 2020 6c6f  g.            lo
-0001a860: 6767 6572 2e77 6172 6e69 6e67 280a 2020  gger.warning(.  
-0001a870: 2020 2020 2020 2020 2020 2020 2020 2255                "U
-0001a880: 6e61 626c 6520 746f 2070 6172 7365 2073  nable to parse s
-0001a890: 6572 7665 7220 6f72 2063 6c69 656e 7420  erver or client 
-0001a8a0: 7665 7273 696f 6e2e 2041 7373 756d 696e  version. Assumin
-0001a8b0: 6720 636f 6d70 6174 6962 6c65 222c 0a20  g compatible",. 
-0001a8c0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0001a8d0: 6572 7665 725f 7665 7273 696f 6e3d 7365  erver_version=se
-0001a8e0: 7276 6572 5f76 6572 7369 6f6e 2c0a 2020  rver_version,.  
-0001a8f0: 2020 2020 2020 2020 2020 2020 2020 636c                cl
-0001a900: 6965 6e74 5f76 6572 7369 6f6e 3d63 6c69  ient_version=cli
-0001a910: 656e 745f 7665 7273 696f 6e2c 0a20 2020  ent_version,.   
-0001a920: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
-0001a930: 2020 2020 2020 2072 6574 7572 6e20 5472         return Tr
-0001a940: 7565 0a20 2020 2020 2020 2069 6620 2870  ue.        if (p
-0001a950: 6172 7365 645f 7365 7276 6572 5f76 6572  arsed_server_ver
-0001a960: 7369 6f6e 2e6d 616a 6f72 203d 3d20 3020  sion.major == 0 
-0001a970: 616e 6420 7061 7273 6564 5f73 6572 7665  and parsed_serve
-0001a980: 725f 7665 7273 696f 6e2e 6d69 6e6f 7220  r_version.minor 
-0001a990: 3d3d 2030 2920 6f72 2028 0a20 2020 2020  == 0) or (.     
-0001a9a0: 2020 2020 2020 2070 6172 7365 645f 636c         parsed_cl
-0001a9b0: 6965 6e74 5f76 6572 7369 6f6e 2e6d 616a  ient_version.maj
-0001a9c0: 6f72 203d 3d20 3020 616e 6420 7061 7273  or == 0 and pars
-0001a9d0: 6564 5f63 6c69 656e 745f 7665 7273 696f  ed_client_versio
-0001a9e0: 6e2e 6d69 6e6f 7220 3d3d 2030 0a20 2020  n.minor == 0.   
-0001a9f0: 2020 2020 2029 3a0a 2020 2020 2020 2020       ):.        
-0001aa00: 2020 2020 6c6f 6767 6572 2e77 6172 6e69      logger.warni
-0001aa10: 6e67 280a 2020 2020 2020 2020 2020 2020  ng(.            
-0001aa20: 2020 2020 2253 6572 7665 7220 6f72 2063      "Server or c
-0001aa30: 6c69 656e 7420 7665 7273 696f 6e20 6973  lient version is
-0001aa40: 2075 6e73 7461 626c 652e 2041 7373 756d   unstable. Assum
-0001aa50: 696e 6720 636f 6d70 6174 6962 6c65 222c  ing compatible",
-0001aa60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001aa70: 2073 6572 7665 725f 7665 7273 696f 6e3d   server_version=
-0001aa80: 7365 7276 6572 5f76 6572 7369 6f6e 2c0a  server_version,.
-0001aa90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aaa0: 636c 6965 6e74 5f76 6572 7369 6f6e 3d63  client_version=c
-0001aab0: 6c69 656e 745f 7665 7273 696f 6e2c 0a20  lient_version,. 
-0001aac0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
-0001aad0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0001aae0: 5472 7565 0a20 2020 2020 2020 2069 6620  True.        if 
-0001aaf0: 7061 7273 6564 5f73 6572 7665 725f 7665  parsed_server_ve
-0001ab00: 7273 696f 6e2e 6d61 6a6f 7220 213d 2070  rsion.major != p
-0001ab10: 6172 7365 645f 636c 6965 6e74 5f76 6572  arsed_client_ver
-0001ab20: 7369 6f6e 2e6d 616a 6f72 3a0a 2020 2020  sion.major:.    
-0001ab30: 2020 2020 2020 2020 6c6f 6767 6572 2e77          logger.w
-0001ab40: 6172 6e69 6e67 280a 2020 2020 2020 2020  arning(.        
-0001ab50: 2020 2020 2020 2020 2253 6572 7665 7220          "Server 
-0001ab60: 616e 6420 636c 6965 6e74 2076 6572 7369  and client versi
-0001ab70: 6f6e 7320 6172 6520 696e 636f 6d70 6174  ons are incompat
-0001ab80: 6962 6c65 222c 0a20 2020 2020 2020 2020  ible",.         
-0001ab90: 2020 2020 2020 2070 6172 7365 645f 7365         parsed_se
-0001aba0: 7276 6572 5f76 6572 7369 6f6e 3d70 6172  rver_version=par
-0001abb0: 7365 645f 7365 7276 6572 5f76 6572 7369  sed_server_versi
-0001abc0: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
-0001abd0: 2020 2020 7061 7273 6564 5f63 6c69 656e      parsed_clien
-0001abe0: 745f 7665 7273 696f 6e3d 7061 7273 6564  t_version=parsed
-0001abf0: 5f63 6c69 656e 745f 7665 7273 696f 6e2c  _client_version,
-0001ac00: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-0001ac10: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0001ac20: 6e20 4661 6c73 650a 2020 2020 2020 2020  n False.        
-0001ac30: 6966 2070 6172 7365 645f 7365 7276 6572  if parsed_server
-0001ac40: 5f76 6572 7369 6f6e 2e6d 696e 6f72 2021  _version.minor !
-0001ac50: 3d20 7061 7273 6564 5f63 6c69 656e 745f  = parsed_client_
-0001ac60: 7665 7273 696f 6e2e 6d69 6e6f 723a 0a20  version.minor:. 
-0001ac70: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
-0001ac80: 722e 696e 666f 280a 2020 2020 2020 2020  r.info(.        
-0001ac90: 2020 2020 2020 2020 2253 6572 7665 7220          "Server 
-0001aca0: 616e 6420 636c 6965 6e74 2076 6572 7369  and client versi
-0001acb0: 6f6e 7320 6172 6520 6e6f 7420 7468 6520  ons are not the 
-0001acc0: 7361 6d65 222c 0a20 2020 2020 2020 2020  same",.         
-0001acd0: 2020 2020 2020 2070 6172 7365 645f 7365         parsed_se
-0001ace0: 7276 6572 5f76 6572 7369 6f6e 3d70 6172  rver_version=par
-0001acf0: 7365 645f 7365 7276 6572 5f76 6572 7369  sed_server_versi
-0001ad00: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
-0001ad10: 2020 2020 7061 7273 6564 5f63 6c69 656e      parsed_clien
-0001ad20: 745f 7665 7273 696f 6e3d 7061 7273 6564  t_version=parsed
-0001ad30: 5f63 6c69 656e 745f 7665 7273 696f 6e2c  _client_version,
-0001ad40: 0a20 2020 2020 2020 2020 2020 2029 0a20  .            ). 
-0001ad50: 2020 2020 2020 2072 6574 7572 6e20 5472         return Tr
-0001ad60: 7565 0a0a 2020 2020 6465 6620 6372 6561  ue..    def crea
-0001ad70: 7465 5f6d 6f64 656c 5f65 6e64 706f 696e  te_model_endpoin
-0001ad80: 7428 0a20 2020 2020 2020 2073 656c 662c  t(.        self,
-0001ad90: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-0001ada0: 3a20 7374 722c 0a20 2020 2020 2020 2065  : str,.        e
-0001adb0: 6e64 706f 696e 745f 6964 3a20 7374 722c  ndpoint_id: str,
-0001adc0: 0a20 2020 2020 2020 206d 6f64 656c 5f65  .        model_e
-0001add0: 6e64 706f 696e 743a 204d 6f64 656c 456e  ndpoint: ModelEn
-0001ade0: 6470 6f69 6e74 2c0a 2020 2020 293a 0a20  dpoint,.    ):. 
-0001adf0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-0001ae00: 2020 2043 7265 6174 6573 2061 2044 4220     Creates a DB 
-0001ae10: 7265 636f 7264 2077 6974 6820 7468 6520  record with the 
-0001ae20: 6769 7665 6e20 6d6f 6465 6c5f 656e 6470  given model_endp
-0001ae30: 6f69 6e74 2072 6563 6f72 642e 0a0a 2020  oint record...  
-0001ae40: 2020 2020 2020 3a70 6172 616d 2070 726f        :param pro
-0001ae50: 6a65 6374 3a20 5468 6520 6e61 6d65 206f  ject: The name o
-0001ae60: 6620 7468 6520 7072 6f6a 6563 742e 0a20  f the project.. 
-0001ae70: 2020 2020 2020 203a 7061 7261 6d20 656e         :param en
-0001ae80: 6470 6f69 6e74 5f69 643a 2054 6865 2069  dpoint_id: The i
-0001ae90: 6420 6f66 2074 6865 2065 6e64 706f 696e  d of the endpoin
-0001aea0: 742e 0a20 2020 2020 2020 203a 7061 7261  t..        :para
-0001aeb0: 6d20 6d6f 6465 6c5f 656e 6470 6f69 6e74  m model_endpoint
-0001aec0: 3a20 416e 206f 626a 6563 7420 7265 7072  : An object repr
-0001aed0: 6573 656e 7469 6e67 2074 6865 206d 6f64  esenting the mod
-0001aee0: 656c 2065 6e64 706f 696e 742e 0a20 2020  el endpoint..   
-0001aef0: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
-0001af00: 2020 7061 7468 203d 2066 2270 726f 6a65    path = f"proje
-0001af10: 6374 732f 7b70 726f 6a65 6374 7d2f 6d6f  cts/{project}/mo
-0001af20: 6465 6c2d 656e 6470 6f69 6e74 732f 7b65  del-endpoints/{e
-0001af30: 6e64 706f 696e 745f 6964 7d22 0a20 2020  ndpoint_id}".   
-0001af40: 2020 2020 2073 656c 662e 6170 695f 6361       self.api_ca
-0001af50: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
-0001af60: 6d65 7468 6f64 3d22 504f 5354 222c 0a20  method="POST",. 
-0001af70: 2020 2020 2020 2020 2020 2070 6174 683d             path=
-0001af80: 7061 7468 2c0a 2020 2020 2020 2020 2020  path,.          
-0001af90: 2020 626f 6479 3d6d 6f64 656c 5f65 6e64    body=model_end
-0001afa0: 706f 696e 742e 6a73 6f6e 2829 2c0a 2020  point.json(),.  
-0001afb0: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
-0001afc0: 2064 656c 6574 655f 6d6f 6465 6c5f 656e   delete_model_en
-0001afd0: 6470 6f69 6e74 280a 2020 2020 2020 2020  dpoint(.        
-0001afe0: 7365 6c66 2c0a 2020 2020 2020 2020 7072  self,.        pr
-0001aff0: 6f6a 6563 743a 2073 7472 2c0a 2020 2020  oject: str,.    
-0001b000: 2020 2020 656e 6470 6f69 6e74 5f69 643a      endpoint_id:
-0001b010: 2073 7472 2c0a 2020 2020 293a 0a20 2020   str,.    ):.   
-0001b020: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0001b030: 2044 656c 6574 6573 2074 6865 204b 5620   Deletes the KV 
-0001b040: 7265 636f 7264 206f 6620 6120 6769 7665  record of a give
-0001b050: 6e20 6d6f 6465 6c20 656e 6470 6f69 6e74  n model endpoint
-0001b060: 2c20 7072 6f6a 6563 7420 616e 6420 656e  , project and en
-0001b070: 6470 6f69 6e74 5f69 6420 6172 6520 7573  dpoint_id are us
-0001b080: 6564 2066 6f72 206c 6f6f 6b75 700a 0a20  ed for lookup.. 
-0001b090: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
-0001b0a0: 6f6a 6563 743a 2054 6865 206e 616d 6520  oject: The name 
-0001b0b0: 6f66 2074 6865 2070 726f 6a65 6374 0a20  of the project. 
-0001b0c0: 2020 2020 2020 203a 7061 7261 6d20 656e         :param en
-0001b0d0: 6470 6f69 6e74 5f69 643a 2054 6865 2069  dpoint_id: The i
-0001b0e0: 6420 6f66 2074 6865 2065 6e64 706f 696e  d of the endpoin
-0001b0f0: 740a 2020 2020 2020 2020 2222 220a 0a20  t.        """.. 
-0001b100: 2020 2020 2020 2070 6174 6820 3d20 6622         path = f"
-0001b110: 7072 6f6a 6563 7473 2f7b 7072 6f6a 6563  projects/{projec
-0001b120: 747d 2f6d 6f64 656c 2d65 6e64 706f 696e  t}/model-endpoin
-0001b130: 7473 2f7b 656e 6470 6f69 6e74 5f69 647d  ts/{endpoint_id}
-0001b140: 220a 2020 2020 2020 2020 7365 6c66 2e61  ".        self.a
-0001b150: 7069 5f63 616c 6c28 0a20 2020 2020 2020  pi_call(.       
-0001b160: 2020 2020 206d 6574 686f 643d 2244 454c       method="DEL
-0001b170: 4554 4522 2c0a 2020 2020 2020 2020 2020  ETE",.          
-0001b180: 2020 7061 7468 3d70 6174 682c 0a20 2020    path=path,.   
-0001b190: 2020 2020 2029 0a0a 2020 2020 6465 6620       )..    def 
-0001b1a0: 6c69 7374 5f6d 6f64 656c 5f65 6e64 706f  list_model_endpo
-0001b1b0: 696e 7473 280a 2020 2020 2020 2020 7365  ints(.        se
-0001b1c0: 6c66 2c0a 2020 2020 2020 2020 7072 6f6a  lf,.        proj
-0001b1d0: 6563 743a 2073 7472 2c0a 2020 2020 2020  ect: str,.      
-0001b1e0: 2020 6d6f 6465 6c3a 204f 7074 696f 6e61    model: Optiona
-0001b1f0: 6c5b 7374 725d 203d 204e 6f6e 652c 0a20  l[str] = None,. 
-0001b200: 2020 2020 2020 2066 756e 6374 696f 6e3a         function:
-0001b210: 204f 7074 696f 6e61 6c5b 7374 725d 203d   Optional[str] =
-0001b220: 204e 6f6e 652c 0a20 2020 2020 2020 206c   None,.        l
-0001b230: 6162 656c 733a 204c 6973 745b 7374 725d  abels: List[str]
-0001b240: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0001b250: 2073 7461 7274 3a20 7374 7220 3d20 226e   start: str = "n
-0001b260: 6f77 2d31 6822 2c0a 2020 2020 2020 2020  ow-1h",.        
-0001b270: 656e 643a 2073 7472 203d 2022 6e6f 7722  end: str = "now"
-0001b280: 2c0a 2020 2020 2020 2020 6d65 7472 6963  ,.        metric
-0001b290: 733a 204f 7074 696f 6e61 6c5b 4c69 7374  s: Optional[List
-0001b2a0: 5b73 7472 5d5d 203d 204e 6f6e 652c 0a20  [str]] = None,. 
-0001b2b0: 2020 2020 2020 2074 6f70 5f6c 6576 656c         top_level
-0001b2c0: 3a20 626f 6f6c 203d 2046 616c 7365 2c0a  : bool = False,.
-0001b2d0: 2020 2020 2020 2020 7569 6473 3a20 4f70          uids: Op
-0001b2e0: 7469 6f6e 616c 5b4c 6973 745b 7374 725d  tional[List[str]
-0001b2f0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2920  ] = None,.    ) 
-0001b300: 2d3e 2073 6368 656d 6173 2e4d 6f64 656c  -> schemas.Model
-0001b310: 456e 6470 6f69 6e74 4c69 7374 3a0a 2020  EndpointList:.  
-0001b320: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-0001b330: 2020 5265 7475 726e 7320 6120 6c69 7374    Returns a list
-0001b340: 206f 6620 4d6f 6465 6c45 6e64 706f 696e   of ModelEndpoin
-0001b350: 7453 7461 7465 206f 626a 6563 7473 2e20  tState objects. 
-0001b360: 4561 6368 206f 626a 6563 7420 7265 7072  Each object repr
-0001b370: 6573 656e 7473 2074 6865 2063 7572 7265  esents the curre
-0001b380: 6e74 2073 7461 7465 206f 6620 6120 6d6f  nt state of a mo
-0001b390: 6465 6c20 656e 6470 6f69 6e74 2e0a 2020  del endpoint..  
-0001b3a0: 2020 2020 2020 5468 6973 2066 756e 6374        This funct
-0001b3b0: 696f 6e73 2073 7570 706f 7274 7320 6669  ions supports fi
-0001b3c0: 6c74 6572 696e 6720 6279 2074 6865 2066  ltering by the f
-0001b3d0: 6f6c 6c6f 7769 6e67 2070 6172 616d 6574  ollowing paramet
-0001b3e0: 6572 733a 0a20 2020 2020 2020 2031 2920  ers:.        1) 
-0001b3f0: 6d6f 6465 6c0a 2020 2020 2020 2020 3229  model.        2)
-0001b400: 2066 756e 6374 696f 6e0a 2020 2020 2020   function.      
-0001b410: 2020 3329 206c 6162 656c 730a 2020 2020    3) labels.    
-0001b420: 2020 2020 4279 2064 6566 6175 6c74 2c20      By default, 
-0001b430: 7768 656e 206e 6f20 6669 6c74 6572 7320  when no filters 
-0001b440: 6172 6520 6170 706c 6965 642c 2061 6c6c  are applied, all
-0001b450: 2061 7661 696c 6162 6c65 2065 6e64 706f   available endpo
-0001b460: 696e 7473 2066 6f72 2074 6865 2067 6976  ints for the giv
-0001b470: 656e 2070 726f 6a65 6374 2077 696c 6c20  en project will 
-0001b480: 6265 206c 6973 7465 642e 0a0a 2020 2020  be listed...    
-0001b490: 2020 2020 496e 2061 6464 6974 696f 6e2c      In addition,
-0001b4a0: 2074 6869 7320 6675 6e63 7469 6f6e 7320   this functions 
-0001b4b0: 7072 6f76 6964 6573 2061 2066 6163 6164  provides a facad
-0001b4c0: 6520 666f 7220 6c69 7374 696e 6720 656e  e for listing en
-0001b4d0: 6470 6f69 6e74 2072 656c 6174 6564 206d  dpoint related m
-0001b4e0: 6574 7269 6373 2e20 5468 6973 2066 6163  etrics. This fac
-0001b4f0: 6164 6520 6973 2074 696d 652d 6261 7365  ade is time-base
-0001b500: 640a 2020 2020 2020 2020 616e 6420 6465  d.        and de
-0001b510: 7065 6e64 7320 6f6e 2074 6865 2027 7374  pends on the 'st
-0001b520: 6172 7427 2061 6e64 2027 656e 6427 2070  art' and 'end' p
-0001b530: 6172 616d 6574 6572 732e 2042 7920 6465  arameters. By de
-0001b540: 6661 756c 742c 2077 6865 6e20 7468 6520  fault, when the 
-0001b550: 6d65 7472 6963 7320 7061 7261 6d65 7465  metrics paramete
-0001b560: 7220 6973 204e 6f6e 652c 206e 6f20 6d65  r is None, no me
-0001b570: 7472 6963 7320 6172 650a 2020 2020 2020  trics are.      
-0001b580: 2020 6164 6465 6420 746f 2074 6865 206f    added to the o
-0001b590: 7574 7075 7420 6f66 2074 6869 7320 6675  utput of this fu
-0001b5a0: 6e63 7469 6f6e 2e0a 0a20 2020 2020 2020  nction...       
-0001b5b0: 203a 7061 7261 6d20 7072 6f6a 6563 743a   :param project:
-0001b5c0: 2054 6865 206e 616d 6520 6f66 2074 6865   The name of the
-0001b5d0: 2070 726f 6a65 6374 0a20 2020 2020 2020   project.       
-0001b5e0: 203a 7061 7261 6d20 6d6f 6465 6c3a 2054   :param model: T
-0001b5f0: 6865 206e 616d 6520 6f66 2074 6865 206d  he name of the m
-0001b600: 6f64 656c 2074 6f20 6669 6c74 6572 2062  odel to filter b
-0001b610: 790a 2020 2020 2020 2020 3a70 6172 616d  y.        :param
-0001b620: 2066 756e 6374 696f 6e3a 2054 6865 206e   function: The n
-0001b630: 616d 6520 6f66 2074 6865 2066 756e 6374  ame of the funct
-0001b640: 696f 6e20 746f 2066 696c 7465 7220 6279  ion to filter by
-0001b650: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0001b660: 6c61 6265 6c73 3a20 4120 6c69 7374 206f  labels: A list o
-0001b670: 6620 6c61 6265 6c73 2074 6f20 6669 6c74  f labels to filt
-0001b680: 6572 2062 792e 204c 6162 656c 2066 696c  er by. Label fil
-0001b690: 7465 7273 2077 6f72 6b20 6279 2065 6974  ters work by eit
-0001b6a0: 6865 7220 6669 6c74 6572 696e 6720 6120  her filtering a 
-0001b6b0: 7370 6563 6966 6963 2076 616c 7565 206f  specific value o
-0001b6c0: 6620 6120 6c61 6265 6c0a 2020 2020 2020  f a label.      
-0001b6d0: 2020 2020 2020 2869 2e65 2e20 6c69 7374        (i.e. list
-0001b6e0: 2822 6b65 793d 3d76 616c 7565 2229 2920  ("key==value")) 
-0001b6f0: 6f72 2062 7920 6c6f 6f6b 696e 6720 666f  or by looking fo
-0001b700: 7220 7468 6520 6578 6973 7465 6e63 6520  r the existence 
-0001b710: 6f66 2061 2067 6976 656e 206b 6579 2028  of a given key (
-0001b720: 692e 652e 2022 6b65 7922 290a 2020 2020  i.e. "key").    
-0001b730: 2020 2020 3a70 6172 616d 206d 6574 7269      :param metri
-0001b740: 6373 3a20 4120 6c69 7374 206f 6620 6d65  cs: A list of me
-0001b750: 7472 6963 7320 746f 2072 6574 7572 6e20  trics to return 
-0001b760: 666f 7220 6561 6368 2065 6e64 706f 696e  for each endpoin
-0001b770: 742c 2072 6561 6420 6d6f 7265 2069 6e20  t, read more in 
-0001b780: 2754 696d 654d 6574 7269 6327 0a20 2020  'TimeMetric'.   
-0001b790: 2020 2020 203a 7061 7261 6d20 7374 6172       :param star
-0001b7a0: 743a 2054 6865 2073 7461 7274 2074 696d  t: The start tim
-0001b7b0: 6520 6f66 2074 6865 206d 6574 7269 6373  e of the metrics
-0001b7c0: 2e20 4361 6e20 6265 2072 6570 7265 7365  . Can be represe
-0001b7d0: 6e74 6564 2062 7920 6120 7374 7269 6e67  nted by a string
-0001b7e0: 2063 6f6e 7461 696e 696e 6720 616e 2052   containing an R
-0001b7f0: 4643 2033 3333 390a 2020 2020 2020 2020  FC 3339.        
-0001b800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b810: 2020 2020 2020 2020 2074 696d 652c 2061           time, a
-0001b820: 2055 6e69 7820 7469 6d65 7374 616d 7020   Unix timestamp 
-0001b830: 696e 206d 696c 6c69 7365 636f 6e64 732c  in milliseconds,
-0001b840: 2061 2072 656c 6174 6976 6520 7469 6d65   a relative time
-0001b850: 2028 6027 6e6f 7727 6020 6f72 0a20 2020   (`'now'` or.   
-0001b860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b870: 2020 2020 2020 2020 2020 2020 2020 6027                `'
-0001b880: 6e6f 772d 5b30 2d39 5d2b 5b6d 6864 5d27  now-[0-9]+[mhd]'
-0001b890: 602c 2077 6865 7265 2060 6d60 203d 206d  `, where `m` = m
-0001b8a0: 696e 7574 6573 2c20 6068 6020 3d20 686f  inutes, `h` = ho
-0001b8b0: 7572 732c 2061 6e64 2060 2764 2760 203d  urs, and `'d'` =
-0001b8c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b8d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b8e0: 2020 6461 7973 292c 206f 7220 3020 666f    days), or 0 fo
-0001b8f0: 7220 7468 6520 6561 726c 6965 7374 2074  r the earliest t
-0001b900: 696d 652e 0a20 2020 2020 2020 203a 7061  ime..        :pa
-0001b910: 7261 6d20 656e 643a 2054 6865 2065 6e64  ram end: The end
-0001b920: 2074 696d 6520 6f66 2074 6865 206d 6574   time of the met
-0001b930: 7269 6373 2e20 4361 6e20 6265 2072 6570  rics. Can be rep
-0001b940: 7265 7365 6e74 6564 2062 7920 6120 7374  resented by a st
-0001b950: 7269 6e67 2063 6f6e 7461 696e 696e 6720  ring containing 
-0001b960: 616e 2052 4643 2033 3333 390a 2020 2020  an RFC 3339.    
-0001b970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b980: 2020 2020 2020 2020 2020 2020 2074 696d               tim
-0001b990: 652c 2061 2055 6e69 7820 7469 6d65 7374  e, a Unix timest
-0001b9a0: 616d 7020 696e 206d 696c 6c69 7365 636f  amp in milliseco
-0001b9b0: 6e64 732c 2061 2072 656c 6174 6976 6520  nds, a relative 
-0001b9c0: 7469 6d65 2028 6027 6e6f 7727 6020 6f72  time (`'now'` or
-0001b9d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b9f0: 2020 6027 6e6f 772d 5b30 2d39 5d2b 5b6d    `'now-[0-9]+[m
-0001ba00: 6864 5d27 602c 2077 6865 7265 2060 6d60  hd]'`, where `m`
-0001ba10: 203d 206d 696e 7574 6573 2c20 6068 6020   = minutes, `h` 
-0001ba20: 3d20 686f 7572 732c 2061 6e64 2060 2764  = hours, and `'d
-0001ba30: 2760 203d 0a20 2020 2020 2020 2020 2020  '` =.           
-0001ba40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ba50: 2020 2020 2020 6461 7973 292c 206f 7220        days), or 
-0001ba60: 3020 666f 7220 7468 6520 6561 726c 6965  0 for the earlie
-0001ba70: 7374 2074 696d 652e 0a20 2020 2020 2020  st time..       
-0001ba80: 203a 7061 7261 6d20 746f 705f 6c65 7665   :param top_leve
-0001ba90: 6c3a 2069 6620 7472 7565 2077 696c 6c20  l: if true will 
-0001baa0: 7265 7475 726e 206f 6e6c 7920 726f 7574  return only rout
-0001bab0: 6572 7320 616e 6420 656e 6470 6f69 6e74  ers and endpoint
-0001bac0: 2074 6861 7420 6172 6520 4e4f 5420 6368   that are NOT ch
-0001bad0: 696c 6472 656e 206f 6620 616e 7920 726f  ildren of any ro
-0001bae0: 7574 6572 0a20 2020 2020 2020 203a 7061  uter.        :pa
-0001baf0: 7261 6d20 7569 6473 3a20 6966 2070 6173  ram uids: if pas
-0001bb00: 7365 6420 7769 6c6c 2072 6574 7572 6e20  sed will return 
-0001bb10: 4d6f 6465 6c45 6e64 706f 696e 744c 6973  ModelEndpointLis
-0001bb20: 7420 6f66 2065 6e64 706f 696e 7473 2077  t of endpoints w
-0001bb30: 6974 6820 7569 6420 696e 2075 6964 730a  ith uid in uids.
-0001bb40: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
-0001bb50: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
-0001bb60: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
-0001bb70: 2f6d 6f64 656c 2d65 6e64 706f 696e 7473  /model-endpoints
-0001bb80: 220a 2020 2020 2020 2020 7265 7370 6f6e  ".        respon
-0001bb90: 7365 203d 2073 656c 662e 6170 695f 6361  se = self.api_ca
-0001bba0: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
-0001bbb0: 6d65 7468 6f64 3d22 4745 5422 2c0a 2020  method="GET",.  
-0001bbc0: 2020 2020 2020 2020 2020 7061 7468 3d70            path=p
-0001bbd0: 6174 682c 0a20 2020 2020 2020 2020 2020  ath,.           
-0001bbe0: 2070 6172 616d 733d 7b0a 2020 2020 2020   params={.      
-0001bbf0: 2020 2020 2020 2020 2020 226d 6f64 656c            "model
-0001bc00: 223a 206d 6f64 656c 2c0a 2020 2020 2020  ": model,.      
-0001bc10: 2020 2020 2020 2020 2020 2266 756e 6374            "funct
-0001bc20: 696f 6e22 3a20 6675 6e63 7469 6f6e 2c0a  ion": function,.
-0001bc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bc40: 226c 6162 656c 223a 206c 6162 656c 7320  "label": labels 
-0001bc50: 6f72 205b 5d2c 0a20 2020 2020 2020 2020  or [],.         
-0001bc60: 2020 2020 2020 2022 7374 6172 7422 3a20         "start": 
-0001bc70: 7374 6172 742c 0a20 2020 2020 2020 2020  start,.         
-0001bc80: 2020 2020 2020 2022 656e 6422 3a20 656e         "end": en
-0001bc90: 642c 0a20 2020 2020 2020 2020 2020 2020  d,.             
-0001bca0: 2020 2022 6d65 7472 6963 223a 206d 6574     "metric": met
-0001bcb0: 7269 6373 206f 7220 5b5d 2c0a 2020 2020  rics or [],.    
-0001bcc0: 2020 2020 2020 2020 2020 2020 2274 6f70              "top
-0001bcd0: 2d6c 6576 656c 223a 2074 6f70 5f6c 6576  -level": top_lev
-0001bce0: 656c 2c0a 2020 2020 2020 2020 2020 2020  el,.            
-0001bcf0: 2020 2020 2275 6964 223a 2075 6964 732c      "uid": uids,
-0001bd00: 0a20 2020 2020 2020 2020 2020 207d 2c0a  .            },.
-0001bd10: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
-0001bd20: 2020 7265 7475 726e 2073 6368 656d 6173    return schemas
-0001bd30: 2e4d 6f64 656c 456e 6470 6f69 6e74 4c69  .ModelEndpointLi
-0001bd40: 7374 282a 2a72 6573 706f 6e73 652e 6a73  st(**response.js
-0001bd50: 6f6e 2829 290a 0a20 2020 2064 6566 2067  on())..    def g
-0001bd60: 6574 5f6d 6f64 656c 5f65 6e64 706f 696e  et_model_endpoin
-0001bd70: 7428 0a20 2020 2020 2020 2073 656c 662c  t(.        self,
-0001bd80: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
-0001bd90: 3a20 7374 722c 0a20 2020 2020 2020 2065  : str,.        e
-0001bda0: 6e64 706f 696e 745f 6964 3a20 7374 722c  ndpoint_id: str,
-0001bdb0: 0a20 2020 2020 2020 2073 7461 7274 3a20  .        start: 
-0001bdc0: 4f70 7469 6f6e 616c 5b73 7472 5d20 3d20  Optional[str] = 
-0001bdd0: 4e6f 6e65 2c0a 2020 2020 2020 2020 656e  None,.        en
-0001bde0: 643a 204f 7074 696f 6e61 6c5b 7374 725d  d: Optional[str]
-0001bdf0: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
-0001be00: 206d 6574 7269 6373 3a20 4f70 7469 6f6e   metrics: Option
-0001be10: 616c 5b4c 6973 745b 7374 725d 5d20 3d20  al[List[str]] = 
-0001be20: 4e6f 6e65 2c0a 2020 2020 2020 2020 6665  None,.        fe
-0001be30: 6174 7572 655f 616e 616c 7973 6973 3a20  ature_analysis: 
-0001be40: 626f 6f6c 203d 2046 616c 7365 2c0a 2020  bool = False,.  
-0001be50: 2020 2920 2d3e 2073 6368 656d 6173 2e4d    ) -> schemas.M
-0001be60: 6f64 656c 456e 6470 6f69 6e74 3a0a 2020  odelEndpoint:.  
-0001be70: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-0001be80: 2020 5265 7475 726e 7320 6120 4d6f 6465    Returns a Mode
-0001be90: 6c45 6e64 706f 696e 7420 6f62 6a65 6374  lEndpoint object
-0001bea0: 2077 6974 6820 6164 6469 7469 6f6e 616c   with additional
-0001beb0: 206d 6574 7269 6373 2061 6e64 2066 6561   metrics and fea
-0001bec0: 7475 7265 2072 656c 6174 6564 2064 6174  ture related dat
-0001bed0: 612e 0a0a 2020 2020 2020 2020 3a70 6172  a...        :par
-0001bee0: 616d 2070 726f 6a65 6374 3a20 5468 6520  am project: The 
-0001bef0: 6e61 6d65 206f 6620 7468 6520 7072 6f6a  name of the proj
-0001bf00: 6563 740a 2020 2020 2020 2020 3a70 6172  ect.        :par
-0001bf10: 616d 2065 6e64 706f 696e 745f 6964 3a20  am endpoint_id: 
-0001bf20: 5468 6520 6964 206f 6620 7468 6520 6d6f  The id of the mo
-0001bf30: 6465 6c20 656e 6470 6f69 6e74 0a20 2020  del endpoint.   
-0001bf40: 2020 2020 203a 7061 7261 6d20 6d65 7472       :param metr
-0001bf50: 6963 733a 2041 206c 6973 7420 6f66 206d  ics: A list of m
-0001bf60: 6574 7269 6373 2074 6f20 7265 7475 726e  etrics to return
-0001bf70: 2066 6f72 2065 6163 6820 656e 6470 6f69   for each endpoi
-0001bf80: 6e74 2c20 7265 6164 206d 6f72 6520 696e  nt, read more in
-0001bf90: 2027 5469 6d65 4d65 7472 6963 270a 2020   'TimeMetric'.  
-0001bfa0: 2020 2020 2020 3a70 6172 616d 2073 7461        :param sta
-0001bfb0: 7274 3a20 5468 6520 7374 6172 7420 7469  rt: The start ti
-0001bfc0: 6d65 206f 6620 7468 6520 6d65 7472 6963  me of the metric
-0001bfd0: 732e 2043 616e 2062 6520 7265 7072 6573  s. Can be repres
-0001bfe0: 656e 7465 6420 6279 2061 2073 7472 696e  ented by a strin
-0001bff0: 6720 636f 6e74 6169 6e69 6e67 2061 6e20  g containing an 
-0001c000: 5246 4320 3333 3339 0a20 2020 2020 2020  RFC 3339.       
-0001c010: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-0001c020: 696d 652c 2061 2055 6e69 7820 7469 6d65  ime, a Unix time
-0001c030: 7374 616d 7020 696e 206d 696c 6c69 7365  stamp in millise
-0001c040: 636f 6e64 732c 2061 2072 656c 6174 6976  conds, a relativ
-0001c050: 6520 7469 6d65 2028 6027 6e6f 7727 6020  e time (`'now'` 
-0001c060: 6f72 2060 276e 6f77 2d5b 302d 395d 2b5b  or `'now-[0-9]+[
-0001c070: 6d68 645d 2760 2c0a 2020 2020 2020 2020  mhd]'`,.        
-0001c080: 2020 2020 2020 2020 2020 2020 2020 7768                wh
-0001c090: 6572 6520 606d 6020 3d20 6d69 6e75 7465  ere `m` = minute
-0001c0a0: 732c 2060 6860 203d 2068 6f75 7273 2c20  s, `h` = hours, 
-0001c0b0: 616e 6420 6027 6427 6020 3d20 6461 7973  and `'d'` = days
-0001c0c0: 292c 206f 7220 3020 666f 7220 7468 6520  ), or 0 for the 
-0001c0d0: 6561 726c 6965 7374 2074 696d 652e 0a20  earliest time.. 
-0001c0e0: 2020 2020 2020 203a 7061 7261 6d20 656e         :param en
-0001c0f0: 643a 2054 6865 2065 6e64 2074 696d 6520  d: The end time 
-0001c100: 6f66 2074 6865 206d 6574 7269 6373 2e20  of the metrics. 
-0001c110: 4361 6e20 6265 2072 6570 7265 7365 6e74  Can be represent
-0001c120: 6564 2062 7920 6120 7374 7269 6e67 2063  ed by a string c
-0001c130: 6f6e 7461 696e 696e 6720 616e 2052 4643  ontaining an RFC
-0001c140: 2033 3333 390a 2020 2020 2020 2020 2020   3339.          
-0001c150: 2020 2020 2020 2020 2020 7469 6d65 2c20            time, 
-0001c160: 6120 556e 6978 2074 696d 6573 7461 6d70  a Unix timestamp
-0001c170: 2069 6e20 6d69 6c6c 6973 6563 6f6e 6473   in milliseconds
-0001c180: 2c20 6120 7265 6c61 7469 7665 2074 696d  , a relative tim
-0001c190: 6520 2860 276e 6f77 2760 206f 7220 6027  e (`'now'` or `'
-0001c1a0: 6e6f 772d 5b30 2d39 5d2b 5b6d 6864 5d27  now-[0-9]+[mhd]'
-0001c1b0: 602c 0a20 2020 2020 2020 2020 2020 2020  `,.             
-0001c1c0: 2020 2020 2020 2077 6865 7265 2060 6d60         where `m`
-0001c1d0: 203d 206d 696e 7574 6573 2c20 6068 6020   = minutes, `h` 
-0001c1e0: 3d20 686f 7572 732c 2061 6e64 2060 2764  = hours, and `'d
-0001c1f0: 2760 203d 2064 6179 7329 2c20 6f72 2030  '` = days), or 0
-0001c200: 2066 6f72 2074 6865 2065 6172 6c69 6573   for the earlies
-0001c210: 7420 7469 6d65 2e0a 2020 2020 2020 2020  t time..        
-0001c220: 3a70 6172 616d 2066 6561 7475 7265 5f61  :param feature_a
-0001c230: 6e61 6c79 7369 733a 2057 6865 6e20 5472  nalysis: When Tr
-0001c240: 7565 2c20 7468 6520 6261 7365 2066 6561  ue, the base fea
-0001c250: 7475 7265 2073 7461 7469 7374 6963 7320  ture statistics 
-0001c260: 616e 6420 6375 7272 656e 7420 6665 6174  and current feat
-0001c270: 7572 6520 7374 6174 6973 7469 6373 2077  ure statistics w
-0001c280: 696c 6c20 6265 2061 6464 6564 2074 6f0a  ill be added to.
-0001c290: 2020 2020 2020 2020 2020 2020 7468 6520              the 
-0001c2a0: 6f75 7470 7574 206f 6620 7468 6520 7265  output of the re
-0001c2b0: 7375 6c74 696e 6720 6f62 6a65 6374 0a20  sulting object. 
-0001c2c0: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-0001c2d0: 2020 2020 7061 7468 203d 2066 2270 726f      path = f"pro
-0001c2e0: 6a65 6374 732f 7b70 726f 6a65 6374 7d2f  jects/{project}/
-0001c2f0: 6d6f 6465 6c2d 656e 6470 6f69 6e74 732f  model-endpoints/
-0001c300: 7b65 6e64 706f 696e 745f 6964 7d22 0a20  {endpoint_id}". 
-0001c310: 2020 2020 2020 2072 6573 706f 6e73 6520         response 
-0001c320: 3d20 7365 6c66 2e61 7069 5f63 616c 6c28  = self.api_call(
-0001c330: 0a20 2020 2020 2020 2020 2020 206d 6574  .            met
-0001c340: 686f 643d 2247 4554 222c 0a20 2020 2020  hod="GET",.     
-0001c350: 2020 2020 2020 2070 6174 683d 7061 7468         path=path
-0001c360: 2c0a 2020 2020 2020 2020 2020 2020 7061  ,.            pa
-0001c370: 7261 6d73 3d7b 0a20 2020 2020 2020 2020  rams={.         
-0001c380: 2020 2020 2020 2022 7374 6172 7422 3a20         "start": 
-0001c390: 7374 6172 742c 0a20 2020 2020 2020 2020  start,.         
-0001c3a0: 2020 2020 2020 2022 656e 6422 3a20 656e         "end": en
-0001c3b0: 642c 0a20 2020 2020 2020 2020 2020 2020  d,.             
-0001c3c0: 2020 2022 6d65 7472 6963 223a 206d 6574     "metric": met
-0001c3d0: 7269 6373 206f 7220 5b5d 2c0a 2020 2020  rics or [],.    
-0001c3e0: 2020 2020 2020 2020 2020 2020 2266 6561              "fea
-0001c3f0: 7475 7265 5f61 6e61 6c79 7369 7322 3a20  ture_analysis": 
-0001c400: 6665 6174 7572 655f 616e 616c 7973 6973  feature_analysis
-0001c410: 2c0a 2020 2020 2020 2020 2020 2020 7d2c  ,.            },
-0001c420: 0a20 2020 2020 2020 2029 0a20 2020 2020  .        ).     
-0001c430: 2020 2072 6574 7572 6e20 7363 6865 6d61     return schema
-0001c440: 732e 4d6f 6465 6c45 6e64 706f 696e 7428  s.ModelEndpoint(
-0001c450: 2a2a 7265 7370 6f6e 7365 2e6a 736f 6e28  **response.json(
-0001c460: 2929 0a0a 2020 2020 6465 6620 7061 7463  ))..    def patc
-0001c470: 685f 6d6f 6465 6c5f 656e 6470 6f69 6e74  h_model_endpoint
-0001c480: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
-0001c490: 2020 2020 2020 2020 7072 6f6a 6563 743a          project:
-0001c4a0: 2073 7472 2c0a 2020 2020 2020 2020 656e   str,.        en
-0001c4b0: 6470 6f69 6e74 5f69 643a 2073 7472 2c0a  dpoint_id: str,.
-0001c4c0: 2020 2020 2020 2020 6174 7472 6962 7574          attribut
-0001c4d0: 6573 3a20 6469 6374 2c0a 2020 2020 293a  es: dict,.    ):
-0001c4e0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-0001c4f0: 2020 2020 2055 7064 6174 6573 206d 6f64       Updates mod
-0001c500: 656c 2065 6e64 706f 696e 7420 7769 7468  el endpoint with
-0001c510: 2070 726f 7669 6465 6420 6174 7472 6962   provided attrib
-0001c520: 7574 6573 2e0a 0a20 2020 2020 2020 203a  utes...        :
-0001c530: 7061 7261 6d20 7072 6f6a 6563 743a 2054  param project: T
-0001c540: 6865 206e 616d 6520 6f66 2074 6865 2070  he name of the p
-0001c550: 726f 6a65 6374 2e0a 2020 2020 2020 2020  roject..        
-0001c560: 3a70 6172 616d 2065 6e64 706f 696e 745f  :param endpoint_
-0001c570: 6964 3a20 5468 6520 6964 206f 6620 7468  id: The id of th
-0001c580: 6520 656e 6470 6f69 6e74 2e0a 2020 2020  e endpoint..    
-0001c590: 2020 2020 3a70 6172 616d 2061 7474 7269      :param attri
-0001c5a0: 6275 7465 733a 2044 6963 7469 6f6e 6172  butes: Dictionar
-0001c5b0: 7920 6f66 2061 7474 7269 6275 7465 7320  y of attributes 
-0001c5c0: 7468 6174 2077 696c 6c20 6265 2075 7365  that will be use
-0001c5d0: 6420 666f 7220 7570 6461 7465 2074 6865  d for update the
-0001c5e0: 206d 6f64 656c 2065 6e64 706f 696e 742e   model endpoint.
-0001c5f0: 2054 6865 206b 6579 730a 2020 2020 2020   The keys.      
-0001c600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c610: 2020 2020 206f 6620 7468 6973 2064 6963       of this dic
-0001c620: 7469 6f6e 6172 7920 7368 6f75 6c64 2065  tionary should e
-0001c630: 7869 7374 2069 6e20 7468 6520 7461 7267  xist in the targ
-0001c640: 6574 2074 6162 6c65 2e20 5468 6520 7661  et table. The va
-0001c650: 6c75 6573 2073 686f 756c 6420 6265 0a20  lues should be. 
-0001c660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c670: 2020 2020 2020 2020 2020 6672 6f6d 2074            from t
-0001c680: 7970 6520 7374 7269 6e67 206f 7220 6672  ype string or fr
-0001c690: 6f6d 2061 2076 616c 6964 206e 756d 6572  om a valid numer
-0001c6a0: 6963 616c 2074 7970 6520 7375 6368 2061  ical type such a
-0001c6b0: 7320 696e 7420 6f72 2066 6c6f 6174 2e20  s int or float. 
-0001c6c0: 4d6f 7265 2064 6574 6169 6c73 0a20 2020  More details.   
-0001c6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c6e0: 2020 2020 2020 2020 6162 6f75 7420 7468          about th
-0001c6f0: 6520 6d6f 6465 6c20 656e 6470 6f69 6e74  e model endpoint
-0001c700: 2061 7661 696c 6162 6c65 2061 7474 7269   available attri
-0001c710: 6275 7465 7320 6361 6e20 6265 2066 6f75  butes can be fou
-0001c720: 6e64 2075 6e64 6572 0a20 2020 2020 2020  nd under.       
-0001c730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c740: 2020 2020 3a70 793a 636c 6173 733a 607e      :py:class:`~
-0001c750: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
-0001c760: 732e 4d6f 6465 6c45 6e64 706f 696e 7460  s.ModelEndpoint`
-0001c770: 2e0a 0a20 2020 2020 2020 2020 2020 2020  ...             
-0001c780: 2020 2020 2020 2020 2020 2020 2020 4578                Ex
-0001c790: 616d 706c 653a 3a0a 0a20 2020 2020 2020  ample::..       
-0001c7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c7b0: 2020 2020 2020 2020 2023 2047 656e 6572           # Gener
-0001c7c0: 6174 6520 6375 7272 656e 7420 7374 6174  ate current stat
-0001c7d0: 7320 666f 7220 7477 6f20 6665 6174 7572  s for two featur
-0001c7e0: 6573 0a20 2020 2020 2020 2020 2020 2020  es.             
-0001c7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c800: 2020 2063 7572 7265 6e74 5f73 7461 7473     current_stats
-0001c810: 203d 207b 2774 7664 5f73 756d 273a 2032   = {'tvd_sum': 2
-0001c820: 2e32 2c0a 2020 2020 2020 2020 2020 2020  .2,.            
-0001c830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c850: 2020 2020 2027 7476 645f 6d65 616e 273a       'tvd_mean':
-0001c860: 2030 2e35 2c0a 2020 2020 2020 2020 2020   0.5,.          
-0001c870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c890: 2020 2020 2020 2027 6865 6c6c 696e 6765         'hellinge
-0001c8a0: 725f 7375 6d27 3a20 332e 362c 0a20 2020  r_sum': 3.6,.   
-0001c8b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c8d0: 2020 2020 2020 2020 2020 2020 2020 2768                'h
-0001c8e0: 656c 6c69 6e67 6572 5f6d 6561 6e27 3a20  ellinger_mean': 
-0001c8f0: 302e 392c 0a20 2020 2020 2020 2020 2020  0.9,.           
-0001c900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c920: 2020 2020 2020 276b 6c64 5f73 756d 273a        'kld_sum':
-0001c930: 2032 342e 322c 0a20 2020 2020 2020 2020   24.2,.         
-0001c940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c960: 2020 2020 2020 2020 276b 6c64 5f6d 6561          'kld_mea
-0001c970: 6e27 3a20 362e 302c 0a20 2020 2020 2020  n': 6.0,.       
-0001c980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c9a0: 2020 2020 2020 2020 2020 2766 3127 3a20            'f1': 
-0001c9b0: 7b27 7476 6427 3a20 302e 352c 2027 6865  {'tvd': 0.5, 'he
-0001c9c0: 6c6c 696e 6765 7227 3a20 312e 302c 2027  llinger': 1.0, '
-0001c9d0: 6b6c 6427 3a20 362e 347d 2c0a 2020 2020  kld': 6.4},.    
-0001c9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ca00: 2020 2020 2020 2020 2020 2020 2027 6632               'f2
-0001ca10: 273a 207b 2774 7664 273a 2030 2e35 2c20  ': {'tvd': 0.5, 
-0001ca20: 2768 656c 6c69 6e67 6572 273a 2031 2e30  'hellinger': 1.0
-0001ca30: 2c20 276b 6c64 273a 2036 2e35 7d7d 0a0a  , 'kld': 6.5}}..
-0001ca40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ca50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ca60: 2320 4372 6561 7465 2061 7474 7269 6275  # Create attribu
-0001ca70: 7465 7320 6469 6374 696f 6e61 7279 2061  tes dictionary a
-0001ca80: 6363 6f72 6469 6e67 2074 6f20 7468 6520  ccording to the 
-0001ca90: 7265 7175 6972 6564 2066 6f72 6d61 740a  required format.
-0001caa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cac0: 6174 7472 6962 7574 6573 203d 207b 6063  attributes = {`c
-0001cad0: 7572 7265 6e74 5f73 7461 7473 603a 206a  urrent_stats`: j
-0001cae0: 736f 6e2e 6475 6d70 7328 6375 7272 656e  son.dumps(curren
-0001caf0: 745f 7374 6174 7329 2c0a 2020 2020 2020  t_stats),.      
-0001cb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cb10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cb20: 2020 2020 2020 2020 6064 7269 6674 5f73          `drift_s
-0001cb30: 7461 7475 7360 3a20 2244 5249 4654 5f44  tatus`: "DRIFT_D
-0001cb40: 4554 4543 5445 4422 7d0a 0a20 2020 2020  ETECTED"}..     
-0001cb50: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
-0001cb60: 6174 7472 6962 7574 6573 203d 207b 2261  attributes = {"a
-0001cb70: 7474 7269 6275 7465 7322 3a20 5f61 735f  ttributes": _as_
-0001cb80: 6a73 6f6e 2861 7474 7269 6275 7465 7329  json(attributes)
-0001cb90: 7d0a 2020 2020 2020 2020 7061 7468 203d  }.        path =
-0001cba0: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
-0001cbb0: 6a65 6374 7d2f 6d6f 6465 6c2d 656e 6470  ject}/model-endp
-0001cbc0: 6f69 6e74 732f 7b65 6e64 706f 696e 745f  oints/{endpoint_
-0001cbd0: 6964 7d22 0a20 2020 2020 2020 2073 656c  id}".        sel
-0001cbe0: 662e 6170 695f 6361 6c6c 280a 2020 2020  f.api_call(.    
-0001cbf0: 2020 2020 2020 2020 6d65 7468 6f64 3d22          method="
-0001cc00: 5041 5443 4822 2c0a 2020 2020 2020 2020  PATCH",.        
-0001cc10: 2020 2020 7061 7468 3d70 6174 682c 0a20      path=path,. 
-0001cc20: 2020 2020 2020 2020 2020 2070 6172 616d             param
-0001cc30: 733d 6174 7472 6962 7574 6573 2c0a 2020  s=attributes,.  
-0001cc40: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
-0001cc50: 2063 7265 6174 655f 6d61 726b 6574 706c   create_marketpl
-0001cc60: 6163 655f 736f 7572 6365 280a 2020 2020  ace_source(.    
-0001cc70: 2020 2020 7365 6c66 2c20 736f 7572 6365      self, source
-0001cc80: 3a20 556e 696f 6e5b 6469 6374 2c20 7363  : Union[dict, sc
-0001cc90: 6865 6d61 732e 496e 6465 7865 644d 6172  hemas.IndexedMar
-0001cca0: 6b65 7470 6c61 6365 536f 7572 6365 5d0a  ketplaceSource].
-0001ccb0: 2020 2020 293a 0a20 2020 2020 2020 2022      ):.        "
-0001ccc0: 2222 0a20 2020 2020 2020 2041 6464 2061  "".        Add a
-0001ccd0: 206e 6577 206d 6172 6b65 7470 6c61 6365   new marketplace
-0001cce0: 2073 6f75 7263 652e 0a0a 2020 2020 2020   source...      
-0001ccf0: 2020 4d4c 5275 6e20 6d61 696e 7461 696e    MLRun maintain
-0001cd00: 7320 616e 206f 7264 6572 6564 206c 6973  s an ordered lis
-0001cd10: 7420 6f66 206d 6172 6b65 7470 6c61 6365  t of marketplace
-0001cd20: 2073 6f75 7263 6573 2028 e280 9c73 6f75   sources (...sou
-0001cd30: 7263 6573 e280 9d29 2045 6163 6820 736f  rces...) Each so
-0001cd40: 7572 6365 2068 6173 0a20 2020 2020 2020  urce has.       
-0001cd50: 2069 7473 2064 6574 6169 6c73 2072 6567   its details reg
-0001cd60: 6973 7465 7265 6420 616e 6420 6974 7320  istered and its 
-0001cd70: 6f72 6465 7220 7769 7468 696e 2074 6865  order within the
-0001cd80: 206c 6973 742e 2057 6865 6e20 6372 6561   list. When crea
-0001cd90: 7469 6e67 2061 206e 6577 2073 6f75 7263  ting a new sourc
-0001cda0: 652c 2074 6865 2073 7065 6369 616c 206f  e, the special o
-0001cdb0: 7264 6572 2060 602d 3160 600a 2020 2020  rder ``-1``.    
-0001cdc0: 2020 2020 6361 6e20 6265 2075 7365 6420      can be used 
-0001cdd0: 746f 206d 6172 6b20 7468 6973 2073 6f75  to mark this sou
-0001cde0: 7263 6520 6173 206c 6173 7420 696e 2074  rce as last in t
-0001cdf0: 6865 206c 6973 742e 2048 6f77 6576 6572  he list. However
-0001ce00: 2c20 6f6e 6365 2074 6865 2073 6f75 7263  , once the sourc
-0001ce10: 6520 6973 2069 6e20 7468 6520 4d4c 5275  e is in the MLRu
-0001ce20: 6e20 6c69 7374 2c0a 2020 2020 2020 2020  n list,.        
-0001ce30: 6974 7320 6f72 6465 7220 7769 6c6c 2061  its order will a
-0001ce40: 6c77 6179 7320 6265 2060 603e 3060 602e  lways be ``>0``.
-0001ce50: 0a0a 2020 2020 2020 2020 5468 6520 676c  ..        The gl
-0001ce60: 6f62 616c 206d 6172 6b65 7470 6c61 6365  obal marketplace
-0001ce70: 2073 6f75 7263 6520 616c 7761 7973 2065   source always e
-0001ce80: 7869 7374 7320 696e 2074 6865 206c 6973  xists in the lis
-0001ce90: 742c 2061 6e64 2069 7320 616c 7761 7973  t, and is always
-0001cea0: 2074 6865 206c 6173 7420 736f 7572 6365   the last source
-0001ceb0: 0a20 2020 2020 2020 2028 6060 6f72 6465  .        (``orde
-0001cec0: 7220 3d20 2d31 6060 292e 2049 7420 6361  r = -1``). It ca
-0001ced0: 6e6e 6f74 2062 6520 6d6f 6469 6669 6564  nnot be modified
-0001cee0: 206e 6f72 2063 616e 2069 7420 6265 206d   nor can it be m
-0001cef0: 6f76 6564 2074 6f20 616e 6f74 6865 7220  oved to another 
-0001cf00: 6f72 6465 7220 696e 2074 6865 206c 6973  order in the lis
-0001cf10: 742e 0a0a 2020 2020 2020 2020 5468 6520  t...        The 
-0001cf20: 736f 7572 6365 206f 626a 6563 7420 6d61  source object ma
-0001cf30: 7920 636f 6e74 6169 6e20 6372 6564 656e  y contain creden
-0001cf40: 7469 616c 7320 7768 6963 6820 6172 6520  tials which are 
-0001cf50: 6e65 6564 6564 2074 6f20 6163 6365 7373  needed to access
-0001cf60: 2074 6865 2064 6174 6173 746f 7265 2077   the datastore w
-0001cf70: 6865 7265 2074 6865 2073 6f75 7263 6520  here the source 
-0001cf80: 6973 2073 746f 7265 642e 0a20 2020 2020  is stored..     
-0001cf90: 2020 2054 6865 7365 2063 7265 6465 6e74     These credent
-0001cfa0: 6961 6c73 2061 7265 206e 6f74 206b 6570  ials are not kep
-0001cfb0: 7420 696e 2074 6865 204d 4c52 756e 2044  t in the MLRun D
-0001cfc0: 422c 2062 7574 2061 7265 2073 746f 7265  B, but are store
-0001cfd0: 6420 696e 7369 6465 2061 206b 7562 6572  d inside a kuber
-0001cfe0: 6e65 7465 7320 7365 6372 6574 206f 626a  netes secret obj
-0001cff0: 6563 7420 6d61 696e 7461 696e 6564 2062  ect maintained b
-0001d000: 790a 2020 2020 2020 2020 4d4c 5275 6e2e  y.        MLRun.
-0001d010: 2054 6865 7920 6172 6520 6e6f 7420 7265   They are not re
-0001d020: 7475 726e 6564 2074 6872 6f75 6768 2061  turned through a
-0001d030: 6e79 2041 5049 2066 726f 6d20 4d4c 5275  ny API from MLRu
-0001d040: 6e2e 0a0a 2020 2020 2020 2020 4578 616d  n...        Exam
-0001d050: 706c 653a 3a0a 0a20 2020 2020 2020 2020  ple::..         
-0001d060: 2020 2069 6d70 6f72 7420 6d6c 7275 6e2e     import mlrun.
-0001d070: 6170 692e 7363 6865 6d61 730a 0a20 2020  api.schemas..   
-0001d080: 2020 2020 2020 2020 2023 2041 6464 2061           # Add a
-0001d090: 2070 7269 7661 7465 2073 6f75 7263 6520   private source 
-0001d0a0: 6173 2074 6865 206c 6173 7420 6f6e 6520  as the last one 
-0001d0b0: 2877 696c 6c20 6265 2023 3120 696e 2074  (will be #1 in t
-0001d0c0: 6865 206c 6973 7429 0a20 2020 2020 2020  he list).       
-0001d0d0: 2020 2020 2070 7269 7661 7465 5f73 6f75       private_sou
-0001d0e0: 7263 6520 3d20 6d6c 7275 6e2e 6170 692e  rce = mlrun.api.
-0001d0f0: 7363 6865 6d61 732e 496e 6465 7865 644d  schemas.IndexedM
-0001d100: 6172 6b65 7470 6c61 6365 536f 7572 6365  arketplaceSource
-0001d110: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
-0001d120: 2020 6f72 6465 723d 2d31 2c0a 2020 2020    order=-1,.    
-0001d130: 2020 2020 2020 2020 2020 2020 736f 7572              sour
-0001d140: 6365 3d6d 6c72 756e 2e61 7069 2e73 6368  ce=mlrun.api.sch
-0001d150: 656d 6173 2e4d 6172 6b65 7470 6c61 6365  emas.Marketplace
-0001d160: 536f 7572 6365 280a 2020 2020 2020 2020  Source(.        
-0001d170: 2020 2020 2020 2020 2020 2020 6d65 7461              meta
-0001d180: 6461 7461 3d6d 6c72 756e 2e61 7069 2e73  data=mlrun.api.s
-0001d190: 6368 656d 6173 2e4d 6172 6b65 7470 6c61  chemas.Marketpla
-0001d1a0: 6365 4f62 6a65 6374 4d65 7461 6461 7461  ceObjectMetadata
-0001d1b0: 286e 616d 653d 2270 7269 7622 2c20 6465  (name="priv", de
-0001d1c0: 7363 7269 7074 696f 6e3d 2261 2070 7269  scription="a pri
-0001d1d0: 7661 7465 2073 6f75 7263 6522 292c 0a20  vate source"),. 
-0001d1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d1f0: 2020 2073 7065 633d 6d6c 7275 6e2e 6170     spec=mlrun.ap
-0001d200: 692e 7363 6865 6d61 732e 4d61 726b 6574  i.schemas.Market
-0001d210: 706c 6163 6553 6f75 7263 6553 7065 6328  placeSourceSpec(
-0001d220: 7061 7468 3d22 2f6c 6f63 616c 2f70 6174  path="/local/pat
-0001d230: 682f 746f 2f73 6f75 7263 6522 2c20 6368  h/to/source", ch
-0001d240: 616e 6e65 6c3d 2264 6576 656c 6f70 6d65  annel="developme
-0001d250: 6e74 2229 0a20 2020 2020 2020 2020 2020  nt").           
-0001d260: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
-0001d270: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
-0001d280: 2064 622e 6372 6561 7465 5f6d 6172 6b65   db.create_marke
-0001d290: 7470 6c61 6365 5f73 6f75 7263 6528 7072  tplace_source(pr
-0001d2a0: 6976 6174 655f 736f 7572 6365 290a 0a20  ivate_source).. 
-0001d2b0: 2020 2020 2020 2020 2020 2023 2041 6464             # Add
-0001d2c0: 2061 6e6f 7468 6572 2073 6f75 7263 6520   another source 
-0001d2d0: 6173 2031 7374 2069 6e20 7468 6520 6c69  as 1st in the li
-0001d2e0: 7374 202d 2077 696c 6c20 7075 7368 2070  st - will push p
-0001d2f0: 7265 7669 6f75 7320 6f6e 6520 746f 2062  revious one to b
-0001d300: 6520 2332 0a20 2020 2020 2020 2020 2020  e #2.           
-0001d310: 2061 6e6f 7468 6572 5f73 6f75 7263 6520   another_source 
-0001d320: 3d20 6d6c 7275 6e2e 6170 692e 7363 6865  = mlrun.api.sche
-0001d330: 6d61 732e 496e 6465 7865 644d 6172 6b65  mas.IndexedMarke
-0001d340: 7470 6c61 6365 536f 7572 6365 280a 2020  tplaceSource(.  
-0001d350: 2020 2020 2020 2020 2020 2020 2020 6f72                or
-0001d360: 6465 723d 312c 0a20 2020 2020 2020 2020  der=1,.         
-0001d370: 2020 2020 2020 2073 6f75 7263 653d 6d6c         source=ml
-0001d380: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
-0001d390: 4d61 726b 6574 706c 6163 6553 6f75 7263  MarketplaceSourc
-0001d3a0: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
-0001d3b0: 2020 2020 2020 206d 6574 6164 6174 613d         metadata=
-0001d3c0: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
-0001d3d0: 732e 4d61 726b 6574 706c 6163 654f 626a  s.MarketplaceObj
-0001d3e0: 6563 744d 6574 6164 6174 6128 6e61 6d65  ectMetadata(name
-0001d3f0: 3d22 7072 6976 2d32 222c 2064 6573 6372  ="priv-2", descr
-0001d400: 6970 7469 6f6e 3d22 616e 6f74 6865 7220  iption="another 
-0001d410: 736f 7572 6365 2229 2c0a 2020 2020 2020  source"),.      
-0001d420: 2020 2020 2020 2020 2020 2020 2020 7370                sp
-0001d430: 6563 3d6d 6c72 756e 2e61 7069 2e73 6368  ec=mlrun.api.sch
-0001d440: 656d 6173 2e4d 6172 6b65 7470 6c61 6365  emas.Marketplace
-0001d450: 536f 7572 6365 5370 6563 280a 2020 2020  SourceSpec(.    
-0001d460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d470: 2020 2020 7061 7468 3d22 2f6c 6f63 616c      path="/local
-0001d480: 2f70 6174 682f 746f 2f73 6f75 7263 652f  /path/to/source/
-0001d490: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-0001d4a0: 2020 2020 2020 2020 2020 2020 6368 616e              chan
-0001d4b0: 6e65 6c3d 2264 6576 656c 6f70 6d65 6e74  nel="development
-0001d4c0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-0001d4d0: 2020 2020 2020 2020 2020 2063 7265 6465             crede
-0001d4e0: 6e74 6961 6c73 3d7b 2e2e 2e7d 0a20 2020  ntials={...}.   
-0001d4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d500: 2029 0a20 2020 2020 2020 2020 2020 2020   ).             
-0001d510: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
-0001d520: 2029 0a20 2020 2020 2020 2020 2020 2064   ).            d
-0001d530: 622e 6372 6561 7465 5f6d 6172 6b65 7470  b.create_marketp
-0001d540: 6c61 6365 5f73 6f75 7263 6528 616e 6f74  lace_source(anot
-0001d550: 6865 725f 736f 7572 6365 290a 0a20 2020  her_source)..   
-0001d560: 2020 2020 203a 7061 7261 6d20 736f 7572       :param sour
-0001d570: 6365 3a20 5468 6520 736f 7572 6365 2061  ce: The source a
-0001d580: 6e64 2069 7473 206f 7264 6572 2c20 6f66  nd its order, of
-0001d590: 2074 7970 650a 2020 2020 2020 2020 2020   type.          
-0001d5a0: 2020 3a70 793a 636c 6173 733a 607e 6d6c    :py:class:`~ml
-0001d5b0: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
-0001d5c0: 6d61 726b 6574 706c 6163 652e 496e 6465  marketplace.Inde
-0001d5d0: 7865 644d 6172 6b65 7470 6c61 6365 536f  xedMarketplaceSo
-0001d5e0: 7572 6365 602c 206f 7220 696e 2064 6963  urce`, or in dic
-0001d5f0: 7469 6f6e 6172 7920 666f 726d 2e0a 2020  tionary form..  
-0001d600: 2020 2020 2020 3a72 6574 7572 6e73 3a20        :returns: 
-0001d610: 5468 6520 736f 7572 6365 206f 626a 6563  The source objec
-0001d620: 7420 6173 2069 6e73 6572 7465 6420 696e  t as inserted in
-0001d630: 746f 2074 6865 2064 6174 6162 6173 652c  to the database,
-0001d640: 2077 6974 6820 6372 6564 656e 7469 616c   with credential
-0001d650: 7320 7374 7269 7070 6564 2e0a 2020 2020  s stripped..    
-0001d660: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-0001d670: 7061 7468 203d 2022 6d61 726b 6574 706c  path = "marketpl
-0001d680: 6163 652f 736f 7572 6365 7322 0a20 2020  ace/sources".   
-0001d690: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
-0001d6a0: 6365 2873 6f75 7263 652c 2073 6368 656d  ce(source, schem
-0001d6b0: 6173 2e49 6e64 6578 6564 4d61 726b 6574  as.IndexedMarket
-0001d6c0: 706c 6163 6553 6f75 7263 6529 3a0a 2020  placeSource):.  
-0001d6d0: 2020 2020 2020 2020 2020 736f 7572 6365            source
-0001d6e0: 203d 2073 6f75 7263 652e 6469 6374 2829   = source.dict()
-0001d6f0: 0a20 2020 2020 2020 2072 6573 706f 6e73  .        respons
-0001d700: 6520 3d20 7365 6c66 2e61 7069 5f63 616c  e = self.api_cal
-0001d710: 6c28 6d65 7468 6f64 3d22 504f 5354 222c  l(method="POST",
-0001d720: 2070 6174 683d 7061 7468 2c20 6a73 6f6e   path=path, json
-0001d730: 3d73 6f75 7263 6529 0a20 2020 2020 2020  =source).       
-0001d740: 2072 6574 7572 6e20 7363 6865 6d61 732e   return schemas.
-0001d750: 496e 6465 7865 644d 6172 6b65 7470 6c61  IndexedMarketpla
-0001d760: 6365 536f 7572 6365 282a 2a72 6573 706f  ceSource(**respo
-0001d770: 6e73 652e 6a73 6f6e 2829 290a 0a20 2020  nse.json())..   
-0001d780: 2064 6566 2073 746f 7265 5f6d 6172 6b65   def store_marke
-0001d790: 7470 6c61 6365 5f73 6f75 7263 6528 0a20  tplace_source(. 
-0001d7a0: 2020 2020 2020 2073 656c 662c 2073 6f75         self, sou
-0001d7b0: 7263 655f 6e61 6d65 3a20 7374 722c 2073  rce_name: str, s
-0001d7c0: 6f75 7263 653a 2055 6e69 6f6e 5b64 6963  ource: Union[dic
-0001d7d0: 742c 2073 6368 656d 6173 2e49 6e64 6578  t, schemas.Index
-0001d7e0: 6564 4d61 726b 6574 706c 6163 6553 6f75  edMarketplaceSou
-0001d7f0: 7263 655d 0a20 2020 2029 3a0a 2020 2020  rce].    ):.    
-0001d800: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-0001d810: 4372 6561 7465 206f 7220 7265 706c 6163  Create or replac
-0001d820: 6520 6120 6d61 726b 6574 706c 6163 6520  e a marketplace 
-0001d830: 736f 7572 6365 2e0a 2020 2020 2020 2020  source..        
-0001d840: 466f 7220 616e 2065 7861 6d70 6c65 206f  For an example o
-0001d850: 6620 7468 6520 736f 7572 6365 2066 6f72  f the source for
-0001d860: 6d61 7420 616e 6420 6578 706c 616e 6174  mat and explanat
-0001d870: 696f 6e20 6f66 2074 6865 2073 6f75 7263  ion of the sourc
-0001d880: 6520 6f72 6465 7220 6c6f 6769 632c 0a20  e order logic,. 
-0001d890: 2020 2020 2020 2070 6c65 6173 6520 7365         please se
-0001d8a0: 6520 3a70 793a 6675 6e63 3a60 7e63 7265  e :py:func:`~cre
-0001d8b0: 6174 655f 6d61 726b 6574 706c 6163 655f  ate_marketplace_
-0001d8c0: 736f 7572 6365 602e 2054 6869 7320 6d65  source`. This me
-0001d8d0: 7468 6f64 2063 616e 2062 6520 7573 6564  thod can be used
-0001d8e0: 2074 6f20 6d6f 6469 6679 2074 6865 2073   to modify the s
-0001d8f0: 6f75 7263 6520 6974 7365 6c66 206f 7220  ource itself or 
-0001d900: 6974 730a 2020 2020 2020 2020 6f72 6465  its.        orde
-0001d910: 7220 696e 2074 6865 206c 6973 7420 6f66  r in the list of
-0001d920: 2073 6f75 7263 6573 2e0a 0a20 2020 2020   sources...     
-0001d930: 2020 203a 7061 7261 6d20 736f 7572 6365     :param source
-0001d940: 5f6e 616d 653a 204e 616d 6520 6f66 2074  _name: Name of t
-0001d950: 6865 2073 6f75 7263 6520 6f62 6a65 6374  he source object
-0001d960: 2074 6f20 6d6f 6469 6679 2f63 7265 6174   to modify/creat
-0001d970: 652e 2049 7420 6d75 7374 206d 6174 6368  e. It must match
-0001d980: 2074 6865 2060 6073 6f75 7263 652e 6d65   the ``source.me
-0001d990: 7461 6461 7461 2e6e 616d 6560 600a 2020  tadata.name``.  
-0001d9a0: 2020 2020 2020 2020 2020 7061 7261 6d65            parame
-0001d9b0: 7465 7220 696e 2074 6865 2073 6f75 7263  ter in the sourc
-0001d9c0: 6520 6974 7365 6c66 2e0a 2020 2020 2020  e itself..      
-0001d9d0: 2020 3a70 6172 616d 2073 6f75 7263 653a    :param source:
-0001d9e0: 2053 6f75 7263 6520 6f62 6a65 6374 2074   Source object t
-0001d9f0: 6f20 7374 6f72 6520 696e 2074 6865 2064  o store in the d
-0001da00: 6174 6162 6173 652e 0a20 2020 2020 2020  atabase..       
-0001da10: 203a 7265 7475 726e 733a 2054 6865 2073   :returns: The s
-0001da20: 6f75 7263 6520 6f62 6a65 6374 2061 7320  ource object as 
-0001da30: 7374 6f72 6564 2069 6e20 7468 6520 4442  stored in the DB
-0001da40: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
-0001da50: 2020 2020 2020 7061 7468 203d 2066 226d        path = f"m
-0001da60: 6172 6b65 7470 6c61 6365 2f73 6f75 7263  arketplace/sourc
-0001da70: 6573 2f7b 736f 7572 6365 5f6e 616d 657d  es/{source_name}
-0001da80: 220a 2020 2020 2020 2020 6966 2069 7369  ".        if isi
-0001da90: 6e73 7461 6e63 6528 736f 7572 6365 2c20  nstance(source, 
-0001daa0: 7363 6865 6d61 732e 496e 6465 7865 644d  schemas.IndexedM
-0001dab0: 6172 6b65 7470 6c61 6365 536f 7572 6365  arketplaceSource
-0001dac0: 293a 0a20 2020 2020 2020 2020 2020 2073  ):.            s
-0001dad0: 6f75 7263 6520 3d20 736f 7572 6365 2e64  ource = source.d
-0001dae0: 6963 7428 290a 0a20 2020 2020 2020 2072  ict()..        r
-0001daf0: 6573 706f 6e73 6520 3d20 7365 6c66 2e61  esponse = self.a
-0001db00: 7069 5f63 616c 6c28 6d65 7468 6f64 3d22  pi_call(method="
-0001db10: 5055 5422 2c20 7061 7468 3d70 6174 682c  PUT", path=path,
-0001db20: 206a 736f 6e3d 736f 7572 6365 290a 2020   json=source).  
-0001db30: 2020 2020 2020 7265 7475 726e 2073 6368        return sch
-0001db40: 656d 6173 2e49 6e64 6578 6564 4d61 726b  emas.IndexedMark
-0001db50: 6574 706c 6163 6553 6f75 7263 6528 2a2a  etplaceSource(**
-0001db60: 7265 7370 6f6e 7365 2e6a 736f 6e28 2929  response.json())
-0001db70: 0a0a 2020 2020 6465 6620 6c69 7374 5f6d  ..    def list_m
-0001db80: 6172 6b65 7470 6c61 6365 5f73 6f75 7263  arketplace_sourc
-0001db90: 6573 2873 656c 6629 3a0a 2020 2020 2020  es(self):.      
-0001dba0: 2020 2222 220a 2020 2020 2020 2020 4c69    """.        Li
-0001dbb0: 7374 206d 6172 6b65 7470 6c61 6365 2073  st marketplace s
-0001dbc0: 6f75 7263 6573 2069 6e20 7468 6520 4d4c  ources in the ML
-0001dbd0: 5275 6e20 4442 2e0a 2020 2020 2020 2020  Run DB..        
-0001dbe0: 2222 220a 2020 2020 2020 2020 7061 7468  """.        path
-0001dbf0: 203d 2022 6d61 726b 6574 706c 6163 652f   = "marketplace/
-0001dc00: 736f 7572 6365 7322 0a20 2020 2020 2020  sources".       
-0001dc10: 2072 6573 706f 6e73 6520 3d20 7365 6c66   response = self
-0001dc20: 2e61 7069 5f63 616c 6c28 6d65 7468 6f64  .api_call(method
-0001dc30: 3d22 4745 5422 2c20 7061 7468 3d70 6174  ="GET", path=pat
-0001dc40: 6829 2e6a 736f 6e28 290a 2020 2020 2020  h).json().      
-0001dc50: 2020 7265 7375 6c74 7320 3d20 5b5d 0a20    results = []. 
-0001dc60: 2020 2020 2020 2066 6f72 2069 7465 6d20         for item 
-0001dc70: 696e 2072 6573 706f 6e73 653a 0a20 2020  in response:.   
-0001dc80: 2020 2020 2020 2020 2072 6573 756c 7473           results
-0001dc90: 2e61 7070 656e 6428 7363 6865 6d61 732e  .append(schemas.
-0001dca0: 496e 6465 7865 644d 6172 6b65 7470 6c61  IndexedMarketpla
-0001dcb0: 6365 536f 7572 6365 282a 2a69 7465 6d29  ceSource(**item)
-0001dcc0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0001dcd0: 2072 6573 756c 7473 0a0a 2020 2020 6465   results..    de
-0001dce0: 6620 6765 745f 6d61 726b 6574 706c 6163  f get_marketplac
-0001dcf0: 655f 736f 7572 6365 2873 656c 662c 2073  e_source(self, s
-0001dd00: 6f75 7263 655f 6e61 6d65 3a20 7374 7229  ource_name: str)
-0001dd10: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-0001dd20: 2020 2020 2020 5265 7472 6965 7665 2061        Retrieve a
-0001dd30: 206d 6172 6b65 7470 6c61 6365 2073 6f75   marketplace sou
-0001dd40: 7263 6520 6672 6f6d 2074 6865 2044 422e  rce from the DB.
-0001dd50: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0001dd60: 2073 6f75 7263 655f 6e61 6d65 3a20 4e61   source_name: Na
-0001dd70: 6d65 206f 6620 7468 6520 6d61 726b 6574  me of the market
-0001dd80: 706c 6163 6520 736f 7572 6365 2074 6f20  place source to 
-0001dd90: 7265 7472 6965 7665 2e0a 2020 2020 2020  retrieve..      
-0001dda0: 2020 2222 220a 2020 2020 2020 2020 7061    """.        pa
-0001ddb0: 7468 203d 2066 226d 6172 6b65 7470 6c61  th = f"marketpla
-0001ddc0: 6365 2f73 6f75 7263 6573 2f7b 736f 7572  ce/sources/{sour
-0001ddd0: 6365 5f6e 616d 657d 220a 2020 2020 2020  ce_name}".      
-0001dde0: 2020 7265 7370 6f6e 7365 203d 2073 656c    response = sel
-0001ddf0: 662e 6170 695f 6361 6c6c 286d 6574 686f  f.api_call(metho
-0001de00: 643d 2247 4554 222c 2070 6174 683d 7061  d="GET", path=pa
-0001de10: 7468 290a 2020 2020 2020 2020 7265 7475  th).        retu
-0001de20: 726e 2073 6368 656d 6173 2e49 6e64 6578  rn schemas.Index
-0001de30: 6564 4d61 726b 6574 706c 6163 6553 6f75  edMarketplaceSou
-0001de40: 7263 6528 2a2a 7265 7370 6f6e 7365 2e6a  rce(**response.j
-0001de50: 736f 6e28 2929 0a0a 2020 2020 6465 6620  son())..    def 
-0001de60: 6465 6c65 7465 5f6d 6172 6b65 7470 6c61  delete_marketpla
-0001de70: 6365 5f73 6f75 7263 6528 7365 6c66 2c20  ce_source(self, 
-0001de80: 736f 7572 6365 5f6e 616d 653a 2073 7472  source_name: str
-0001de90: 293a 0a20 2020 2020 2020 2022 2222 0a20  ):.        """. 
-0001dea0: 2020 2020 2020 2044 656c 6574 6520 6120         Delete a 
-0001deb0: 6d61 726b 6574 706c 6163 6520 736f 7572  marketplace sour
-0001dec0: 6365 2066 726f 6d20 7468 6520 4442 2e0a  ce from the DB..
-0001ded0: 2020 2020 2020 2020 5468 6520 736f 7572          The sour
-0001dee0: 6365 2077 696c 6c20 6265 2064 656c 6574  ce will be delet
-0001def0: 6564 2066 726f 6d20 7468 6520 6c69 7374  ed from the list
-0001df00: 2c20 616e 6420 616e 7920 666f 6c6c 6f77  , and any follow
-0001df10: 696e 6720 736f 7572 6365 7320 7769 6c6c  ing sources will
-0001df20: 2062 6520 7072 6f6d 6f74 6564 202d 2066   be promoted - f
-0001df30: 6f72 2065 7861 6d70 6c65 2c20 6966 2074  or example, if t
-0001df40: 6865 0a20 2020 2020 2020 2031 7374 2073  he.        1st s
-0001df50: 6f75 7263 6520 6973 2064 656c 6574 6564  ource is deleted
-0001df60: 2c20 7468 6520 326e 6420 736f 7572 6365  , the 2nd source
-0001df70: 2077 696c 6c20 6265 636f 6d65 2023 3120   will become #1 
-0001df80: 696e 2074 6865 206c 6973 742e 0a20 2020  in the list..   
-0001df90: 2020 2020 2054 6865 2067 6c6f 6261 6c20       The global 
-0001dfa0: 6d61 726b 6574 706c 6163 6520 736f 7572  marketplace sour
-0001dfb0: 6365 2063 616e 6e6f 7420 6265 2064 656c  ce cannot be del
-0001dfc0: 6574 6564 2e0a 0a20 2020 2020 2020 203a  eted...        :
-0001dfd0: 7061 7261 6d20 736f 7572 6365 5f6e 616d  param source_nam
-0001dfe0: 653a 204e 616d 6520 6f66 2074 6865 206d  e: Name of the m
-0001dff0: 6172 6b65 7470 6c61 6365 2073 6f75 7263  arketplace sourc
-0001e000: 6520 746f 2064 656c 6574 652e 0a20 2020  e to delete..   
-0001e010: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0001e020: 2070 6174 6820 3d20 6622 6d61 726b 6574   path = f"market
-0001e030: 706c 6163 652f 736f 7572 6365 732f 7b73  place/sources/{s
-0001e040: 6f75 7263 655f 6e61 6d65 7d22 0a20 2020  ource_name}".   
-0001e050: 2020 2020 2073 656c 662e 6170 695f 6361       self.api_ca
-0001e060: 6c6c 286d 6574 686f 643d 2244 454c 4554  ll(method="DELET
-0001e070: 4522 2c20 7061 7468 3d70 6174 6829 0a0a  E", path=path)..
-0001e080: 2020 2020 6465 6620 6765 745f 6d61 726b      def get_mark
-0001e090: 6574 706c 6163 655f 6361 7461 6c6f 6728  etplace_catalog(
-0001e0a0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
-0001e0b0: 2020 2020 2020 2073 6f75 7263 655f 6e61         source_na
-0001e0c0: 6d65 3a20 7374 722c 0a20 2020 2020 2020  me: str,.       
-0001e0d0: 2063 6861 6e6e 656c 3a20 7374 7220 3d20   channel: str = 
-0001e0e0: 4e6f 6e65 2c0a 2020 2020 2020 2020 7665  None,.        ve
-0001e0f0: 7273 696f 6e3a 2073 7472 203d 204e 6f6e  rsion: str = Non
-0001e100: 652c 0a20 2020 2020 2020 2074 6167 3a20  e,.        tag: 
-0001e110: 7374 7220 3d20 4e6f 6e65 2c0a 2020 2020  str = None,.    
-0001e120: 2020 2020 666f 7263 655f 7265 6672 6573      force_refres
-0001e130: 683a 2062 6f6f 6c20 3d20 4661 6c73 652c  h: bool = False,
-0001e140: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
-0001e150: 2222 220a 2020 2020 2020 2020 5265 7472  """.        Retr
-0001e160: 6965 7665 2074 6865 2069 7465 6d20 6361  ieve the item ca
-0001e170: 7461 6c6f 6720 666f 7220 6120 7370 6563  talog for a spec
-0001e180: 6966 6965 6420 6d61 726b 6574 706c 6163  ified marketplac
-0001e190: 6520 736f 7572 6365 2e0a 2020 2020 2020  e source..      
-0001e1a0: 2020 5468 6520 6c69 7374 206f 6620 6974    The list of it
-0001e1b0: 656d 7320 6361 6e20 6265 2066 696c 7465  ems can be filte
-0001e1c0: 7265 6420 6163 636f 7264 696e 6720 746f  red according to
-0001e1d0: 2076 6172 696f 7573 2066 696c 7465 7273   various filters
-0001e1e0: 2c20 7573 696e 6720 6974 656d 2773 206d  , using item's m
-0001e1f0: 6574 6164 6174 6120 746f 2066 696c 7465  etadata to filte
-0001e200: 722e 0a0a 2020 2020 2020 2020 3a70 6172  r...        :par
-0001e210: 616d 2073 6f75 7263 655f 6e61 6d65 3a20  am source_name: 
-0001e220: 4e61 6d65 206f 6620 7468 6520 736f 7572  Name of the sour
-0001e230: 6365 2e0a 2020 2020 2020 2020 3a70 6172  ce..        :par
-0001e240: 616d 2063 6861 6e6e 656c 3a20 4669 6c74  am channel: Filt
-0001e250: 6572 2069 7465 6d73 2061 6363 6f72 6469  er items accordi
-0001e260: 6e67 2074 6f20 7468 6569 7220 6368 616e  ng to their chan
-0001e270: 6e65 6c2e 2046 6f72 2065 7861 6d70 6c65  nel. For example
-0001e280: 2060 6064 6576 656c 6f70 6d65 6e74 6060   ``development``
-0001e290: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0001e2a0: 2076 6572 7369 6f6e 3a20 4669 6c74 6572   version: Filter
-0001e2b0: 2069 7465 6d73 2061 6363 6f72 6469 6e67   items according
-0001e2c0: 2074 6f20 7468 6569 7220 7665 7273 696f   to their versio
-0001e2d0: 6e2e 0a20 2020 2020 2020 203a 7061 7261  n..        :para
-0001e2e0: 6d20 7461 673a 2046 696c 7465 7220 6974  m tag: Filter it
-0001e2f0: 656d 7320 6261 7365 6420 6f6e 2074 6167  ems based on tag
-0001e300: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0001e310: 2066 6f72 6365 5f72 6566 7265 7368 3a20   force_refresh: 
-0001e320: 4d61 6b65 2074 6865 2073 6572 7665 7220  Make the server 
-0001e330: 6665 7463 6820 7468 6520 6361 7461 6c6f  fetch the catalo
-0001e340: 6720 6672 6f6d 2074 6865 2061 6374 7561  g from the actua
-0001e350: 6c20 6d61 726b 6574 706c 6163 6520 736f  l marketplace so
-0001e360: 7572 6365 2c0a 2020 2020 2020 2020 2020  urce,.          
-0001e370: 2020 7261 7468 6572 2074 6861 6e20 7265    rather than re
-0001e380: 6c79 206f 6e20 6361 6368 6564 2069 6e66  ly on cached inf
-0001e390: 6f72 6d61 7469 6f6e 2077 6869 6368 206d  ormation which m
-0001e3a0: 6179 2065 7869 7374 2066 726f 6d20 7072  ay exist from pr
-0001e3b0: 6576 696f 7573 2067 6574 2072 6571 7565  evious get reque
-0001e3c0: 7374 732e 2046 6f72 2065 7861 6d70 6c65  sts. For example
-0001e3d0: 2c0a 2020 2020 2020 2020 2020 2020 6966  ,.            if
-0001e3e0: 2074 6865 2073 6f75 7263 6520 7761 7320   the source was 
-0001e3f0: 7265 2d62 7569 6c74 2c0a 2020 2020 2020  re-built,.      
-0001e400: 2020 2020 2020 7468 6973 2077 696c 6c20        this will 
-0001e410: 6d61 6b65 2074 6865 2073 6572 7665 7220  make the server 
-0001e420: 6765 7420 7468 6520 7570 6461 7465 6420  get the updated 
-0001e430: 696e 666f 726d 6174 696f 6e2e 2044 6566  information. Def
-0001e440: 6175 6c74 2069 7320 6060 4661 6c73 6560  ault is ``False`
-0001e450: 602e 0a20 2020 2020 2020 203a 7265 7475  `..        :retu
-0001e460: 726e 733a 203a 7079 3a63 6c61 7373 3a60  rns: :py:class:`
-0001e470: 7e6d 6c72 756e 2e61 7069 2e73 6368 656d  ~mlrun.api.schem
-0001e480: 6173 2e6d 6172 6b65 7470 6c61 6365 2e4d  as.marketplace.M
-0001e490: 6172 6b65 7470 6c61 6365 4361 7461 6c6f  arketplaceCatalo
-0001e4a0: 6760 206f 626a 6563 742c 2077 6869 6368  g` object, which
-0001e4b0: 2069 7320 6573 7365 6e74 6961 6c6c 7920   is essentially 
-0001e4c0: 6120 6c69 7374 0a20 2020 2020 2020 2020  a list.         
-0001e4d0: 2020 206f 6620 3a70 793a 636c 6173 733a     of :py:class:
-0001e4e0: 607e 6d6c 7275 6e2e 6170 692e 7363 6865  `~mlrun.api.sche
-0001e4f0: 6d61 732e 6d61 726b 6574 706c 6163 652e  mas.marketplace.
-0001e500: 4d61 726b 6574 706c 6163 6549 7465 6d60  MarketplaceItem`
-0001e510: 2065 6e74 7269 6573 2e0a 2020 2020 2020   entries..      
-0001e520: 2020 2222 220a 2020 2020 2020 2020 7061    """.        pa
-0001e530: 7468 203d 2028 6622 6d61 726b 6574 706c  th = (f"marketpl
-0001e540: 6163 652f 736f 7572 6365 732f 7b73 6f75  ace/sources/{sou
-0001e550: 7263 655f 6e61 6d65 7d2f 6974 656d 7322  rce_name}/items"
-0001e560: 2c29 0a20 2020 2020 2020 2070 6172 616d  ,).        param
-0001e570: 7320 3d20 7b0a 2020 2020 2020 2020 2020  s = {.          
-0001e580: 2020 2263 6861 6e6e 656c 223a 2063 6861    "channel": cha
-0001e590: 6e6e 656c 2c0a 2020 2020 2020 2020 2020  nnel,.          
-0001e5a0: 2020 2276 6572 7369 6f6e 223a 2076 6572    "version": ver
-0001e5b0: 7369 6f6e 2c0a 2020 2020 2020 2020 2020  sion,.          
-0001e5c0: 2020 2274 6167 223a 2074 6167 2c0a 2020    "tag": tag,.  
-0001e5d0: 2020 2020 2020 2020 2020 2266 6f72 6365            "force
-0001e5e0: 2d72 6566 7265 7368 223a 2066 6f72 6365  -refresh": force
-0001e5f0: 5f72 6566 7265 7368 2c0a 2020 2020 2020  _refresh,.      
-0001e600: 2020 7d0a 2020 2020 2020 2020 7265 7370    }.        resp
-0001e610: 6f6e 7365 203d 2073 656c 662e 6170 695f  onse = self.api_
-0001e620: 6361 6c6c 286d 6574 686f 643d 2247 4554  call(method="GET
-0001e630: 222c 2070 6174 683d 7061 7468 2c20 7061  ", path=path, pa
-0001e640: 7261 6d73 3d70 6172 616d 7329 0a20 2020  rams=params).   
-0001e650: 2020 2020 2072 6574 7572 6e20 7363 6865       return sche
-0001e660: 6d61 732e 4d61 726b 6574 706c 6163 6543  mas.MarketplaceC
-0001e670: 6174 616c 6f67 282a 2a72 6573 706f 6e73  atalog(**respons
-0001e680: 652e 6a73 6f6e 2829 290a 0a20 2020 2064  e.json())..    d
-0001e690: 6566 2067 6574 5f6d 6172 6b65 7470 6c61  ef get_marketpla
-0001e6a0: 6365 5f69 7465 6d28 0a20 2020 2020 2020  ce_item(.       
-0001e6b0: 2073 656c 662c 0a20 2020 2020 2020 2073   self,.        s
-0001e6c0: 6f75 7263 655f 6e61 6d65 3a20 7374 722c  ource_name: str,
-0001e6d0: 0a20 2020 2020 2020 2069 7465 6d5f 6e61  .        item_na
-0001e6e0: 6d65 3a20 7374 722c 0a20 2020 2020 2020  me: str,.       
-0001e6f0: 2063 6861 6e6e 656c 3a20 7374 7220 3d20   channel: str = 
-0001e700: 2264 6576 656c 6f70 6d65 6e74 222c 0a20  "development",. 
-0001e710: 2020 2020 2020 2076 6572 7369 6f6e 3a20         version: 
-0001e720: 7374 7220 3d20 4e6f 6e65 2c0a 2020 2020  str = None,.    
-0001e730: 2020 2020 7461 673a 2073 7472 203d 2022      tag: str = "
-0001e740: 6c61 7465 7374 222c 0a20 2020 2020 2020  latest",.       
-0001e750: 2066 6f72 6365 5f72 6566 7265 7368 3a20   force_refresh: 
-0001e760: 626f 6f6c 203d 2046 616c 7365 2c0a 2020  bool = False,.  
-0001e770: 2020 293a 0a20 2020 2020 2020 2022 2222    ):.        """
-0001e780: 0a20 2020 2020 2020 2052 6574 7269 6576  .        Retriev
-0001e790: 6520 6120 7370 6563 6966 6963 206d 6172  e a specific mar
-0001e7a0: 6b65 7470 6c61 6365 2069 7465 6d2e 0a0a  ketplace item...
-0001e7b0: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
-0001e7c0: 6f75 7263 655f 6e61 6d65 3a20 4e61 6d65  ource_name: Name
-0001e7d0: 206f 6620 736f 7572 6365 2e0a 2020 2020   of source..    
-0001e7e0: 2020 2020 3a70 6172 616d 2069 7465 6d5f      :param item_
-0001e7f0: 6e61 6d65 3a20 4e61 6d65 206f 6620 7468  name: Name of th
-0001e800: 6520 6974 656d 2074 6f20 7265 7472 6965  e item to retrie
-0001e810: 7665 2c20 6173 2069 7420 6170 7065 6172  ve, as it appear
-0001e820: 7320 696e 2074 6865 2063 6174 616c 6f67  s in the catalog
-0001e830: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
-0001e840: 2063 6861 6e6e 656c 3a20 4765 7420 7468   channel: Get th
-0001e850: 6520 6974 656d 2066 726f 6d20 7468 6520  e item from the 
-0001e860: 7370 6563 6966 6965 6420 6368 616e 6e65  specified channe
-0001e870: 6c2e 2044 6566 6175 6c74 2069 7320 6060  l. Default is ``
-0001e880: 6465 7665 6c6f 706d 656e 7460 602e 0a20  development``.. 
-0001e890: 2020 2020 2020 203a 7061 7261 6d20 7665         :param ve
-0001e8a0: 7273 696f 6e3a 2047 6574 2061 2073 7065  rsion: Get a spe
-0001e8b0: 6369 6669 6320 7665 7273 696f 6e20 6f66  cific version of
-0001e8c0: 2074 6865 2069 7465 6d2e 2044 6566 6175   the item. Defau
-0001e8d0: 6c74 2069 7320 6060 4e6f 6e65 6060 2e0a  lt is ``None``..
-0001e8e0: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
-0001e8f0: 6167 3a20 4765 7420 6120 7370 6563 6966  ag: Get a specif
-0001e900: 6963 2076 6572 7369 6f6e 206f 6620 7468  ic version of th
-0001e910: 6520 6974 656d 2069 6465 6e74 6966 6965  e item identifie
-0001e920: 6420 6279 2074 6167 2e20 4465 6661 756c  d by tag. Defaul
-0001e930: 7420 6973 2060 606c 6174 6573 7460 602e  t is ``latest``.
-0001e940: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
-0001e950: 666f 7263 655f 7265 6672 6573 683a 204d  force_refresh: M
-0001e960: 616b 6520 7468 6520 7365 7276 6572 2066  ake the server f
-0001e970: 6574 6368 2074 6865 2069 6e66 6f72 6d61  etch the informa
-0001e980: 7469 6f6e 2066 726f 6d20 7468 6520 6163  tion from the ac
-0001e990: 7475 616c 206d 6172 6b65 7470 6c61 6365  tual marketplace
-0001e9a0: 0a20 2020 2020 2020 2020 2020 2073 6f75  .            sou
-0001e9b0: 7263 652c 2072 6174 6865 7220 7468 616e  rce, rather than
-0001e9c0: 0a20 2020 2020 2020 2020 2020 2072 656c  .            rel
-0001e9d0: 7920 6f6e 2063 6163 6865 6420 696e 666f  y on cached info
-0001e9e0: 726d 6174 696f 6e2e 2044 6566 6175 6c74  rmation. Default
-0001e9f0: 2069 7320 6060 4661 6c73 6560 602e 0a20   is ``False``.. 
-0001ea00: 2020 2020 2020 203a 7265 7475 726e 733a         :returns:
-0001ea10: 203a 7079 3a63 6c61 7373 3a60 7e6d 6c72   :py:class:`~mlr
-0001ea20: 756e 2e61 7069 2e73 6368 656d 6173 2e6d  un.api.schemas.m
-0001ea30: 6172 6b65 7470 6c61 6365 2e4d 6172 6b65  arketplace.Marke
-0001ea40: 7470 6c61 6365 4974 656d 602e 0a20 2020  tplaceItem`..   
-0001ea50: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0001ea60: 2070 6174 6820 3d20 2866 226d 6172 6b65   path = (f"marke
-0001ea70: 7470 6c61 6365 2f73 6f75 7263 6573 2f7b  tplace/sources/{
-0001ea80: 736f 7572 6365 5f6e 616d 657d 2f69 7465  source_name}/ite
-0001ea90: 6d73 2f7b 6974 656d 5f6e 616d 657d 222c  ms/{item_name}",
-0001eaa0: 290a 2020 2020 2020 2020 7061 7261 6d73  ).        params
-0001eab0: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
-0001eac0: 2022 6368 616e 6e65 6c22 3a20 6368 616e   "channel": chan
-0001ead0: 6e65 6c2c 0a20 2020 2020 2020 2020 2020  nel,.           
-0001eae0: 2022 7665 7273 696f 6e22 3a20 7665 7273   "version": vers
-0001eaf0: 696f 6e2c 0a20 2020 2020 2020 2020 2020  ion,.           
-0001eb00: 2022 7461 6722 3a20 7461 672c 0a20 2020   "tag": tag,.   
-0001eb10: 2020 2020 2020 2020 2022 666f 7263 652d           "force-
-0001eb20: 7265 6672 6573 6822 3a20 666f 7263 655f  refresh": force_
-0001eb30: 7265 6672 6573 682c 0a20 2020 2020 2020  refresh,.       
-0001eb40: 207d 0a20 2020 2020 2020 2072 6573 706f   }.        respo
-0001eb50: 6e73 6520 3d20 7365 6c66 2e61 7069 5f63  nse = self.api_c
-0001eb60: 616c 6c28 6d65 7468 6f64 3d22 4745 5422  all(method="GET"
-0001eb70: 2c20 7061 7468 3d70 6174 682c 2070 6172  , path=path, par
-0001eb80: 616d 733d 7061 7261 6d73 290a 2020 2020  ams=params).    
-0001eb90: 2020 2020 7265 7475 726e 2073 6368 656d      return schem
-0001eba0: 6173 2e4d 6172 6b65 7470 6c61 6365 4974  as.MarketplaceIt
-0001ebb0: 656d 282a 2a72 6573 706f 6e73 652e 6a73  em(**response.js
-0001ebc0: 6f6e 2829 290a 0a20 2020 2064 6566 2076  on())..    def v
-0001ebd0: 6572 6966 795f 6175 7468 6f72 697a 6174  erify_authorizat
-0001ebe0: 696f 6e28 0a20 2020 2020 2020 2073 656c  ion(.        sel
-0001ebf0: 662c 2061 7574 686f 7269 7a61 7469 6f6e  f, authorization
-0001ec00: 5f76 6572 6966 6963 6174 696f 6e5f 696e  _verification_in
-0001ec10: 7075 743a 2073 6368 656d 6173 2e41 7574  put: schemas.Aut
-0001ec20: 686f 7269 7a61 7469 6f6e 5665 7269 6669  horizationVerifi
-0001ec30: 6361 7469 6f6e 496e 7075 740a 2020 2020  cationInput.    
-0001ec40: 293a 0a20 2020 2020 2020 2022 2222 5665  ):.        """Ve
-0001ec50: 7269 6669 6573 2061 7574 686f 7269 7a61  rifies authoriza
-0001ec60: 7469 6f6e 2066 6f72 2074 6865 2070 726f  tion for the pro
-0001ec70: 7669 6465 6420 6163 7469 6f6e 206f 6e20  vided action on 
-0001ec80: 7468 6520 7072 6f76 6964 6564 2072 6573  the provided res
-0001ec90: 6f75 7263 652e 0a0a 2020 2020 2020 2020  ource...        
-0001eca0: 3a70 6172 616d 2061 7574 686f 7269 7a61  :param authoriza
-0001ecb0: 7469 6f6e 5f76 6572 6966 6963 6174 696f  tion_verificatio
-0001ecc0: 6e5f 696e 7075 743a 2049 6e73 7461 6e63  n_input: Instanc
-0001ecd0: 6520 6f66 0a20 2020 2020 2020 2020 2020  e of.           
-0001ece0: 203a 7079 3a63 6c61 7373 3a60 7e6d 6c72   :py:class:`~mlr
-0001ecf0: 756e 2e61 7069 2e73 6368 656d 6173 2e41  un.api.schemas.A
-0001ed00: 7574 686f 7269 7a61 7469 6f6e 5665 7269  uthorizationVeri
-0001ed10: 6669 6361 7469 6f6e 496e 7075 7460 2074  ficationInput` t
-0001ed20: 6861 7420 696e 636c 7564 6573 2061 6c6c  hat includes all
-0001ed30: 2074 6865 206e 6565 6465 6420 7061 7261   the needed para
-0001ed40: 6d65 7465 7273 2066 6f72 0a20 2020 2020  meters for.     
-0001ed50: 2020 2020 2020 2074 6865 2061 7574 6820         the auth 
-0001ed60: 7665 7269 6669 6361 7469 6f6e 0a20 2020  verification.   
-0001ed70: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0001ed80: 2065 7272 6f72 5f6d 6573 7361 6765 203d   error_message =
-0001ed90: 2022 4175 7468 6f72 697a 6174 696f 6e20   "Authorization 
-0001eda0: 6368 6563 6b20 6661 696c 6564 220a 2020  check failed".  
-0001edb0: 2020 2020 2020 7365 6c66 2e61 7069 5f63        self.api_c
-0001edc0: 616c 6c28 0a20 2020 2020 2020 2020 2020  all(.           
-0001edd0: 2022 504f 5354 222c 0a20 2020 2020 2020   "POST",.       
-0001ede0: 2020 2020 2022 6175 7468 6f72 697a 6174       "authorizat
-0001edf0: 696f 6e2f 7665 7269 6669 6361 7469 6f6e  ion/verification
-0001ee00: 7322 2c0a 2020 2020 2020 2020 2020 2020  s",.            
-0001ee10: 6572 726f 725f 6d65 7373 6167 652c 0a20  error_message,. 
-0001ee20: 2020 2020 2020 2020 2020 2062 6f64 793d             body=
-0001ee30: 6469 6374 5f74 6f5f 6a73 6f6e 2861 7574  dict_to_json(aut
-0001ee40: 686f 7269 7a61 7469 6f6e 5f76 6572 6966  horization_verif
-0001ee50: 6963 6174 696f 6e5f 696e 7075 742e 6469  ication_input.di
-0001ee60: 6374 2829 292c 0a20 2020 2020 2020 2029  ct()),.        )
-0001ee70: 0a0a 2020 2020 6465 6620 7472 6967 6765  ..    def trigge
-0001ee80: 725f 6d69 6772 6174 696f 6e73 2873 656c  r_migrations(sel
-0001ee90: 6629 202d 3e20 4f70 7469 6f6e 616c 5b73  f) -> Optional[s
-0001eea0: 6368 656d 6173 2e42 6163 6b67 726f 756e  chemas.Backgroun
-0001eeb0: 6454 6173 6b5d 3a0a 2020 2020 2020 2020  dTask]:.        
-0001eec0: 2222 2254 7269 6767 6572 206d 6967 7261  """Trigger migra
-0001eed0: 7469 6f6e 7320 2877 696c 6c20 646f 206e  tions (will do n
-0001eee0: 6f74 6869 6e67 2069 6620 6e6f 206d 6967  othing if no mig
-0001eef0: 7261 7469 6f6e 7320 6172 6520 6e65 6564  rations are need
-0001ef00: 6564 2920 616e 6420 7761 6974 2066 6f72  ed) and wait for
-0001ef10: 2074 6865 6d20 746f 2066 696e 6973 6820   them to finish 
-0001ef20: 6966 2061 6374 7561 6c6c 790a 2020 2020  if actually.    
-0001ef30: 2020 2020 7472 6967 6765 7265 640a 2020      triggered.  
-0001ef40: 2020 2020 2020 3a72 6574 7572 6e73 3a20        :returns: 
-0001ef50: 3a70 793a 636c 6173 733a 607e 6d6c 7275  :py:class:`~mlru
-0001ef60: 6e2e 6170 692e 7363 6865 6d61 732e 4261  n.api.schemas.Ba
-0001ef70: 636b 6772 6f75 6e64 5461 736b 602e 0a20  ckgroundTask`.. 
-0001ef80: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-0001ef90: 2020 2072 6573 706f 6e73 6520 3d20 7365     response = se
-0001efa0: 6c66 2e61 7069 5f63 616c 6c28 0a20 2020  lf.api_call(.   
-0001efb0: 2020 2020 2020 2020 2022 504f 5354 222c           "POST",
-0001efc0: 0a20 2020 2020 2020 2020 2020 2022 6f70  .            "op
-0001efd0: 6572 6174 696f 6e73 2f6d 6967 7261 7469  erations/migrati
-0001efe0: 6f6e 7322 2c0a 2020 2020 2020 2020 2020  ons",.          
-0001eff0: 2020 2246 6169 6c65 6420 7472 6967 6765    "Failed trigge
-0001f000: 7269 6e67 206d 6967 7261 7469 6f6e 7322  ring migrations"
-0001f010: 2c0a 2020 2020 2020 2020 290a 2020 2020  ,.        ).    
-0001f020: 2020 2020 6966 2072 6573 706f 6e73 652e      if response.
-0001f030: 7374 6174 7573 5f63 6f64 6520 3d3d 2068  status_code == h
-0001f040: 7474 702e 4854 5450 5374 6174 7573 2e41  ttp.HTTPStatus.A
-0001f050: 4343 4550 5445 443a 0a20 2020 2020 2020  CCEPTED:.       
-0001f060: 2020 2020 2062 6163 6b67 726f 756e 645f       background_
-0001f070: 7461 736b 203d 2073 6368 656d 6173 2e42  task = schemas.B
-0001f080: 6163 6b67 726f 756e 6454 6173 6b28 2a2a  ackgroundTask(**
-0001f090: 7265 7370 6f6e 7365 2e6a 736f 6e28 2929  response.json())
-0001f0a0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0001f0b0: 7572 6e20 7365 6c66 2e5f 7761 6974 5f66  urn self._wait_f
-0001f0c0: 6f72 5f62 6163 6b67 726f 756e 645f 7461  or_background_ta
-0001f0d0: 736b 5f74 6f5f 7265 6163 685f 7465 726d  sk_to_reach_term
-0001f0e0: 696e 616c 5f73 7461 7465 280a 2020 2020  inal_state(.    
-0001f0f0: 2020 2020 2020 2020 2020 2020 6261 636b              back
-0001f100: 6772 6f75 6e64 5f74 6173 6b2e 6d65 7461  ground_task.meta
-0001f110: 6461 7461 2e6e 616d 650a 2020 2020 2020  data.name.      
-0001f120: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
-0001f130: 7265 7475 726e 204e 6f6e 650a 0a0a 6465  return None...de
-0001f140: 6620 5f61 735f 6a73 6f6e 286f 626a 293a  f _as_json(obj):
-0001f150: 0a20 2020 2066 6e20 3d20 6765 7461 7474  .    fn = getatt
-0001f160: 7228 6f62 6a2c 2022 746f 5f6a 736f 6e22  r(obj, "to_json"
-0001f170: 2c20 4e6f 6e65 290a 2020 2020 6966 2066  , None).    if f
-0001f180: 6e3a 0a20 2020 2020 2020 2072 6574 7572  n:.        retur
-0001f190: 6e20 666e 2829 0a20 2020 2072 6574 7572  n fn().    retur
-0001f1a0: 6e20 6469 6374 5f74 6f5f 6a73 6f6e 286f  n dict_to_json(o
-0001f1b0: 626a 290a                                bj).
+00000280: 706f 7274 2074 7970 696e 670a 696d 706f  port typing.impo
+00000290: 7274 2077 6172 6e69 6e67 730a 6672 6f6d  rt warnings.from
+000002a0: 2064 6174 6574 696d 6520 696d 706f 7274   datetime import
+000002b0: 2064 6174 6574 696d 650a 6672 6f6d 206f   datetime.from o
+000002c0: 7320 696d 706f 7274 2070 6174 682c 2072  s import path, r
+000002d0: 656d 6f76 650a 6672 6f6d 2074 7970 696e  emove.from typin
+000002e0: 6720 696d 706f 7274 2044 6963 742c 204c  g import Dict, L
+000002f0: 6973 742c 204f 7074 696f 6e61 6c2c 2055  ist, Optional, U
+00000300: 6e69 6f6e 0a0a 696d 706f 7274 206b 6670  nion..import kfp
+00000310: 0a69 6d70 6f72 7420 7265 7175 6573 7473  .import requests
+00000320: 0a69 6d70 6f72 7420 7365 6d76 6572 0a0a  .import semver..
+00000330: 696d 706f 7274 206d 6c72 756e 0a69 6d70  import mlrun.imp
+00000340: 6f72 7420 6d6c 7275 6e2e 6d6f 6465 6c5f  ort mlrun.model_
+00000350: 6d6f 6e69 746f 7269 6e67 2e6d 6f64 656c  monitoring.model
+00000360: 5f65 6e64 706f 696e 740a 696d 706f 7274  _endpoint.import
+00000370: 206d 6c72 756e 2e70 726f 6a65 6374 730a   mlrun.projects.
+00000380: 6672 6f6d 206d 6c72 756e 2e61 7069 2069  from mlrun.api i
+00000390: 6d70 6f72 7420 7363 6865 6d61 730a 6672  mport schemas.fr
+000003a0: 6f6d 206d 6c72 756e 2e65 7272 6f72 7320  om mlrun.errors 
+000003b0: 696d 706f 7274 204d 4c52 756e 496e 7661  import MLRunInva
+000003c0: 6c69 6441 7267 756d 656e 7445 7272 6f72  lidArgumentError
+000003d0: 2c20 6572 725f 746f 5f73 7472 0a0a 6672  , err_to_str..fr
+000003e0: 6f6d 202e 2e61 7274 6966 6163 7473 2069  om ..artifacts i
+000003f0: 6d70 6f72 7420 4172 7469 6661 6374 0a66  mport Artifact.f
+00000400: 726f 6d20 2e2e 636f 6e66 6967 2069 6d70  rom ..config imp
+00000410: 6f72 7420 636f 6e66 6967 0a66 726f 6d20  ort config.from 
+00000420: 2e2e 6665 6174 7572 655f 7374 6f72 6520  ..feature_store 
+00000430: 696d 706f 7274 2046 6561 7475 7265 5365  import FeatureSe
+00000440: 742c 2046 6561 7475 7265 5665 6374 6f72  t, FeatureVector
+00000450: 0a66 726f 6d20 2e2e 6c69 7374 7320 696d  .from ..lists im
+00000460: 706f 7274 2041 7274 6966 6163 744c 6973  port ArtifactLis
+00000470: 742c 2052 756e 4c69 7374 0a66 726f 6d20  t, RunList.from 
+00000480: 2e2e 7275 6e74 696d 6573 2069 6d70 6f72  ..runtimes impor
+00000490: 7420 4261 7365 5275 6e74 696d 650a 6672  t BaseRuntime.fr
+000004a0: 6f6d 202e 2e75 7469 6c73 2069 6d70 6f72  om ..utils impor
+000004b0: 7420 280a 2020 2020 6461 7465 7469 6d65  t (.    datetime
+000004c0: 5f74 6f5f 6973 6f2c 0a20 2020 2064 6963  _to_iso,.    dic
+000004d0: 745f 746f 5f6a 736f 6e2c 0a20 2020 206c  t_to_json,.    l
+000004e0: 6f67 6765 722c 0a20 2020 206e 6577 5f70  ogger,.    new_p
+000004f0: 6970 655f 6d65 7461 6461 7461 2c0a 2020  ipe_metadata,.  
+00000500: 2020 6e6f 726d 616c 697a 655f 6e61 6d65    normalize_name
+00000510: 2c0a 2020 2020 7665 7273 696f 6e2c 0a29  ,.    version,.)
+00000520: 0a66 726f 6d20 2e62 6173 6520 696d 706f  .from .base impo
+00000530: 7274 2052 756e 4442 4572 726f 722c 2052  rt RunDBError, R
+00000540: 756e 4442 496e 7465 7266 6163 650a 0a5f  unDBInterface.._
+00000550: 6172 7469 6661 6374 5f6b 6579 7320 3d20  artifact_keys = 
+00000560: 5b0a 2020 2020 2266 6f72 6d61 7422 2c0a  [.    "format",.
+00000570: 2020 2020 2269 6e6c 696e 6522 2c0a 2020      "inline",.  
+00000580: 2020 226b 6579 222c 0a20 2020 2022 7372    "key",.    "sr
+00000590: 635f 7061 7468 222c 0a20 2020 2022 7461  c_path",.    "ta
+000005a0: 7267 6574 5f70 6174 6822 2c0a 2020 2020  rget_path",.    
+000005b0: 2276 6965 7765 7222 2c0a 5d0a 0a0a 6465  "viewer",.]...de
+000005c0: 6620 626f 6f6c 3273 7472 2876 616c 293a  f bool2str(val):
+000005d0: 0a20 2020 2072 6574 7572 6e20 2279 6573  .    return "yes
+000005e0: 2220 6966 2076 616c 2065 6c73 6520 226e  " if val else "n
+000005f0: 6f22 0a0a 0a63 6c61 7373 2048 5454 5052  o"...class HTTPR
+00000600: 756e 4442 2852 756e 4442 496e 7465 7266  unDB(RunDBInterf
+00000610: 6163 6529 3a0a 2020 2020 2222 2249 6e74  ace):.    """Int
+00000620: 6572 6661 6365 2066 6f72 2061 6363 6573  erface for acces
+00000630: 7369 6e67 2061 6e64 206d 616e 6970 756c  sing and manipul
+00000640: 6174 696e 6720 7468 6520 3a70 793a 6d6f  ating the :py:mo
+00000650: 643a 606d 6c72 756e 6020 7065 7273 6973  d:`mlrun` persis
+00000660: 7465 6e74 2073 746f 7265 2c20 6d61 696e  tent store, main
+00000670: 7461 696e 696e 6720 7468 6520 6675 6c6c  taining the full
+00000680: 2073 7461 7465 0a20 2020 2061 6e64 2063   state.    and c
+00000690: 6174 616c 6f67 206f 6620 6f62 6a65 6374  atalog of object
+000006a0: 7320 7468 6174 204d 4c52 756e 2075 7365  s that MLRun use
+000006b0: 732e 2054 6865 203a 7079 3a63 6c61 7373  s. The :py:class
+000006c0: 3a60 4854 5450 5275 6e44 4260 2063 6c61  :`HTTPRunDB` cla
+000006d0: 7373 2073 6572 7665 7320 6173 2061 2063  ss serves as a c
+000006e0: 6c69 656e 742d 7369 6465 2070 726f 7879  lient-side proxy
+000006f0: 2074 6f20 7468 6520 4d4c 5275 6e0a 2020   to the MLRun.  
+00000700: 2020 4150 4920 7365 7276 6963 6520 7768    API service wh
+00000710: 6963 6820 6d61 696e 7461 696e 7320 7468  ich maintains th
+00000720: 6520 6163 7475 616c 2064 6174 612d 7374  e actual data-st
+00000730: 6f72 652c 2061 6363 6573 7365 7320 7468  ore, accesses th
+00000740: 6520 7365 7276 6572 2074 6872 6f75 6768  e server through
+00000750: 2052 4553 5420 4150 4973 2e0a 0a20 2020   REST APIs...   
+00000760: 2054 6865 2063 6c61 7373 2070 726f 7669   The class provi
+00000770: 6465 7320 6675 6e63 7469 6f6e 7320 666f  des functions fo
+00000780: 7220 6163 6365 7373 696e 6720 616e 6420  r accessing and 
+00000790: 6d6f 6469 6679 696e 6720 7468 6520 7661  modifying the va
+000007a0: 7269 6f75 7320 6f62 6a65 6374 7320 7468  rious objects th
+000007b0: 6174 2061 7265 2075 7365 6420 6279 204d  at are used by M
+000007c0: 4c52 756e 2069 6e20 6974 730a 2020 2020  LRun in its.    
+000007d0: 6f70 6572 6174 696f 6e2e 2054 6865 2066  operation. The f
+000007e0: 756e 6374 696f 6e73 2070 726f 7669 6465  unctions provide
+000007f0: 6420 666f 6c6c 6f77 2073 6f6d 6520 7374  d follow some st
+00000800: 616e 6461 7264 2067 7569 6465 6c69 6e65  andard guideline
+00000810: 732c 2077 6869 6368 2061 7265 3a0a 0a20  s, which are:.. 
+00000820: 2020 202d 2045 7665 7279 206f 626a 6563     - Every objec
+00000830: 7420 696e 204d 4c52 756e 2065 7869 7374  t in MLRun exist
+00000840: 7320 696e 2074 6865 2063 6f6e 7465 7874  s in the context
+00000850: 206f 6620 6120 7072 6f6a 6563 7420 2865   of a project (e
+00000860: 7863 6570 7420 7072 6f6a 6563 7473 2074  xcept projects t
+00000870: 6865 6d73 656c 7665 7329 2e20 5768 656e  hemselves). When
+00000880: 2072 6566 6572 656e 6369 6e67 2061 6e20   referencing an 
+00000890: 6f62 6a65 6374 0a20 2020 2020 2074 6872  object.      thr
+000008a0: 6f75 6768 2061 6e79 2041 5049 2c20 6120  ough any API, a 
+000008b0: 7072 6f6a 6563 7420 6e61 6d65 206d 7573  project name mus
+000008c0: 7420 6265 2070 726f 7669 6465 642e 2054  t be provided. T
+000008d0: 6865 2064 6566 6175 6c74 2066 6f72 206d  he default for m
+000008e0: 6f73 7420 4150 4973 2069 7320 666f 7220  ost APIs is for 
+000008f0: 616e 2065 6d70 7479 2070 726f 6a65 6374  an empty project
+00000900: 206e 616d 652c 2077 6869 6368 0a20 2020   name, which.   
+00000910: 2020 2077 696c 6c20 6265 2072 6570 6c61     will be repla
+00000920: 6365 6420 6279 2074 6865 206e 616d 6520  ced by the name 
+00000930: 6f66 2074 6865 2064 6566 6175 6c74 2070  of the default p
+00000940: 726f 6a65 6374 2028 7573 7561 6c6c 7920  roject (usually 
+00000950: 6060 6465 6661 756c 7460 6029 2e20 5468  ``default``). Th
+00000960: 6572 6566 6f72 652c 2069 6620 7065 7266  erefore, if perf
+00000970: 6f72 6d69 6e67 2061 6e20 4150 4920 746f  orming an API to
+00000980: 0a20 2020 2020 206c 6973 7420 6675 6e63  .      list func
+00000990: 7469 6f6e 732c 2066 6f72 2065 7861 6d70  tions, for examp
+000009a0: 6c65 2c20 616e 6420 6e6f 7420 7072 6f76  le, and not prov
+000009b0: 6964 696e 6720 6120 7072 6f6a 6563 7420  iding a project 
+000009c0: 6e61 6d65 202d 2074 6865 2072 6573 756c  name - the resul
+000009d0: 7420 7769 6c6c 206e 6f74 2062 6520 6675  t will not be fu
+000009e0: 6e63 7469 6f6e 7320 6672 6f6d 2061 6c6c  nctions from all
+000009f0: 0a20 2020 2020 2070 726f 6a65 6374 7320  .      projects 
+00000a00: 6275 7420 7261 7468 6572 2066 726f 6d20  but rather from 
+00000a10: 7468 6520 6060 6465 6661 756c 7460 6020  the ``default`` 
+00000a20: 7072 6f6a 6563 742e 0a20 2020 202d 204d  project..    - M
+00000a30: 616e 7920 6f62 6a65 6374 7320 6361 6e20  any objects can 
+00000a40: 6265 2061 7373 6967 6e65 6420 6c61 6265  be assigned labe
+00000a50: 6c73 2c20 616e 6420 6c69 7374 6564 2f71  ls, and listed/q
+00000a60: 7565 7269 6564 2062 7920 6c61 6265 6c2e  ueried by label.
+00000a70: 2054 6865 206c 6162 656c 2070 6172 616d   The label param
+00000a80: 6574 6572 2066 6f72 2071 7565 7279 2041  eter for query A
+00000a90: 5049 7320 616c 6c6f 7773 2066 6f72 0a20  PIs allows for. 
+00000aa0: 2020 2020 206c 6973 7469 6e67 206f 626a       listing obj
+00000ab0: 6563 7473 2074 6861 743a 0a0a 2020 2020  ects that:..    
+00000ac0: 2020 2d20 4861 7665 2061 2073 7065 6369    - Have a speci
+00000ad0: 6669 6320 6c61 6265 6c2c 2062 7920 6173  fic label, by as
+00000ae0: 6b69 6e67 2066 6f72 2060 606c 6162 656c  king for ``label
+00000af0: 3d22 3c6c 6162 656c 5f6e 616d 653e 2260  ="<label_name>"`
+00000b00: 602e 2049 6e20 7468 6973 2063 6173 6520  `. In this case 
+00000b10: 7468 6520 6163 7475 616c 2076 616c 7565  the actual value
+00000b20: 206f 6620 7468 6520 6c61 6265 6c0a 2020   of the label.  
+00000b30: 2020 2020 2020 646f 6573 6e27 7420 6d61        doesn't ma
+00000b40: 7474 6572 2061 6e64 2065 7665 7279 206f  tter and every o
+00000b50: 626a 6563 7420 7769 7468 2074 6861 7420  bject with that 
+00000b60: 6c61 6265 6c20 7769 6c6c 2062 6520 7265  label will be re
+00000b70: 7475 726e 6564 0a20 2020 2020 202d 2048  turned.      - H
+00000b80: 6176 6520 6120 6c61 6265 6c20 7769 7468  ave a label with
+00000b90: 2061 2073 7065 6369 6669 6320 7661 6c75   a specific valu
+00000ba0: 652e 2054 6869 7320 6973 2064 6f6e 6520  e. This is done 
+00000bb0: 6279 2073 7065 6369 6679 696e 6720 6060  by specifying ``
+00000bc0: 6c61 6265 6c3d 223c 6c61 6265 6c5f 6e61  label="<label_na
+00000bd0: 6d65 3e3d 3c6c 6162 656c 5f76 616c 7565  me>=<label_value
+00000be0: 3e22 6060 2e20 496e 2074 6869 730a 2020  >"``. In this.  
+00000bf0: 2020 2020 2020 6361 7365 206f 6e6c 7920        case only 
+00000c00: 6f62 6a65 6374 7320 7768 6f73 6520 6c61  objects whose la
+00000c10: 6265 6c20 6d61 7463 6865 7320 7468 6520  bel matches the 
+00000c20: 7661 6c75 6520 7769 6c6c 2062 6520 7265  value will be re
+00000c30: 7475 726e 6564 0a0a 2020 2020 2d20 4d6f  turned..    - Mo
+00000c40: 7374 206f 626a 6563 7473 2068 6176 6520  st objects have 
+00000c50: 6120 6060 6372 6561 7465 6060 206d 6574  a ``create`` met
+00000c60: 686f 6420 6173 2077 656c 6c20 6173 2061  hod as well as a
+00000c70: 2060 6073 746f 7265 6060 206d 6574 686f   ``store`` metho
+00000c80: 642e 2043 7265 6174 6520 6361 6e20 6f6e  d. Create can on
+00000c90: 6c79 2062 6520 6361 6c6c 6564 2077 6865  ly be called whe
+00000ca0: 6e20 7375 6368 2061 6e0a 2020 2020 2020  n such an.      
+00000cb0: 646f 6573 206e 6f74 2065 7869 7374 2079  does not exist y
+00000cc0: 6574 2c20 7768 696c 6520 7374 6f72 6520  et, while store 
+00000cd0: 616c 6c6f 7773 2066 6f72 2065 6974 6865  allows for eithe
+00000ce0: 7220 6372 6561 7469 6e67 2061 206e 6577  r creating a new
+00000cf0: 206f 626a 6563 7420 6f72 206f 7665 7277   object or overw
+00000d00: 7269 7469 6e67 2061 6e20 6578 6973 7469  riting an existi
+00000d10: 6e67 206f 626a 6563 742e 0a20 2020 202d  ng object..    -
+00000d20: 2053 6f6d 6520 6f62 6a65 6374 7320 6861   Some objects ha
+00000d30: 7665 2061 2060 6076 6572 7369 6f6e 6564  ve a ``versioned
+00000d40: 6060 206f 7074 696f 6e2c 2069 6e20 7768  `` option, in wh
+00000d50: 6963 6820 6361 7365 206f 7665 7277 7269  ich case overwri
+00000d60: 7469 6e67 2074 6865 2073 616d 6520 6f62  ting the same ob
+00000d70: 6a65 6374 2077 6974 6820 6120 6469 6666  ject with a diff
+00000d80: 6572 656e 7420 7665 7273 696f 6e20 6f66  erent version of
+00000d90: 0a20 2020 2020 2069 7420 646f 6573 206e  .      it does n
+00000da0: 6f74 2064 656c 6574 6520 7468 6520 7072  ot delete the pr
+00000db0: 6576 696f 7573 2076 6572 7369 6f6e 2c20  evious version, 
+00000dc0: 6275 7420 7261 7468 6572 2063 7265 6174  but rather creat
+00000dd0: 6573 2061 206e 6577 2076 6572 7369 6f6e  es a new version
+00000de0: 206f 6620 7468 6520 6f62 6a65 6374 2061   of the object a
+00000df0: 6e64 206b 6565 7073 2062 6f74 6820 7665  nd keeps both ve
+00000e00: 7273 696f 6e73 2e0a 2020 2020 2020 5665  rsions..      Ve
+00000e10: 7273 696f 6e65 6420 6f62 6a65 6374 7320  rsioned objects 
+00000e20: 7573 7561 6c6c 7920 6861 7665 2061 2060  usually have a `
+00000e30: 6075 6964 6060 2070 726f 7065 7274 7920  `uid`` property 
+00000e40: 7768 6963 6820 6973 2062 6173 6564 206f  which is based o
+00000e50: 6e20 7468 6569 7220 636f 6e74 656e 7420  n their content 
+00000e60: 616e 6420 616c 6c6f 7773 2074 6f20 7265  and allows to re
+00000e70: 6665 7265 6e63 6520 610a 2020 2020 2020  ference a.      
+00000e80: 7370 6563 6966 6963 2076 6572 7369 6f6e  specific version
+00000e90: 206f 6620 616e 206f 626a 6563 7420 286f   of an object (o
+00000ea0: 7468 6572 2074 6861 6e20 7461 6767 696e  ther than taggin
+00000eb0: 6720 6f62 6a65 6374 732c 2077 6869 6368  g objects, which
+00000ec0: 2061 6c73 6f20 616c 6c6f 7773 2066 6f72   also allows for
+00000ed0: 2065 6173 7920 7265 6665 7265 6e63 696e   easy referencin
+00000ee0: 6729 2e0a 2020 2020 2d20 4d61 6e79 206f  g)..    - Many o
+00000ef0: 626a 6563 7473 2068 6176 6520 626f 7468  bjects have both
+00000f00: 2061 2060 6073 746f 7265 6060 2066 756e   a ``store`` fun
+00000f10: 6374 696f 6e20 616e 6420 6120 6060 7061  ction and a ``pa
+00000f20: 7463 6860 6020 6675 6e63 7469 6f6e 2e20  tch`` function. 
+00000f30: 5468 6573 6520 6172 6520 7573 6564 2069  These are used i
+00000f40: 6e20 7468 6520 7361 6d65 2077 6179 2061  n the same way a
+00000f50: 7320 7468 650a 2020 2020 2020 636f 7272  s the.      corr
+00000f60: 6573 706f 6e64 696e 6720 5245 5354 2076  esponding REST v
+00000f70: 6572 6273 202d 2061 2060 6073 746f 7265  erbs - a ``store
+00000f80: 6060 2069 7320 7061 7373 6564 2061 2066  `` is passed a f
+00000f90: 756c 6c20 6f62 6a65 6374 2061 6e64 2077  ull object and w
+00000fa0: 696c 6c20 6261 7369 6361 6c6c 7920 7065  ill basically pe
+00000fb0: 7266 6f72 6d20 6120 5055 5420 6f70 6572  rform a PUT oper
+00000fc0: 6174 696f 6e2c 0a20 2020 2020 2072 6570  ation,.      rep
+00000fd0: 6c61 6369 6e67 2074 6865 2066 756c 6c20  lacing the full 
+00000fe0: 6f62 6a65 6374 2028 6966 2069 7420 6578  object (if it ex
+00000ff0: 6973 7473 2920 7768 696c 6520 6060 7061  ists) while ``pa
+00001000: 7463 6860 6020 7265 6365 6976 6573 206a  tch`` receives j
+00001010: 7573 7420 6120 6469 6374 696f 6e61 7279  ust a dictionary
+00001020: 2063 6f6e 7461 696e 696e 6720 7468 6520   containing the 
+00001030: 6469 6666 6572 656e 6365 7320 746f 0a20  differences to. 
+00001040: 2020 2020 2062 6520 6170 706c 6965 6420       be applied 
+00001050: 746f 2074 6865 206f 626a 6563 742c 2061  to the object, a
+00001060: 6e64 2077 696c 6c20 6d65 7267 6520 7468  nd will merge th
+00001070: 6f73 6520 6368 616e 6765 7320 746f 2074  ose changes to t
+00001080: 6865 2065 7869 7374 696e 6720 6f62 6a65  he existing obje
+00001090: 6374 2e20 5468 6520 6060 7061 7463 6860  ct. The ``patch`
+000010a0: 600a 2020 2020 2020 6f70 6572 6174 696f  `.      operatio
+000010b0: 6e20 616c 736f 2068 6173 2061 2073 7472  n also has a str
+000010c0: 6174 6567 7920 6173 7369 676e 6564 2074  ategy assigned t
+000010d0: 6f20 6974 2077 6869 6368 2064 6574 6572  o it which deter
+000010e0: 6d69 6e65 7320 686f 7720 7468 6520 6d65  mines how the me
+000010f0: 7267 6520 6c6f 6769 6320 7368 6f75 6c64  rge logic should
+00001100: 2062 6568 6176 652e 0a20 2020 2020 2054   behave..      T
+00001110: 6865 2073 7472 6174 6567 7920 6361 6e20  he strategy can 
+00001120: 6265 2065 6974 6865 7220 6060 7265 706c  be either ``repl
+00001130: 6163 6560 6020 6f72 2060 6061 6464 6974  ace`` or ``addit
+00001140: 6976 6560 602e 2046 6f72 2066 7572 7468  ive``. For furth
+00001150: 6572 2064 6574 6169 6c73 206f 6e20 7468  er details on th
+00001160: 6f73 6520 7374 7261 7465 6769 6573 2c20  ose strategies, 
+00001170: 7265 6665 720a 2020 2020 2020 746f 2068  refer.      to h
+00001180: 7474 7073 3a2f 2f70 7970 692e 6f72 672f  ttps://pypi.org/
+00001190: 7072 6f6a 6563 742f 6d65 7267 6564 6565  project/mergedee
+000011a0: 702f 0a20 2020 2022 2222 0a0a 2020 2020  p/.    """..    
+000011b0: 6b69 6e64 203d 2022 6874 7470 220a 0a20  kind = "http".. 
+000011c0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+000011d0: 7365 6c66 2c20 6261 7365 5f75 726c 2c20  self, base_url, 
+000011e0: 7573 6572 3d22 222c 2070 6173 7377 6f72  user="", passwor
+000011f0: 643d 2222 2c20 746f 6b65 6e3d 2222 293a  d="", token=""):
+00001200: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
+00001210: 7365 5f75 726c 203d 2062 6173 655f 7572  se_url = base_ur
+00001220: 6c0a 2020 2020 2020 2020 7365 6c66 2e75  l.        self.u
+00001230: 7365 7220 3d20 7573 6572 0a20 2020 2020  ser = user.     
+00001240: 2020 2073 656c 662e 7061 7373 776f 7264     self.password
+00001250: 203d 2070 6173 7377 6f72 640a 2020 2020   = password.    
+00001260: 2020 2020 7365 6c66 2e74 6f6b 656e 203d      self.token =
+00001270: 2074 6f6b 656e 0a20 2020 2020 2020 2073   token.        s
+00001280: 656c 662e 7365 7276 6572 5f76 6572 7369  elf.server_versi
+00001290: 6f6e 203d 2022 220a 2020 2020 2020 2020  on = "".        
+000012a0: 7365 6c66 2e73 6573 7369 6f6e 203d 204e  self.session = N
+000012b0: 6f6e 650a 2020 2020 2020 2020 7365 6c66  one.        self
+000012c0: 2e5f 7761 6974 5f66 6f72 5f70 726f 6a65  ._wait_for_proje
+000012d0: 6374 5f74 6572 6d69 6e61 6c5f 7374 6174  ct_terminal_stat
+000012e0: 655f 7265 7472 795f 696e 7465 7276 616c  e_retry_interval
+000012f0: 203d 2033 0a20 2020 2020 2020 2073 656c   = 3.        sel
+00001300: 662e 5f77 6169 745f 666f 725f 6261 636b  f._wait_for_back
+00001310: 6772 6f75 6e64 5f74 6173 6b5f 7465 726d  ground_task_term
+00001320: 696e 616c 5f73 7461 7465 5f72 6574 7279  inal_state_retry
+00001330: 5f69 6e74 6572 7661 6c20 3d20 330a 2020  _interval = 3.  
+00001340: 2020 2020 2020 7365 6c66 2e5f 7761 6974        self._wait
+00001350: 5f66 6f72 5f70 726f 6a65 6374 5f64 656c  _for_project_del
+00001360: 6574 696f 6e5f 696e 7465 7276 616c 203d  etion_interval =
+00001370: 2033 0a20 2020 2020 2020 2073 656c 662e   3.        self.
+00001380: 636c 6965 6e74 5f76 6572 7369 6f6e 203d  client_version =
+00001390: 2076 6572 7369 6f6e 2e56 6572 7369 6f6e   version.Version
+000013a0: 2829 2e67 6574 2829 5b22 7665 7273 696f  ().get()["versio
+000013b0: 6e22 5d0a 2020 2020 2020 2020 7365 6c66  n"].        self
+000013c0: 2e70 7974 686f 6e5f 7665 7273 696f 6e20  .python_version 
+000013d0: 3d20 7374 7228 7665 7273 696f 6e2e 5665  = str(version.Ve
+000013e0: 7273 696f 6e28 292e 6765 745f 7079 7468  rsion().get_pyth
+000013f0: 6f6e 5f76 6572 7369 6f6e 2829 290a 0a20  on_version()).. 
+00001400: 2020 2064 6566 205f 5f72 6570 725f 5f28     def __repr__(
+00001410: 7365 6c66 293a 0a20 2020 2020 2020 2063  self):.        c
+00001420: 6c73 203d 2073 656c 662e 5f5f 636c 6173  ls = self.__clas
+00001430: 735f 5f2e 5f5f 6e61 6d65 5f5f 0a20 2020  s__.__name__.   
+00001440: 2020 2020 2072 6574 7572 6e20 6622 7b63       return f"{c
+00001450: 6c73 7d28 7b73 656c 662e 6261 7365 5f75  ls}({self.base_u
+00001460: 726c 2172 7d29 220a 0a20 2020 2040 7374  rl!r})"..    @st
+00001470: 6174 6963 6d65 7468 6f64 0a20 2020 2064  aticmethod.    d
+00001480: 6566 2067 6574 5f61 7069 5f70 6174 685f  ef get_api_path_
+00001490: 7072 6566 6978 2876 6572 7369 6f6e 3a20  prefix(version: 
+000014a0: 7374 7220 3d20 4e6f 6e65 2920 2d3e 2073  str = None) -> s
+000014b0: 7472 3a0a 2020 2020 2020 2020 2222 220a  tr:.        """.
+000014c0: 2020 2020 2020 2020 3a70 6172 616d 2076          :param v
+000014d0: 6572 7369 6f6e 3a20 4150 4920 7665 7273  ersion: API vers
+000014e0: 696f 6e20 746f 2075 7365 2c20 4e6f 6e65  ion to use, None
+000014f0: 2028 7468 6520 6465 6661 756c 7429 2077   (the default) w
+00001500: 696c 6c20 6d65 616e 2074 6f20 7573 6520  ill mean to use 
+00001510: 7468 6520 6465 6661 756c 7420 7661 6c75  the default valu
+00001520: 6520 6672 6f6d 206d 6c63 6f6e 662c 0a20  e from mlconf,. 
+00001530: 2020 2020 2020 2020 666f 7220 756e 2d76          for un-v
+00001540: 6572 7369 6f6e 6564 2061 7069 2073 6574  ersioned api set
+00001550: 2061 6e20 656d 7074 7920 7374 7269 6e67   an empty string
+00001560: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+00001570: 2020 2020 2020 6966 2076 6572 7369 6f6e        if version
+00001580: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+00001590: 2020 2020 2020 2020 2020 7265 7475 726e            return
+000015a0: 2066 2261 7069 2f7b 7665 7273 696f 6e7d   f"api/{version}
+000015b0: 2220 6966 2076 6572 7369 6f6e 2065 6c73  " if version els
+000015c0: 6520 2261 7069 220a 0a20 2020 2020 2020  e "api"..       
+000015d0: 2061 7069 5f76 6572 7369 6f6e 5f70 6174   api_version_pat
+000015e0: 6820 3d20 280a 2020 2020 2020 2020 2020  h = (.          
+000015f0: 2020 6622 6170 692f 7b63 6f6e 6669 672e    f"api/{config.
+00001600: 6170 695f 6261 7365 5f76 6572 7369 6f6e  api_base_version
+00001610: 7d22 2069 6620 636f 6e66 6967 2e61 7069  }" if config.api
+00001620: 5f62 6173 655f 7665 7273 696f 6e20 656c  _base_version el
+00001630: 7365 2022 6170 6922 0a20 2020 2020 2020  se "api".       
+00001640: 2029 0a20 2020 2020 2020 2072 6574 7572   ).        retur
+00001650: 6e20 6170 695f 7665 7273 696f 6e5f 7061  n api_version_pa
+00001660: 7468 0a0a 2020 2020 6465 6620 6765 745f  th..    def get_
+00001670: 6261 7365 5f61 7069 5f75 726c 2873 656c  base_api_url(sel
+00001680: 662c 2070 6174 683a 2073 7472 2c20 7665  f, path: str, ve
+00001690: 7273 696f 6e3a 2073 7472 203d 204e 6f6e  rsion: str = Non
+000016a0: 6529 202d 3e20 7374 723a 0a20 2020 2020  e) -> str:.     
+000016b0: 2020 2070 6174 685f 7072 6566 6978 203d     path_prefix =
+000016c0: 2073 656c 662e 6765 745f 6170 695f 7061   self.get_api_pa
+000016d0: 7468 5f70 7265 6669 7828 7665 7273 696f  th_prefix(versio
+000016e0: 6e29 0a20 2020 2020 2020 2075 726c 203d  n).        url =
+000016f0: 2066 227b 7365 6c66 2e62 6173 655f 7572   f"{self.base_ur
+00001700: 6c7d 2f7b 7061 7468 5f70 7265 6669 787d  l}/{path_prefix}
+00001710: 2f7b 7061 7468 7d22 0a20 2020 2020 2020  /{path}".       
+00001720: 2072 6574 7572 6e20 7572 6c0a 0a20 2020   return url..   
+00001730: 2064 6566 2061 7069 5f63 616c 6c28 0a20   def api_call(. 
+00001740: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
+00001750: 2020 2020 206d 6574 686f 642c 0a20 2020       method,.   
+00001760: 2020 2020 2070 6174 682c 0a20 2020 2020       path,.     
+00001770: 2020 2065 7272 6f72 3d4e 6f6e 652c 0a20     error=None,. 
+00001780: 2020 2020 2020 2070 6172 616d 733d 4e6f         params=No
+00001790: 6e65 2c0a 2020 2020 2020 2020 626f 6479  ne,.        body
+000017a0: 3d4e 6f6e 652c 0a20 2020 2020 2020 206a  =None,.        j
+000017b0: 736f 6e3d 4e6f 6e65 2c0a 2020 2020 2020  son=None,.      
+000017c0: 2020 6865 6164 6572 733d 4e6f 6e65 2c0a    headers=None,.
+000017d0: 2020 2020 2020 2020 7469 6d65 6f75 743d          timeout=
+000017e0: 3435 2c0a 2020 2020 2020 2020 7665 7273  45,.        vers
+000017f0: 696f 6e3d 4e6f 6e65 2c0a 2020 2020 293a  ion=None,.    ):
+00001800: 0a20 2020 2020 2020 2022 2222 5065 7266  .        """Perf
+00001810: 6f72 6d20 6120 6469 7265 6374 2052 4553  orm a direct RES
+00001820: 5420 4150 4920 6361 6c6c 206f 6e20 7468  T API call on th
+00001830: 6520 3a70 793a 6d6f 643a 606d 6c72 756e  e :py:mod:`mlrun
+00001840: 6020 4150 4920 7365 7276 6572 2e0a 0a20  ` API server... 
+00001850: 2020 2020 2020 2043 6175 7469 6f6e 3a0a         Caution:.
+00001860: 2020 2020 2020 2020 2020 2020 466f 7220              For 
+00001870: 6164 7661 6e63 6564 2075 7361 6765 202d  advanced usage -
+00001880: 2070 7265 6665 7220 7573 696e 6720 7468   prefer using th
+00001890: 6520 7661 7269 6f75 7320 4150 4973 2065  e various APIs e
+000018a0: 7870 6f73 6564 2074 6872 6f75 6768 2074  xposed through t
+000018b0: 6869 7320 636c 6173 732c 2072 6174 6865  his class, rathe
+000018c0: 7220 7468 616e 0a20 2020 2020 2020 2020  r than.         
+000018d0: 2020 2064 6972 6563 746c 7920 696e 766f     directly invo
+000018e0: 6b69 6e67 2052 4553 5420 6361 6c6c 732e  king REST calls.
+000018f0: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+00001900: 206d 6574 686f 643a 2052 4553 5420 6d65   method: REST me
+00001910: 7468 6f64 2028 504f 5354 2c20 4745 542c  thod (POST, GET,
+00001920: 2050 5554 2e2e 2e29 0a20 2020 2020 2020   PUT...).       
+00001930: 203a 7061 7261 6d20 7061 7468 3a20 5061   :param path: Pa
+00001940: 7468 2074 6f20 656e 6470 6f69 6e74 2065  th to endpoint e
+00001950: 7865 6375 7465 642c 2066 6f72 2065 7861  xecuted, for exa
+00001960: 6d70 6c65 2060 6022 7072 6f6a 6563 7473  mple ``"projects
+00001970: 2260 600a 2020 2020 2020 2020 3a70 6172  "``.        :par
+00001980: 616d 2065 7272 6f72 3a20 4572 726f 7220  am error: Error 
+00001990: 746f 2072 6574 7572 6e20 6966 2041 5049  to return if API
+000019a0: 2069 6e76 6f63 6174 696f 6e20 6661 696c   invocation fail
+000019b0: 730a 2020 2020 2020 2020 3a70 6172 616d  s.        :param
+000019c0: 2070 6172 616d 733a 2052 6573 7420 7061   params: Rest pa
+000019d0: 7261 6d65 7465 7273 2c20 7061 7373 6564  rameters, passed
+000019e0: 2061 7320 6120 6469 6374 696f 6e61 7279   as a dictionary
+000019f0: 3a20 6060 7b22 3c70 6172 616d 2d6e 616d  : ``{"<param-nam
+00001a00: 653e 223a 203c 2270 6172 616d 2d76 616c  e>": <"param-val
+00001a10: 7565 223e 7d60 600a 2020 2020 2020 2020  ue">}``.        
+00001a20: 3a70 6172 616d 2062 6f64 793a 2050 6179  :param body: Pay
+00001a30: 6c6f 6164 2074 6f20 6265 2070 6173 7365  load to be passe
+00001a40: 6420 696e 2074 6865 2063 616c 6c2e 2049  d in the call. I
+00001a50: 6620 7573 696e 6720 4a53 4f4e 206f 626a  f using JSON obj
+00001a60: 6563 7473 2c20 7072 6566 6572 2075 7369  ects, prefer usi
+00001a70: 6e67 2074 6865 2060 606a 736f 6e60 6020  ng the ``json`` 
+00001a80: 7061 7261 6d0a 2020 2020 2020 2020 3a70  param.        :p
+00001a90: 6172 616d 206a 736f 6e3a 204a 534f 4e20  aram json: JSON 
+00001aa0: 7061 796c 6f61 6420 746f 2062 6520 7061  payload to be pa
+00001ab0: 7373 6564 2069 6e20 7468 6520 6361 6c6c  ssed in the call
+00001ac0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00001ad0: 6865 6164 6572 733a 2052 4553 5420 6865  headers: REST he
+00001ae0: 6164 6572 732c 2070 6173 7365 6420 6173  aders, passed as
+00001af0: 2061 2064 6963 7469 6f6e 6172 793a 2060   a dictionary: `
+00001b00: 607b 223c 6865 6164 6572 2d6e 616d 653e  `{"<header-name>
+00001b10: 223a 2022 3c68 6561 6465 722d 7661 6c75  ": "<header-valu
+00001b20: 653e 227d 6060 0a20 2020 2020 2020 203a  e>"}``.        :
+00001b30: 7061 7261 6d20 7469 6d65 6f75 743a 2041  param timeout: A
+00001b40: 5049 2063 616c 6c20 7469 6d65 6f75 740a  PI call timeout.
+00001b50: 2020 2020 2020 2020 3a70 6172 616d 2076          :param v
+00001b60: 6572 7369 6f6e 3a20 4150 4920 7665 7273  ersion: API vers
+00001b70: 696f 6e20 746f 2075 7365 2c20 4e6f 6e65  ion to use, None
+00001b80: 2028 7468 6520 6465 6661 756c 7429 2077   (the default) w
+00001b90: 696c 6c20 6d65 616e 2074 6f20 7573 6520  ill mean to use 
+00001ba0: 7468 6520 6465 6661 756c 7420 7661 6c75  the default valu
+00001bb0: 6520 6672 6f6d 2063 6f6e 6669 672c 0a20  e from config,. 
+00001bc0: 2020 2020 2020 2020 666f 7220 756e 2d76          for un-v
+00001bd0: 6572 7369 6f6e 6564 2061 7069 2073 6574  ersioned api set
+00001be0: 2061 6e20 656d 7074 7920 7374 7269 6e67   an empty string
+00001bf0: 2e0a 0a20 2020 2020 2020 203a 7265 7475  ...        :retu
+00001c00: 726e 3a20 5079 7468 6f6e 2048 5454 5020  rn: Python HTTP 
+00001c10: 7265 7370 6f6e 7365 206f 626a 6563 740a  response object.
+00001c20: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+00001c30: 2020 2020 7572 6c20 3d20 7365 6c66 2e67      url = self.g
+00001c40: 6574 5f62 6173 655f 6170 695f 7572 6c28  et_base_api_url(
+00001c50: 7061 7468 2c20 7665 7273 696f 6e29 0a20  path, version). 
+00001c60: 2020 2020 2020 206b 7720 3d20 7b0a 2020         kw = {.  
+00001c70: 2020 2020 2020 2020 2020 6b65 793a 2076            key: v
+00001c80: 616c 7565 0a20 2020 2020 2020 2020 2020  alue.           
+00001c90: 2066 6f72 206b 6579 2c20 7661 6c75 6520   for key, value 
+00001ca0: 696e 2028 0a20 2020 2020 2020 2020 2020  in (.           
+00001cb0: 2020 2020 2028 2270 6172 616d 7322 2c20       ("params", 
+00001cc0: 7061 7261 6d73 292c 0a20 2020 2020 2020  params),.       
+00001cd0: 2020 2020 2020 2020 2028 2264 6174 6122           ("data"
+00001ce0: 2c20 626f 6479 292c 0a20 2020 2020 2020  , body),.       
+00001cf0: 2020 2020 2020 2020 2028 226a 736f 6e22           ("json"
+00001d00: 2c20 6a73 6f6e 292c 0a20 2020 2020 2020  , json),.       
+00001d10: 2020 2020 2020 2020 2028 2268 6561 6465           ("heade
+00001d20: 7273 222c 2068 6561 6465 7273 292c 0a20  rs", headers),. 
+00001d30: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00001d40: 2020 2020 2020 2020 2069 6620 7661 6c75           if valu
+00001d50: 6520 6973 206e 6f74 204e 6f6e 650a 2020  e is not None.  
+00001d60: 2020 2020 2020 7d0a 0a20 2020 2020 2020        }..       
+00001d70: 2069 6620 7365 6c66 2e75 7365 723a 0a20   if self.user:. 
+00001d80: 2020 2020 2020 2020 2020 206b 775b 2261             kw["a
+00001d90: 7574 6822 5d20 3d20 2873 656c 662e 7573  uth"] = (self.us
+00001da0: 6572 2c20 7365 6c66 2e70 6173 7377 6f72  er, self.passwor
+00001db0: 6429 0a20 2020 2020 2020 2065 6c69 6620  d).        elif 
+00001dc0: 7365 6c66 2e74 6f6b 656e 3a0a 2020 2020  self.token:.    
+00001dd0: 2020 2020 2020 2020 2320 4967 7561 7a69          # Iguazi
+00001de0: 6f20 6175 7468 2064 6f65 736e 2774 2073  o auth doesn't s
+00001df0: 7570 706f 7274 2070 6173 7369 6e67 2074  upport passing t
+00001e00: 6f6b 656e 2074 6872 6f75 6768 2062 6561  oken through bea
+00001e10: 7265 722c 2073 6f20 7573 6520 636f 6f6b  rer, so use cook
+00001e20: 6965 2069 6e73 7465 6164 0a20 2020 2020  ie instead.     
+00001e30: 2020 2020 2020 2069 6620 6d6c 7275 6e2e         if mlrun.
+00001e40: 706c 6174 666f 726d 732e 6967 7561 7a69  platforms.iguazi
+00001e50: 6f2e 6973 5f69 6775 617a 696f 5f73 6573  o.is_iguazio_ses
+00001e60: 7369 6f6e 2873 656c 662e 746f 6b65 6e29  sion(self.token)
+00001e70: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00001e80: 2020 7365 7373 696f 6e5f 636f 6f6b 6965    session_cookie
+00001e90: 203d 2066 276a 3a7b 7b22 7369 6422 3a20   = f'j:{{"sid": 
+00001ea0: 227b 7365 6c66 2e74 6f6b 656e 7d22 7d7d  "{self.token}"}}
+00001eb0: 270a 2020 2020 2020 2020 2020 2020 2020  '.              
+00001ec0: 2020 636f 6f6b 6965 7320 3d20 7b0a 2020    cookies = {.  
+00001ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ee0: 2020 2273 6573 7369 6f6e 223a 2073 6573    "session": ses
+00001ef0: 7369 6f6e 5f63 6f6f 6b69 652c 0a20 2020  sion_cookie,.   
+00001f00: 2020 2020 2020 2020 2020 2020 207d 0a20               }. 
+00001f10: 2020 2020 2020 2020 2020 2020 2020 206b                 k
+00001f20: 775b 2263 6f6f 6b69 6573 225d 203d 2063  w["cookies"] = c
+00001f30: 6f6f 6b69 6573 0a20 2020 2020 2020 2020  ookies.         
+00001f40: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00001f50: 2020 2020 2020 2020 2069 6620 2241 7574           if "Aut
+00001f60: 686f 7269 7a61 7469 6f6e 2220 6e6f 7420  horization" not 
+00001f70: 696e 206b 772e 7365 7464 6566 6175 6c74  in kw.setdefault
+00001f80: 2822 6865 6164 6572 7322 2c20 7b7d 293a  ("headers", {}):
+00001f90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001fa0: 2020 2020 206b 775b 2268 6561 6465 7273       kw["headers
+00001fb0: 225d 2e75 7064 6174 6528 7b22 4175 7468  "].update({"Auth
+00001fc0: 6f72 697a 6174 696f 6e22 3a20 2242 6561  orization": "Bea
+00001fd0: 7265 7220 2220 2b20 7365 6c66 2e74 6f6b  rer " + self.tok
+00001fe0: 656e 7d29 0a0a 2020 2020 2020 2020 6966  en})..        if
+00001ff0: 206d 6c72 756e 2e61 7069 2e73 6368 656d   mlrun.api.schem
+00002000: 6173 2e48 6561 6465 724e 616d 6573 2e63  as.HeaderNames.c
+00002010: 6c69 656e 745f 7665 7273 696f 6e20 6e6f  lient_version no
+00002020: 7420 696e 206b 772e 7365 7464 6566 6175  t in kw.setdefau
+00002030: 6c74 280a 2020 2020 2020 2020 2020 2020  lt(.            
+00002040: 2268 6561 6465 7273 222c 207b 7d0a 2020  "headers", {}.  
+00002050: 2020 2020 2020 293a 0a20 2020 2020 2020        ):.       
+00002060: 2020 2020 206b 775b 2268 6561 6465 7273       kw["headers
+00002070: 225d 2e75 7064 6174 6528 0a20 2020 2020  "].update(.     
+00002080: 2020 2020 2020 2020 2020 207b 0a20 2020             {.   
+00002090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000020a0: 206d 6c72 756e 2e61 7069 2e73 6368 656d   mlrun.api.schem
+000020b0: 6173 2e48 6561 6465 724e 616d 6573 2e63  as.HeaderNames.c
+000020c0: 6c69 656e 745f 7665 7273 696f 6e3a 2073  lient_version: s
+000020d0: 656c 662e 636c 6965 6e74 5f76 6572 7369  elf.client_versi
+000020e0: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
+000020f0: 2020 2020 2020 2020 6d6c 7275 6e2e 6170          mlrun.ap
+00002100: 692e 7363 6865 6d61 732e 4865 6164 6572  i.schemas.Header
+00002110: 4e61 6d65 732e 7079 7468 6f6e 5f76 6572  Names.python_ver
+00002120: 7369 6f6e 3a20 7365 6c66 2e70 7974 686f  sion: self.pytho
+00002130: 6e5f 7665 7273 696f 6e2c 0a20 2020 2020  n_version,.     
+00002140: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
+00002150: 2020 2020 2020 2020 2029 0a0a 2020 2020           )..    
+00002160: 2020 2020 2320 7265 7175 6573 7473 206e      # requests n
+00002170: 6f20 6c6f 6e67 6572 2073 7570 706f 7274  o longer support
+00002180: 7320 6865 6164 6572 2076 616c 7565 7320  s header values 
+00002190: 746f 2062 6520 656e 756d 2028 6874 7470  to be enum (http
+000021a0: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f70  s://github.com/p
+000021b0: 7366 2f72 6571 7565 7374 732f 7075 6c6c  sf/requests/pull
+000021c0: 2f36 3135 3429 0a20 2020 2020 2020 2023  /6154).        #
+000021d0: 2063 6f6e 7665 7274 2074 6f20 7374 7269   convert to stri
+000021e0: 6e67 732e 2044 6f20 7468 6520 7361 6d65  ngs. Do the same
+000021f0: 2066 6f72 2070 6172 616d 7320 666f 7220   for params for 
+00002200: 6e69 6365 6e65 7373 0a20 2020 2020 2020  niceness.       
+00002210: 2066 6f72 2064 6963 745f 2069 6e20 5b68   for dict_ in [h
+00002220: 6561 6465 7273 2c20 7061 7261 6d73 5d3a  eaders, params]:
+00002230: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00002240: 6469 6374 5f20 6973 206e 6f74 204e 6f6e  dict_ is not Non
+00002250: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00002260: 2020 2066 6f72 206b 6579 2069 6e20 6469     for key in di
+00002270: 6374 5f2e 6b65 7973 2829 3a0a 2020 2020  ct_.keys():.    
+00002280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002290: 6966 2069 7369 6e73 7461 6e63 6528 6469  if isinstance(di
+000022a0: 6374 5f5b 6b65 795d 2c20 656e 756d 2e45  ct_[key], enum.E
+000022b0: 6e75 6d29 3a0a 2020 2020 2020 2020 2020  num):.          
+000022c0: 2020 2020 2020 2020 2020 2020 2020 6469                di
+000022d0: 6374 5f5b 6b65 795d 203d 2064 6963 745f  ct_[key] = dict_
+000022e0: 5b6b 6579 5d2e 7661 6c75 650a 0a20 2020  [key].value..   
+000022f0: 2020 2020 2069 6620 6e6f 7420 7365 6c66       if not self
+00002300: 2e73 6573 7369 6f6e 3a0a 2020 2020 2020  .session:.      
+00002310: 2020 2020 2020 7365 6c66 2e73 6573 7369        self.sessi
+00002320: 6f6e 203d 2073 656c 662e 5f69 6e69 745f  on = self._init_
+00002330: 7365 7373 696f 6e28 290a 0a20 2020 2020  session()..     
+00002340: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+00002350: 2020 2020 7265 7370 6f6e 7365 203d 2073      response = s
+00002360: 656c 662e 7365 7373 696f 6e2e 7265 7175  elf.session.requ
+00002370: 6573 7428 0a20 2020 2020 2020 2020 2020  est(.           
+00002380: 2020 2020 206d 6574 686f 642c 2075 726c       method, url
+00002390: 2c20 7469 6d65 6f75 743d 7469 6d65 6f75  , timeout=timeou
+000023a0: 742c 2076 6572 6966 793d 4661 6c73 652c  t, verify=False,
+000023b0: 202a 2a6b 770a 2020 2020 2020 2020 2020   **kw.          
+000023c0: 2020 290a 2020 2020 2020 2020 6578 6365    ).        exce
+000023d0: 7074 2072 6571 7565 7374 732e 5265 7175  pt requests.Requ
+000023e0: 6573 7445 7863 6570 7469 6f6e 2061 7320  estException as 
+000023f0: 6578 633a 0a20 2020 2020 2020 2020 2020  exc:.           
+00002400: 2065 7272 6f72 203d 2066 227b 6572 725f   error = f"{err_
+00002410: 746f 5f73 7472 2865 7863 297d 3a20 7b65  to_str(exc)}: {e
+00002420: 7272 6f72 7d22 2069 6620 6572 726f 7220  rror}" if error 
+00002430: 656c 7365 2065 7272 5f74 6f5f 7374 7228  else err_to_str(
+00002440: 6578 6329 0a20 2020 2020 2020 2020 2020  exc).           
+00002450: 2072 6169 7365 206d 6c72 756e 2e65 7272   raise mlrun.err
+00002460: 6f72 732e 4d4c 5275 6e52 756e 7469 6d65  ors.MLRunRuntime
+00002470: 4572 726f 7228 6572 726f 7229 2066 726f  Error(error) fro
+00002480: 6d20 6578 630a 0a20 2020 2020 2020 2069  m exc..        i
+00002490: 6620 6e6f 7420 7265 7370 6f6e 7365 2e6f  f not response.o
+000024a0: 6b3a 0a20 2020 2020 2020 2020 2020 2069  k:.            i
+000024b0: 6620 7265 7370 6f6e 7365 2e63 6f6e 7465  f response.conte
+000024c0: 6e74 3a0a 2020 2020 2020 2020 2020 2020  nt:.            
+000024d0: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+000024e0: 2020 2020 2020 2020 2020 2020 2064 6174               dat
+000024f0: 6120 3d20 7265 7370 6f6e 7365 2e6a 736f  a = response.jso
+00002500: 6e28 290a 2020 2020 2020 2020 2020 2020  n().            
+00002510: 2020 2020 2020 2020 6572 726f 725f 6465          error_de
+00002520: 7461 696c 7320 3d20 6461 7461 2e67 6574  tails = data.get
+00002530: 2822 6465 7461 696c 222c 207b 7d29 0a20  ("detail", {}). 
+00002540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002550: 2020 2069 6620 6e6f 7420 6572 726f 725f     if not error_
+00002560: 6465 7461 696c 733a 0a20 2020 2020 2020  details:.       
+00002570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002580: 206c 6f67 6765 722e 7761 726e 696e 6728   logger.warning(
+00002590: 2246 6169 6c65 6420 7061 7273 696e 6720  "Failed parsing 
+000025a0: 6572 726f 7220 7265 7370 6f6e 7365 2062  error response b
+000025b0: 6f64 7922 2c20 6461 7461 3d64 6174 6129  ody", data=data)
+000025c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000025d0: 2065 7863 6570 7420 4578 6365 7074 696f   except Exceptio
+000025e0: 6e3a 0a20 2020 2020 2020 2020 2020 2020  n:.             
+000025f0: 2020 2020 2020 2065 7272 6f72 5f64 6574         error_det
+00002600: 6169 6c73 203d 2022 220a 2020 2020 2020  ails = "".      
+00002610: 2020 2020 2020 2020 2020 6966 2065 7272            if err
+00002620: 6f72 5f64 6574 6169 6c73 3a0a 2020 2020  or_details:.    
+00002630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002640: 6572 726f 725f 6465 7461 696c 7320 3d20  error_details = 
+00002650: 6622 6465 7461 696c 733a 207b 6572 726f  f"details: {erro
+00002660: 725f 6465 7461 696c 737d 220a 2020 2020  r_details}".    
+00002670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002680: 6572 726f 7220 3d20 6622 7b65 7272 6f72  error = f"{error
+00002690: 7d20 7b65 7272 6f72 5f64 6574 6169 6c73  } {error_details
+000026a0: 7d22 2069 6620 6572 726f 7220 656c 7365  }" if error else
+000026b0: 2065 7272 6f72 5f64 6574 6169 6c73 0a20   error_details. 
+000026c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026d0: 2020 206d 6c72 756e 2e65 7272 6f72 732e     mlrun.errors.
+000026e0: 7261 6973 655f 666f 725f 7374 6174 7573  raise_for_status
+000026f0: 2872 6573 706f 6e73 652c 2065 7272 6f72  (response, error
+00002700: 290a 0a20 2020 2020 2020 2020 2020 206d  )..            m
+00002710: 6c72 756e 2e65 7272 6f72 732e 7261 6973  lrun.errors.rais
+00002720: 655f 666f 725f 7374 6174 7573 2872 6573  e_for_status(res
+00002730: 706f 6e73 652c 2065 7272 6f72 290a 0a20  ponse, error).. 
+00002740: 2020 2020 2020 2072 6574 7572 6e20 7265         return re
+00002750: 7370 6f6e 7365 0a0a 2020 2020 6465 6620  sponse..    def 
+00002760: 5f69 6e69 745f 7365 7373 696f 6e28 7365  _init_session(se
+00002770: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
+00002780: 7572 6e20 6d6c 7275 6e2e 7574 696c 732e  urn mlrun.utils.
+00002790: 4854 5450 5365 7373 696f 6e57 6974 6852  HTTPSessionWithR
+000027a0: 6574 7279 280a 2020 2020 2020 2020 2020  etry(.          
+000027b0: 2020 7265 7472 795f 6f6e 5f65 7863 6570    retry_on_excep
+000027c0: 7469 6f6e 3d63 6f6e 6669 672e 6874 7470  tion=config.http
+000027d0: 6462 2e72 6574 7279 5f61 7069 5f63 616c  db.retry_api_cal
+000027e0: 6c5f 6f6e 5f65 7863 6570 7469 6f6e 0a20  l_on_exception. 
+000027f0: 2020 2020 2020 2020 2020 203d 3d20 6d6c             == ml
+00002800: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
+00002810: 4854 5450 5365 7373 696f 6e52 6574 7279  HTTPSessionRetry
+00002820: 4d6f 6465 2e65 6e61 626c 6564 2e76 616c  Mode.enabled.val
+00002830: 7565 0a20 2020 2020 2020 2029 0a0a 2020  ue.        )..  
+00002840: 2020 6465 6620 5f70 6174 685f 6f66 2873    def _path_of(s
+00002850: 656c 662c 2070 7265 6669 782c 2070 726f  elf, prefix, pro
+00002860: 6a65 6374 2c20 7569 6429 3a0a 2020 2020  ject, uid):.    
+00002870: 2020 2020 7072 6f6a 6563 7420 3d20 7072      project = pr
+00002880: 6f6a 6563 7420 6f72 2063 6f6e 6669 672e  oject or config.
+00002890: 6465 6661 756c 745f 7072 6f6a 6563 740a  default_project.
+000028a0: 2020 2020 2020 2020 7265 7475 726e 2066          return f
+000028b0: 227b 7072 6566 6978 7d2f 7b70 726f 6a65  "{prefix}/{proje
+000028c0: 6374 7d2f 7b75 6964 7d22 0a0a 2020 2020  ct}/{uid}"..    
+000028d0: 6465 6620 636f 6e6e 6563 7428 7365 6c66  def connect(self
+000028e0: 2c20 7365 6372 6574 733d 4e6f 6e65 293a  , secrets=None):
+000028f0: 0a20 2020 2020 2020 2022 2222 436f 6e6e  .        """Conn
+00002900: 6563 7420 746f 2074 6865 204d 4c52 756e  ect to the MLRun
+00002910: 2041 5049 2073 6572 7665 722e 204d 7573   API server. Mus
+00002920: 7420 6265 2063 616c 6c65 6420 7072 696f  t be called prio
+00002930: 7220 746f 2065 7865 6375 7469 6e67 2061  r to executing a
+00002940: 6e79 206f 7468 6572 206d 6574 686f 642e  ny other method.
+00002950: 0a20 2020 2020 2020 2054 6865 2063 6f64  .        The cod
+00002960: 6520 7574 696c 697a 6573 2074 6865 2055  e utilizes the U
+00002970: 524c 2066 6f72 2074 6865 2041 5049 2073  RL for the API s
+00002980: 6572 7665 7220 6672 6f6d 2074 6865 2063  erver from the c
+00002990: 6f6e 6669 6775 7261 7469 6f6e 202d 2060  onfiguration - `
+000029a0: 606d 6c63 6f6e 662e 6462 7061 7468 6060  `mlconf.dbpath``
+000029b0: 2e0a 0a20 2020 2020 2020 2046 6f72 2065  ...        For e
+000029c0: 7861 6d70 6c65 3a3a 0a0a 2020 2020 2020  xample::..      
+000029d0: 2020 2020 2020 6d6c 636f 6e66 2e64 6270        mlconf.dbp
+000029e0: 6174 6820 3d20 6d6c 636f 6e66 2e64 6270  ath = mlconf.dbp
+000029f0: 6174 6820 6f72 2027 6874 7470 3a2f 2f6d  ath or 'http://m
+00002a00: 6c72 756e 2d61 7069 3a38 3038 3027 0a20  lrun-api:8080'. 
+00002a10: 2020 2020 2020 2020 2020 2064 6220 3d20             db = 
+00002a20: 6765 745f 7275 6e5f 6462 2829 2e63 6f6e  get_run_db().con
+00002a30: 6e65 6374 2829 0a20 2020 2020 2020 2022  nect().        "
+00002a40: 2222 0a20 2020 2020 2020 2023 2068 6163  "".        # hac
+00002a50: 6b20 746f 2061 6c6c 6f77 2075 6e69 7420  k to allow unit 
+00002a60: 7465 7374 7320 746f 2069 6e73 7461 6e74  tests to instant
+00002a70: 6961 7465 2048 5454 5052 756e 4442 2077  iate HTTPRunDB w
+00002a80: 6974 686f 7574 2061 2072 6561 6c20 7365  ithout a real se
+00002a90: 7276 6572 2062 6568 696e 640a 2020 2020  rver behind.    
+00002aa0: 2020 2020 6966 2022 6d6f 636b 2d73 6572      if "mock-ser
+00002ab0: 7665 7222 2069 6e20 7365 6c66 2e62 6173  ver" in self.bas
+00002ac0: 655f 7572 6c3a 0a20 2020 2020 2020 2020  e_url:.         
+00002ad0: 2020 2072 6574 7572 6e0a 2020 2020 2020     return.      
+00002ae0: 2020 7265 7370 203d 2073 656c 662e 6170    resp = self.ap
+00002af0: 695f 6361 6c6c 2822 4745 5422 2c20 2263  i_call("GET", "c
+00002b00: 6c69 656e 742d 7370 6563 222c 2074 696d  lient-spec", tim
+00002b10: 656f 7574 3d35 290a 2020 2020 2020 2020  eout=5).        
+00002b20: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
+00002b30: 2073 6572 7665 725f 6366 6720 3d20 7265   server_cfg = re
+00002b40: 7370 2e6a 736f 6e28 290a 2020 2020 2020  sp.json().      
+00002b50: 2020 2020 2020 7365 6c66 2e73 6572 7665        self.serve
+00002b60: 725f 7665 7273 696f 6e20 3d20 7365 7276  r_version = serv
+00002b70: 6572 5f63 6667 5b22 7665 7273 696f 6e22  er_cfg["version"
+00002b80: 5d0a 2020 2020 2020 2020 2020 2020 7365  ].            se
+00002b90: 6c66 2e5f 7661 6c69 6461 7465 5f76 6572  lf._validate_ver
+00002ba0: 7369 6f6e 5f63 6f6d 7061 7469 6269 6c69  sion_compatibili
+00002bb0: 7479 2873 656c 662e 7365 7276 6572 5f76  ty(self.server_v
+00002bc0: 6572 7369 6f6e 2c20 636f 6e66 6967 2e76  ersion, config.v
+00002bd0: 6572 7369 6f6e 290a 2020 2020 2020 2020  ersion).        
+00002be0: 2020 2020 636f 6e66 6967 2e6e 616d 6573      config.names
+00002bf0: 7061 6365 203d 2063 6f6e 6669 672e 6e61  pace = config.na
+00002c00: 6d65 7370 6163 6520 6f72 2073 6572 7665  mespace or serve
+00002c10: 725f 6366 672e 6765 7428 226e 616d 6573  r_cfg.get("names
+00002c20: 7061 6365 2229 0a20 2020 2020 2020 2020  pace").         
+00002c30: 2020 2069 6620 280a 2020 2020 2020 2020     if (.        
+00002c40: 2020 2020 2020 2020 226e 616d 6573 7061          "namespa
+00002c50: 6365 2220 696e 2073 6572 7665 725f 6366  ce" in server_cf
+00002c60: 670a 2020 2020 2020 2020 2020 2020 2020  g.              
+00002c70: 2020 616e 6420 7365 7276 6572 5f63 6667    and server_cfg
+00002c80: 5b22 6e61 6d65 7370 6163 6522 5d20 213d  ["namespace"] !=
+00002c90: 2063 6f6e 6669 672e 6e61 6d65 7370 6163   config.namespac
+00002ca0: 650a 2020 2020 2020 2020 2020 2020 293a  e.            ):
+00002cb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002cc0: 206c 6f67 6765 722e 7761 726e 696e 6728   logger.warning(
+00002cd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002ce0: 2020 2020 2066 2277 6172 6e69 6e67 212c       f"warning!,
+00002cf0: 2073 6572 7665 7220 287b 7365 7276 6572   server ({server
+00002d00: 5f63 6667 5b27 6e61 6d65 7370 6163 6527  _cfg['namespace'
+00002d10: 5d7d 2920 616e 6420 636c 6965 6e74 2028  ]}) and client (
+00002d20: 7b63 6f6e 6669 672e 6e61 6d65 7370 6163  {config.namespac
+00002d30: 657d 2922 0a20 2020 2020 2020 2020 2020  e})".           
+00002d40: 2020 2020 2020 2020 2022 206e 616d 6573           " names
+00002d50: 7061 6365 2064 6f6e 2774 206d 6174 6368  pace don't match
+00002d60: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00002d70: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00002d80: 6966 2063 6f6e 6669 672e 6365 2e6d 6f64  if config.ce.mod
+00002d90: 6520 616e 6420 636f 6e66 6967 2e63 652e  e and config.ce.
+00002da0: 6d6f 6465 2021 3d20 7365 7276 6572 5f63  mode != server_c
+00002db0: 6667 2e67 6574 2822 6365 5f6d 6f64 6522  fg.get("ce_mode"
+00002dc0: 2c20 2222 293a 0a20 2020 2020 2020 2020  , ""):.         
+00002dd0: 2020 2020 2020 206c 6f67 6765 722e 7761         logger.wa
+00002de0: 726e 696e 6728 0a20 2020 2020 2020 2020  rning(.         
+00002df0: 2020 2020 2020 2020 2020 2066 2277 6172             f"war
+00002e00: 6e69 6e67 212c 2073 6572 7665 7220 287b  ning!, server ({
+00002e10: 7365 7276 6572 5f63 6667 5b27 6365 5f6d  server_cfg['ce_m
+00002e20: 6f64 6527 5d7d 2920 616e 6420 636c 6965  ode']}) and clie
+00002e30: 6e74 2028 7b63 6f6e 6669 672e 6365 2e6d  nt ({config.ce.m
+00002e40: 6f64 657d 2922 0a20 2020 2020 2020 2020  ode})".         
+00002e50: 2020 2020 2020 2020 2020 2022 2043 4520             " CE 
+00002e60: 6d6f 6465 2064 6f6e 2774 206d 6174 6368  mode don't match
+00002e70: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00002e80: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00002e90: 636f 6e66 6967 2e63 6520 3d20 7365 7276  config.ce = serv
+00002ea0: 6572 5f63 6667 2e67 6574 2822 6365 2229  er_cfg.get("ce")
+00002eb0: 206f 7220 636f 6e66 6967 2e63 650a 0a20   or config.ce.. 
+00002ec0: 2020 2020 2020 2020 2020 2023 2067 6574             # get
+00002ed0: 2064 6566 6175 6c74 7320 6672 6f6d 2072   defaults from r
+00002ee0: 656d 6f74 6520 7365 7276 6572 0a20 2020  emote server.   
+00002ef0: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+00002f00: 7265 6d6f 7465 5f68 6f73 7420 3d20 636f  remote_host = co
+00002f10: 6e66 6967 2e72 656d 6f74 655f 686f 7374  nfig.remote_host
+00002f20: 206f 7220 7365 7276 6572 5f63 6667 2e67   or server_cfg.g
+00002f30: 6574 2822 7265 6d6f 7465 5f68 6f73 7422  et("remote_host"
+00002f40: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
+00002f50: 6e66 6967 2e6d 7069 6a6f 625f 6372 645f  nfig.mpijob_crd_
+00002f60: 7665 7273 696f 6e20 3d20 636f 6e66 6967  version = config
+00002f70: 2e6d 7069 6a6f 625f 6372 645f 7665 7273  .mpijob_crd_vers
+00002f80: 696f 6e20 6f72 2073 6572 7665 725f 6366  ion or server_cf
+00002f90: 672e 6765 7428 0a20 2020 2020 2020 2020  g.get(.         
+00002fa0: 2020 2020 2020 2022 6d70 696a 6f62 5f63         "mpijob_c
+00002fb0: 7264 5f76 6572 7369 6f6e 220a 2020 2020  rd_version".    
+00002fc0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00002fd0: 2020 2020 2020 636f 6e66 6967 2e75 692e        config.ui.
+00002fe0: 7572 6c20 3d20 636f 6e66 6967 2e72 6573  url = config.res
+00002ff0: 6f6c 7665 5f75 695f 7572 6c28 2920 6f72  olve_ui_url() or
+00003000: 2073 6572 7665 725f 6366 672e 6765 7428   server_cfg.get(
+00003010: 2275 695f 7572 6c22 290a 2020 2020 2020  "ui_url").      
+00003020: 2020 2020 2020 636f 6e66 6967 2e61 7274        config.art
+00003030: 6966 6163 745f 7061 7468 203d 2063 6f6e  ifact_path = con
+00003040: 6669 672e 6172 7469 6661 6374 5f70 6174  fig.artifact_pat
+00003050: 6820 6f72 2073 6572 7665 725f 6366 672e  h or server_cfg.
+00003060: 6765 7428 0a20 2020 2020 2020 2020 2020  get(.           
+00003070: 2020 2020 2022 6172 7469 6661 6374 5f70       "artifact_p
+00003080: 6174 6822 0a20 2020 2020 2020 2020 2020  ath".           
+00003090: 2029 0a20 2020 2020 2020 2020 2020 2063   ).            c
+000030a0: 6f6e 6669 672e 6665 6174 7572 655f 7374  onfig.feature_st
+000030b0: 6f72 652e 6461 7461 5f70 7265 6669 7865  ore.data_prefixe
+000030c0: 7320 3d20 280a 2020 2020 2020 2020 2020  s = (.          
+000030d0: 2020 2020 2020 636f 6e66 6967 2e66 6561        config.fea
+000030e0: 7475 7265 5f73 746f 7265 2e64 6174 615f  ture_store.data_
+000030f0: 7072 6566 6978 6573 0a20 2020 2020 2020  prefixes.       
+00003100: 2020 2020 2020 2020 206f 7220 7365 7276           or serv
+00003110: 6572 5f63 6667 2e67 6574 2822 6665 6174  er_cfg.get("feat
+00003120: 7572 655f 7374 6f72 655f 6461 7461 5f70  ure_store_data_p
+00003130: 7265 6669 7865 7322 290a 2020 2020 2020  refixes").      
+00003140: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00003150: 2020 2020 636f 6e66 6967 2e73 7061 726b      config.spark
+00003160: 5f61 7070 5f69 6d61 6765 203d 2063 6f6e  _app_image = con
+00003170: 6669 672e 7370 6172 6b5f 6170 705f 696d  fig.spark_app_im
+00003180: 6167 6520 6f72 2073 6572 7665 725f 6366  age or server_cf
+00003190: 672e 6765 7428 0a20 2020 2020 2020 2020  g.get(.         
+000031a0: 2020 2020 2020 2022 7370 6172 6b5f 6170         "spark_ap
+000031b0: 705f 696d 6167 6522 0a20 2020 2020 2020  p_image".       
+000031c0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+000031d0: 2020 2063 6f6e 6669 672e 7370 6172 6b5f     config.spark_
+000031e0: 6170 705f 696d 6167 655f 7461 6720 3d20  app_image_tag = 
+000031f0: 636f 6e66 6967 2e73 7061 726b 5f61 7070  config.spark_app
+00003200: 5f69 6d61 6765 5f74 6167 206f 7220 7365  _image_tag or se
+00003210: 7276 6572 5f63 6667 2e67 6574 280a 2020  rver_cfg.get(.  
+00003220: 2020 2020 2020 2020 2020 2020 2020 2273                "s
+00003230: 7061 726b 5f61 7070 5f69 6d61 6765 5f74  park_app_image_t
+00003240: 6167 220a 2020 2020 2020 2020 2020 2020  ag".            
+00003250: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
+00003260: 6e66 6967 2e73 7061 726b 5f68 6973 746f  nfig.spark_histo
+00003270: 7279 5f73 6572 7665 725f 7061 7468 203d  ry_server_path =
+00003280: 2028 0a20 2020 2020 2020 2020 2020 2020   (.             
+00003290: 2020 2063 6f6e 6669 672e 7370 6172 6b5f     config.spark_
+000032a0: 6869 7374 6f72 795f 7365 7276 6572 5f70  history_server_p
+000032b0: 6174 680a 2020 2020 2020 2020 2020 2020  ath.            
+000032c0: 2020 2020 6f72 2073 6572 7665 725f 6366      or server_cf
+000032d0: 672e 6765 7428 2273 7061 726b 5f68 6973  g.get("spark_his
+000032e0: 746f 7279 5f73 6572 7665 725f 7061 7468  tory_server_path
+000032f0: 2229 0a20 2020 2020 2020 2020 2020 2029  ").            )
+00003300: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+00003310: 6669 672e 6874 7470 6462 2e62 7569 6c64  fig.httpdb.build
+00003320: 6572 2e64 6f63 6b65 725f 7265 6769 7374  er.docker_regist
+00003330: 7279 203d 2028 0a20 2020 2020 2020 2020  ry = (.         
+00003340: 2020 2020 2020 2063 6f6e 6669 672e 6874         config.ht
+00003350: 7470 6462 2e62 7569 6c64 6572 2e64 6f63  tpdb.builder.doc
+00003360: 6b65 725f 7265 6769 7374 7279 0a20 2020  ker_registry.   
+00003370: 2020 2020 2020 2020 2020 2020 206f 7220               or 
+00003380: 7365 7276 6572 5f63 6667 2e67 6574 2822  server_cfg.get("
+00003390: 646f 636b 6572 5f72 6567 6973 7472 7922  docker_registry"
+000033a0: 290a 2020 2020 2020 2020 2020 2020 290a  ).            ).
+000033b0: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+000033c0: 6967 2e68 7474 7064 622e 6170 695f 7572  ig.httpdb.api_ur
+000033d0: 6c20 3d20 636f 6e66 6967 2e68 7474 7064  l = config.httpd
+000033e0: 622e 6170 695f 7572 6c20 6f72 2073 6572  b.api_url or ser
+000033f0: 7665 725f 6366 672e 6765 7428 2261 7069  ver_cfg.get("api
+00003400: 5f75 726c 2229 0a20 2020 2020 2020 2020  _url").         
+00003410: 2020 2063 6f6e 6669 672e 6e75 636c 696f     config.nuclio
+00003420: 5f76 6572 7369 6f6e 203d 2063 6f6e 6669  _version = confi
+00003430: 672e 6e75 636c 696f 5f76 6572 7369 6f6e  g.nuclio_version
+00003440: 206f 7220 7365 7276 6572 5f63 6667 2e67   or server_cfg.g
+00003450: 6574 280a 2020 2020 2020 2020 2020 2020  et(.            
+00003460: 2020 2020 226e 7563 6c69 6f5f 7665 7273      "nuclio_vers
+00003470: 696f 6e22 0a20 2020 2020 2020 2020 2020  ion".           
+00003480: 2029 0a20 2020 2020 2020 2020 2020 2063   ).            c
+00003490: 6f6e 6669 672e 6465 6661 756c 745f 6675  onfig.default_fu
+000034a0: 6e63 7469 6f6e 5f70 7269 6f72 6974 795f  nction_priority_
+000034b0: 636c 6173 735f 6e61 6d65 203d 2028 0a20  class_name = (. 
+000034c0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000034d0: 6f6e 6669 672e 6465 6661 756c 745f 6675  onfig.default_fu
+000034e0: 6e63 7469 6f6e 5f70 7269 6f72 6974 795f  nction_priority_
+000034f0: 636c 6173 735f 6e61 6d65 0a20 2020 2020  class_name.     
+00003500: 2020 2020 2020 2020 2020 206f 7220 7365             or se
+00003510: 7276 6572 5f63 6667 2e67 6574 2822 6465  rver_cfg.get("de
+00003520: 6661 756c 745f 6675 6e63 7469 6f6e 5f70  fault_function_p
+00003530: 7269 6f72 6974 795f 636c 6173 735f 6e61  riority_class_na
+00003540: 6d65 2229 0a20 2020 2020 2020 2020 2020  me").           
+00003550: 2029 0a20 2020 2020 2020 2020 2020 2063   ).            c
+00003560: 6f6e 6669 672e 7661 6c69 645f 6675 6e63  onfig.valid_func
+00003570: 7469 6f6e 5f70 7269 6f72 6974 795f 636c  tion_priority_cl
+00003580: 6173 735f 6e61 6d65 7320 3d20 280a 2020  ass_names = (.  
+00003590: 2020 2020 2020 2020 2020 2020 2020 636f                co
+000035a0: 6e66 6967 2e76 616c 6964 5f66 756e 6374  nfig.valid_funct
+000035b0: 696f 6e5f 7072 696f 7269 7479 5f63 6c61  ion_priority_cla
+000035c0: 7373 5f6e 616d 6573 0a20 2020 2020 2020  ss_names.       
+000035d0: 2020 2020 2020 2020 206f 7220 7365 7276           or serv
+000035e0: 6572 5f63 6667 2e67 6574 2822 7661 6c69  er_cfg.get("vali
+000035f0: 645f 6675 6e63 7469 6f6e 5f70 7269 6f72  d_function_prior
+00003600: 6974 795f 636c 6173 735f 6e61 6d65 7322  ity_class_names"
+00003610: 290a 2020 2020 2020 2020 2020 2020 290a  ).            ).
+00003620: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00003630: 6967 2e61 7274 6966 6163 7473 2e63 616c  ig.artifacts.cal
+00003640: 6375 6c61 7465 5f68 6173 6820 3d20 280a  culate_hash = (.
+00003650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003660: 636f 6e66 6967 2e61 7274 6966 6163 7473  config.artifacts
+00003670: 2e63 616c 6375 6c61 7465 5f68 6173 680a  .calculate_hash.
+00003680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003690: 6966 2063 6f6e 6669 672e 6172 7469 6661  if config.artifa
+000036a0: 6374 732e 6361 6c63 756c 6174 655f 6861  cts.calculate_ha
+000036b0: 7368 2069 7320 6e6f 7420 4e6f 6e65 0a20  sh is not None. 
+000036c0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+000036d0: 6c73 6520 7365 7276 6572 5f63 6667 2e67  lse server_cfg.g
+000036e0: 6574 2822 6361 6c63 756c 6174 655f 6172  et("calculate_ar
+000036f0: 7469 6661 6374 5f68 6173 6822 290a 2020  tifact_hash").  
+00003700: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00003710: 2020 2020 2020 2020 636f 6e66 6967 2e61          config.a
+00003720: 7274 6966 6163 7473 2e67 656e 6572 6174  rtifacts.generat
+00003730: 655f 7461 7267 6574 5f70 6174 685f 6672  e_target_path_fr
+00003740: 6f6d 5f61 7274 6966 6163 745f 6861 7368  om_artifact_hash
+00003750: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
+00003760: 2020 2020 2063 6f6e 6669 672e 6172 7469       config.arti
+00003770: 6661 6374 732e 6765 6e65 7261 7465 5f74  facts.generate_t
+00003780: 6172 6765 745f 7061 7468 5f66 726f 6d5f  arget_path_from_
+00003790: 6172 7469 6661 6374 5f68 6173 680a 2020  artifact_hash.  
+000037a0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+000037b0: 2063 6f6e 6669 672e 6172 7469 6661 6374   config.artifact
+000037c0: 732e 6765 6e65 7261 7465 5f74 6172 6765  s.generate_targe
+000037d0: 745f 7061 7468 5f66 726f 6d5f 6172 7469  t_path_from_arti
+000037e0: 6661 6374 5f68 6173 6820 6973 206e 6f74  fact_hash is not
+000037f0: 204e 6f6e 650a 2020 2020 2020 2020 2020   None.          
+00003800: 2020 2020 2020 656c 7365 2073 6572 7665        else serve
+00003810: 725f 6366 672e 6765 7428 2267 656e 6572  r_cfg.get("gener
+00003820: 6174 655f 6172 7469 6661 6374 5f74 6172  ate_artifact_tar
+00003830: 6765 745f 7061 7468 5f66 726f 6d5f 6172  get_path_from_ar
+00003840: 7469 6661 6374 5f68 6173 6822 290a 2020  tifact_hash").  
+00003850: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00003860: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+00003870: 7265 6469 732e 7572 6c20 3d20 636f 6e66  redis.url = conf
+00003880: 6967 2e72 6564 6973 2e75 726c 206f 7220  ig.redis.url or 
+00003890: 7365 7276 6572 5f63 6667 2e67 6574 2822  server_cfg.get("
+000038a0: 7265 6469 735f 7572 6c22 290a 2020 2020  redis_url").    
+000038b0: 2020 2020 2020 2020 2320 616c 6c6f 7720          # allow 
+000038c0: 636c 6965 6e74 2074 6f20 7365 7420 7468  client to set th
+000038d0: 6520 6465 6661 756c 7420 7061 7274 6961  e default partia
+000038e0: 6c20 5741 2066 6f72 206c 6163 6b20 6f66  l WA for lack of
+000038f0: 2073 7570 706f 7274 206f 6620 7065 722d   support of per-
+00003900: 7461 7267 6574 2061 7578 696c 6961 7279  target auxiliary
+00003910: 206f 7074 696f 6e73 0a20 2020 2020 2020   options.       
+00003920: 2020 2020 2063 6f6e 6669 672e 7265 6469       config.redi
+00003930: 732e 7479 7065 203d 2063 6f6e 6669 672e  s.type = config.
+00003940: 7265 6469 732e 7479 7065 206f 7220 7365  redis.type or se
+00003950: 7276 6572 5f63 6667 2e67 6574 2822 7265  rver_cfg.get("re
+00003960: 6469 735f 7479 7065 2229 0a0a 2020 2020  dis_type")..    
+00003970: 2020 2020 2020 2020 636f 6e66 6967 2e73          config.s
+00003980: 716c 2e75 726c 203d 2063 6f6e 6669 672e  ql.url = config.
+00003990: 7371 6c2e 7572 6c20 6f72 2073 6572 7665  sql.url or serve
+000039a0: 725f 6366 672e 6765 7428 2273 716c 5f75  r_cfg.get("sql_u
+000039b0: 726c 2229 0a20 2020 2020 2020 2020 2020  rl").           
+000039c0: 2023 2054 6865 7365 2068 6176 6520 6120   # These have a 
+000039d0: 6465 6661 756c 7420 7661 6c75 652c 2074  default value, t
+000039e0: 6865 7265 666f 7265 206c 6f63 616c 2063  herefore local c
+000039f0: 6f6e 6669 6720 7769 6c6c 2061 6c77 6179  onfig will alway
+00003a00: 7320 6861 7665 2061 2076 616c 7565 2c20  s have a value, 
+00003a10: 7072 696f 7269 7469 7a65 2074 6865 0a20  prioritize the. 
+00003a20: 2020 2020 2020 2020 2020 2023 2041 5049             # API
+00003a30: 2076 616c 7565 2066 6972 7374 0a20 2020   value first.   
+00003a40: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+00003a50: 7569 2e70 726f 6a65 6374 735f 7072 6566  ui.projects_pref
+00003a60: 6978 203d 2028 0a20 2020 2020 2020 2020  ix = (.         
+00003a70: 2020 2020 2020 2073 6572 7665 725f 6366         server_cf
+00003a80: 672e 6765 7428 2275 695f 7072 6f6a 6563  g.get("ui_projec
+00003a90: 7473 5f70 7265 6669 7822 2920 6f72 2063  ts_prefix") or c
+00003aa0: 6f6e 6669 672e 7569 2e70 726f 6a65 6374  onfig.ui.project
+00003ab0: 735f 7072 6566 6978 0a20 2020 2020 2020  s_prefix.       
+00003ac0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00003ad0: 2020 2063 6f6e 6669 672e 6b66 705f 696d     config.kfp_im
+00003ae0: 6167 6520 3d20 7365 7276 6572 5f63 6667  age = server_cfg
+00003af0: 2e67 6574 2822 6b66 705f 696d 6167 6522  .get("kfp_image"
+00003b00: 2920 6f72 2063 6f6e 6669 672e 6b66 705f  ) or config.kfp_
+00003b10: 696d 6167 650a 2020 2020 2020 2020 2020  image.          
+00003b20: 2020 636f 6e66 6967 2e6b 6670 5f75 726c    config.kfp_url
+00003b30: 203d 2073 6572 7665 725f 6366 672e 6765   = server_cfg.ge
+00003b40: 7428 226b 6670 5f75 726c 2229 206f 7220  t("kfp_url") or 
+00003b50: 636f 6e66 6967 2e6b 6670 5f75 726c 0a20  config.kfp_url. 
+00003b60: 2020 2020 2020 2020 2020 2063 6f6e 6669             confi
+00003b70: 672e 6461 736b 5f6b 6670 5f69 6d61 6765  g.dask_kfp_image
+00003b80: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
+00003b90: 2020 2020 2073 6572 7665 725f 6366 672e       server_cfg.
+00003ba0: 6765 7428 2264 6173 6b5f 6b66 705f 696d  get("dask_kfp_im
+00003bb0: 6167 6522 2920 6f72 2063 6f6e 6669 672e  age") or config.
+00003bc0: 6461 736b 5f6b 6670 5f69 6d61 6765 0a20  dask_kfp_image. 
+00003bd0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00003be0: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+00003bf0: 7363 7261 7065 5f6d 6574 7269 6373 203d  scrape_metrics =
+00003c00: 2028 0a20 2020 2020 2020 2020 2020 2020   (.             
+00003c10: 2020 2073 6572 7665 725f 6366 672e 6765     server_cfg.ge
+00003c20: 7428 2273 6372 6170 655f 6d65 7472 6963  t("scrape_metric
+00003c30: 7322 290a 2020 2020 2020 2020 2020 2020  s").            
+00003c40: 2020 2020 6966 2073 6572 7665 725f 6366      if server_cf
+00003c50: 672e 6765 7428 2273 6372 6170 655f 6d65  g.get("scrape_me
+00003c60: 7472 6963 7322 2920 6973 206e 6f74 204e  trics") is not N
+00003c70: 6f6e 650a 2020 2020 2020 2020 2020 2020  one.            
+00003c80: 2020 2020 656c 7365 2063 6f6e 6669 672e      else config.
+00003c90: 7363 7261 7065 5f6d 6574 7269 6373 0a20  scrape_metrics. 
+00003ca0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00003cb0: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+00003cc0: 6875 625f 7572 6c20 3d20 7365 7276 6572  hub_url = server
+00003cd0: 5f63 6667 2e67 6574 2822 6875 625f 7572  _cfg.get("hub_ur
+00003ce0: 6c22 2920 6f72 2063 6f6e 6669 672e 6875  l") or config.hu
+00003cf0: 625f 7572 6c0a 2020 2020 2020 2020 2020  b_url.          
+00003d00: 2020 636f 6e66 6967 2e64 6566 6175 6c74    config.default
+00003d10: 5f66 756e 6374 696f 6e5f 6e6f 6465 5f73  _function_node_s
+00003d20: 656c 6563 746f 7220 3d20 280a 2020 2020  elector = (.    
+00003d30: 2020 2020 2020 2020 2020 2020 7365 7276              serv
+00003d40: 6572 5f63 6667 2e67 6574 2822 6465 6661  er_cfg.get("defa
+00003d50: 756c 745f 6675 6e63 7469 6f6e 5f6e 6f64  ult_function_nod
+00003d60: 655f 7365 6c65 6374 6f72 2229 0a20 2020  e_selector").   
+00003d70: 2020 2020 2020 2020 2020 2020 206f 7220               or 
+00003d80: 636f 6e66 6967 2e64 6566 6175 6c74 5f66  config.default_f
+00003d90: 756e 6374 696f 6e5f 6e6f 6465 5f73 656c  unction_node_sel
+00003da0: 6563 746f 720a 2020 2020 2020 2020 2020  ector.          
+00003db0: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00003dc0: 636f 6e66 6967 2e69 677a 5f76 6572 7369  config.igz_versi
+00003dd0: 6f6e 203d 2073 6572 7665 725f 6366 672e  on = server_cfg.
+00003de0: 6765 7428 2269 677a 5f76 6572 7369 6f6e  get("igz_version
+00003df0: 2229 206f 7220 636f 6e66 6967 2e69 677a  ") or config.igz
+00003e00: 5f76 6572 7369 6f6e 0a20 2020 2020 2020  _version.       
+00003e10: 2020 2020 2063 6f6e 6669 672e 7374 6f72       config.stor
+00003e20: 6167 652e 6175 746f 5f6d 6f75 6e74 5f74  age.auto_mount_t
+00003e30: 7970 6520 3d20 280a 2020 2020 2020 2020  ype = (.        
+00003e40: 2020 2020 2020 2020 7365 7276 6572 5f63          server_c
+00003e50: 6667 2e67 6574 2822 6175 746f 5f6d 6f75  fg.get("auto_mou
+00003e60: 6e74 5f74 7970 6522 2920 6f72 2063 6f6e  nt_type") or con
+00003e70: 6669 672e 7374 6f72 6167 652e 6175 746f  fig.storage.auto
+00003e80: 5f6d 6f75 6e74 5f74 7970 650a 2020 2020  _mount_type.    
+00003e90: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00003ea0: 2020 2020 2020 636f 6e66 6967 2e73 746f        config.sto
+00003eb0: 7261 6765 2e61 7574 6f5f 6d6f 756e 745f  rage.auto_mount_
+00003ec0: 7061 7261 6d73 203d 2028 0a20 2020 2020  params = (.     
+00003ed0: 2020 2020 2020 2020 2020 2073 6572 7665             serve
+00003ee0: 725f 6366 672e 6765 7428 2261 7574 6f5f  r_cfg.get("auto_
+00003ef0: 6d6f 756e 745f 7061 7261 6d73 2229 206f  mount_params") o
+00003f00: 7220 636f 6e66 6967 2e73 746f 7261 6765  r config.storage
+00003f10: 2e61 7574 6f5f 6d6f 756e 745f 7061 7261  .auto_mount_para
+00003f20: 6d73 0a20 2020 2020 2020 2020 2020 2029  ms.            )
+00003f30: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+00003f40: 6669 672e 7370 6172 6b5f 6f70 6572 6174  fig.spark_operat
+00003f50: 6f72 5f76 6572 7369 6f6e 203d 2028 0a20  or_version = (. 
+00003f60: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00003f70: 6572 7665 725f 6366 672e 6765 7428 2273  erver_cfg.get("s
+00003f80: 7061 726b 5f6f 7065 7261 746f 725f 7665  park_operator_ve
+00003f90: 7273 696f 6e22 290a 2020 2020 2020 2020  rsion").        
+00003fa0: 2020 2020 2020 2020 6f72 2063 6f6e 6669          or confi
+00003fb0: 672e 7370 6172 6b5f 6f70 6572 6174 6f72  g.spark_operator
+00003fc0: 5f76 6572 7369 6f6e 0a20 2020 2020 2020  _version.       
+00003fd0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00003fe0: 2020 2063 6f6e 6669 672e 6465 6661 756c     config.defaul
+00003ff0: 745f 7465 6e73 6f72 626f 6172 645f 6c6f  t_tensorboard_lo
+00004000: 6773 5f70 6174 6820 3d20 280a 2020 2020  gs_path = (.    
+00004010: 2020 2020 2020 2020 2020 2020 7365 7276              serv
+00004020: 6572 5f63 6667 2e67 6574 2822 6465 6661  er_cfg.get("defa
+00004030: 756c 745f 7465 6e73 6f72 626f 6172 645f  ult_tensorboard_
+00004040: 6c6f 6773 5f70 6174 6822 290a 2020 2020  logs_path").    
+00004050: 2020 2020 2020 2020 2020 2020 6f72 2063              or c
+00004060: 6f6e 6669 672e 6465 6661 756c 745f 7465  onfig.default_te
+00004070: 6e73 6f72 626f 6172 645f 6c6f 6773 5f70  nsorboard_logs_p
+00004080: 6174 680a 2020 2020 2020 2020 2020 2020  ath.            
+00004090: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
+000040a0: 6e66 6967 2e64 6566 6175 6c74 5f66 756e  nfig.default_fun
+000040b0: 6374 696f 6e5f 706f 645f 7265 736f 7572  ction_pod_resour
+000040c0: 6365 7320 3d20 280a 2020 2020 2020 2020  ces = (.        
+000040d0: 2020 2020 2020 2020 7365 7276 6572 5f63          server_c
+000040e0: 6667 2e67 6574 2822 6465 6661 756c 745f  fg.get("default_
+000040f0: 6675 6e63 7469 6f6e 5f70 6f64 5f72 6573  function_pod_res
+00004100: 6f75 7263 6573 2229 0a20 2020 2020 2020  ources").       
+00004110: 2020 2020 2020 2020 206f 7220 636f 6e66           or conf
+00004120: 6967 2e64 6566 6175 6c74 5f66 756e 6374  ig.default_funct
+00004130: 696f 6e5f 706f 645f 7265 736f 7572 6365  ion_pod_resource
+00004140: 730a 2020 2020 2020 2020 2020 2020 290a  s.            ).
+00004150: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+00004160: 6967 2e66 756e 6374 696f 6e5f 6465 6661  ig.function_defa
+00004170: 756c 7473 2e70 7265 656d 7074 696f 6e5f  ults.preemption_
+00004180: 6d6f 6465 203d 2028 0a20 2020 2020 2020  mode = (.       
+00004190: 2020 2020 2020 2020 2073 6572 7665 725f           server_
+000041a0: 6366 672e 6765 7428 2264 6566 6175 6c74  cfg.get("default
+000041b0: 5f70 7265 656d 7074 696f 6e5f 6d6f 6465  _preemption_mode
+000041c0: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+000041d0: 2020 206f 7220 636f 6e66 6967 2e66 756e     or config.fun
+000041e0: 6374 696f 6e5f 6465 6661 756c 7473 2e70  ction_defaults.p
+000041f0: 7265 656d 7074 696f 6e5f 6d6f 6465 0a20  reemption_mode. 
+00004200: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00004210: 2020 2020 2020 2020 2063 6f6e 6669 672e           config.
+00004220: 7072 6565 6d70 7469 626c 655f 6e6f 6465  preemptible_node
+00004230: 732e 6e6f 6465 5f73 656c 6563 746f 7220  s.node_selector 
+00004240: 3d20 280a 2020 2020 2020 2020 2020 2020  = (.            
+00004250: 2020 2020 7365 7276 6572 5f63 6667 2e67      server_cfg.g
+00004260: 6574 2822 7072 6565 6d70 7469 626c 655f  et("preemptible_
+00004270: 6e6f 6465 735f 6e6f 6465 5f73 656c 6563  nodes_node_selec
+00004280: 746f 7222 290a 2020 2020 2020 2020 2020  tor").          
+00004290: 2020 2020 2020 6f72 2063 6f6e 6669 672e        or config.
+000042a0: 7072 6565 6d70 7469 626c 655f 6e6f 6465  preemptible_node
+000042b0: 732e 6e6f 6465 5f73 656c 6563 746f 720a  s.node_selector.
+000042c0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+000042d0: 2020 2020 2020 2020 2020 636f 6e66 6967            config
+000042e0: 2e70 7265 656d 7074 6962 6c65 5f6e 6f64  .preemptible_nod
+000042f0: 6573 2e74 6f6c 6572 6174 696f 6e73 203d  es.tolerations =
+00004300: 2028 0a20 2020 2020 2020 2020 2020 2020   (.             
+00004310: 2020 2073 6572 7665 725f 6366 672e 6765     server_cfg.ge
+00004320: 7428 2270 7265 656d 7074 6962 6c65 5f6e  t("preemptible_n
+00004330: 6f64 6573 5f74 6f6c 6572 6174 696f 6e73  odes_tolerations
+00004340: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+00004350: 2020 206f 7220 636f 6e66 6967 2e70 7265     or config.pre
+00004360: 656d 7074 6962 6c65 5f6e 6f64 6573 2e74  emptible_nodes.t
+00004370: 6f6c 6572 6174 696f 6e73 0a20 2020 2020  olerations.     
+00004380: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00004390: 2020 2020 2063 6f6e 6669 672e 666f 7263       config.forc
+000043a0: 655f 7275 6e5f 6c6f 6361 6c20 3d20 280a  e_run_local = (.
+000043b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000043c0: 7365 7276 6572 5f63 6667 2e67 6574 2822  server_cfg.get("
+000043d0: 666f 7263 655f 7275 6e5f 6c6f 6361 6c22  force_run_local"
+000043e0: 2920 6f72 2063 6f6e 6669 672e 666f 7263  ) or config.forc
+000043f0: 655f 7275 6e5f 6c6f 6361 6c0a 2020 2020  e_run_local.    
+00004400: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00004410: 2020 2020 2020 636f 6e66 6967 2e66 756e        config.fun
+00004420: 6374 696f 6e20 3d20 7365 7276 6572 5f63  ction = server_c
+00004430: 6667 2e67 6574 2822 6675 6e63 7469 6f6e  fg.get("function
+00004440: 2229 206f 7220 636f 6e66 6967 2e66 756e  ") or config.fun
+00004450: 6374 696f 6e0a 2020 2020 2020 2020 2020  ction.          
+00004460: 2020 636f 6e66 6967 2e68 7474 7064 622e    config.httpdb.
+00004470: 6c6f 6773 203d 2073 6572 7665 725f 6366  logs = server_cf
+00004480: 672e 6765 7428 226c 6f67 7322 2920 6f72  g.get("logs") or
+00004490: 2063 6f6e 6669 672e 6874 7470 6462 2e6c   config.httpdb.l
+000044a0: 6f67 730a 0a20 2020 2020 2020 2065 7863  ogs..        exc
+000044b0: 6570 7420 4578 6365 7074 696f 6e20 6173  ept Exception as
+000044c0: 2065 7863 3a0a 2020 2020 2020 2020 2020   exc:.          
+000044d0: 2020 6c6f 6767 6572 2e77 6172 6e69 6e67    logger.warning
+000044e0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+000044f0: 2020 2246 6169 6c65 6420 7379 6e63 696e    "Failed syncin
+00004500: 6720 636f 6e66 6967 2066 726f 6d20 7365  g config from se
+00004510: 7276 6572 222c 0a20 2020 2020 2020 2020  rver",.         
+00004520: 2020 2020 2020 2065 7863 3d65 7272 5f74         exc=err_t
+00004530: 6f5f 7374 7228 6578 6329 2c0a 2020 2020  o_str(exc),.    
+00004540: 2020 2020 2020 2020 2020 2020 7472 6163              trac
+00004550: 6562 6163 6b3d 7472 6163 6562 6163 6b2e  eback=traceback.
+00004560: 666f 726d 6174 5f65 7863 2829 2c0a 2020  format_exc(),.  
+00004570: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00004580: 2020 2020 7265 7475 726e 2073 656c 660a      return self.
+00004590: 0a20 2020 2064 6566 2073 746f 7265 5f6c  .    def store_l
+000045a0: 6f67 2873 656c 662c 2075 6964 2c20 7072  og(self, uid, pr
+000045b0: 6f6a 6563 743d 2222 2c20 626f 6479 3d4e  oject="", body=N
+000045c0: 6f6e 652c 2061 7070 656e 643d 4661 6c73  one, append=Fals
+000045d0: 6529 3a0a 2020 2020 2020 2020 2222 2253  e):.        """S
+000045e0: 6176 6520 6120 6c6f 6720 7065 7273 6973  ave a log persis
+000045f0: 7465 6e74 6c79 2e0a 0a20 2020 2020 2020  tently...       
+00004600: 203a 7061 7261 6d20 7569 643a 204c 6f67   :param uid: Log
+00004610: 2075 6e69 7175 6520 4944 0a20 2020 2020   unique ID.     
+00004620: 2020 203a 7061 7261 6d20 7072 6f6a 6563     :param projec
+00004630: 743a 2050 726f 6a65 6374 206e 616d 6520  t: Project name 
+00004640: 666f 7220 7768 6963 6820 7468 6973 206c  for which this l
+00004650: 6f67 2062 656c 6f6e 6773 0a20 2020 2020  og belongs.     
+00004660: 2020 203a 7061 7261 6d20 626f 6479 3a20     :param body: 
+00004670: 5468 6520 6163 7475 616c 206c 6f67 2074  The actual log t
+00004680: 6f20 7374 6f72 650a 2020 2020 2020 2020  o store.        
+00004690: 3a70 6172 616d 2061 7070 656e 643a 2057  :param append: W
+000046a0: 6865 7468 6572 2074 6f20 6170 7065 6e64  hether to append
+000046b0: 2074 6865 206c 6f67 2070 726f 7669 6465   the log provide
+000046c0: 6420 696e 2060 6062 6f64 7960 6020 746f  d in ``body`` to
+000046d0: 2061 6e20 6578 6973 7469 6e67 206c 6f67   an existing log
+000046e0: 2077 6974 6820 7468 6520 7361 6d65 2060   with the same `
+000046f0: 6075 6964 6060 206f 7220 746f 0a20 2020  `uid`` or to.   
+00004700: 2020 2020 2020 2020 2063 7265 6174 6520           create 
+00004710: 6120 6e65 7720 6c6f 672e 2049 6620 7365  a new log. If se
+00004720: 7420 746f 2060 6046 616c 7365 6060 2c20  t to ``False``, 
+00004730: 616e 2065 7869 7374 696e 6720 6c6f 6720  an existing log 
+00004740: 7769 7468 2073 616d 6520 6060 7569 6460  with same ``uid`
+00004750: 6020 7769 6c6c 2062 6520 6f76 6572 7772  ` will be overwr
+00004760: 6974 7465 6e0a 2020 2020 2020 2020 2222  itten.        ""
+00004770: 220a 0a20 2020 2020 2020 2069 6620 6e6f  "..        if no
+00004780: 7420 626f 6479 3a0a 2020 2020 2020 2020  t body:.        
+00004790: 2020 2020 7265 7475 726e 0a0a 2020 2020      return..    
+000047a0: 2020 2020 7061 7468 203d 2073 656c 662e      path = self.
+000047b0: 5f70 6174 685f 6f66 2822 6c6f 6722 2c20  _path_of("log", 
+000047c0: 7072 6f6a 6563 742c 2075 6964 290a 2020  project, uid).  
+000047d0: 2020 2020 2020 7061 7261 6d73 203d 207b        params = {
+000047e0: 2261 7070 656e 6422 3a20 626f 6f6c 3273  "append": bool2s
+000047f0: 7472 2861 7070 656e 6429 7d0a 2020 2020  tr(append)}.    
+00004800: 2020 2020 6572 726f 7220 3d20 6622 7374      error = f"st
+00004810: 6f72 6520 6c6f 6720 7b70 726f 6a65 6374  ore log {project
+00004820: 7d2f 7b75 6964 7d22 0a20 2020 2020 2020  }/{uid}".       
+00004830: 2073 656c 662e 6170 695f 6361 6c6c 2822   self.api_call("
+00004840: 504f 5354 222c 2070 6174 682c 2065 7272  POST", path, err
+00004850: 6f72 2c20 7061 7261 6d73 2c20 626f 6479  or, params, body
+00004860: 290a 0a20 2020 2064 6566 2067 6574 5f6c  )..    def get_l
+00004870: 6f67 2873 656c 662c 2075 6964 2c20 7072  og(self, uid, pr
+00004880: 6f6a 6563 743d 2222 2c20 6f66 6673 6574  oject="", offset
+00004890: 3d30 2c20 7369 7a65 3d2d 3129 3a0a 2020  =0, size=-1):.  
+000048a0: 2020 2020 2020 2222 2252 6574 7269 6576        """Retriev
+000048b0: 6520 6120 6c6f 672e 0a0a 2020 2020 2020  e a log...      
+000048c0: 2020 3a70 6172 616d 2075 6964 3a20 4c6f    :param uid: Lo
+000048d0: 6720 756e 6971 7565 2049 440a 2020 2020  g unique ID.    
+000048e0: 2020 2020 3a70 6172 616d 2070 726f 6a65      :param proje
+000048f0: 6374 3a20 5072 6f6a 6563 7420 6e61 6d65  ct: Project name
+00004900: 2066 6f72 2077 6869 6368 2074 6865 206c   for which the l
+00004910: 6f67 2062 656c 6f6e 6773 0a20 2020 2020  og belongs.     
+00004920: 2020 203a 7061 7261 6d20 6f66 6673 6574     :param offset
+00004930: 3a20 5265 7472 6965 7665 2070 6172 7469  : Retrieve parti
+00004940: 616c 206c 6f67 2c20 6765 7420 7570 2074  al log, get up t
+00004950: 6f20 6060 7369 7a65 6060 2062 7974 6573  o ``size`` bytes
+00004960: 2073 7461 7274 696e 6720 6174 206f 6666   starting at off
+00004970: 7365 7420 6060 6f66 6673 6574 6060 0a20  set ``offset``. 
+00004980: 2020 2020 2020 2020 2020 2066 726f 6d20             from 
+00004990: 6265 6769 6e6e 696e 6720 6f66 206c 6f67  beginning of log
+000049a0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+000049b0: 7369 7a65 3a20 5365 6520 6060 6f66 6673  size: See ``offs
+000049c0: 6574 6060 2e20 4966 2073 6574 2074 6f20  et``. If set to 
+000049d0: 6060 2d31 6060 2028 7468 6520 6465 6661  ``-1`` (the defa
+000049e0: 756c 7429 2077 696c 6c20 7265 7472 6965  ult) will retrie
+000049f0: 7665 2061 6c6c 2064 6174 6120 746f 2065  ve all data to e
+00004a00: 6e64 206f 6620 6c6f 672e 0a20 2020 2020  nd of log..     
+00004a10: 2020 203a 7265 7475 726e 733a 2054 6865     :returns: The
+00004a20: 2066 6f6c 6c6f 7769 6e67 206f 626a 6563   following objec
+00004a30: 7473 3a0a 0a20 2020 2020 2020 2020 2020  ts:..           
+00004a40: 202d 2073 7461 7465 202d 2054 6865 2073   - state - The s
+00004a50: 7461 7465 206f 6620 7468 6520 7275 6e74  tate of the runt
+00004a60: 696d 6520 6f62 6a65 6374 2077 6869 6368  ime object which
+00004a70: 2067 656e 6572 6174 6573 2074 6869 7320   generates this 
+00004a80: 6c6f 672c 2069 6620 6974 2065 7869 7374  log, if it exist
+00004a90: 732e 2049 6e20 6361 7365 206e 6f20 6b6e  s. In case no kn
+00004aa0: 6f77 6e20 7374 6174 650a 2020 2020 2020  own state.      
+00004ab0: 2020 2020 2020 2020 6578 6973 7473 2c20          exists, 
+00004ac0: 7468 6973 2077 696c 6c20 6265 2060 6075  this will be ``u
+00004ad0: 6e6b 6e6f 776e 6060 2e0a 2020 2020 2020  nknown``..      
+00004ae0: 2020 2020 2020 2d20 636f 6e74 656e 7420        - content 
+00004af0: 2d20 5468 6520 6163 7475 616c 206c 6f67  - The actual log
+00004b00: 2063 6f6e 7465 6e74 2e0a 2020 2020 2020   content..      
+00004b10: 2020 2222 220a 0a20 2020 2020 2020 2070    """..        p
+00004b20: 6172 616d 7320 3d20 7b22 6f66 6673 6574  arams = {"offset
+00004b30: 223a 206f 6666 7365 742c 2022 7369 7a65  ": offset, "size
+00004b40: 223a 2073 697a 657d 0a20 2020 2020 2020  ": size}.       
+00004b50: 2070 6174 6820 3d20 7365 6c66 2e5f 7061   path = self._pa
+00004b60: 7468 5f6f 6628 226c 6f67 222c 2070 726f  th_of("log", pro
+00004b70: 6a65 6374 2c20 7569 6429 0a20 2020 2020  ject, uid).     
+00004b80: 2020 2065 7272 6f72 203d 2066 2267 6574     error = f"get
+00004b90: 206c 6f67 207b 7072 6f6a 6563 747d 2f7b   log {project}/{
+00004ba0: 7569 647d 220a 2020 2020 2020 2020 7265  uid}".        re
+00004bb0: 7370 203d 2073 656c 662e 6170 695f 6361  sp = self.api_ca
+00004bc0: 6c6c 2822 4745 5422 2c20 7061 7468 2c20  ll("GET", path, 
+00004bd0: 6572 726f 722c 2070 6172 616d 733d 7061  error, params=pa
+00004be0: 7261 6d73 290a 2020 2020 2020 2020 6966  rams).        if
+00004bf0: 2072 6573 702e 6865 6164 6572 733a 0a20   resp.headers:. 
+00004c00: 2020 2020 2020 2020 2020 2073 7461 7465             state
+00004c10: 203d 2072 6573 702e 6865 6164 6572 732e   = resp.headers.
+00004c20: 6765 7428 2278 2d6d 6c72 756e 2d72 756e  get("x-mlrun-run
+00004c30: 2d73 7461 7465 222c 2022 2229 0a20 2020  -state", "").   
+00004c40: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00004c50: 7374 6174 652e 6c6f 7765 7228 292c 2072  state.lower(), r
+00004c60: 6573 702e 636f 6e74 656e 740a 0a20 2020  esp.content..   
+00004c70: 2020 2020 2072 6574 7572 6e20 2275 6e6b       return "unk
+00004c80: 6e6f 776e 222c 2072 6573 702e 636f 6e74  nown", resp.cont
+00004c90: 656e 740a 0a20 2020 2064 6566 2077 6174  ent..    def wat
+00004ca0: 6368 5f6c 6f67 2873 656c 662c 2075 6964  ch_log(self, uid
+00004cb0: 2c20 7072 6f6a 6563 743d 2222 2c20 7761  , project="", wa
+00004cc0: 7463 683d 5472 7565 2c20 6f66 6673 6574  tch=True, offset
+00004cd0: 3d30 293a 0a20 2020 2020 2020 2022 2222  =0):.        """
+00004ce0: 5265 7472 6965 7665 206c 6f67 7320 6f66  Retrieve logs of
+00004cf0: 2061 2072 756e 6e69 6e67 2070 726f 6365   a running proce
+00004d00: 7373 2c20 616e 6420 7761 7463 6820 7468  ss, and watch th
+00004d10: 6520 7072 6f67 7265 7373 206f 6620 7468  e progress of th
+00004d20: 6520 6578 6563 7574 696f 6e20 756e 7469  e execution unti
+00004d30: 6c20 6974 2063 6f6d 706c 6574 6573 2e20  l it completes. 
+00004d40: 5468 6973 0a20 2020 2020 2020 206d 6574  This.        met
+00004d50: 686f 6420 7769 6c6c 2070 7269 6e74 206f  hod will print o
+00004d60: 7574 2074 6865 206c 6f67 7320 616e 6420  ut the logs and 
+00004d70: 636f 6e74 696e 7565 2074 6f20 7065 7269  continue to peri
+00004d80: 6f64 6963 616c 6c79 2070 6f6c 6c20 666f  odically poll fo
+00004d90: 722c 2061 6e64 2070 7269 6e74 2c20 6e65  r, and print, ne
+00004da0: 7720 6c6f 6773 2061 7320 6c6f 6e67 2061  w logs as long a
+00004db0: 7320 7468 650a 2020 2020 2020 2020 7374  s the.        st
+00004dc0: 6174 6520 6f66 2074 6865 2072 756e 7469  ate of the runti
+00004dd0: 6d65 2077 6869 6368 2067 656e 6572 6174  me which generat
+00004de0: 6573 2074 6869 7320 6c6f 6720 6973 2065  es this log is e
+00004df0: 6974 6865 7220 6060 7065 6e64 696e 6760  ither ``pending`
+00004e00: 6020 6f72 2060 6072 756e 6e69 6e67 6060  ` or ``running``
+00004e10: 2e0a 0a20 2020 2020 2020 203a 7061 7261  ...        :para
+00004e20: 6d20 7569 643a 2054 6865 2075 6964 206f  m uid: The uid o
+00004e30: 6620 7468 6520 6c6f 6720 6f62 6a65 6374  f the log object
+00004e40: 2074 6f20 7761 7463 682e 0a20 2020 2020   to watch..     
+00004e50: 2020 203a 7061 7261 6d20 7072 6f6a 6563     :param projec
+00004e60: 743a 2050 726f 6a65 6374 2074 6861 7420  t: Project that 
+00004e70: 7468 6520 6c6f 6720 6265 6c6f 6e67 7320  the log belongs 
+00004e80: 746f 2e0a 2020 2020 2020 2020 3a70 6172  to..        :par
+00004e90: 616d 2077 6174 6368 3a20 4966 2073 6574  am watch: If set
+00004ea0: 2074 6f20 6060 5472 7565 6060 2077 696c   to ``True`` wil
+00004eb0: 6c20 636f 6e74 696e 7565 2074 7261 636b  l continue track
+00004ec0: 696e 6720 7468 6520 6c6f 6720 6173 2064  ing the log as d
+00004ed0: 6573 6372 6962 6564 2061 626f 7665 2e20  escribed above. 
+00004ee0: 4f74 6865 7277 6973 6520 7468 6973 2066  Otherwise this f
+00004ef0: 756e 6374 696f 6e0a 2020 2020 2020 2020  unction.        
+00004f00: 2020 2020 6973 2070 7261 6374 6963 616c      is practical
+00004f10: 6c79 2065 7175 6976 616c 656e 7420 746f  ly equivalent to
+00004f20: 2074 6865 203a 7079 3a66 756e 633a 607e   the :py:func:`~
+00004f30: 6765 745f 6c6f 6760 2066 756e 6374 696f  get_log` functio
+00004f40: 6e2e 0a20 2020 2020 2020 203a 7061 7261  n..        :para
+00004f50: 6d20 6f66 6673 6574 3a20 4d69 6e69 6d61  m offset: Minima
+00004f60: 6c20 6f66 6673 6574 2069 6e20 7468 6520  l offset in the 
+00004f70: 6c6f 6720 746f 2077 6174 6368 2e0a 2020  log to watch..  
+00004f80: 2020 2020 2020 3a72 6574 7572 6e73 3a20        :returns: 
+00004f90: 5468 6520 6669 6e61 6c20 7374 6174 6520  The final state 
+00004fa0: 6f66 2074 6865 206c 6f67 2062 6569 6e67  of the log being
+00004fb0: 2077 6174 6368 6564 2e0a 2020 2020 2020   watched..      
+00004fc0: 2020 2222 220a 0a20 2020 2020 2020 2073    """..        s
+00004fd0: 7461 7465 2c20 7465 7874 203d 2073 656c  tate, text = sel
+00004fe0: 662e 6765 745f 6c6f 6728 7569 642c 2070  f.get_log(uid, p
+00004ff0: 726f 6a65 6374 2c20 6f66 6673 6574 3d6f  roject, offset=o
+00005000: 6666 7365 7429 0a20 2020 2020 2020 2069  ffset).        i
+00005010: 6620 7465 7874 3a0a 2020 2020 2020 2020  f text:.        
+00005020: 2020 2020 7072 696e 7428 7465 7874 2e64      print(text.d
+00005030: 6563 6f64 6528 6572 726f 7273 3d6d 6c72  ecode(errors=mlr
+00005040: 756e 2e6d 6c63 6f6e 662e 6874 7470 6462  un.mlconf.httpdb
+00005050: 2e6c 6f67 732e 6465 636f 6465 2e65 7272  .logs.decode.err
+00005060: 6f72 7329 290a 2020 2020 2020 2020 6966  ors)).        if
+00005070: 2077 6174 6368 3a0a 2020 2020 2020 2020   watch:.        
+00005080: 2020 2020 6e69 6c5f 7265 7370 203d 2030      nil_resp = 0
+00005090: 0a20 2020 2020 2020 2020 2020 2077 6869  .            whi
+000050a0: 6c65 2073 7461 7465 2069 6e20 5b22 7065  le state in ["pe
+000050b0: 6e64 696e 6722 2c20 2272 756e 6e69 6e67  nding", "running
+000050c0: 225d 3a0a 2020 2020 2020 2020 2020 2020  "]:.            
+000050d0: 2020 2020 6f66 6673 6574 202b 3d20 6c65      offset += le
+000050e0: 6e28 7465 7874 290a 2020 2020 2020 2020  n(text).        
+000050f0: 2020 2020 2020 2020 2320 6966 2077 6520          # if we 
+00005100: 6765 7420 3320 6e69 6c20 7265 7370 6f6e  get 3 nil respon
+00005110: 7365 7320 696e 2061 2072 6f77 2c20 696e  ses in a row, in
+00005120: 6372 6561 7365 2074 6865 2073 6c65 6570  crease the sleep
+00005130: 2074 696d 6520 746f 2031 3020 7365 636f   time to 10 seco
+00005140: 6e64 730a 2020 2020 2020 2020 2020 2020  nds.            
+00005150: 2020 2020 2320 544f 444f 3a20 7265 6661      # TODO: refa
+00005160: 6374 6f72 2074 6869 7320 746f 2075 7365  ctor this to use
+00005170: 2061 2063 6f6e 6469 7469 6f6e 616c 2062   a conditional b
+00005180: 6163 6b6f 6666 206d 6563 6861 6e69 736d  ackoff mechanism
+00005190: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000051a0: 2069 6620 6e69 6c5f 7265 7370 203c 2033   if nil_resp < 3
+000051b0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000051c0: 2020 2020 2020 7469 6d65 2e73 6c65 6570        time.sleep
+000051d0: 2869 6e74 286d 6c72 756e 2e6d 6c63 6f6e  (int(mlrun.mlcon
+000051e0: 662e 6874 7470 6462 2e6c 6f67 732e 7075  f.httpdb.logs.pu
+000051f0: 6c6c 5f6c 6f67 735f 6465 6661 756c 745f  ll_logs_default_
+00005200: 696e 7465 7276 616c 2929 0a20 2020 2020  interval)).     
+00005210: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00005220: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005230: 2020 2020 2074 696d 652e 736c 6565 7028       time.sleep(
+00005240: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005250: 2020 2020 2020 2020 2069 6e74 280a 2020           int(.  
+00005260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005270: 2020 2020 2020 2020 2020 6d6c 7275 6e2e            mlrun.
+00005280: 6d6c 636f 6e66 2e68 7474 7064 622e 6c6f  mlconf.httpdb.lo
+00005290: 6773 2e70 756c 6c5f 6c6f 6773 5f62 6163  gs.pull_logs_bac
+000052a0: 6b6f 6666 5f6e 6f5f 6c6f 6773 5f64 6566  koff_no_logs_def
+000052b0: 6175 6c74 5f69 6e74 6572 7661 6c0a 2020  ault_interval.  
+000052c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000052d0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+000052e0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+000052f0: 2020 2020 2020 2020 2020 2020 2020 7374                st
+00005300: 6174 652c 2074 6578 7420 3d20 7365 6c66  ate, text = self
+00005310: 2e67 6574 5f6c 6f67 2875 6964 2c20 7072  .get_log(uid, pr
+00005320: 6f6a 6563 742c 206f 6666 7365 743d 6f66  oject, offset=of
+00005330: 6673 6574 290a 2020 2020 2020 2020 2020  fset).          
+00005340: 2020 2020 2020 6966 2074 6578 743a 0a20        if text:. 
+00005350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005360: 2020 206e 696c 5f72 6573 7020 3d20 300a     nil_resp = 0.
+00005370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005380: 2020 2020 7072 696e 7428 0a20 2020 2020      print(.     
+00005390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000053a0: 2020 2074 6578 742e 6465 636f 6465 2865     text.decode(e
+000053b0: 7272 6f72 733d 6d6c 7275 6e2e 6d6c 636f  rrors=mlrun.mlco
+000053c0: 6e66 2e68 7474 7064 622e 6c6f 6773 2e64  nf.httpdb.logs.d
+000053d0: 6563 6f64 652e 6572 726f 7273 292c 0a20  ecode.errors),. 
+000053e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000053f0: 2020 2020 2020 2065 6e64 3d22 222c 0a20         end="",. 
+00005400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005410: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00005420: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00005430: 2020 2020 2020 2020 2020 2020 2020 206e                 n
+00005440: 696c 5f72 6573 7020 2b3d 2031 0a20 2020  il_resp += 1.   
+00005450: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00005460: 2020 2020 2020 206f 6666 7365 7420 2b3d         offset +=
+00005470: 206c 656e 2874 6578 7429 0a0a 2020 2020   len(text)..    
+00005480: 2020 2020 7265 7475 726e 2073 7461 7465      return state
+00005490: 2c20 6f66 6673 6574 0a0a 2020 2020 6465  , offset..    de
+000054a0: 6620 7374 6f72 655f 7275 6e28 7365 6c66  f store_run(self
+000054b0: 2c20 7374 7275 6374 2c20 7569 642c 2070  , struct, uid, p
+000054c0: 726f 6a65 6374 3d22 222c 2069 7465 723d  roject="", iter=
+000054d0: 3029 3a0a 2020 2020 2020 2020 2222 2253  0):.        """S
+000054e0: 746f 7265 2072 756e 2064 6574 6169 6c73  tore run details
+000054f0: 2069 6e20 7468 6520 4442 2e20 5468 6973   in the DB. This
+00005500: 206d 6574 686f 6420 6973 2075 7375 616c   method is usual
+00005510: 6c79 2063 616c 6c65 6420 6672 6f6d 2077  ly called from w
+00005520: 6974 6869 6e20 6f74 6865 7220 3a70 793a  ithin other :py:
+00005530: 6d6f 643a 606d 6c72 756e 6020 666c 6f77  mod:`mlrun` flow
+00005540: 730a 2020 2020 2020 2020 616e 6420 6e6f  s.        and no
+00005550: 7420 6361 6c6c 6564 2064 6972 6563 746c  t called directl
+00005560: 7920 6279 2074 6865 2075 7365 722e 2222  y by the user.""
+00005570: 220a 0a20 2020 2020 2020 2070 6174 6820  "..        path 
+00005580: 3d20 7365 6c66 2e5f 7061 7468 5f6f 6628  = self._path_of(
+00005590: 2272 756e 222c 2070 726f 6a65 6374 2c20  "run", project, 
+000055a0: 7569 6429 0a20 2020 2020 2020 2070 6172  uid).        par
+000055b0: 616d 7320 3d20 7b22 6974 6572 223a 2069  ams = {"iter": i
+000055c0: 7465 727d 0a20 2020 2020 2020 2065 7272  ter}.        err
+000055d0: 6f72 203d 2066 2273 746f 7265 2072 756e  or = f"store run
+000055e0: 207b 7072 6f6a 6563 747d 2f7b 7569 647d   {project}/{uid}
+000055f0: 220a 2020 2020 2020 2020 626f 6479 203d  ".        body =
+00005600: 205f 6173 5f6a 736f 6e28 7374 7275 6374   _as_json(struct
+00005610: 290a 2020 2020 2020 2020 7365 6c66 2e61  ).        self.a
+00005620: 7069 5f63 616c 6c28 2250 4f53 5422 2c20  pi_call("POST", 
+00005630: 7061 7468 2c20 6572 726f 722c 2070 6172  path, error, par
+00005640: 616d 733d 7061 7261 6d73 2c20 626f 6479  ams=params, body
+00005650: 3d62 6f64 7929 0a0a 2020 2020 6465 6620  =body)..    def 
+00005660: 7570 6461 7465 5f72 756e 2873 656c 662c  update_run(self,
+00005670: 2075 7064 6174 6573 3a20 6469 6374 2c20   updates: dict, 
+00005680: 7569 642c 2070 726f 6a65 6374 3d22 222c  uid, project="",
+00005690: 2069 7465 723d 3029 3a0a 2020 2020 2020   iter=0):.      
+000056a0: 2020 2222 2255 7064 6174 6520 7468 6520    """Update the 
+000056b0: 6465 7461 696c 7320 6f66 2061 2073 746f  details of a sto
+000056c0: 7265 6420 7275 6e20 696e 2074 6865 2044  red run in the D
+000056d0: 422e 2222 220a 0a20 2020 2020 2020 2070  B."""..        p
+000056e0: 6174 6820 3d20 7365 6c66 2e5f 7061 7468  ath = self._path
+000056f0: 5f6f 6628 2272 756e 222c 2070 726f 6a65  _of("run", proje
+00005700: 6374 2c20 7569 6429 0a20 2020 2020 2020  ct, uid).       
+00005710: 2070 6172 616d 7320 3d20 7b22 6974 6572   params = {"iter
+00005720: 223a 2069 7465 727d 0a20 2020 2020 2020  ": iter}.       
+00005730: 2065 7272 6f72 203d 2066 2275 7064 6174   error = f"updat
+00005740: 6520 7275 6e20 7b70 726f 6a65 6374 7d2f  e run {project}/
+00005750: 7b75 6964 7d22 0a20 2020 2020 2020 2062  {uid}".        b
+00005760: 6f64 7920 3d20 5f61 735f 6a73 6f6e 2875  ody = _as_json(u
+00005770: 7064 6174 6573 290a 2020 2020 2020 2020  pdates).        
+00005780: 7365 6c66 2e61 7069 5f63 616c 6c28 2250  self.api_call("P
+00005790: 4154 4348 222c 2070 6174 682c 2065 7272  ATCH", path, err
+000057a0: 6f72 2c20 7061 7261 6d73 3d70 6172 616d  or, params=param
+000057b0: 732c 2062 6f64 793d 626f 6479 290a 0a20  s, body=body).. 
+000057c0: 2020 2064 6566 2061 626f 7274 5f72 756e     def abort_run
+000057d0: 2873 656c 662c 2075 6964 2c20 7072 6f6a  (self, uid, proj
+000057e0: 6563 743d 2222 2c20 6974 6572 3d30 293a  ect="", iter=0):
+000057f0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00005800: 2020 2020 2041 626f 7274 2061 2072 756e       Abort a run
+00005810: 6e69 6e67 2072 756e 202d 2077 696c 6c20  ning run - will 
+00005820: 7265 6d6f 7665 2074 6865 2072 756e 2773  remove the run's
+00005830: 2072 756e 7469 6d65 2072 6573 6f75 7263   runtime resourc
+00005840: 6573 2061 6e64 206d 6172 6b20 6974 7320  es and mark its 
+00005850: 7374 6174 6520 6173 2061 626f 7274 6564  state as aborted
+00005860: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00005870: 2020 2020 2073 656c 662e 7570 6461 7465       self.update
+00005880: 5f72 756e 280a 2020 2020 2020 2020 2020  _run(.          
+00005890: 2020 7b22 7374 6174 7573 2e73 7461 7465    {"status.state
+000058a0: 223a 206d 6c72 756e 2e72 756e 7469 6d65  ": mlrun.runtime
+000058b0: 732e 636f 6e73 7461 6e74 732e 5275 6e53  s.constants.RunS
+000058c0: 7461 7465 732e 6162 6f72 7465 647d 2c0a  tates.aborted},.
+000058d0: 2020 2020 2020 2020 2020 2020 7569 642c              uid,
+000058e0: 0a20 2020 2020 2020 2020 2020 2070 726f  .            pro
+000058f0: 6a65 6374 2c0a 2020 2020 2020 2020 2020  ject,.          
+00005900: 2020 6974 6572 2c0a 2020 2020 2020 2020    iter,.        
+00005910: 290a 0a20 2020 2064 6566 2072 6561 645f  )..    def read_
+00005920: 7275 6e28 7365 6c66 2c20 7569 642c 2070  run(self, uid, p
+00005930: 726f 6a65 6374 3d22 222c 2069 7465 723d  roject="", iter=
+00005940: 3029 3a0a 2020 2020 2020 2020 2222 2252  0):.        """R
+00005950: 6561 6420 7468 6520 6465 7461 696c 7320  ead the details 
+00005960: 6f66 2061 2073 746f 7265 6420 7275 6e20  of a stored run 
+00005970: 6672 6f6d 2074 6865 2044 422e 0a0a 2020  from the DB...  
+00005980: 2020 2020 2020 3a70 6172 616d 2075 6964        :param uid
+00005990: 3a20 5468 6520 7275 6e27 7320 756e 6971  : The run's uniq
+000059a0: 7565 2049 442e 0a20 2020 2020 2020 203a  ue ID..        :
+000059b0: 7061 7261 6d20 7072 6f6a 6563 743a 2050  param project: P
+000059c0: 726f 6a65 6374 206e 616d 652e 0a20 2020  roject name..   
+000059d0: 2020 2020 203a 7061 7261 6d20 6974 6572       :param iter
+000059e0: 3a20 4974 6572 6174 696f 6e20 7769 7468  : Iteration with
+000059f0: 696e 2061 2073 7065 6369 6669 6320 6578  in a specific ex
+00005a00: 6563 7574 696f 6e2e 0a20 2020 2020 2020  ecution..       
+00005a10: 2022 2222 0a0a 2020 2020 2020 2020 7061   """..        pa
+00005a20: 7468 203d 2073 656c 662e 5f70 6174 685f  th = self._path_
+00005a30: 6f66 2822 7275 6e22 2c20 7072 6f6a 6563  of("run", projec
+00005a40: 742c 2075 6964 290a 2020 2020 2020 2020  t, uid).        
+00005a50: 7061 7261 6d73 203d 207b 2269 7465 7222  params = {"iter"
+00005a60: 3a20 6974 6572 7d0a 2020 2020 2020 2020  : iter}.        
+00005a70: 6572 726f 7220 3d20 6622 6765 7420 7275  error = f"get ru
+00005a80: 6e20 7b70 726f 6a65 6374 7d2f 7b75 6964  n {project}/{uid
+00005a90: 7d22 0a20 2020 2020 2020 2072 6573 7020  }".        resp 
+00005aa0: 3d20 7365 6c66 2e61 7069 5f63 616c 6c28  = self.api_call(
+00005ab0: 2247 4554 222c 2070 6174 682c 2065 7272  "GET", path, err
+00005ac0: 6f72 2c20 7061 7261 6d73 3d70 6172 616d  or, params=param
+00005ad0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+00005ae0: 6e20 7265 7370 2e6a 736f 6e28 295b 2264  n resp.json()["d
+00005af0: 6174 6122 5d0a 0a20 2020 2064 6566 2064  ata"]..    def d
+00005b00: 656c 5f72 756e 2873 656c 662c 2075 6964  el_run(self, uid
+00005b10: 2c20 7072 6f6a 6563 743d 2222 2c20 6974  , project="", it
+00005b20: 6572 3d30 293a 0a20 2020 2020 2020 2022  er=0):.        "
+00005b30: 2222 4465 6c65 7465 2064 6574 6169 6c73  ""Delete details
+00005b40: 206f 6620 6120 7370 6563 6966 6963 2072   of a specific r
+00005b50: 756e 2066 726f 6d20 4442 2e0a 0a20 2020  un from DB...   
+00005b60: 2020 2020 203a 7061 7261 6d20 7569 643a       :param uid:
+00005b70: 2055 6e69 7175 6520 4944 2066 6f72 2074   Unique ID for t
+00005b80: 6865 2073 7065 6369 6669 6320 7275 6e20  he specific run 
+00005b90: 746f 2064 656c 6574 652e 0a20 2020 2020  to delete..     
+00005ba0: 2020 203a 7061 7261 6d20 7072 6f6a 6563     :param projec
+00005bb0: 743a 2050 726f 6a65 6374 2074 6861 7420  t: Project that 
+00005bc0: 7468 6520 7275 6e20 6265 6c6f 6e67 7320  the run belongs 
+00005bd0: 746f 2e0a 2020 2020 2020 2020 3a70 6172  to..        :par
+00005be0: 616d 2069 7465 723a 2049 7465 7261 7469  am iter: Iterati
+00005bf0: 6f6e 2077 6974 6869 6e20 6120 7370 6563  on within a spec
+00005c00: 6966 6963 2074 6173 6b2e 0a20 2020 2020  ific task..     
+00005c10: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
+00005c20: 7061 7468 203d 2073 656c 662e 5f70 6174  path = self._pat
+00005c30: 685f 6f66 2822 7275 6e22 2c20 7072 6f6a  h_of("run", proj
+00005c40: 6563 742c 2075 6964 290a 2020 2020 2020  ect, uid).      
+00005c50: 2020 7061 7261 6d73 203d 207b 2269 7465    params = {"ite
+00005c60: 7222 3a20 6974 6572 7d0a 2020 2020 2020  r": iter}.      
+00005c70: 2020 6572 726f 7220 3d20 6622 6465 6c20    error = f"del 
+00005c80: 7275 6e20 7b70 726f 6a65 6374 7d2f 7b75  run {project}/{u
+00005c90: 6964 7d22 0a20 2020 2020 2020 2073 656c  id}".        sel
+00005ca0: 662e 6170 695f 6361 6c6c 2822 4445 4c45  f.api_call("DELE
+00005cb0: 5445 222c 2070 6174 682c 2065 7272 6f72  TE", path, error
+00005cc0: 2c20 7061 7261 6d73 3d70 6172 616d 7329  , params=params)
+00005cd0: 0a0a 2020 2020 6465 6620 6c69 7374 5f72  ..    def list_r
+00005ce0: 756e 7328 0a20 2020 2020 2020 2073 656c  uns(.        sel
+00005cf0: 662c 0a20 2020 2020 2020 206e 616d 653d  f,.        name=
+00005d00: 4e6f 6e65 2c0a 2020 2020 2020 2020 7569  None,.        ui
+00005d10: 643a 204f 7074 696f 6e61 6c5b 556e 696f  d: Optional[Unio
+00005d20: 6e5b 7374 722c 204c 6973 745b 7374 725d  n[str, List[str]
+00005d30: 5d5d 203d 204e 6f6e 652c 0a20 2020 2020  ]] = None,.     
+00005d40: 2020 2070 726f 6a65 6374 3d4e 6f6e 652c     project=None,
+00005d50: 0a20 2020 2020 2020 206c 6162 656c 733d  .        labels=
+00005d60: 4e6f 6e65 2c0a 2020 2020 2020 2020 7374  None,.        st
+00005d70: 6174 653d 4e6f 6e65 2c0a 2020 2020 2020  ate=None,.      
+00005d80: 2020 736f 7274 3d54 7275 652c 0a20 2020    sort=True,.   
+00005d90: 2020 2020 206c 6173 743d 302c 0a20 2020       last=0,.   
+00005da0: 2020 2020 2069 7465 723d 4661 6c73 652c       iter=False,
+00005db0: 0a20 2020 2020 2020 2073 7461 7274 5f74  .        start_t
+00005dc0: 696d 655f 6672 6f6d 3a20 6461 7465 7469  ime_from: dateti
+00005dd0: 6d65 203d 204e 6f6e 652c 0a20 2020 2020  me = None,.     
+00005de0: 2020 2073 7461 7274 5f74 696d 655f 746f     start_time_to
+00005df0: 3a20 6461 7465 7469 6d65 203d 204e 6f6e  : datetime = Non
+00005e00: 652c 0a20 2020 2020 2020 206c 6173 745f  e,.        last_
+00005e10: 7570 6461 7465 5f74 696d 655f 6672 6f6d  update_time_from
+00005e20: 3a20 6461 7465 7469 6d65 203d 204e 6f6e  : datetime = Non
+00005e30: 652c 0a20 2020 2020 2020 206c 6173 745f  e,.        last_
+00005e40: 7570 6461 7465 5f74 696d 655f 746f 3a20  update_time_to: 
+00005e50: 6461 7465 7469 6d65 203d 204e 6f6e 652c  datetime = None,
+00005e60: 0a20 2020 2020 2020 2070 6172 7469 7469  .        partiti
+00005e70: 6f6e 5f62 793a 2055 6e69 6f6e 5b73 6368  on_by: Union[sch
+00005e80: 656d 6173 2e52 756e 5061 7274 6974 696f  emas.RunPartitio
+00005e90: 6e42 7946 6965 6c64 2c20 7374 725d 203d  nByField, str] =
+00005ea0: 204e 6f6e 652c 0a20 2020 2020 2020 2072   None,.        r
+00005eb0: 6f77 735f 7065 725f 7061 7274 6974 696f  ows_per_partitio
+00005ec0: 6e3a 2069 6e74 203d 2031 2c0a 2020 2020  n: int = 1,.    
+00005ed0: 2020 2020 7061 7274 6974 696f 6e5f 736f      partition_so
+00005ee0: 7274 5f62 793a 2055 6e69 6f6e 5b73 6368  rt_by: Union[sch
+00005ef0: 656d 6173 2e53 6f72 7446 6965 6c64 2c20  emas.SortField, 
+00005f00: 7374 725d 203d 204e 6f6e 652c 0a20 2020  str] = None,.   
+00005f10: 2020 2020 2070 6172 7469 7469 6f6e 5f6f       partition_o
+00005f20: 7264 6572 3a20 556e 696f 6e5b 7363 6865  rder: Union[sche
+00005f30: 6d61 732e 4f72 6465 7254 7970 652c 2073  mas.OrderType, s
+00005f40: 7472 5d20 3d20 7363 6865 6d61 732e 4f72  tr] = schemas.Or
+00005f50: 6465 7254 7970 652e 6465 7363 2c0a 2020  derType.desc,.  
+00005f60: 2020 2020 2020 6d61 785f 7061 7274 6974        max_partit
+00005f70: 696f 6e73 3a20 696e 7420 3d20 302c 0a20  ions: int = 0,. 
+00005f80: 2020 2029 202d 3e20 5275 6e4c 6973 743a     ) -> RunList:
+00005f90: 0a20 2020 2020 2020 2022 2222 5265 7472  .        """Retr
+00005fa0: 6965 7665 2061 206c 6973 7420 6f66 2072  ieve a list of r
+00005fb0: 756e 732c 2066 696c 7465 7265 6420 6279  uns, filtered by
+00005fc0: 2076 6172 696f 7573 206f 7074 696f 6e73   various options
+00005fd0: 2e0a 2020 2020 2020 2020 4578 616d 706c  ..        Exampl
+00005fe0: 653a 3a0a 0a20 2020 2020 2020 2020 2020  e::..           
+00005ff0: 2072 756e 7320 3d20 6462 2e6c 6973 745f   runs = db.list_
+00006000: 7275 6e73 286e 616d 653d 2764 6f77 6e6c  runs(name='downl
+00006010: 6f61 6427 2c20 7072 6f6a 6563 743d 2769  oad', project='i
+00006020: 7269 7327 2c20 6c61 6265 6c73 3d27 6f77  ris', labels='ow
+00006030: 6e65 723d 6164 6d69 6e27 290a 2020 2020  ner=admin').    
+00006040: 2020 2020 2020 2020 2320 4966 2072 756e          # If run
+00006050: 6e69 6e67 2069 6e20 4a75 7079 7465 722c  ning in Jupyter,
+00006060: 2063 616e 2075 7365 2074 6865 202e 7368   can use the .sh
+00006070: 6f77 2829 2066 756e 6374 696f 6e20 746f  ow() function to
+00006080: 2064 6973 706c 6179 2074 6865 2072 6573   display the res
+00006090: 756c 7473 0a20 2020 2020 2020 2020 2020  ults.           
+000060a0: 2064 622e 6c69 7374 5f72 756e 7328 6e61   db.list_runs(na
+000060b0: 6d65 3d27 272c 2070 726f 6a65 6374 3d70  me='', project=p
+000060c0: 726f 6a65 6374 5f6e 616d 6529 2e73 686f  roject_name).sho
+000060d0: 7728 290a 0a0a 2020 2020 2020 2020 3a70  w()...        :p
+000060e0: 6172 616d 206e 616d 653a 204e 616d 6520  aram name: Name 
+000060f0: 6f66 2074 6865 2072 756e 2074 6f20 7265  of the run to re
+00006100: 7472 6965 7665 2e0a 2020 2020 2020 2020  trieve..        
+00006110: 3a70 6172 616d 2075 6964 3a20 556e 6971  :param uid: Uniq
+00006120: 7565 2049 4420 6f66 2074 6865 2072 756e  ue ID of the run
+00006130: 2c20 6f72 2061 206c 6973 7420 6f66 2072  , or a list of r
+00006140: 756e 2055 4944 732e 0a20 2020 2020 2020  un UIDs..       
+00006150: 203a 7061 7261 6d20 7072 6f6a 6563 743a   :param project:
+00006160: 2050 726f 6a65 6374 2074 6861 7420 7468   Project that th
+00006170: 6520 7275 6e73 2062 656c 6f6e 6773 2074  e runs belongs t
+00006180: 6f2e 0a20 2020 2020 2020 203a 7061 7261  o..        :para
+00006190: 6d20 6c61 6265 6c73 3a20 4c69 7374 2072  m labels: List r
+000061a0: 756e 7320 7468 6174 2068 6176 6520 6120  uns that have a 
+000061b0: 7370 6563 6966 6963 206c 6162 656c 2061  specific label a
+000061c0: 7373 6967 6e65 642e 2043 7572 7265 6e74  ssigned. Current
+000061d0: 6c79 206f 6e6c 7920 6120 7369 6e67 6c65  ly only a single
+000061e0: 206c 6162 656c 2066 696c 7465 7220 6361   label filter ca
+000061f0: 6e20 6265 0a20 2020 2020 2020 2020 2020  n be.           
+00006200: 2061 7070 6c69 6564 2c20 6f74 6865 7277   applied, otherw
+00006210: 6973 6520 7265 7375 6c74 2077 696c 6c20  ise result will 
+00006220: 6265 2065 6d70 7479 2e0a 2020 2020 2020  be empty..      
+00006230: 2020 3a70 6172 616d 2073 7461 7465 3a20    :param state: 
+00006240: 4c69 7374 206f 6e6c 7920 7275 6e73 2077  List only runs w
+00006250: 686f 7365 2073 7461 7465 2069 7320 7370  hose state is sp
+00006260: 6563 6966 6965 642e 0a20 2020 2020 2020  ecified..       
+00006270: 203a 7061 7261 6d20 736f 7274 3a20 5768   :param sort: Wh
+00006280: 6574 6865 7220 746f 2073 6f72 7420 7468  ether to sort th
+00006290: 6520 7265 7375 6c74 2061 6363 6f72 6469  e result accordi
+000062a0: 6e67 2074 6f20 7468 6569 7220 7374 6172  ng to their star
+000062b0: 7420 7469 6d65 2e20 4f74 6865 7277 6973  t time. Otherwis
+000062c0: 652c 2072 6573 756c 7473 2077 696c 6c20  e, results will 
+000062d0: 6265 0a20 2020 2020 2020 2020 2020 2072  be.            r
+000062e0: 6574 7572 6e65 6420 6279 2074 6865 6972  eturned by their
+000062f0: 2069 6e74 6572 6e61 6c20 6f72 6465 7220   internal order 
+00006300: 696e 2074 6865 2044 4220 286f 7264 6572  in the DB (order
+00006310: 2077 696c 6c20 6e6f 7420 6265 2067 7561   will not be gua
+00006320: 7261 6e74 6565 6429 2e0a 2020 2020 2020  ranteed)..      
+00006330: 2020 3a70 6172 616d 206c 6173 743a 2044    :param last: D
+00006340: 6570 7265 6361 7465 6420 2d20 6375 7272  eprecated - curr
+00006350: 656e 746c 7920 6e6f 7420 7573 6564 2e0a  ently not used..
+00006360: 2020 2020 2020 2020 3a70 6172 616d 2069          :param i
+00006370: 7465 723a 2049 6620 6060 5472 7565 6060  ter: If ``True``
+00006380: 2072 6574 7572 6e20 7275 6e73 2066 726f   return runs fro
+00006390: 6d20 616c 6c20 6974 6572 6174 696f 6e73  m all iterations
+000063a0: 2e20 4f74 6865 7277 6973 652c 2072 6574  . Otherwise, ret
+000063b0: 7572 6e20 6f6e 6c79 2072 756e 7320 7768  urn only runs wh
+000063c0: 6f73 6520 6060 6974 6572 6060 2069 7320  ose ``iter`` is 
+000063d0: 302e 0a20 2020 2020 2020 203a 7061 7261  0..        :para
+000063e0: 6d20 7374 6172 745f 7469 6d65 5f66 726f  m start_time_fro
+000063f0: 6d3a 2046 696c 7465 7220 6279 2072 756e  m: Filter by run
+00006400: 2073 7461 7274 2074 696d 6520 696e 2060   start time in `
+00006410: 605b 7374 6172 745f 7469 6d65 5f66 726f  `[start_time_fro
+00006420: 6d2c 2073 7461 7274 5f74 696d 655f 746f  m, start_time_to
+00006430: 5d60 602e 0a20 2020 2020 2020 203a 7061  ]``..        :pa
+00006440: 7261 6d20 7374 6172 745f 7469 6d65 5f74  ram start_time_t
+00006450: 6f3a 2046 696c 7465 7220 6279 2072 756e  o: Filter by run
+00006460: 2073 7461 7274 2074 696d 6520 696e 2060   start time in `
+00006470: 605b 7374 6172 745f 7469 6d65 5f66 726f  `[start_time_fro
+00006480: 6d2c 2073 7461 7274 5f74 696d 655f 746f  m, start_time_to
+00006490: 5d60 602e 0a20 2020 2020 2020 203a 7061  ]``..        :pa
+000064a0: 7261 6d20 6c61 7374 5f75 7064 6174 655f  ram last_update_
+000064b0: 7469 6d65 5f66 726f 6d3a 2046 696c 7465  time_from: Filte
+000064c0: 7220 6279 2072 756e 206c 6173 7420 7570  r by run last up
+000064d0: 6461 7465 2074 696d 6520 696e 2060 6028  date time in ``(
+000064e0: 6c61 7374 5f75 7064 6174 655f 7469 6d65  last_update_time
+000064f0: 5f66 726f 6d2c 0a20 2020 2020 2020 2020  _from,.         
+00006500: 2020 206c 6173 745f 7570 6461 7465 5f74     last_update_t
+00006510: 696d 655f 746f 2960 602e 0a20 2020 2020  ime_to)``..     
+00006520: 2020 203a 7061 7261 6d20 6c61 7374 5f75     :param last_u
+00006530: 7064 6174 655f 7469 6d65 5f74 6f3a 2046  pdate_time_to: F
+00006540: 696c 7465 7220 6279 2072 756e 206c 6173  ilter by run las
+00006550: 7420 7570 6461 7465 2074 696d 6520 696e  t update time in
+00006560: 2060 6028 6c61 7374 5f75 7064 6174 655f   ``(last_update_
+00006570: 7469 6d65 5f66 726f 6d2c 206c 6173 745f  time_from, last_
+00006580: 7570 6461 7465 5f74 696d 655f 746f 2960  update_time_to)`
+00006590: 602e 0a20 2020 2020 2020 203a 7061 7261  `..        :para
+000065a0: 6d20 7061 7274 6974 696f 6e5f 6279 3a20  m partition_by: 
+000065b0: 4669 656c 6420 746f 2067 726f 7570 2072  Field to group r
+000065c0: 6573 756c 7473 2062 792e 204f 6e6c 7920  esults by. Only 
+000065d0: 616c 6c6f 7765 6420 7661 6c75 6520 6973  allowed value is
+000065e0: 2060 6e61 6d65 602e 2057 6865 6e20 6070   `name`. When `p
+000065f0: 6172 7469 7469 6f6e 5f62 7960 2069 7320  artition_by` is 
+00006600: 7370 6563 6966 6965 642c 0a20 2020 2020  specified,.     
+00006610: 2020 2020 2020 2074 6865 2060 7061 7274         the `part
+00006620: 6974 696f 6e5f 736f 7274 5f62 7960 2070  ition_sort_by` p
+00006630: 6172 616d 6574 6572 206d 7573 7420 6265  arameter must be
+00006640: 2070 726f 7669 6465 6420 6173 2077 656c   provided as wel
+00006650: 6c2e 0a20 2020 2020 2020 203a 7061 7261  l..        :para
+00006660: 6d20 726f 7773 5f70 6572 5f70 6172 7469  m rows_per_parti
+00006670: 7469 6f6e 3a20 486f 7720 6d61 6e79 2074  tion: How many t
+00006680: 6f70 2072 6f77 7320 2870 6572 2073 6f72  op rows (per sor
+00006690: 7469 6e67 2064 6566 696e 6564 2062 7920  ting defined by 
+000066a0: 6070 6172 7469 7469 6f6e 5f73 6f72 745f  `partition_sort_
+000066b0: 6279 6020 616e 6420 6070 6172 7469 7469  by` and `partiti
+000066c0: 6f6e 5f6f 7264 6572 6029 0a20 2020 2020  on_order`).     
+000066d0: 2020 2020 2020 2074 6f20 7265 7475 726e         to return
+000066e0: 2070 6572 2067 726f 7570 2e20 4465 6661   per group. Defa
+000066f0: 756c 7420 7661 6c75 6520 6973 2031 2e0a  ult value is 1..
+00006700: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
+00006710: 6172 7469 7469 6f6e 5f73 6f72 745f 6279  artition_sort_by
+00006720: 3a20 5768 6174 2066 6965 6c64 2074 6f20  : What field to 
+00006730: 736f 7274 2074 6865 2072 6573 756c 7473  sort the results
+00006740: 2062 792c 2077 6974 6869 6e20 6561 6368   by, within each
+00006750: 2070 6172 7469 7469 6f6e 2064 6566 696e   partition defin
+00006760: 6564 2062 7920 6070 6172 7469 7469 6f6e  ed by `partition
+00006770: 5f62 7960 2e0a 2020 2020 2020 2020 2020  _by`..          
+00006780: 2020 4375 7272 656e 746c 7920 7468 6520    Currently the 
+00006790: 6f6e 6c79 2061 6c6c 6f77 6564 2076 616c  only allowed val
+000067a0: 7565 7320 6172 6520 6063 7265 6174 6564  ues are `created
+000067b0: 6020 616e 6420 6075 7064 6174 6564 602e  ` and `updated`.
+000067c0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+000067d0: 7061 7274 6974 696f 6e5f 6f72 6465 723a  partition_order:
+000067e0: 204f 7264 6572 206f 6620 736f 7274 696e   Order of sortin
+000067f0: 6720 7769 7468 696e 2070 6172 7469 7469  g within partiti
+00006800: 6f6e 7320 2d20 6061 7363 6020 6f72 2060  ons - `asc` or `
+00006810: 6465 7363 602e 2044 6566 6175 6c74 2069  desc`. Default i
+00006820: 7320 6064 6573 6360 2e0a 2020 2020 2020  s `desc`..      
+00006830: 2020 3a70 6172 616d 206d 6178 5f70 6172    :param max_par
+00006840: 7469 7469 6f6e 733a 204d 6178 696d 616c  titions: Maximal
+00006850: 206e 756d 6265 7220 6f66 2070 6172 7469   number of parti
+00006860: 7469 6f6e 7320 746f 2069 6e63 6c75 6465  tions to include
+00006870: 2069 6e20 7468 6520 7265 7375 6c74 2e20   in the result. 
+00006880: 4465 6661 756c 7420 6973 2060 3060 2077  Default is `0` w
+00006890: 6869 6368 206d 6561 6e73 206e 6f0a 2020  hich means no.  
+000068a0: 2020 2020 2020 2020 2020 6c69 6d69 742e            limit.
+000068b0: 0a20 2020 2020 2020 2022 2222 0a0a 2020  .        """..  
+000068c0: 2020 2020 2020 7072 6f6a 6563 7420 3d20        project = 
+000068d0: 7072 6f6a 6563 7420 6f72 2063 6f6e 6669  project or confi
+000068e0: 672e 6465 6661 756c 745f 7072 6f6a 6563  g.default_projec
+000068f0: 740a 2020 2020 2020 2020 7061 7261 6d73  t.        params
+00006900: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
+00006910: 2022 6e61 6d65 223a 206e 616d 652c 0a20   "name": name,. 
+00006920: 2020 2020 2020 2020 2020 2022 7569 6422             "uid"
+00006930: 3a20 7569 642c 0a20 2020 2020 2020 2020  : uid,.         
+00006940: 2020 2022 7072 6f6a 6563 7422 3a20 7072     "project": pr
+00006950: 6f6a 6563 742c 0a20 2020 2020 2020 2020  oject,.         
+00006960: 2020 2022 6c61 6265 6c22 3a20 6c61 6265     "label": labe
+00006970: 6c73 206f 7220 5b5d 2c0a 2020 2020 2020  ls or [],.      
+00006980: 2020 2020 2020 2273 7461 7465 223a 2073        "state": s
+00006990: 7461 7465 2c0a 2020 2020 2020 2020 2020  tate,.          
+000069a0: 2020 2273 6f72 7422 3a20 626f 6f6c 3273    "sort": bool2s
+000069b0: 7472 2873 6f72 7429 2c0a 2020 2020 2020  tr(sort),.      
+000069c0: 2020 2020 2020 2269 7465 7222 3a20 626f        "iter": bo
+000069d0: 6f6c 3273 7472 2869 7465 7229 2c0a 2020  ol2str(iter),.  
+000069e0: 2020 2020 2020 2020 2020 2273 7461 7274            "start
+000069f0: 5f74 696d 655f 6672 6f6d 223a 2064 6174  _time_from": dat
+00006a00: 6574 696d 655f 746f 5f69 736f 2873 7461  etime_to_iso(sta
+00006a10: 7274 5f74 696d 655f 6672 6f6d 292c 0a20  rt_time_from),. 
+00006a20: 2020 2020 2020 2020 2020 2022 7374 6172             "star
+00006a30: 745f 7469 6d65 5f74 6f22 3a20 6461 7465  t_time_to": date
+00006a40: 7469 6d65 5f74 6f5f 6973 6f28 7374 6172  time_to_iso(star
+00006a50: 745f 7469 6d65 5f74 6f29 2c0a 2020 2020  t_time_to),.    
+00006a60: 2020 2020 2020 2020 226c 6173 745f 7570          "last_up
+00006a70: 6461 7465 5f74 696d 655f 6672 6f6d 223a  date_time_from":
+00006a80: 2064 6174 6574 696d 655f 746f 5f69 736f   datetime_to_iso
+00006a90: 286c 6173 745f 7570 6461 7465 5f74 696d  (last_update_tim
+00006aa0: 655f 6672 6f6d 292c 0a20 2020 2020 2020  e_from),.       
+00006ab0: 2020 2020 2022 6c61 7374 5f75 7064 6174       "last_updat
+00006ac0: 655f 7469 6d65 5f74 6f22 3a20 6461 7465  e_time_to": date
+00006ad0: 7469 6d65 5f74 6f5f 6973 6f28 6c61 7374  time_to_iso(last
+00006ae0: 5f75 7064 6174 655f 7469 6d65 5f74 6f29  _update_time_to)
+00006af0: 2c0a 2020 2020 2020 2020 7d0a 0a20 2020  ,.        }..   
+00006b00: 2020 2020 2069 6620 7061 7274 6974 696f       if partitio
+00006b10: 6e5f 6279 3a0a 2020 2020 2020 2020 2020  n_by:.          
+00006b20: 2020 7061 7261 6d73 2e75 7064 6174 6528    params.update(
+00006b30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006b40: 2073 656c 662e 5f67 656e 6572 6174 655f   self._generate_
+00006b50: 7061 7274 6974 696f 6e5f 6279 5f70 6172  partition_by_par
+00006b60: 616d 7328 0a20 2020 2020 2020 2020 2020  ams(.           
+00006b70: 2020 2020 2020 2020 2073 6368 656d 6173           schemas
+00006b80: 2e52 756e 5061 7274 6974 696f 6e42 7946  .RunPartitionByF
+00006b90: 6965 6c64 2c0a 2020 2020 2020 2020 2020  ield,.          
+00006ba0: 2020 2020 2020 2020 2020 7061 7274 6974            partit
+00006bb0: 696f 6e5f 6279 2c0a 2020 2020 2020 2020  ion_by,.        
+00006bc0: 2020 2020 2020 2020 2020 2020 726f 7773              rows
+00006bd0: 5f70 6572 5f70 6172 7469 7469 6f6e 2c0a  _per_partition,.
+00006be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006bf0: 2020 2020 7061 7274 6974 696f 6e5f 736f      partition_so
+00006c00: 7274 5f62 792c 0a20 2020 2020 2020 2020  rt_by,.         
+00006c10: 2020 2020 2020 2020 2020 2070 6172 7469             parti
+00006c20: 7469 6f6e 5f6f 7264 6572 2c0a 2020 2020  tion_order,.    
+00006c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006c40: 6d61 785f 7061 7274 6974 696f 6e73 2c0a  max_partitions,.
+00006c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006c60: 290a 2020 2020 2020 2020 2020 2020 290a  ).            ).
+00006c70: 2020 2020 2020 2020 6572 726f 7220 3d20          error = 
+00006c80: 226c 6973 7420 7275 6e73 220a 2020 2020  "list runs".    
+00006c90: 2020 2020 7265 7370 203d 2073 656c 662e      resp = self.
+00006ca0: 6170 695f 6361 6c6c 2822 4745 5422 2c20  api_call("GET", 
+00006cb0: 2272 756e 7322 2c20 6572 726f 722c 2070  "runs", error, p
+00006cc0: 6172 616d 733d 7061 7261 6d73 290a 2020  arams=params).  
+00006cd0: 2020 2020 2020 7265 7475 726e 2052 756e        return Run
+00006ce0: 4c69 7374 2872 6573 702e 6a73 6f6e 2829  List(resp.json()
+00006cf0: 5b22 7275 6e73 225d 290a 0a20 2020 2064  ["runs"])..    d
+00006d00: 6566 2064 656c 5f72 756e 7328 7365 6c66  ef del_runs(self
+00006d10: 2c20 6e61 6d65 3d4e 6f6e 652c 2070 726f  , name=None, pro
+00006d20: 6a65 6374 3d4e 6f6e 652c 206c 6162 656c  ject=None, label
+00006d30: 733d 4e6f 6e65 2c20 7374 6174 653d 4e6f  s=None, state=No
+00006d40: 6e65 2c20 6461 7973 5f61 676f 3d30 293a  ne, days_ago=0):
+00006d50: 0a20 2020 2020 2020 2022 2222 4465 6c65  .        """Dele
+00006d60: 7465 2061 2067 726f 7570 206f 6620 7275  te a group of ru
+00006d70: 6e73 2069 6465 6e74 6966 6965 6420 6279  ns identified by
+00006d80: 2074 6865 2070 6172 616d 6574 6572 7320   the parameters 
+00006d90: 6f66 2074 6865 2066 756e 6374 696f 6e2e  of the function.
+00006da0: 0a0a 2020 2020 2020 2020 4578 616d 706c  ..        Exampl
+00006db0: 653a 3a0a 0a20 2020 2020 2020 2020 2020  e::..           
+00006dc0: 2064 622e 6465 6c5f 7275 6e73 2873 7461   db.del_runs(sta
+00006dd0: 7465 3d27 636f 6d70 6c65 7465 6427 290a  te='completed').
+00006de0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00006df0: 6e61 6d65 3a20 4e61 6d65 206f 6620 7468  name: Name of th
+00006e00: 6520 7461 736b 2077 6869 6368 2074 6865  e task which the
+00006e10: 2072 756e 7320 6265 6c6f 6e67 2074 6f2e   runs belong to.
+00006e20: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00006e30: 7072 6f6a 6563 743a 2050 726f 6a65 6374  project: Project
+00006e40: 2074 6f20 7768 6963 6820 7468 6520 7275   to which the ru
+00006e50: 6e73 2062 656c 6f6e 672e 0a20 2020 2020  ns belong..     
+00006e60: 2020 203a 7061 7261 6d20 6c61 6265 6c73     :param labels
+00006e70: 3a20 4669 6c74 6572 2072 756e 7320 7468  : Filter runs th
+00006e80: 6174 2061 7265 206c 6162 656c 6564 2075  at are labeled u
+00006e90: 7369 6e67 2074 6865 7365 2073 7065 6369  sing these speci
+00006ea0: 6669 6320 6c61 6265 6c20 7661 6c75 6573  fic label values
+00006eb0: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+00006ec0: 2073 7461 7465 3a20 4669 6c74 6572 206f   state: Filter o
+00006ed0: 6e6c 7920 7275 6e73 2077 6869 6368 2061  nly runs which a
+00006ee0: 7265 2069 6e20 7468 6973 2073 7461 7465  re in this state
+00006ef0: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+00006f00: 2064 6179 735f 6167 6f3a 2046 696c 7465   days_ago: Filte
+00006f10: 7220 7275 6e73 2077 686f 7365 2073 7461  r runs whose sta
+00006f20: 7274 2074 696d 6520 6973 206e 6577 6572  rt time is newer
+00006f30: 2074 6861 6e20 7468 6973 2070 6172 616d   than this param
+00006f40: 6574 6572 2e0a 2020 2020 2020 2020 2222  eter..        ""
+00006f50: 220a 0a20 2020 2020 2020 2070 726f 6a65  "..        proje
+00006f60: 6374 203d 2070 726f 6a65 6374 206f 7220  ct = project or 
+00006f70: 636f 6e66 6967 2e64 6566 6175 6c74 5f70  config.default_p
+00006f80: 726f 6a65 6374 0a20 2020 2020 2020 2070  roject.        p
+00006f90: 6172 616d 7320 3d20 7b0a 2020 2020 2020  arams = {.      
+00006fa0: 2020 2020 2020 226e 616d 6522 3a20 6e61        "name": na
+00006fb0: 6d65 2c0a 2020 2020 2020 2020 2020 2020  me,.            
+00006fc0: 2270 726f 6a65 6374 223a 2070 726f 6a65  "project": proje
+00006fd0: 6374 2c0a 2020 2020 2020 2020 2020 2020  ct,.            
+00006fe0: 226c 6162 656c 223a 206c 6162 656c 7320  "label": labels 
+00006ff0: 6f72 205b 5d2c 0a20 2020 2020 2020 2020  or [],.         
+00007000: 2020 2022 7374 6174 6522 3a20 7374 6174     "state": stat
+00007010: 652c 0a20 2020 2020 2020 2020 2020 2022  e,.            "
+00007020: 6461 7973 5f61 676f 223a 2073 7472 2864  days_ago": str(d
+00007030: 6179 735f 6167 6f29 2c0a 2020 2020 2020  ays_ago),.      
+00007040: 2020 7d0a 2020 2020 2020 2020 6572 726f    }.        erro
+00007050: 7220 3d20 2264 656c 2072 756e 7322 0a20  r = "del runs". 
+00007060: 2020 2020 2020 2073 656c 662e 6170 695f         self.api_
+00007070: 6361 6c6c 2822 4445 4c45 5445 222c 2022  call("DELETE", "
+00007080: 7275 6e73 222c 2065 7272 6f72 2c20 7061  runs", error, pa
+00007090: 7261 6d73 3d70 6172 616d 7329 0a0a 2020  rams=params)..  
+000070a0: 2020 6465 6620 7374 6f72 655f 6172 7469    def store_arti
+000070b0: 6661 6374 2873 656c 662c 206b 6579 2c20  fact(self, key, 
+000070c0: 6172 7469 6661 6374 2c20 7569 642c 2069  artifact, uid, i
+000070d0: 7465 723d 4e6f 6e65 2c20 7461 673d 4e6f  ter=None, tag=No
+000070e0: 6e65 2c20 7072 6f6a 6563 743d 2222 293a  ne, project=""):
+000070f0: 0a20 2020 2020 2020 2022 2222 5374 6f72  .        """Stor
+00007100: 6520 616e 2061 7274 6966 6163 7420 696e  e an artifact in
+00007110: 2074 6865 2044 422e 0a0a 2020 2020 2020   the DB...      
+00007120: 2020 3a70 6172 616d 206b 6579 3a20 4964    :param key: Id
+00007130: 656e 7469 6679 696e 6720 6b65 7920 6f66  entifying key of
+00007140: 2074 6865 2061 7274 6966 6163 742e 0a20   the artifact.. 
+00007150: 2020 2020 2020 203a 7061 7261 6d20 6172         :param ar
+00007160: 7469 6661 6374 3a20 5468 6520 6163 7475  tifact: The actu
+00007170: 616c 2061 7274 6966 6163 7420 746f 2073  al artifact to s
+00007180: 746f 7265 2e0a 2020 2020 2020 2020 3a70  tore..        :p
+00007190: 6172 616d 2075 6964 3a20 4120 756e 6971  aram uid: A uniq
+000071a0: 7565 2049 4420 666f 7220 7468 6973 2073  ue ID for this s
+000071b0: 7065 6369 6669 6320 7665 7273 696f 6e20  pecific version 
+000071c0: 6f66 2074 6865 2061 7274 6966 6163 742e  of the artifact.
+000071d0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+000071e0: 6974 6572 3a20 5468 6520 7461 736b 2069  iter: The task i
+000071f0: 7465 7261 7469 6f6e 2077 6869 6368 2067  teration which g
+00007200: 656e 6572 6174 6564 2074 6869 7320 6172  enerated this ar
+00007210: 7469 6661 6374 2e20 4966 2060 6069 7465  tifact. If ``ite
+00007220: 7260 6020 6973 206e 6f74 2060 604e 6f6e  r`` is not ``Non
+00007230: 6560 6020 7468 6520 6974 6572 6174 696f  e`` the iteratio
+00007240: 6e20 7769 6c6c 0a20 2020 2020 2020 2020  n will.         
+00007250: 2020 2062 6520 6164 6465 6420 746f 2074     be added to t
+00007260: 6865 206b 6579 2070 726f 7669 6465 6420  he key provided 
+00007270: 746f 2067 656e 6572 6174 6520 6120 756e  to generate a un
+00007280: 6971 7565 206b 6579 2066 6f72 2074 6865  ique key for the
+00007290: 2061 7274 6966 6163 7420 6f66 2074 6865   artifact of the
+000072a0: 2073 7065 6369 6669 6320 6974 6572 6174   specific iterat
+000072b0: 696f 6e2e 0a20 2020 2020 2020 203a 7061  ion..        :pa
+000072c0: 7261 6d20 7461 673a 2054 6167 206f 6620  ram tag: Tag of 
+000072d0: 7468 6520 6172 7469 6661 6374 2e0a 2020  the artifact..  
+000072e0: 2020 2020 2020 3a70 6172 616d 2070 726f        :param pro
+000072f0: 6a65 6374 3a20 5072 6f6a 6563 7420 7468  ject: Project th
+00007300: 6174 2074 6865 2061 7274 6966 6163 7420  at the artifact 
+00007310: 6265 6c6f 6e67 7320 746f 2e0a 2020 2020  belongs to..    
+00007320: 2020 2020 2222 220a 0a20 2020 2020 2020      """..       
+00007330: 2065 6e64 706f 696e 745f 7061 7468 203d   endpoint_path =
+00007340: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
+00007350: 6a65 6374 7d2f 6172 7469 6661 6374 732f  ject}/artifacts/
+00007360: 7b75 6964 7d2f 7b6b 6579 7d22 0a20 2020  {uid}/{key}".   
+00007370: 2020 2020 2070 6172 616d 7320 3d20 7b0a       params = {.
+00007380: 2020 2020 2020 2020 2020 2020 2274 6167              "tag
+00007390: 223a 2074 6167 2c0a 2020 2020 2020 2020  ": tag,.        
+000073a0: 7d0a 2020 2020 2020 2020 6966 2069 7465  }.        if ite
+000073b0: 723a 0a20 2020 2020 2020 2020 2020 2070  r:.            p
+000073c0: 6172 616d 735b 2269 7465 7222 5d20 3d20  arams["iter"] = 
+000073d0: 7374 7228 6974 6572 290a 0a20 2020 2020  str(iter)..     
+000073e0: 2020 2065 7272 6f72 203d 2066 2273 746f     error = f"sto
+000073f0: 7265 2061 7274 6966 6163 7420 7b70 726f  re artifact {pro
+00007400: 6a65 6374 7d2f 7b75 6964 7d2f 7b6b 6579  ject}/{uid}/{key
+00007410: 7d22 0a0a 2020 2020 2020 2020 626f 6479  }"..        body
+00007420: 203d 205f 6173 5f6a 736f 6e28 6172 7469   = _as_json(arti
+00007430: 6661 6374 290a 2020 2020 2020 2020 7365  fact).        se
+00007440: 6c66 2e61 7069 5f63 616c 6c28 2250 4f53  lf.api_call("POS
+00007450: 5422 2c20 656e 6470 6f69 6e74 5f70 6174  T", endpoint_pat
+00007460: 682c 2065 7272 6f72 2c20 7061 7261 6d73  h, error, params
+00007470: 3d70 6172 616d 732c 2062 6f64 793d 626f  =params, body=bo
+00007480: 6479 290a 0a20 2020 2064 6566 2072 6561  dy)..    def rea
+00007490: 645f 6172 7469 6661 6374 2873 656c 662c  d_artifact(self,
+000074a0: 206b 6579 2c20 7461 673d 4e6f 6e65 2c20   key, tag=None, 
+000074b0: 6974 6572 3d4e 6f6e 652c 2070 726f 6a65  iter=None, proje
+000074c0: 6374 3d22 2229 3a0a 2020 2020 2020 2020  ct=""):.        
+000074d0: 2222 2252 6561 6420 616e 2061 7274 6966  """Read an artif
+000074e0: 6163 742c 2069 6465 6e74 6966 6965 6420  act, identified 
+000074f0: 6279 2069 7473 206b 6579 2c20 7461 6720  by its key, tag 
+00007500: 616e 6420 6974 6572 6174 696f 6e2e 2222  and iteration.""
+00007510: 220a 0a20 2020 2020 2020 2070 726f 6a65  "..        proje
+00007520: 6374 203d 2070 726f 6a65 6374 206f 7220  ct = project or 
+00007530: 636f 6e66 6967 2e64 6566 6175 6c74 5f70  config.default_p
+00007540: 726f 6a65 6374 0a20 2020 2020 2020 2074  roject.        t
+00007550: 6167 203d 2074 6167 206f 7220 226c 6174  ag = tag or "lat
+00007560: 6573 7422 0a20 2020 2020 2020 2065 6e64  est".        end
+00007570: 706f 696e 745f 7061 7468 203d 2066 2270  point_path = f"p
+00007580: 726f 6a65 6374 732f 7b70 726f 6a65 6374  rojects/{project
+00007590: 7d2f 6172 7469 6661 6374 732f 7b6b 6579  }/artifacts/{key
+000075a0: 7d3f 7461 673d 7b74 6167 7d22 0a20 2020  }?tag={tag}".   
+000075b0: 2020 2020 2065 7272 6f72 203d 2066 2272       error = f"r
+000075c0: 6561 6420 6172 7469 6661 6374 207b 7072  ead artifact {pr
+000075d0: 6f6a 6563 747d 2f7b 6b65 797d 220a 2020  oject}/{key}".  
+000075e0: 2020 2020 2020 2320 6578 706c 6963 6974        # explicit
+000075f0: 6c79 2073 6574 2061 7274 6966 6163 7473  ly set artifacts
+00007600: 2066 6f72 6d61 7420 746f 2027 6675 6c6c   format to 'full
+00007610: 2720 7369 6e63 6520 6f6c 6420 7365 7276  ' since old serv
+00007620: 6572 7320 6d61 7920 6465 6661 756c 7420  ers may default 
+00007630: 746f 2027 6c65 6761 6379 270a 2020 2020  to 'legacy'.    
+00007640: 2020 2020 7061 7261 6d73 203d 207b 2266      params = {"f
+00007650: 6f72 6d61 7422 3a20 7363 6865 6d61 732e  ormat": schemas.
+00007660: 4172 7469 6661 6374 7346 6f72 6d61 742e  ArtifactsFormat.
+00007670: 6675 6c6c 2e76 616c 7565 7d0a 2020 2020  full.value}.    
+00007680: 2020 2020 6966 2069 7465 723a 0a20 2020      if iter:.   
+00007690: 2020 2020 2020 2020 2070 6172 616d 735b           params[
+000076a0: 2269 7465 7222 5d20 3d20 7374 7228 6974  "iter"] = str(it
+000076b0: 6572 290a 2020 2020 2020 2020 7265 7370  er).        resp
+000076c0: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
+000076d0: 2822 4745 5422 2c20 656e 6470 6f69 6e74  ("GET", endpoint
+000076e0: 5f70 6174 682c 2065 7272 6f72 2c20 7061  _path, error, pa
+000076f0: 7261 6d73 3d70 6172 616d 7329 0a20 2020  rams=params).   
+00007700: 2020 2020 2072 6574 7572 6e20 7265 7370       return resp
+00007710: 2e6a 736f 6e28 295b 2264 6174 6122 5d0a  .json()["data"].
+00007720: 0a20 2020 2064 6566 2064 656c 5f61 7274  .    def del_art
+00007730: 6966 6163 7428 7365 6c66 2c20 6b65 792c  ifact(self, key,
+00007740: 2074 6167 3d4e 6f6e 652c 2070 726f 6a65   tag=None, proje
+00007750: 6374 3d22 2229 3a0a 2020 2020 2020 2020  ct=""):.        
+00007760: 2222 2244 656c 6574 6520 616e 2061 7274  """Delete an art
+00007770: 6966 6163 742e 2222 220a 0a20 2020 2020  ifact."""..     
+00007780: 2020 2065 6e64 706f 696e 745f 7061 7468     endpoint_path
+00007790: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
+000077a0: 726f 6a65 6374 7d2f 6172 7469 6661 6374  roject}/artifact
+000077b0: 732f 7b6b 6579 7d22 0a20 2020 2020 2020  s/{key}".       
+000077c0: 2070 6172 616d 7320 3d20 7b0a 2020 2020   params = {.    
+000077d0: 2020 2020 2020 2020 226b 6579 223a 206b          "key": k
+000077e0: 6579 2c0a 2020 2020 2020 2020 2020 2020  ey,.            
+000077f0: 2274 6167 223a 2074 6167 2c0a 2020 2020  "tag": tag,.    
+00007800: 2020 2020 7d0a 2020 2020 2020 2020 6572      }.        er
+00007810: 726f 7220 3d20 6622 6465 6c20 6172 7469  ror = f"del arti
+00007820: 6661 6374 207b 7072 6f6a 6563 747d 2f7b  fact {project}/{
+00007830: 6b65 797d 220a 2020 2020 2020 2020 7365  key}".        se
+00007840: 6c66 2e61 7069 5f63 616c 6c28 2244 454c  lf.api_call("DEL
+00007850: 4554 4522 2c20 656e 6470 6f69 6e74 5f70  ETE", endpoint_p
+00007860: 6174 682c 2065 7272 6f72 2c20 7061 7261  ath, error, para
+00007870: 6d73 3d70 6172 616d 7329 0a0a 2020 2020  ms=params)..    
+00007880: 6465 6620 6c69 7374 5f61 7274 6966 6163  def list_artifac
+00007890: 7473 280a 2020 2020 2020 2020 7365 6c66  ts(.        self
+000078a0: 2c0a 2020 2020 2020 2020 6e61 6d65 3d4e  ,.        name=N
+000078b0: 6f6e 652c 0a20 2020 2020 2020 2070 726f  one,.        pro
+000078c0: 6a65 6374 3d4e 6f6e 652c 0a20 2020 2020  ject=None,.     
+000078d0: 2020 2074 6167 3d4e 6f6e 652c 0a20 2020     tag=None,.   
+000078e0: 2020 2020 206c 6162 656c 733a 204f 7074       labels: Opt
+000078f0: 696f 6e61 6c5b 556e 696f 6e5b 4469 6374  ional[Union[Dict
+00007900: 5b73 7472 2c20 7374 725d 2c20 4c69 7374  [str, str], List
+00007910: 5b73 7472 5d5d 5d20 3d20 4e6f 6e65 2c0a  [str]]] = None,.
+00007920: 2020 2020 2020 2020 7369 6e63 653d 4e6f          since=No
+00007930: 6e65 2c0a 2020 2020 2020 2020 756e 7469  ne,.        unti
+00007940: 6c3d 4e6f 6e65 2c0a 2020 2020 2020 2020  l=None,.        
+00007950: 6974 6572 3a20 696e 7420 3d20 4e6f 6e65  iter: int = None
+00007960: 2c0a 2020 2020 2020 2020 6265 7374 5f69  ,.        best_i
+00007970: 7465 7261 7469 6f6e 3a20 626f 6f6c 203d  teration: bool =
+00007980: 2046 616c 7365 2c0a 2020 2020 2020 2020   False,.        
+00007990: 6b69 6e64 3a20 7374 7220 3d20 4e6f 6e65  kind: str = None
+000079a0: 2c0a 2020 2020 2020 2020 6361 7465 676f  ,.        catego
+000079b0: 7279 3a20 556e 696f 6e5b 7374 722c 2073  ry: Union[str, s
+000079c0: 6368 656d 6173 2e41 7274 6966 6163 7443  chemas.ArtifactC
+000079d0: 6174 6567 6f72 6965 735d 203d 204e 6f6e  ategories] = Non
+000079e0: 652c 0a20 2020 2029 202d 3e20 4172 7469  e,.    ) -> Arti
+000079f0: 6661 6374 4c69 7374 3a0a 2020 2020 2020  factList:.      
+00007a00: 2020 2222 224c 6973 7420 6172 7469 6661    """List artifa
+00007a10: 6374 7320 6669 6c74 6572 6564 2062 7920  cts filtered by 
+00007a20: 7661 7269 6f75 7320 7061 7261 6d65 7465  various paramete
+00007a30: 7273 2e0a 0a20 2020 2020 2020 2045 7861  rs...        Exa
+00007a40: 6d70 6c65 733a 3a0a 0a20 2020 2020 2020  mples::..       
+00007a50: 2020 2020 2023 2053 686f 7720 6c61 7465       # Show late
+00007a60: 7374 2076 6572 7369 6f6e 206f 6620 616c  st version of al
+00007a70: 6c20 6172 7469 6661 6374 7320 696e 2070  l artifacts in p
+00007a80: 726f 6a65 6374 0a20 2020 2020 2020 2020  roject.         
+00007a90: 2020 206c 6174 6573 745f 6172 7469 6661     latest_artifa
+00007aa0: 6374 7320 3d20 6462 2e6c 6973 745f 6172  cts = db.list_ar
+00007ab0: 7469 6661 6374 7328 2727 2c20 7461 673d  tifacts('', tag=
+00007ac0: 276c 6174 6573 7427 2c20 7072 6f6a 6563  'latest', projec
+00007ad0: 743d 2769 7269 7327 290a 2020 2020 2020  t='iris').      
+00007ae0: 2020 2020 2020 2320 6368 6563 6b20 6469        # check di
+00007af0: 6666 6572 656e 7420 6172 7469 6661 6374  fferent artifact
+00007b00: 2076 6572 7369 6f6e 7320 666f 7220 6120   versions for a 
+00007b10: 7370 6563 6966 6963 2061 7274 6966 6163  specific artifac
+00007b20: 740a 2020 2020 2020 2020 2020 2020 7265  t.            re
+00007b30: 7375 6c74 5f76 6572 7369 6f6e 7320 3d20  sult_versions = 
+00007b40: 6462 2e6c 6973 745f 6172 7469 6661 6374  db.list_artifact
+00007b50: 7328 2772 6573 756c 7473 272c 2074 6167  s('results', tag
+00007b60: 3d27 2a27 2c20 7072 6f6a 6563 743d 2769  ='*', project='i
+00007b70: 7269 7327 290a 2020 2020 2020 2020 2020  ris').          
+00007b80: 2020 2320 5368 6f77 2061 7274 6966 6163    # Show artifac
+00007b90: 7473 2077 6974 6820 6c61 6265 6c20 6669  ts with label fi
+00007ba0: 6c74 6572 7320 2d20 626f 7468 2075 706c  lters - both upl
+00007bb0: 6f61 6465 6420 616e 6420 6f66 2062 696e  oaded and of bin
+00007bc0: 6172 7920 7479 7065 0a20 2020 2020 2020  ary type.       
+00007bd0: 2020 2020 2072 6573 756c 745f 6c61 6265       result_labe
+00007be0: 6c73 203d 2064 622e 6c69 7374 5f61 7274  ls = db.list_art
+00007bf0: 6966 6163 7473 2827 7265 7375 6c74 7327  ifacts('results'
+00007c00: 2c20 7461 673d 272a 272c 2070 726f 6a65  , tag='*', proje
+00007c10: 6374 3d27 6972 6973 272c 206c 6162 656c  ct='iris', label
+00007c20: 733d 5b27 7570 6c6f 6164 6564 272c 2027  s=['uploaded', '
+00007c30: 7479 7065 3d62 696e 6172 7927 5d29 0a0a  type=binary'])..
+00007c40: 2020 2020 2020 2020 3a70 6172 616d 206e          :param n
+00007c50: 616d 653a 204e 616d 6520 6f66 2061 7274  ame: Name of art
+00007c60: 6966 6163 7473 2074 6f20 7265 7472 6965  ifacts to retrie
+00007c70: 7665 2e20 4e61 6d65 2069 7320 7573 6564  ve. Name is used
+00007c80: 2061 7320 6120 6c69 6b65 2071 7565 7279   as a like query
+00007c90: 2c20 616e 6420 6973 206e 6f74 2063 6173  , and is not cas
+00007ca0: 652d 7365 6e73 6974 6976 652e 2054 6869  e-sensitive. Thi
+00007cb0: 7320 6d65 616e 730a 2020 2020 2020 2020  s means.        
+00007cc0: 2020 2020 7468 6174 2071 7565 7279 696e      that queryin
+00007cd0: 6720 666f 7220 6060 6e61 6d65 6060 206d  g for ``name`` m
+00007ce0: 6179 2072 6574 7572 6e20 6172 7469 6661  ay return artifa
+00007cf0: 6374 7320 6e61 6d65 6420 6060 6d79 5f4e  cts named ``my_N
+00007d00: 616d 655f 3160 6020 6f72 2060 6073 7572  ame_1`` or ``sur
+00007d10: 6e61 6d65 6060 2e0a 2020 2020 2020 2020  name``..        
+00007d20: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
+00007d30: 5072 6f6a 6563 7420 6e61 6d65 2e0a 2020  Project name..  
+00007d40: 2020 2020 2020 3a70 6172 616d 2074 6167        :param tag
+00007d50: 3a20 5265 7475 726e 2061 7274 6966 6163  : Return artifac
+00007d60: 7473 2061 7373 6967 6e65 6420 7468 6973  ts assigned this
+00007d70: 2074 6167 2e0a 2020 2020 2020 2020 3a70   tag..        :p
+00007d80: 6172 616d 206c 6162 656c 733a 2052 6574  aram labels: Ret
+00007d90: 7572 6e20 6172 7469 6661 6374 7320 7468  urn artifacts th
+00007da0: 6174 2068 6176 6520 7468 6573 6520 6c61  at have these la
+00007db0: 6265 6c73 2e20 4c61 6265 6c73 2063 616e  bels. Labels can
+00007dc0: 2065 6974 6865 7220 6265 2061 2064 6963   either be a dic
+00007dd0: 7469 6f6e 6172 7920 7b22 6c61 6265 6c22  tionary {"label"
+00007de0: 3a20 2276 616c 7565 227d 206f 720a 2020  : "value"} or.  
+00007df0: 2020 2020 2020 2020 2020 6120 6c69 7374            a list
+00007e00: 206f 6620 226c 6162 656c 3d76 616c 7565   of "label=value
+00007e10: 2220 286d 6174 6368 206c 6162 656c 206b  " (match label k
+00007e20: 6579 2061 6e64 2076 616c 7565 2920 6f72  ey and value) or
+00007e30: 2022 6c61 6265 6c22 2028 6d61 7463 6820   "label" (match 
+00007e40: 6a75 7374 206c 6162 656c 206b 6579 2920  just label key) 
+00007e50: 7374 7269 6e67 732e 0a20 2020 2020 2020  strings..       
+00007e60: 203a 7061 7261 6d20 7369 6e63 653a 204e   :param since: N
+00007e70: 6f74 2069 6e20 7573 6520 696e 203a 7079  ot in use in :py
+00007e80: 3a63 6c61 7373 3a60 4854 5450 5275 6e44  :class:`HTTPRunD
+00007e90: 4260 2e0a 2020 2020 2020 2020 3a70 6172  B`..        :par
+00007ea0: 616d 2075 6e74 696c 3a20 4e6f 7420 696e  am until: Not in
+00007eb0: 2075 7365 2069 6e20 3a70 793a 636c 6173   use in :py:clas
+00007ec0: 733a 6048 5454 5052 756e 4442 602e 0a20  s:`HTTPRunDB`.. 
+00007ed0: 2020 2020 2020 203a 7061 7261 6d20 6974         :param it
+00007ee0: 6572 3a20 5265 7475 726e 2061 7274 6966  er: Return artif
+00007ef0: 6163 7473 2066 726f 6d20 6120 7370 6563  acts from a spec
+00007f00: 6966 6963 2069 7465 7261 7469 6f6e 2028  ific iteration (
+00007f10: 7768 6572 6520 6060 6974 6572 3d30 6060  where ``iter=0``
+00007f20: 206d 6561 6e73 2074 6865 2072 6f6f 7420   means the root 
+00007f30: 6974 6572 6174 696f 6e29 2e20 4966 0a20  iteration). If. 
+00007f40: 2020 2020 2020 2020 2020 2060 604e 6f6e             ``Non
+00007f50: 6560 6020 2864 6566 6175 6c74 2920 7265  e`` (default) re
+00007f60: 7475 726e 2061 7274 6966 6163 7473 2066  turn artifacts f
+00007f70: 726f 6d20 616c 6c20 6974 6572 6174 696f  rom all iteratio
+00007f80: 6e73 2e0a 2020 2020 2020 2020 3a70 6172  ns..        :par
+00007f90: 616d 2062 6573 745f 6974 6572 6174 696f  am best_iteratio
+00007fa0: 6e3a 2052 6574 7572 6e73 2074 6865 2061  n: Returns the a
+00007fb0: 7274 6966 6163 7420 7768 6963 6820 6265  rtifact which be
+00007fc0: 6c6f 6e67 7320 746f 2074 6865 2062 6573  longs to the bes
+00007fd0: 7420 6974 6572 6174 696f 6e20 6f66 2061  t iteration of a
+00007fe0: 2067 6976 656e 2072 756e 2c20 696e 2074   given run, in t
+00007ff0: 6865 2063 6173 6520 6f66 0a20 2020 2020  he case of.     
+00008000: 2020 2020 2020 2061 7274 6966 6163 7473         artifacts
+00008010: 2067 656e 6572 6174 6564 2066 726f 6d20   generated from 
+00008020: 6120 6879 7065 722d 7061 7261 6d20 7275  a hyper-param ru
+00008030: 6e2e 2049 6620 6f6e 6c79 2061 2073 696e  n. If only a sin
+00008040: 676c 6520 6974 6572 6174 696f 6e20 6578  gle iteration ex
+00008050: 6973 7473 2c20 7769 6c6c 2072 6574 7572  ists, will retur
+00008060: 6e20 7468 6520 6172 7469 6661 6374 0a20  n the artifact. 
+00008070: 2020 2020 2020 2020 2020 2066 726f 6d20             from 
+00008080: 7468 6174 2069 7465 7261 7469 6f6e 2e20  that iteration. 
+00008090: 4966 2075 7369 6e67 2060 6062 6573 745f  If using ``best_
+000080a0: 6974 6572 6060 2c20 7468 6520 6060 6974  iter``, the ``it
+000080b0: 6572 6060 2070 6172 616d 6574 6572 206d  er`` parameter m
+000080c0: 7573 7420 6e6f 7420 6265 2075 7365 642e  ust not be used.
+000080d0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+000080e0: 6b69 6e64 3a20 5265 7475 726e 2061 7274  kind: Return art
+000080f0: 6966 6163 7473 206f 6620 7468 6520 7265  ifacts of the re
+00008100: 7175 6573 7465 6420 6b69 6e64 2e0a 2020  quested kind..  
+00008110: 2020 2020 2020 3a70 6172 616d 2063 6174        :param cat
+00008120: 6567 6f72 793a 2052 6574 7572 6e20 6172  egory: Return ar
+00008130: 7469 6661 6374 7320 6f66 2074 6865 2072  tifacts of the r
+00008140: 6571 7565 7374 6564 2063 6174 6567 6f72  equested categor
+00008150: 792e 0a20 2020 2020 2020 2022 2222 0a0a  y..        """..
+00008160: 2020 2020 2020 2020 7072 6f6a 6563 7420          project 
+00008170: 3d20 7072 6f6a 6563 7420 6f72 2063 6f6e  = project or con
+00008180: 6669 672e 6465 6661 756c 745f 7072 6f6a  fig.default_proj
+00008190: 6563 740a 0a20 2020 2020 2020 206c 6162  ect..        lab
+000081a0: 656c 7320 3d20 6c61 6265 6c73 206f 7220  els = labels or 
+000081b0: 5b5d 0a20 2020 2020 2020 2069 6620 6973  [].        if is
+000081c0: 696e 7374 616e 6365 286c 6162 656c 732c  instance(labels,
+000081d0: 2064 6963 7429 3a0a 2020 2020 2020 2020   dict):.        
+000081e0: 2020 2020 6c61 6265 6c73 203d 205b 6622      labels = [f"
+000081f0: 7b6b 6579 7d3d 7b76 616c 7565 7d22 2066  {key}={value}" f
+00008200: 6f72 206b 6579 2c20 7661 6c75 6520 696e  or key, value in
+00008210: 206c 6162 656c 732e 6974 656d 7328 295d   labels.items()]
+00008220: 0a0a 2020 2020 2020 2020 7061 7261 6d73  ..        params
+00008230: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
+00008240: 2022 6e61 6d65 223a 206e 616d 652c 0a20   "name": name,. 
+00008250: 2020 2020 2020 2020 2020 2022 7461 6722             "tag"
+00008260: 3a20 7461 672c 0a20 2020 2020 2020 2020  : tag,.         
+00008270: 2020 2022 6c61 6265 6c22 3a20 6c61 6265     "label": labe
+00008280: 6c73 2c0a 2020 2020 2020 2020 2020 2020  ls,.            
+00008290: 2269 7465 7222 3a20 6974 6572 2c0a 2020  "iter": iter,.  
+000082a0: 2020 2020 2020 2020 2020 2262 6573 742d            "best-
+000082b0: 6974 6572 6174 696f 6e22 3a20 6265 7374  iteration": best
+000082c0: 5f69 7465 7261 7469 6f6e 2c0a 2020 2020  _iteration,.    
+000082d0: 2020 2020 2020 2020 226b 696e 6422 3a20          "kind": 
+000082e0: 6b69 6e64 2c0a 2020 2020 2020 2020 2020  kind,.          
+000082f0: 2020 2263 6174 6567 6f72 7922 3a20 6361    "category": ca
+00008300: 7465 676f 7279 2c0a 2020 2020 2020 2020  tegory,.        
+00008310: 2020 2020 2266 6f72 6d61 7422 3a20 7363      "format": sc
+00008320: 6865 6d61 732e 4172 7469 6661 6374 7346  hemas.ArtifactsF
+00008330: 6f72 6d61 742e 6675 6c6c 2e76 616c 7565  ormat.full.value
+00008340: 2c0a 2020 2020 2020 2020 7d0a 2020 2020  ,.        }.    
+00008350: 2020 2020 6572 726f 7220 3d20 226c 6973      error = "lis
+00008360: 7420 6172 7469 6661 6374 7322 0a20 2020  t artifacts".   
+00008370: 2020 2020 2065 6e64 706f 696e 745f 7061       endpoint_pa
+00008380: 7468 203d 2066 2270 726f 6a65 6374 732f  th = f"projects/
+00008390: 7b70 726f 6a65 6374 7d2f 6172 7469 6661  {project}/artifa
+000083a0: 6374 7322 0a20 2020 2020 2020 2072 6573  cts".        res
+000083b0: 7020 3d20 7365 6c66 2e61 7069 5f63 616c  p = self.api_cal
+000083c0: 6c28 2247 4554 222c 2065 6e64 706f 696e  l("GET", endpoin
+000083d0: 745f 7061 7468 2c20 6572 726f 722c 2070  t_path, error, p
+000083e0: 6172 616d 733d 7061 7261 6d73 290a 2020  arams=params).  
+000083f0: 2020 2020 2020 7661 6c75 6573 203d 2041        values = A
+00008400: 7274 6966 6163 744c 6973 7428 7265 7370  rtifactList(resp
+00008410: 2e6a 736f 6e28 295b 2261 7274 6966 6163  .json()["artifac
+00008420: 7473 225d 290a 2020 2020 2020 2020 7661  ts"]).        va
+00008430: 6c75 6573 2e74 6167 203d 2074 6167 0a20  lues.tag = tag. 
+00008440: 2020 2020 2020 2072 6574 7572 6e20 7661         return va
+00008450: 6c75 6573 0a0a 2020 2020 6465 6620 6465  lues..    def de
+00008460: 6c5f 6172 7469 6661 6374 7328 7365 6c66  l_artifacts(self
+00008470: 2c20 6e61 6d65 3d4e 6f6e 652c 2070 726f  , name=None, pro
+00008480: 6a65 6374 3d4e 6f6e 652c 2074 6167 3d4e  ject=None, tag=N
+00008490: 6f6e 652c 206c 6162 656c 733d 4e6f 6e65  one, labels=None
+000084a0: 2c20 6461 7973 5f61 676f 3d30 293a 0a20  , days_ago=0):. 
+000084b0: 2020 2020 2020 2022 2222 4465 6c65 7465         """Delete
+000084c0: 2061 7274 6966 6163 7473 2072 6566 6572   artifacts refer
+000084d0: 656e 6365 6420 6279 2074 6865 2070 6172  enced by the par
+000084e0: 616d 6574 6572 732e 0a0a 2020 2020 2020  ameters...      
+000084f0: 2020 3a70 6172 616d 206e 616d 653a 204e    :param name: N
+00008500: 616d 6520 6f66 2061 7274 6966 6163 7473  ame of artifacts
+00008510: 2074 6f20 6465 6c65 7465 2e20 4e6f 7465   to delete. Note
+00008520: 2074 6861 7420 7468 6973 2069 7320 6120   that this is a 
+00008530: 6c69 6b65 2071 7565 7279 2c20 616e 6420  like query, and 
+00008540: 6973 2063 6173 652d 696e 7365 6e73 6974  is case-insensit
+00008550: 6976 652e 2053 6565 0a20 2020 2020 2020  ive. See.       
+00008560: 2020 2020 203a 7079 3a66 756e 633a 607e       :py:func:`~
+00008570: 6c69 7374 5f61 7274 6966 6163 7473 6020  list_artifacts` 
+00008580: 666f 7220 6d6f 7265 2064 6574 6169 6c73  for more details
+00008590: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+000085a0: 2070 726f 6a65 6374 3a20 5072 6f6a 6563   project: Projec
+000085b0: 7420 7468 6174 2061 7274 6966 6163 7473  t that artifacts
+000085c0: 2062 656c 6f6e 6720 746f 2e0a 2020 2020   belong to..    
+000085d0: 2020 2020 3a70 6172 616d 2074 6167 3a20      :param tag: 
+000085e0: 4368 6f6f 7365 2061 7274 6966 6163 7473  Choose artifacts
+000085f0: 2077 686f 2061 7265 2061 7373 6967 6e65   who are assigne
+00008600: 6420 7468 6973 2074 6167 2e0a 2020 2020  d this tag..    
+00008610: 2020 2020 3a70 6172 616d 206c 6162 656c      :param label
+00008620: 733a 2043 686f 6f73 6520 6172 7469 6661  s: Choose artifa
+00008630: 6374 7320 7768 6963 6820 6172 6520 6c61  cts which are la
+00008640: 6265 6c65 642e 0a20 2020 2020 2020 203a  beled..        :
+00008650: 7061 7261 6d20 6461 7973 5f61 676f 3a20  param days_ago: 
+00008660: 5468 6973 2070 6172 616d 6574 6572 2069  This parameter i
+00008670: 7320 6465 7072 6563 6174 6564 2061 6e64  s deprecated and
+00008680: 206e 6f74 2075 7365 642e 0a20 2020 2020   not used..     
+00008690: 2020 2022 2222 0a20 2020 2020 2020 2070     """.        p
+000086a0: 726f 6a65 6374 203d 2070 726f 6a65 6374  roject = project
+000086b0: 206f 7220 636f 6e66 6967 2e64 6566 6175   or config.defau
+000086c0: 6c74 5f70 726f 6a65 6374 0a20 2020 2020  lt_project.     
+000086d0: 2020 2070 6172 616d 7320 3d20 7b0a 2020     params = {.  
+000086e0: 2020 2020 2020 2020 2020 226e 616d 6522            "name"
+000086f0: 3a20 6e61 6d65 2c0a 2020 2020 2020 2020  : name,.        
+00008700: 2020 2020 2274 6167 223a 2074 6167 2c0a      "tag": tag,.
+00008710: 2020 2020 2020 2020 2020 2020 226c 6162              "lab
+00008720: 656c 223a 206c 6162 656c 7320 6f72 205b  el": labels or [
+00008730: 5d2c 0a20 2020 2020 2020 2020 2020 2022  ],.            "
+00008740: 6461 7973 5f61 676f 223a 2073 7472 2864  days_ago": str(d
+00008750: 6179 735f 6167 6f29 2c0a 2020 2020 2020  ays_ago),.      
+00008760: 2020 7d0a 2020 2020 2020 2020 6572 726f    }.        erro
+00008770: 7220 3d20 2264 656c 2061 7274 6966 6163  r = "del artifac
+00008780: 7473 220a 2020 2020 2020 2020 656e 6470  ts".        endp
+00008790: 6f69 6e74 5f70 6174 6820 3d20 6622 7072  oint_path = f"pr
+000087a0: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
+000087b0: 2f61 7274 6966 6163 7473 220a 2020 2020  /artifacts".    
+000087c0: 2020 2020 7365 6c66 2e61 7069 5f63 616c      self.api_cal
+000087d0: 6c28 2244 454c 4554 4522 2c20 656e 6470  l("DELETE", endp
+000087e0: 6f69 6e74 5f70 6174 682c 2065 7272 6f72  oint_path, error
+000087f0: 2c20 7061 7261 6d73 3d70 6172 616d 7329  , params=params)
+00008800: 0a0a 2020 2020 6465 6620 6c69 7374 5f61  ..    def list_a
+00008810: 7274 6966 6163 745f 7461 6773 280a 2020  rtifact_tags(.  
+00008820: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
+00008830: 2020 2020 7072 6f6a 6563 743d 4e6f 6e65      project=None
+00008840: 2c0a 2020 2020 2020 2020 6361 7465 676f  ,.        catego
+00008850: 7279 3a20 556e 696f 6e5b 7374 722c 2073  ry: Union[str, s
+00008860: 6368 656d 6173 2e41 7274 6966 6163 7443  chemas.ArtifactC
+00008870: 6174 6567 6f72 6965 735d 203d 204e 6f6e  ategories] = Non
+00008880: 652c 0a20 2020 2029 202d 3e20 4c69 7374  e,.    ) -> List
+00008890: 5b73 7472 5d3a 0a20 2020 2020 2020 2022  [str]:.        "
+000088a0: 2222 5265 7475 726e 2061 206c 6973 7420  ""Return a list 
+000088b0: 6f66 2061 6c6c 2074 6865 2074 6167 7320  of all the tags 
+000088c0: 6173 7369 676e 6564 2074 6f20 6172 7469  assigned to arti
+000088d0: 6661 6374 7320 696e 2074 6865 2073 636f  facts in the sco
+000088e0: 7065 206f 6620 7468 6520 6769 7665 6e20  pe of the given 
+000088f0: 7072 6f6a 6563 742e 2222 220a 0a20 2020  project."""..   
+00008900: 2020 2020 2070 726f 6a65 6374 203d 2070       project = p
+00008910: 726f 6a65 6374 206f 7220 636f 6e66 6967  roject or config
+00008920: 2e64 6566 6175 6c74 5f70 726f 6a65 6374  .default_project
+00008930: 0a20 2020 2020 2020 2065 7272 6f72 5f6d  .        error_m
+00008940: 6573 7361 6765 203d 2066 2246 6169 6c65  essage = f"Faile
+00008950: 6420 6c69 7374 696e 6720 6172 7469 6661  d listing artifa
+00008960: 6374 2074 6167 732e 2070 726f 6a65 6374  ct tags. project
+00008970: 3d7b 7072 6f6a 6563 747d 220a 2020 2020  ={project}".    
+00008980: 2020 2020 7061 7261 6d73 203d 207b 2263      params = {"c
+00008990: 6174 6567 6f72 7922 3a20 6361 7465 676f  ategory": catego
+000089a0: 7279 7d20 6966 2063 6174 6567 6f72 7920  ry} if category 
+000089b0: 656c 7365 207b 7d0a 0a20 2020 2020 2020  else {}..       
+000089c0: 2072 6573 706f 6e73 6520 3d20 7365 6c66   response = self
+000089d0: 2e61 7069 5f63 616c 6c28 0a20 2020 2020  .api_call(.     
+000089e0: 2020 2020 2020 2022 4745 5422 2c20 6622         "GET", f"
+000089f0: 7072 6f6a 6563 7473 2f7b 7072 6f6a 6563  projects/{projec
+00008a00: 747d 2f61 7274 6966 6163 742d 7461 6773  t}/artifact-tags
+00008a10: 222c 2065 7272 6f72 5f6d 6573 7361 6765  ", error_message
+00008a20: 2c20 7061 7261 6d73 3d70 6172 616d 730a  , params=params.
+00008a30: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00008a40: 2020 7265 7475 726e 2072 6573 706f 6e73    return respons
+00008a50: 652e 6a73 6f6e 2829 5b22 7461 6773 225d  e.json()["tags"]
+00008a60: 0a0a 2020 2020 6465 6620 7374 6f72 655f  ..    def store_
+00008a70: 6675 6e63 7469 6f6e 280a 2020 2020 2020  function(.      
+00008a80: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
+00008a90: 6675 6e63 7469 6f6e 3a20 7479 7069 6e67  function: typing
+00008aa0: 2e55 6e69 6f6e 5b6d 6c72 756e 2e72 756e  .Union[mlrun.run
+00008ab0: 7469 6d65 732e 4261 7365 5275 6e74 696d  times.BaseRuntim
+00008ac0: 652c 2064 6963 745d 2c0a 2020 2020 2020  e, dict],.      
+00008ad0: 2020 6e61 6d65 2c0a 2020 2020 2020 2020    name,.        
+00008ae0: 7072 6f6a 6563 743d 2222 2c0a 2020 2020  project="",.    
+00008af0: 2020 2020 7461 673d 4e6f 6e65 2c0a 2020      tag=None,.  
+00008b00: 2020 2020 2020 7665 7273 696f 6e65 643d        versioned=
+00008b10: 4661 6c73 652c 0a20 2020 2029 3a0a 2020  False,.    ):.  
+00008b20: 2020 2020 2020 2222 2253 746f 7265 2061        """Store a
+00008b30: 2066 756e 6374 696f 6e20 6f62 6a65 6374   function object
+00008b40: 2e20 4675 6e63 7469 6f6e 2069 7320 6964  . Function is id
+00008b50: 656e 7469 6669 6564 2062 7920 6974 7320  entified by its 
+00008b60: 6e61 6d65 2061 6e64 2074 6167 2c20 616e  name and tag, an
+00008b70: 6420 6361 6e20 6265 2076 6572 7369 6f6e  d can be version
+00008b80: 6564 2e22 2222 0a20 2020 2020 2020 206e  ed.""".        n
+00008b90: 616d 6520 3d20 6d6c 7275 6e2e 7574 696c  ame = mlrun.util
+00008ba0: 732e 6e6f 726d 616c 697a 655f 6e61 6d65  s.normalize_name
+00008bb0: 286e 616d 6529 0a20 2020 2020 2020 2069  (name).        i
+00008bc0: 6620 6861 7361 7474 7228 6675 6e63 7469  f hasattr(functi
+00008bd0: 6f6e 2c20 2274 6f5f 6469 6374 2229 3a0a  on, "to_dict"):.
+00008be0: 2020 2020 2020 2020 2020 2020 6675 6e63              func
+00008bf0: 7469 6f6e 203d 2066 756e 6374 696f 6e2e  tion = function.
+00008c00: 746f 5f64 6963 7428 290a 0a20 2020 2020  to_dict()..     
+00008c10: 2020 2070 6172 616d 7320 3d20 7b22 7461     params = {"ta
+00008c20: 6722 3a20 7461 672c 2022 7665 7273 696f  g": tag, "versio
+00008c30: 6e65 6422 3a20 7665 7273 696f 6e65 647d  ned": versioned}
+00008c40: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
+00008c50: 203d 2070 726f 6a65 6374 206f 7220 636f   = project or co
+00008c60: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
+00008c70: 6a65 6374 0a20 2020 2020 2020 2070 6174  ject.        pat
+00008c80: 6820 3d20 7365 6c66 2e5f 7061 7468 5f6f  h = self._path_o
+00008c90: 6628 2266 756e 6322 2c20 7072 6f6a 6563  f("func", projec
+00008ca0: 742c 206e 616d 6529 0a0a 2020 2020 2020  t, name)..      
+00008cb0: 2020 6572 726f 7220 3d20 6622 7374 6f72    error = f"stor
+00008cc0: 6520 6675 6e63 7469 6f6e 207b 7072 6f6a  e function {proj
+00008cd0: 6563 747d 2f7b 6e61 6d65 7d22 0a20 2020  ect}/{name}".   
+00008ce0: 2020 2020 2072 6573 7020 3d20 7365 6c66       resp = self
+00008cf0: 2e61 7069 5f63 616c 6c28 0a20 2020 2020  .api_call(.     
+00008d00: 2020 2020 2020 2022 504f 5354 222c 2070         "POST", p
+00008d10: 6174 682c 2065 7272 6f72 2c20 7061 7261  ath, error, para
+00008d20: 6d73 3d70 6172 616d 732c 2062 6f64 793d  ms=params, body=
+00008d30: 6469 6374 5f74 6f5f 6a73 6f6e 2866 756e  dict_to_json(fun
+00008d40: 6374 696f 6e29 0a20 2020 2020 2020 2029  ction).        )
+00008d50: 0a0a 2020 2020 2020 2020 2320 6861 7368  ..        # hash
+00008d60: 206b 6579 206f 7074 696f 6e61 6c20 746f   key optional to
+00008d70: 2062 6520 6261 636b 7761 7264 7320 636f   be backwards co
+00008d80: 6d70 6174 6962 6c65 2074 6f20 4150 4920  mpatible to API 
+00008d90: 763c 302e 342e 3130 2069 6e20 7768 6963  v<0.4.10 in whic
+00008da0: 6820 6974 2077 6173 6e27 7420 696e 2074  h it wasn't in t
+00008db0: 6865 2072 6573 706f 6e73 650a 2020 2020  he response.    
+00008dc0: 2020 2020 7265 7475 726e 2072 6573 702e      return resp.
+00008dd0: 6a73 6f6e 2829 2e67 6574 2822 6861 7368  json().get("hash
+00008de0: 5f6b 6579 2229 0a0a 2020 2020 6465 6620  _key")..    def 
+00008df0: 6765 745f 6675 6e63 7469 6f6e 2873 656c  get_function(sel
+00008e00: 662c 206e 616d 652c 2070 726f 6a65 6374  f, name, project
+00008e10: 3d22 222c 2074 6167 3d4e 6f6e 652c 2068  ="", tag=None, h
+00008e20: 6173 685f 6b65 793d 2222 293a 0a20 2020  ash_key=""):.   
+00008e30: 2020 2020 2022 2222 5265 7472 6965 7665       """Retrieve
+00008e40: 2064 6574 6169 6c73 206f 6620 6120 7370   details of a sp
+00008e50: 6563 6966 6963 2066 756e 6374 696f 6e2c  ecific function,
+00008e60: 2069 6465 6e74 6966 6965 6420 6279 2069   identified by i
+00008e70: 7473 206e 616d 6520 616e 6420 706f 7465  ts name and pote
+00008e80: 6e74 6961 6c6c 7920 6120 7461 6720 6f72  ntially a tag or
+00008e90: 2066 756e 6374 696f 6e20 6861 7368 2e22   function hash."
+00008ea0: 2222 0a0a 2020 2020 2020 2020 7061 7261  ""..        para
+00008eb0: 6d73 203d 207b 2274 6167 223a 2074 6167  ms = {"tag": tag
+00008ec0: 2c20 2268 6173 685f 6b65 7922 3a20 6861  , "hash_key": ha
+00008ed0: 7368 5f6b 6579 7d0a 2020 2020 2020 2020  sh_key}.        
+00008ee0: 7072 6f6a 6563 7420 3d20 7072 6f6a 6563  project = projec
+00008ef0: 7420 6f72 2063 6f6e 6669 672e 6465 6661  t or config.defa
+00008f00: 756c 745f 7072 6f6a 6563 740a 2020 2020  ult_project.    
+00008f10: 2020 2020 7061 7468 203d 2073 656c 662e      path = self.
+00008f20: 5f70 6174 685f 6f66 2822 6675 6e63 222c  _path_of("func",
+00008f30: 2070 726f 6a65 6374 2c20 6e61 6d65 290a   project, name).
+00008f40: 2020 2020 2020 2020 6572 726f 7220 3d20          error = 
+00008f50: 6622 6765 7420 6675 6e63 7469 6f6e 207b  f"get function {
+00008f60: 7072 6f6a 6563 747d 2f7b 6e61 6d65 7d22  project}/{name}"
+00008f70: 0a20 2020 2020 2020 2072 6573 7020 3d20  .        resp = 
+00008f80: 7365 6c66 2e61 7069 5f63 616c 6c28 2247  self.api_call("G
+00008f90: 4554 222c 2070 6174 682c 2065 7272 6f72  ET", path, error
+00008fa0: 2c20 7061 7261 6d73 3d70 6172 616d 7329  , params=params)
+00008fb0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00008fc0: 7265 7370 2e6a 736f 6e28 295b 2266 756e  resp.json()["fun
+00008fd0: 6322 5d0a 0a20 2020 2064 6566 2064 656c  c"]..    def del
+00008fe0: 6574 655f 6675 6e63 7469 6f6e 2873 656c  ete_function(sel
+00008ff0: 662c 206e 616d 653a 2073 7472 2c20 7072  f, name: str, pr
+00009000: 6f6a 6563 743a 2073 7472 203d 2022 2229  oject: str = "")
+00009010: 3a0a 2020 2020 2020 2020 2222 2244 656c  :.        """Del
+00009020: 6574 6520 6120 6675 6e63 7469 6f6e 2062  ete a function b
+00009030: 656c 6f6e 6769 6e67 2074 6f20 6120 7370  elonging to a sp
+00009040: 6563 6966 6963 2070 726f 6a65 6374 2e22  ecific project."
+00009050: 2222 0a0a 2020 2020 2020 2020 7072 6f6a  ""..        proj
+00009060: 6563 7420 3d20 7072 6f6a 6563 7420 6f72  ect = project or
+00009070: 2063 6f6e 6669 672e 6465 6661 756c 745f   config.default_
+00009080: 7072 6f6a 6563 740a 2020 2020 2020 2020  project.        
+00009090: 7061 7468 203d 2066 2270 726f 6a65 6374  path = f"project
+000090a0: 732f 7b70 726f 6a65 6374 7d2f 6675 6e63  s/{project}/func
+000090b0: 7469 6f6e 732f 7b6e 616d 657d 220a 2020  tions/{name}".  
+000090c0: 2020 2020 2020 6572 726f 725f 6d65 7373        error_mess
+000090d0: 6167 6520 3d20 6622 4661 696c 6564 2064  age = f"Failed d
+000090e0: 656c 6574 696e 6720 6675 6e63 7469 6f6e  eleting function
+000090f0: 207b 7072 6f6a 6563 747d 2f7b 6e61 6d65   {project}/{name
+00009100: 7d22 0a20 2020 2020 2020 2073 656c 662e  }".        self.
+00009110: 6170 695f 6361 6c6c 2822 4445 4c45 5445  api_call("DELETE
+00009120: 222c 2070 6174 682c 2065 7272 6f72 5f6d  ", path, error_m
+00009130: 6573 7361 6765 290a 0a20 2020 2064 6566  essage)..    def
+00009140: 206c 6973 745f 6675 6e63 7469 6f6e 7328   list_functions(
+00009150: 7365 6c66 2c20 6e61 6d65 3d4e 6f6e 652c  self, name=None,
+00009160: 2070 726f 6a65 6374 3d4e 6f6e 652c 2074   project=None, t
+00009170: 6167 3d4e 6f6e 652c 206c 6162 656c 733d  ag=None, labels=
+00009180: 4e6f 6e65 293a 0a20 2020 2020 2020 2022  None):.        "
+00009190: 2222 5265 7472 6965 7665 2061 206c 6973  ""Retrieve a lis
+000091a0: 7420 6f66 2066 756e 6374 696f 6e73 2c20  t of functions, 
+000091b0: 6669 6c74 6572 6564 2062 7920 7370 6563  filtered by spec
+000091c0: 6966 6963 2063 7269 7465 7269 612e 0a0a  ific criteria...
+000091d0: 2020 2020 2020 2020 3a70 6172 616d 206e          :param n
+000091e0: 616d 653a 2052 6574 7572 6e20 6f6e 6c79  ame: Return only
+000091f0: 2066 756e 6374 696f 6e73 2077 6974 6820   functions with 
+00009200: 6120 7370 6563 6966 6963 206e 616d 652e  a specific name.
+00009210: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00009220: 7072 6f6a 6563 743a 2052 6574 7572 6e20  project: Return 
+00009230: 6675 6e63 7469 6f6e 7320 6265 6c6f 6e67  functions belong
+00009240: 696e 6720 746f 2074 6869 7320 7072 6f6a  ing to this proj
+00009250: 6563 742e 2049 6620 6e6f 7420 7370 6563  ect. If not spec
+00009260: 6966 6965 642c 2074 6865 2064 6566 6175  ified, the defau
+00009270: 6c74 2070 726f 6a65 6374 2069 7320 7573  lt project is us
+00009280: 6564 2e0a 2020 2020 2020 2020 3a70 6172  ed..        :par
+00009290: 616d 2074 6167 3a20 5265 7475 726e 2066  am tag: Return f
+000092a0: 756e 6374 696f 6e20 7665 7273 696f 6e73  unction versions
+000092b0: 2077 6974 6820 7370 6563 6966 6963 2074   with specific t
+000092c0: 6167 732e 0a20 2020 2020 2020 203a 7061  ags..        :pa
+000092d0: 7261 6d20 6c61 6265 6c73 3a20 5265 7475  ram labels: Retu
+000092e0: 726e 2066 756e 6374 696f 6e73 2074 6861  rn functions tha
+000092f0: 7420 6861 7665 2073 7065 6369 6669 6320  t have specific 
+00009300: 6c61 6265 6c73 2061 7373 6967 6e65 6420  labels assigned 
+00009310: 746f 2074 6865 6d2e 0a20 2020 2020 2020  to them..       
+00009320: 203a 7265 7475 726e 733a 204c 6973 7420   :returns: List 
+00009330: 6f66 2066 756e 6374 696f 6e20 6f62 6a65  of function obje
+00009340: 6374 7320 2861 7320 6469 6374 696f 6e61  cts (as dictiona
+00009350: 7279 292e 0a20 2020 2020 2020 2022 2222  ry)..        """
+00009360: 0a0a 2020 2020 2020 2020 7061 7261 6d73  ..        params
+00009370: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
+00009380: 2022 7072 6f6a 6563 7422 3a20 7072 6f6a   "project": proj
+00009390: 6563 7420 6f72 2063 6f6e 6669 672e 6465  ect or config.de
+000093a0: 6661 756c 745f 7072 6f6a 6563 742c 0a20  fault_project,. 
+000093b0: 2020 2020 2020 2020 2020 2022 6e61 6d65             "name
+000093c0: 223a 206e 616d 652c 0a20 2020 2020 2020  ": name,.       
+000093d0: 2020 2020 2022 7461 6722 3a20 7461 672c       "tag": tag,
+000093e0: 0a20 2020 2020 2020 2020 2020 2022 6c61  .            "la
+000093f0: 6265 6c22 3a20 6c61 6265 6c73 206f 7220  bel": labels or 
+00009400: 5b5d 2c0a 2020 2020 2020 2020 7d0a 2020  [],.        }.  
+00009410: 2020 2020 2020 6572 726f 7220 3d20 226c        error = "l
+00009420: 6973 7420 6675 6e63 7469 6f6e 7322 0a20  ist functions". 
+00009430: 2020 2020 2020 2072 6573 7020 3d20 7365         resp = se
+00009440: 6c66 2e61 7069 5f63 616c 6c28 2247 4554  lf.api_call("GET
+00009450: 222c 2022 6675 6e63 7322 2c20 6572 726f  ", "funcs", erro
+00009460: 722c 2070 6172 616d 733d 7061 7261 6d73  r, params=params
+00009470: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00009480: 2072 6573 702e 6a73 6f6e 2829 5b22 6675   resp.json()["fu
+00009490: 6e63 7322 5d0a 0a20 2020 2064 6566 206c  ncs"]..    def l
+000094a0: 6973 745f 7275 6e74 696d 655f 7265 736f  ist_runtime_reso
+000094b0: 7572 6365 7328 0a20 2020 2020 2020 2073  urces(.        s
+000094c0: 656c 662c 0a20 2020 2020 2020 2070 726f  elf,.        pro
+000094d0: 6a65 6374 3a20 4f70 7469 6f6e 616c 5b73  ject: Optional[s
+000094e0: 7472 5d20 3d20 4e6f 6e65 2c0a 2020 2020  tr] = None,.    
+000094f0: 2020 2020 6c61 6265 6c5f 7365 6c65 6374      label_select
+00009500: 6f72 3a20 4f70 7469 6f6e 616c 5b73 7472  or: Optional[str
+00009510: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+00009520: 2020 6b69 6e64 3a20 4f70 7469 6f6e 616c    kind: Optional
+00009530: 5b73 7472 5d20 3d20 4e6f 6e65 2c0a 2020  [str] = None,.  
+00009540: 2020 2020 2020 6f62 6a65 6374 5f69 643a        object_id:
+00009550: 204f 7074 696f 6e61 6c5b 7374 725d 203d   Optional[str] =
+00009560: 204e 6f6e 652c 0a20 2020 2020 2020 2067   None,.        g
+00009570: 726f 7570 5f62 793a 204f 7074 696f 6e61  roup_by: Optiona
+00009580: 6c5b 6d6c 7275 6e2e 6170 692e 7363 6865  l[mlrun.api.sche
+00009590: 6d61 732e 4c69 7374 5275 6e74 696d 6552  mas.ListRuntimeR
+000095a0: 6573 6f75 7263 6573 4772 6f75 7042 7946  esourcesGroupByF
+000095b0: 6965 6c64 5d20 3d20 4e6f 6e65 2c0a 2020  ield] = None,.  
+000095c0: 2020 2920 2d3e 2055 6e69 6f6e 5b0a 2020    ) -> Union[.  
+000095d0: 2020 2020 2020 6d6c 7275 6e2e 6170 692e        mlrun.api.
+000095e0: 7363 6865 6d61 732e 5275 6e74 696d 6552  schemas.RuntimeR
+000095f0: 6573 6f75 7263 6573 4f75 7470 7574 2c0a  esourcesOutput,.
+00009600: 2020 2020 2020 2020 6d6c 7275 6e2e 6170          mlrun.ap
+00009610: 692e 7363 6865 6d61 732e 4772 6f75 7065  i.schemas.Groupe
+00009620: 6442 794a 6f62 5275 6e74 696d 6552 6573  dByJobRuntimeRes
+00009630: 6f75 7263 6573 4f75 7470 7574 2c0a 2020  ourcesOutput,.  
+00009640: 2020 2020 2020 6d6c 7275 6e2e 6170 692e        mlrun.api.
+00009650: 7363 6865 6d61 732e 4772 6f75 7065 6442  schemas.GroupedB
+00009660: 7950 726f 6a65 6374 5275 6e74 696d 6552  yProjectRuntimeR
+00009670: 6573 6f75 7263 6573 4f75 7470 7574 2c0a  esourcesOutput,.
+00009680: 2020 2020 5d3a 0a20 2020 2020 2020 2022      ]:.        "
+00009690: 2222 4c69 7374 2063 7572 7265 6e74 2072  ""List current r
+000096a0: 756e 7469 6d65 2072 6573 6f75 7263 6573  untime resources
+000096b0: 2c20 7768 6963 6820 6172 6520 7573 7561  , which are usua
+000096c0: 6c6c 7920 2862 7574 206e 6f74 206c 696d  lly (but not lim
+000096d0: 6974 6564 2074 6f29 204b 7562 6572 6e65  ited to) Kuberne
+000096e0: 7465 7320 706f 6473 206f 7220 4352 4473  tes pods or CRDs
+000096f0: 2e0a 2020 2020 2020 2020 4675 6e63 7469  ..        Functi
+00009700: 6f6e 2061 7070 6c69 6573 2066 6f72 2072  on applies for r
+00009710: 756e 7320 6f66 2074 7970 6520 605b 2764  uns of type `['d
+00009720: 6173 6b27 2c20 276a 6f62 272c 2027 7370  ask', 'job', 'sp
+00009730: 6172 6b27 2c20 2772 656d 6f74 652d 7370  ark', 'remote-sp
+00009740: 6172 6b27 2c20 276d 7069 6a6f 6227 5d60  ark', 'mpijob']`
+00009750: 2c20 616e 6420 7769 6c6c 2072 6574 7572  , and will retur
+00009760: 6e20 7065 720a 2020 2020 2020 2020 7275  n per.        ru
+00009770: 6e74 696d 6520 6b69 6e64 2061 206c 6973  ntime kind a lis
+00009780: 7420 6f66 2074 6865 2072 756e 7469 6d65  t of the runtime
+00009790: 2072 6573 6f75 7263 6573 2028 7768 6963   resources (whic
+000097a0: 6820 6d61 7920 6861 7665 2061 6c72 6561  h may have alrea
+000097b0: 6479 2063 6f6d 706c 6574 6564 2074 6865  dy completed the
+000097c0: 6972 2065 7865 6375 7469 6f6e 292e 0a0a  ir execution)...
+000097d0: 2020 2020 2020 2020 3a70 6172 616d 2070          :param p
+000097e0: 726f 6a65 6374 3a20 4765 7420 6f6e 6c79  roject: Get only
+000097f0: 2072 756e 7469 6d65 2072 6573 6f75 7263   runtime resourc
+00009800: 6573 206f 6620 6120 7370 6563 6966 6963  es of a specific
+00009810: 2070 726f 6a65 6374 2c20 6279 2064 6566   project, by def
+00009820: 6175 6c74 204e 6f6e 652c 2077 6869 6368  ault None, which
+00009830: 2077 696c 6c20 7265 7475 726e 206f 6e6c   will return onl
+00009840: 7920 7468 650a 2020 2020 2020 2020 2020  y the.          
+00009850: 2020 7072 6f6a 6563 7473 2079 6f75 2772    projects you'r
+00009860: 6520 6175 7468 6f72 697a 6564 2074 6f20  e authorized to 
+00009870: 7365 652e 0a20 2020 2020 2020 203a 7061  see..        :pa
+00009880: 7261 6d20 6c61 6265 6c5f 7365 6c65 6374  ram label_select
+00009890: 6f72 3a20 4120 6c61 6265 6c20 6669 6c74  or: A label filt
+000098a0: 6572 2074 6861 7420 7769 6c6c 2062 6520  er that will be 
+000098b0: 7061 7373 6564 2074 6f20 4b75 6265 726e  passed to Kubern
+000098c0: 6574 6573 2066 6f72 2066 696c 7465 7269  etes for filteri
+000098d0: 6e67 2074 6865 2072 6573 756c 7473 2061  ng the results a
+000098e0: 6363 6f72 6469 6e67 0a20 2020 2020 2020  ccording.       
+000098f0: 2020 2020 2074 6f20 7468 6569 7220 6c61       to their la
+00009900: 6265 6c73 2e0a 2020 2020 2020 2020 3a70  bels..        :p
+00009910: 6172 616d 206b 696e 643a 2054 6865 206b  aram kind: The k
+00009920: 696e 6420 6f66 2072 756e 7469 6d65 2074  ind of runtime t
+00009930: 6f20 7175 6572 792e 204d 6179 2062 6520  o query. May be 
+00009940: 6f6e 6520 6f66 2060 5b27 6461 736b 272c  one of `['dask',
+00009950: 2027 6a6f 6227 2c20 2773 7061 726b 272c   'job', 'spark',
+00009960: 2027 7265 6d6f 7465 2d73 7061 726b 272c   'remote-spark',
+00009970: 2027 6d70 696a 6f62 275d 600a 2020 2020   'mpijob']`.    
+00009980: 2020 2020 3a70 6172 616d 206f 626a 6563      :param objec
+00009990: 745f 6964 3a20 5468 6520 6964 656e 7469  t_id: The identi
+000099a0: 6669 6572 206f 6620 7468 6520 6d6c 7275  fier of the mlru
+000099b0: 6e20 6f62 6a65 6374 2074 6f20 7175 6572  n object to quer
+000099c0: 7920 6974 7320 7275 6e74 696d 6520 7265  y its runtime re
+000099d0: 736f 7572 6365 732e 2066 6f72 206d 6f73  sources. for mos
+000099e0: 7420 6675 6e63 7469 6f6e 2072 756e 7469  t function runti
+000099f0: 6d65 732c 0a20 2020 2020 2020 2020 2020  mes,.           
+00009a00: 2072 756e 7469 6d65 2072 6573 6f75 7263   runtime resourc
+00009a10: 6573 2061 7265 2070 6572 2052 756e 2c20  es are per Run, 
+00009a20: 666f 7220 7768 6963 6820 7468 6520 6964  for which the id
+00009a30: 656e 7469 6669 6572 2069 7320 7468 6520  entifier is the 
+00009a40: 5275 6e27 7320 5549 442e 2046 6f72 2064  Run's UID. For d
+00009a50: 6173 6b20 7275 6e74 696d 652c 2074 6865  ask runtime, the
+00009a60: 2072 756e 7469 6d65 0a20 2020 2020 2020   runtime.       
+00009a70: 2020 2020 2072 6573 6f75 7263 6573 2061       resources a
+00009a80: 7265 2070 6572 2046 756e 6374 696f 6e2c  re per Function,
+00009a90: 2066 6f72 2077 6869 6368 2074 6865 2069   for which the i
+00009aa0: 6465 6e74 6966 6965 7220 6973 2074 6865  dentifier is the
+00009ab0: 2046 756e 6374 696f 6e27 7320 6e61 6d65   Function's name
+00009ac0: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+00009ad0: 2067 726f 7570 5f62 793a 204f 626a 6563   group_by: Objec
+00009ae0: 7420 746f 2067 726f 7570 2072 6573 756c  t to group resul
+00009af0: 7473 2062 792e 2041 6c6c 6f77 6564 2076  ts by. Allowed v
+00009b00: 616c 7565 7320 6172 6520 606a 6f62 6020  alues are `job` 
+00009b10: 616e 6420 6070 726f 6a65 6374 602e 0a20  and `project`.. 
+00009b20: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00009b30: 2020 2070 6172 616d 7320 3d20 7b0a 2020     params = {.  
+00009b40: 2020 2020 2020 2020 2020 226c 6162 656c            "label
+00009b50: 5f73 656c 6563 746f 7222 3a20 6c61 6265  _selector": labe
+00009b60: 6c5f 7365 6c65 6374 6f72 2c0a 2020 2020  l_selector,.    
+00009b70: 2020 2020 2020 2020 2267 726f 7570 2d62          "group-b
+00009b80: 7922 3a20 6772 6f75 705f 6279 2c0a 2020  y": group_by,.  
+00009b90: 2020 2020 2020 2020 2020 226b 696e 6422            "kind"
+00009ba0: 3a20 6b69 6e64 2c0a 2020 2020 2020 2020  : kind,.        
+00009bb0: 2020 2020 226f 626a 6563 742d 6964 223a      "object-id":
+00009bc0: 206f 626a 6563 745f 6964 2c0a 2020 2020   object_id,.    
+00009bd0: 2020 2020 7d0a 2020 2020 2020 2020 7072      }.        pr
+00009be0: 6f6a 6563 745f 7061 7468 203d 2070 726f  oject_path = pro
+00009bf0: 6a65 6374 2069 6620 7072 6f6a 6563 7420  ject if project 
+00009c00: 656c 7365 2022 2a22 0a20 2020 2020 2020  else "*".       
+00009c10: 2065 7272 6f72 203d 2022 4661 696c 6564   error = "Failed
+00009c20: 206c 6973 7469 6e67 2072 756e 7469 6d65   listing runtime
+00009c30: 2072 6573 6f75 7263 6573 220a 2020 2020   resources".    
+00009c40: 2020 2020 7265 7370 6f6e 7365 203d 2073      response = s
+00009c50: 656c 662e 6170 695f 6361 6c6c 280a 2020  elf.api_call(.  
+00009c60: 2020 2020 2020 2020 2020 2247 4554 222c            "GET",
+00009c70: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
+00009c80: 6a65 6374 5f70 6174 687d 2f72 756e 7469  ject_path}/runti
+00009c90: 6d65 2d72 6573 6f75 7263 6573 222c 2065  me-resources", e
+00009ca0: 7272 6f72 2c20 7061 7261 6d73 3d70 6172  rror, params=par
+00009cb0: 616d 730a 2020 2020 2020 2020 290a 2020  ams.        ).  
+00009cc0: 2020 2020 2020 6966 2067 726f 7570 5f62        if group_b
+00009cd0: 7920 6973 204e 6f6e 653a 0a20 2020 2020  y is None:.     
+00009ce0: 2020 2020 2020 2073 7472 7563 7475 7265         structure
+00009cf0: 645f 6c69 7374 203d 205b 0a20 2020 2020  d_list = [.     
+00009d00: 2020 2020 2020 2020 2020 206d 6c72 756e             mlrun
+00009d10: 2e61 7069 2e73 6368 656d 6173 2e4b 696e  .api.schemas.Kin
+00009d20: 6452 756e 7469 6d65 5265 736f 7572 6365  dRuntimeResource
+00009d30: 7328 2a2a 6b69 6e64 5f72 756e 7469 6d65  s(**kind_runtime
+00009d40: 5f72 6573 6f75 7263 6573 290a 2020 2020  _resources).    
+00009d50: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+00009d60: 6b69 6e64 5f72 756e 7469 6d65 5f72 6573  kind_runtime_res
+00009d70: 6f75 7263 6573 2069 6e20 7265 7370 6f6e  ources in respon
+00009d80: 7365 2e6a 736f 6e28 290a 2020 2020 2020  se.json().      
+00009d90: 2020 2020 2020 5d0a 2020 2020 2020 2020        ].        
+00009da0: 2020 2020 7265 7475 726e 2073 7472 7563      return struc
+00009db0: 7475 7265 645f 6c69 7374 0a20 2020 2020  tured_list.     
+00009dc0: 2020 2065 6c69 6620 6772 6f75 705f 6279     elif group_by
+00009dd0: 203d 3d20 6d6c 7275 6e2e 6170 692e 7363   == mlrun.api.sc
+00009de0: 6865 6d61 732e 4c69 7374 5275 6e74 696d  hemas.ListRuntim
+00009df0: 6552 6573 6f75 7263 6573 4772 6f75 7042  eResourcesGroupB
+00009e00: 7946 6965 6c64 2e6a 6f62 3a0a 2020 2020  yField.job:.    
+00009e10: 2020 2020 2020 2020 7374 7275 6374 7572          structur
+00009e20: 6564 5f64 6963 7420 3d20 7b7d 0a20 2020  ed_dict = {}.   
+00009e30: 2020 2020 2020 2020 2066 6f72 2070 726f           for pro
+00009e40: 6a65 6374 2c20 6a6f 625f 7275 6e74 696d  ject, job_runtim
+00009e50: 655f 7265 736f 7572 6365 735f 6d61 7020  e_resources_map 
+00009e60: 696e 2072 6573 706f 6e73 652e 6a73 6f6e  in response.json
+00009e70: 2829 2e69 7465 6d73 2829 3a0a 2020 2020  ().items():.    
+00009e80: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+00009e90: 6a6f 625f 6964 2c20 7275 6e74 696d 655f  job_id, runtime_
+00009ea0: 7265 736f 7572 6365 7320 696e 206a 6f62  resources in job
+00009eb0: 5f72 756e 7469 6d65 5f72 6573 6f75 7263  _runtime_resourc
+00009ec0: 6573 5f6d 6170 2e69 7465 6d73 2829 3a0a  es_map.items():.
+00009ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009ee0: 2020 2020 7374 7275 6374 7572 6564 5f64      structured_d
+00009ef0: 6963 742e 7365 7464 6566 6175 6c74 2870  ict.setdefault(p
+00009f00: 726f 6a65 6374 2c20 7b7d 295b 0a20 2020  roject, {})[.   
+00009f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f20: 2020 2020 206a 6f62 5f69 640a 2020 2020       job_id.    
+00009f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f40: 5d20 3d20 6d6c 7275 6e2e 6170 692e 7363  ] = mlrun.api.sc
+00009f50: 6865 6d61 732e 5275 6e74 696d 6552 6573  hemas.RuntimeRes
+00009f60: 6f75 7263 6573 282a 2a72 756e 7469 6d65  ources(**runtime
+00009f70: 5f72 6573 6f75 7263 6573 290a 2020 2020  _resources).    
+00009f80: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00009f90: 7472 7563 7475 7265 645f 6469 6374 0a20  tructured_dict. 
+00009fa0: 2020 2020 2020 2065 6c69 6620 6772 6f75         elif grou
+00009fb0: 705f 6279 203d 3d20 6d6c 7275 6e2e 6170  p_by == mlrun.ap
+00009fc0: 692e 7363 6865 6d61 732e 4c69 7374 5275  i.schemas.ListRu
+00009fd0: 6e74 696d 6552 6573 6f75 7263 6573 4772  ntimeResourcesGr
+00009fe0: 6f75 7042 7946 6965 6c64 2e70 726f 6a65  oupByField.proje
+00009ff0: 6374 3a0a 2020 2020 2020 2020 2020 2020  ct:.            
+0000a000: 7374 7275 6374 7572 6564 5f64 6963 7420  structured_dict 
+0000a010: 3d20 7b7d 0a20 2020 2020 2020 2020 2020  = {}.           
+0000a020: 2066 6f72 2070 726f 6a65 6374 2c20 6b69   for project, ki
+0000a030: 6e64 5f72 756e 7469 6d65 5f72 6573 6f75  nd_runtime_resou
+0000a040: 7263 6573 5f6d 6170 2069 6e20 7265 7370  rces_map in resp
+0000a050: 6f6e 7365 2e6a 736f 6e28 292e 6974 656d  onse.json().item
+0000a060: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+0000a070: 2020 2020 2066 6f72 206b 696e 642c 2072       for kind, r
+0000a080: 756e 7469 6d65 5f72 6573 6f75 7263 6573  untime_resources
+0000a090: 2069 6e20 6b69 6e64 5f72 756e 7469 6d65   in kind_runtime
+0000a0a0: 5f72 6573 6f75 7263 6573 5f6d 6170 2e69  _resources_map.i
+0000a0b0: 7465 6d73 2829 3a0a 2020 2020 2020 2020  tems():.        
+0000a0c0: 2020 2020 2020 2020 2020 2020 7374 7275              stru
+0000a0d0: 6374 7572 6564 5f64 6963 742e 7365 7464  ctured_dict.setd
+0000a0e0: 6566 6175 6c74 2870 726f 6a65 6374 2c20  efault(project, 
+0000a0f0: 7b7d 295b 0a20 2020 2020 2020 2020 2020  {})[.           
+0000a100: 2020 2020 2020 2020 2020 2020 206b 696e               kin
+0000a110: 640a 2020 2020 2020 2020 2020 2020 2020  d.              
+0000a120: 2020 2020 2020 5d20 3d20 6d6c 7275 6e2e        ] = mlrun.
+0000a130: 6170 692e 7363 6865 6d61 732e 5275 6e74  api.schemas.Runt
+0000a140: 696d 6552 6573 6f75 7263 6573 282a 2a72  imeResources(**r
+0000a150: 756e 7469 6d65 5f72 6573 6f75 7263 6573  untime_resources
+0000a160: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+0000a170: 7475 726e 2073 7472 7563 7475 7265 645f  turn structured_
+0000a180: 6469 6374 0a20 2020 2020 2020 2065 6c73  dict.        els
+0000a190: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+0000a1a0: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
+0000a1b0: 7465 6445 7272 6f72 280a 2020 2020 2020  tedError(.      
+0000a1c0: 2020 2020 2020 2020 2020 6622 5072 6f76            f"Prov
+0000a1d0: 6964 6564 2067 726f 7570 2062 7920 6669  ided group by fi
+0000a1e0: 656c 6420 6973 206e 6f74 2073 7570 706f  eld is not suppo
+0000a1f0: 7274 6564 2e20 6772 6f75 705f 6279 3d7b  rted. group_by={
+0000a200: 6772 6f75 705f 6279 7d22 0a20 2020 2020  group_by}".     
+0000a210: 2020 2020 2020 2029 0a0a 2020 2020 6465         )..    de
+0000a220: 6620 6465 6c65 7465 5f72 756e 7469 6d65  f delete_runtime
+0000a230: 5f72 6573 6f75 7263 6573 280a 2020 2020  _resources(.    
+0000a240: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+0000a250: 2020 7072 6f6a 6563 743a 204f 7074 696f    project: Optio
+0000a260: 6e61 6c5b 7374 725d 203d 204e 6f6e 652c  nal[str] = None,
+0000a270: 0a20 2020 2020 2020 206c 6162 656c 5f73  .        label_s
+0000a280: 656c 6563 746f 723a 204f 7074 696f 6e61  elector: Optiona
+0000a290: 6c5b 7374 725d 203d 204e 6f6e 652c 0a20  l[str] = None,. 
+0000a2a0: 2020 2020 2020 206b 696e 643a 204f 7074         kind: Opt
+0000a2b0: 696f 6e61 6c5b 7374 725d 203d 204e 6f6e  ional[str] = Non
+0000a2c0: 652c 0a20 2020 2020 2020 206f 626a 6563  e,.        objec
+0000a2d0: 745f 6964 3a20 4f70 7469 6f6e 616c 5b73  t_id: Optional[s
+0000a2e0: 7472 5d20 3d20 4e6f 6e65 2c0a 2020 2020  tr] = None,.    
+0000a2f0: 2020 2020 666f 7263 653a 2062 6f6f 6c20      force: bool 
+0000a300: 3d20 4661 6c73 652c 0a20 2020 2020 2020  = False,.       
+0000a310: 2067 7261 6365 5f70 6572 696f 643a 2069   grace_period: i
+0000a320: 6e74 203d 204e 6f6e 652c 0a20 2020 2029  nt = None,.    )
+0000a330: 202d 3e20 6d6c 7275 6e2e 6170 692e 7363   -> mlrun.api.sc
+0000a340: 6865 6d61 732e 4772 6f75 7065 6442 7950  hemas.GroupedByP
+0000a350: 726f 6a65 6374 5275 6e74 696d 6552 6573  rojectRuntimeRes
+0000a360: 6f75 7263 6573 4f75 7470 7574 3a0a 2020  ourcesOutput:.  
+0000a370: 2020 2020 2020 2222 2244 656c 6574 6520        """Delete 
+0000a380: 616c 6c20 7275 6e74 696d 6520 7265 736f  all runtime reso
+0000a390: 7572 6365 7320 7768 6963 6820 6172 6520  urces which are 
+0000a3a0: 696e 2074 6572 6d69 6e61 6c20 7374 6174  in terminal stat
+0000a3b0: 652e 0a0a 2020 2020 2020 2020 3a70 6172  e...        :par
+0000a3c0: 616d 2070 726f 6a65 6374 3a20 4465 6c65  am project: Dele
+0000a3d0: 7465 206f 6e6c 7920 7275 6e74 696d 6520  te only runtime 
+0000a3e0: 7265 736f 7572 6365 7320 6f66 2061 2073  resources of a s
+0000a3f0: 7065 6369 6669 6320 7072 6f6a 6563 742c  pecific project,
+0000a400: 2062 7920 6465 6661 756c 7420 4e6f 6e65   by default None
+0000a410: 2c20 7768 6963 6820 7769 6c6c 2064 656c  , which will del
+0000a420: 6574 6520 6f6e 6c79 0a20 2020 2020 2020  ete only.       
+0000a430: 2020 2020 2066 726f 6d20 7468 6520 7072       from the pr
+0000a440: 6f6a 6563 7473 2079 6f75 2772 6520 6175  ojects you're au
+0000a450: 7468 6f72 697a 6564 2074 6f20 6465 6c65  thorized to dele
+0000a460: 7465 2066 726f 6d2e 0a20 2020 2020 2020  te from..       
+0000a470: 203a 7061 7261 6d20 6c61 6265 6c5f 7365   :param label_se
+0000a480: 6c65 6374 6f72 3a20 4465 6c65 7465 206f  lector: Delete o
+0000a490: 6e6c 7920 7275 6e74 696d 6520 7265 736f  nly runtime reso
+0000a4a0: 7572 6365 7320 6d61 7463 6869 6e67 2074  urces matching t
+0000a4b0: 6865 206c 6162 656c 2073 656c 6563 746f  he label selecto
+0000a4c0: 722e 0a20 2020 2020 2020 203a 7061 7261  r..        :para
+0000a4d0: 6d20 6b69 6e64 3a20 5468 6520 6b69 6e64  m kind: The kind
+0000a4e0: 206f 6620 7275 6e74 696d 6520 746f 2064   of runtime to d
+0000a4f0: 656c 6574 652e 204d 6179 2062 6520 6f6e  elete. May be on
+0000a500: 6520 6f66 2060 5b27 6461 736b 272c 2027  e of `['dask', '
+0000a510: 6a6f 6227 2c20 2773 7061 726b 272c 2027  job', 'spark', '
+0000a520: 7265 6d6f 7465 2d73 7061 726b 272c 2027  remote-spark', '
+0000a530: 6d70 696a 6f62 275d 600a 2020 2020 2020  mpijob']`.      
+0000a540: 2020 3a70 6172 616d 206f 626a 6563 745f    :param object_
+0000a550: 6964 3a20 5468 6520 6964 656e 7469 6669  id: The identifi
+0000a560: 6572 206f 6620 7468 6520 6d6c 7275 6e20  er of the mlrun 
+0000a570: 6f62 6a65 6374 2074 6f20 6465 6c65 7465  object to delete
+0000a580: 2069 7473 2072 756e 7469 6d65 2072 6573   its runtime res
+0000a590: 6f75 7263 6573 2e20 666f 7220 6d6f 7374  ources. for most
+0000a5a0: 2066 756e 6374 696f 6e0a 2020 2020 2020   function.      
+0000a5b0: 2020 2020 2020 7275 6e74 696d 6573 2c20        runtimes, 
+0000a5c0: 7275 6e74 696d 6520 7265 736f 7572 6365  runtime resource
+0000a5d0: 7320 6172 6520 7065 7220 5275 6e2c 2066  s are per Run, f
+0000a5e0: 6f72 2077 6869 6368 2074 6865 2069 6465  or which the ide
+0000a5f0: 6e74 6966 6965 7220 6973 2074 6865 2052  ntifier is the R
+0000a600: 756e 2773 2055 4944 2e20 466f 7220 6461  un's UID. For da
+0000a610: 736b 2072 756e 7469 6d65 2c20 7468 650a  sk runtime, the.
+0000a620: 2020 2020 2020 2020 2020 2020 7275 6e74              runt
+0000a630: 696d 6520 7265 736f 7572 6365 7320 6172  ime resources ar
+0000a640: 6520 7065 7220 4675 6e63 7469 6f6e 2c20  e per Function, 
+0000a650: 666f 7220 7768 6963 6820 7468 6520 6964  for which the id
+0000a660: 656e 7469 6669 6572 2069 7320 7468 6520  entifier is the 
+0000a670: 4675 6e63 7469 6f6e 2773 206e 616d 652e  Function's name.
+0000a680: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0000a690: 666f 7263 653a 2046 6f72 6365 2064 656c  force: Force del
+0000a6a0: 6574 696f 6e20 2d20 6465 6c65 7465 2074  etion - delete t
+0000a6b0: 6865 2072 756e 7469 6d65 2072 6573 6f75  he runtime resou
+0000a6c0: 7263 6520 6576 656e 2069 6620 6974 2773  rce even if it's
+0000a6d0: 206e 6f74 2069 6e20 7465 726d 696e 616c   not in terminal
+0000a6e0: 2073 7461 7465 206f 7220 6966 2074 6865   state or if the
+0000a6f0: 2067 7261 6365 0a20 2020 2020 2020 2020   grace.         
+0000a700: 2020 2070 6572 696f 6420 6469 646e 2774     period didn't
+0000a710: 2070 6173 732e 0a20 2020 2020 2020 203a   pass..        :
+0000a720: 7061 7261 6d20 6772 6163 655f 7065 7269  param grace_peri
+0000a730: 6f64 3a20 4772 6163 6520 7065 7269 6f64  od: Grace period
+0000a740: 2067 6976 656e 2074 6f20 7468 6520 7275   given to the ru
+0000a750: 6e74 696d 6520 7265 736f 7572 6365 2062  ntime resource b
+0000a760: 6566 6f72 6520 7468 6579 2061 7265 2061  efore they are a
+0000a770: 6374 7561 6c6c 7920 7265 6d6f 7665 642c  ctually removed,
+0000a780: 2063 6f75 6e74 6564 2066 726f 6d0a 2020   counted from.  
+0000a790: 2020 2020 2020 2020 2020 7468 6520 6d6f            the mo
+0000a7a0: 6d65 6e74 2074 6865 7920 6d6f 7665 6420  ment they moved 
+0000a7b0: 746f 2074 6572 6d69 6e61 6c20 7374 6174  to terminal stat
+0000a7c0: 6520 2864 6566 6175 6c74 7320 746f 206d  e (defaults to m
+0000a7d0: 6c72 756e 2e6d 6c63 6f6e 662e 7275 6e74  lrun.mlconf.runt
+0000a7e0: 696d 655f 7265 736f 7572 6365 735f 6465  ime_resources_de
+0000a7f0: 6c65 7469 6f6e 5f67 7261 6365 5f70 6572  letion_grace_per
+0000a800: 696f 6429 2e0a 0a20 2020 2020 2020 203a  iod)...        :
+0000a810: 7265 7475 726e 733a 203a 7079 3a63 6c61  returns: :py:cla
+0000a820: 7373 3a60 7e6d 6c72 756e 2e61 7069 2e73  ss:`~mlrun.api.s
+0000a830: 6368 656d 6173 2e47 726f 7570 6564 4279  chemas.GroupedBy
+0000a840: 5072 6f6a 6563 7452 756e 7469 6d65 5265  ProjectRuntimeRe
+0000a850: 736f 7572 6365 734f 7574 7075 7460 206c  sourcesOutput` l
+0000a860: 6973 7469 6e67 2074 6865 2072 756e 7469  isting the runti
+0000a870: 6d65 2072 6573 6f75 7263 6573 0a20 2020  me resources.   
+0000a880: 2020 2020 2020 2020 2074 6861 7420 7765           that we
+0000a890: 7265 2072 656d 6f76 6564 2e0a 2020 2020  re removed..    
+0000a8a0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0000a8b0: 6966 2067 7261 6365 5f70 6572 696f 6420  if grace_period 
+0000a8c0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+0000a8d0: 2020 2020 2067 7261 6365 5f70 6572 696f       grace_perio
+0000a8e0: 6420 3d20 636f 6e66 6967 2e72 756e 7469  d = config.runti
+0000a8f0: 6d65 5f72 6573 6f75 7263 6573 5f64 656c  me_resources_del
+0000a900: 6574 696f 6e5f 6772 6163 655f 7065 7269  etion_grace_peri
+0000a910: 6f64 0a20 2020 2020 2020 2020 2020 206c  od.            l
+0000a920: 6f67 6765 722e 696e 666f 280a 2020 2020  ogger.info(.    
+0000a930: 2020 2020 2020 2020 2020 2020 2255 7369              "Usi
+0000a940: 6e67 2064 6566 6175 6c74 2067 7261 6365  ng default grace
+0000a950: 2070 6572 696f 6420 666f 7220 7275 6e74   period for runt
+0000a960: 696d 6520 7265 736f 7572 6365 7320 6465  ime resources de
+0000a970: 6c65 7469 6f6e 222c 0a20 2020 2020 2020  letion",.       
+0000a980: 2020 2020 2020 2020 2067 7261 6365 5f70           grace_p
+0000a990: 6572 696f 643d 6772 6163 655f 7065 7269  eriod=grace_peri
+0000a9a0: 6f64 2c0a 2020 2020 2020 2020 2020 2020  od,.            
+0000a9b0: 290a 0a20 2020 2020 2020 2070 6172 616d  )..        param
+0000a9c0: 7320 3d20 7b0a 2020 2020 2020 2020 2020  s = {.          
+0000a9d0: 2020 226c 6162 656c 2d73 656c 6563 746f    "label-selecto
+0000a9e0: 7222 3a20 6c61 6265 6c5f 7365 6c65 6374  r": label_select
+0000a9f0: 6f72 2c0a 2020 2020 2020 2020 2020 2020  or,.            
+0000aa00: 226b 696e 6422 3a20 6b69 6e64 2c0a 2020  "kind": kind,.  
+0000aa10: 2020 2020 2020 2020 2020 226f 626a 6563            "objec
+0000aa20: 742d 6964 223a 206f 626a 6563 745f 6964  t-id": object_id
+0000aa30: 2c0a 2020 2020 2020 2020 2020 2020 2266  ,.            "f
+0000aa40: 6f72 6365 223a 2066 6f72 6365 2c0a 2020  orce": force,.  
+0000aa50: 2020 2020 2020 2020 2020 2267 7261 6365            "grace
+0000aa60: 2d70 6572 696f 6422 3a20 6772 6163 655f  -period": grace_
+0000aa70: 7065 7269 6f64 2c0a 2020 2020 2020 2020  period,.        
+0000aa80: 7d0a 2020 2020 2020 2020 6572 726f 7220  }.        error 
+0000aa90: 3d20 2246 6169 6c65 6420 6465 6c65 7469  = "Failed deleti
+0000aaa0: 6e67 2072 756e 7469 6d65 2072 6573 6f75  ng runtime resou
+0000aab0: 7263 6573 220a 2020 2020 2020 2020 7072  rces".        pr
+0000aac0: 6f6a 6563 745f 7061 7468 203d 2070 726f  oject_path = pro
+0000aad0: 6a65 6374 2069 6620 7072 6f6a 6563 7420  ject if project 
+0000aae0: 656c 7365 2022 2a22 0a20 2020 2020 2020  else "*".       
+0000aaf0: 2072 6573 706f 6e73 6520 3d20 7365 6c66   response = self
+0000ab00: 2e61 7069 5f63 616c 6c28 0a20 2020 2020  .api_call(.     
+0000ab10: 2020 2020 2020 2022 4445 4c45 5445 222c         "DELETE",
+0000ab20: 0a20 2020 2020 2020 2020 2020 2066 2270  .            f"p
+0000ab30: 726f 6a65 6374 732f 7b70 726f 6a65 6374  rojects/{project
+0000ab40: 5f70 6174 687d 2f72 756e 7469 6d65 2d72  _path}/runtime-r
+0000ab50: 6573 6f75 7263 6573 222c 0a20 2020 2020  esources",.     
+0000ab60: 2020 2020 2020 2065 7272 6f72 2c0a 2020         error,.  
+0000ab70: 2020 2020 2020 2020 2020 7061 7261 6d73            params
+0000ab80: 3d70 6172 616d 732c 0a20 2020 2020 2020  =params,.       
+0000ab90: 2029 0a20 2020 2020 2020 2073 7472 7563   ).        struc
+0000aba0: 7475 7265 645f 6469 6374 203d 207b 7d0a  tured_dict = {}.
+0000abb0: 2020 2020 2020 2020 666f 7220 7072 6f6a          for proj
+0000abc0: 6563 742c 206b 696e 645f 7275 6e74 696d  ect, kind_runtim
+0000abd0: 655f 7265 736f 7572 6365 735f 6d61 7020  e_resources_map 
+0000abe0: 696e 2072 6573 706f 6e73 652e 6a73 6f6e  in response.json
+0000abf0: 2829 2e69 7465 6d73 2829 3a0a 2020 2020  ().items():.    
+0000ac00: 2020 2020 2020 2020 666f 7220 6b69 6e64          for kind
+0000ac10: 2c20 7275 6e74 696d 655f 7265 736f 7572  , runtime_resour
+0000ac20: 6365 7320 696e 206b 696e 645f 7275 6e74  ces in kind_runt
+0000ac30: 696d 655f 7265 736f 7572 6365 735f 6d61  ime_resources_ma
+0000ac40: 702e 6974 656d 7328 293a 0a20 2020 2020  p.items():.     
+0000ac50: 2020 2020 2020 2020 2020 2073 7472 7563             struc
+0000ac60: 7475 7265 645f 6469 6374 2e73 6574 6465  tured_dict.setde
+0000ac70: 6661 756c 7428 7072 6f6a 6563 742c 207b  fault(project, {
+0000ac80: 7d29 5b0a 2020 2020 2020 2020 2020 2020  })[.            
+0000ac90: 2020 2020 2020 2020 6b69 6e64 0a20 2020          kind.   
+0000aca0: 2020 2020 2020 2020 2020 2020 205d 203d               ] =
+0000acb0: 206d 6c72 756e 2e61 7069 2e73 6368 656d   mlrun.api.schem
+0000acc0: 6173 2e52 756e 7469 6d65 5265 736f 7572  as.RuntimeResour
+0000acd0: 6365 7328 2a2a 7275 6e74 696d 655f 7265  ces(**runtime_re
+0000ace0: 736f 7572 6365 7329 0a20 2020 2020 2020  sources).       
+0000acf0: 2072 6574 7572 6e20 7374 7275 6374 7572   return structur
+0000ad00: 6564 5f64 6963 740a 0a20 2020 2064 6566  ed_dict..    def
+0000ad10: 2063 7265 6174 655f 7363 6865 6475 6c65   create_schedule
+0000ad20: 2873 656c 662c 2070 726f 6a65 6374 3a20  (self, project: 
+0000ad30: 7374 722c 2073 6368 6564 756c 653a 2073  str, schedule: s
+0000ad40: 6368 656d 6173 2e53 6368 6564 756c 6549  chemas.ScheduleI
+0000ad50: 6e70 7574 293a 0a20 2020 2020 2020 2022  nput):.        "
+0000ad60: 2222 4372 6561 7465 2061 206e 6577 2073  ""Create a new s
+0000ad70: 6368 6564 756c 6520 6f6e 2074 6865 2067  chedule on the g
+0000ad80: 6976 656e 2070 726f 6a65 6374 2e20 5468  iven project. Th
+0000ad90: 6520 6465 7461 696c 7320 6f6e 2074 6865  e details on the
+0000ada0: 2061 6374 7561 6c20 6f62 6a65 6374 2074   actual object t
+0000adb0: 6f20 7363 6865 6475 6c65 2061 7320 7765  o schedule as we
+0000adc0: 6c6c 2061 7320 7468 650a 2020 2020 2020  ll as the.      
+0000add0: 2020 7363 6865 6475 6c65 2069 7473 656c    schedule itsel
+0000ade0: 6620 6172 6520 7769 7468 696e 2074 6865  f are within the
+0000adf0: 2073 6368 6564 756c 6520 6f62 6a65 6374   schedule object
+0000ae00: 2070 726f 7669 6465 642e 0a20 2020 2020   provided..     
+0000ae10: 2020 2054 6865 203a 7079 3a63 6c61 7373     The :py:class
+0000ae20: 3a60 7e53 6368 6564 756c 6543 726f 6e54  :`~ScheduleCronT
+0000ae30: 7269 6767 6572 6020 666f 6c6c 6f77 7320  rigger` follows 
+0000ae40: 7468 6520 6775 6964 656c 696e 6573 2069  the guidelines i
+0000ae50: 6e0a 2020 2020 2020 2020 6874 7470 733a  n.        https:
+0000ae60: 2f2f 6170 7363 6865 6475 6c65 722e 7265  //apscheduler.re
+0000ae70: 6164 7468 6564 6f63 732e 696f 2f65 6e2f  adthedocs.io/en/
+0000ae80: 332e 782f 6d6f 6475 6c65 732f 7472 6967  3.x/modules/trig
+0000ae90: 6765 7273 2f63 726f 6e2e 6874 6d6c 2e0a  gers/cron.html..
+0000aea0: 2020 2020 2020 2020 4974 2061 6c73 6f20          It also 
+0000aeb0: 7375 7070 6f72 7473 2061 203a 7079 3a66  supports a :py:f
+0000aec0: 756e 633a 607e 5363 6865 6475 6c65 4372  unc:`~ScheduleCr
+0000aed0: 6f6e 5472 6967 6765 722e 6672 6f6d 5f63  onTrigger.from_c
+0000aee0: 726f 6e74 6162 6020 6675 6e63 7469 6f6e  rontab` function
+0000aef0: 2074 6861 7420 6163 6365 7074 7320 610a   that accepts a.
+0000af00: 2020 2020 2020 2020 6372 6f6e 7461 622d          crontab-
+0000af10: 666f 726d 6174 7465 6420 7374 7269 6e67  formatted string
+0000af20: 2028 7365 6520 6874 7470 733a 2f2f 656e   (see https://en
+0000af30: 2e77 696b 6970 6564 6961 2e6f 7267 2f77  .wikipedia.org/w
+0000af40: 696b 692f 4372 6f6e 2066 6f72 206d 6f72  iki/Cron for mor
+0000af50: 6520 696e 666f 726d 6174 696f 6e20 6f6e  e information on
+0000af60: 2074 6865 2066 6f72 6d61 7420 616e 640a   the format and.
+0000af70: 2020 2020 2020 2020 6e6f 7465 2074 6861          note tha
+0000af80: 7420 7468 6520 3020 7765 656b 6461 7920  t the 0 weekday 
+0000af90: 6973 2061 6c77 6179 7320 6d6f 6e64 6179  is always monday
+0000afa0: 292e 0a0a 0a20 2020 2020 2020 2045 7861  )....        Exa
+0000afb0: 6d70 6c65 3a3a 0a0a 2020 2020 2020 2020  mple::..        
+0000afc0: 2020 2020 6672 6f6d 206d 6c72 756e 2e61      from mlrun.a
+0000afd0: 7069 2069 6d70 6f72 7420 7363 6865 6d61  pi import schema
+0000afe0: 730a 0a20 2020 2020 2020 2020 2020 2023  s..            #
+0000aff0: 2045 7865 6375 7465 2074 6865 2067 6574   Execute the get
+0000b000: 5f64 6174 615f 6675 6e63 2066 756e 6374  _data_func funct
+0000b010: 696f 6e20 6576 6572 7920 5475 6573 6461  ion every Tuesda
+0000b020: 7920 6174 2031 353a 3330 0a20 2020 2020  y at 15:30.     
+0000b030: 2020 2020 2020 2073 6368 6564 756c 6520         schedule 
+0000b040: 3d20 7363 6865 6d61 732e 5363 6865 6475  = schemas.Schedu
+0000b050: 6c65 496e 7075 7428 0a20 2020 2020 2020  leInput(.       
+0000b060: 2020 2020 2020 2020 206e 616d 653d 2272           name="r
+0000b070: 756e 5f66 756e 635f 6f6e 5f74 7565 7364  un_func_on_tuesd
+0000b080: 6179 7322 2c0a 2020 2020 2020 2020 2020  ays",.          
+0000b090: 2020 2020 2020 6b69 6e64 3d22 6a6f 6222        kind="job"
+0000b0a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000b0b0: 2020 7363 6865 6475 6c65 645f 6f62 6a65    scheduled_obje
+0000b0c0: 6374 3d67 6574 5f64 6174 615f 6675 6e63  ct=get_data_func
+0000b0d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000b0e0: 2020 6372 6f6e 5f74 7269 6767 6572 3d73    cron_trigger=s
+0000b0f0: 6368 656d 6173 2e53 6368 6564 756c 6543  chemas.ScheduleC
+0000b100: 726f 6e54 7269 6767 6572 2864 6179 5f6f  ronTrigger(day_o
+0000b110: 665f 7765 656b 3d27 7475 6527 2c20 686f  f_week='tue', ho
+0000b120: 7572 3d31 352c 206d 696e 7574 653d 3330  ur=15, minute=30
+0000b130: 292c 0a20 2020 2020 2020 2020 2020 2029  ),.            )
+0000b140: 0a20 2020 2020 2020 2020 2020 2064 622e  .            db.
+0000b150: 6372 6561 7465 5f73 6368 6564 756c 6528  create_schedule(
+0000b160: 7072 6f6a 6563 745f 6e61 6d65 2c20 7363  project_name, sc
+0000b170: 6865 6475 6c65 290a 2020 2020 2020 2020  hedule).        
+0000b180: 2222 220a 0a20 2020 2020 2020 2070 726f  """..        pro
+0000b190: 6a65 6374 203d 2070 726f 6a65 6374 206f  ject = project o
+0000b1a0: 7220 636f 6e66 6967 2e64 6566 6175 6c74  r config.default
+0000b1b0: 5f70 726f 6a65 6374 0a20 2020 2020 2020  _project.       
+0000b1c0: 2070 6174 6820 3d20 6622 7072 6f6a 6563   path = f"projec
+0000b1d0: 7473 2f7b 7072 6f6a 6563 747d 2f73 6368  ts/{project}/sch
+0000b1e0: 6564 756c 6573 220a 0a20 2020 2020 2020  edules"..       
+0000b1f0: 2065 7272 6f72 5f6d 6573 7361 6765 203d   error_message =
+0000b200: 2066 2246 6169 6c65 6420 6372 6561 7469   f"Failed creati
+0000b210: 6e67 2073 6368 6564 756c 6520 7b70 726f  ng schedule {pro
+0000b220: 6a65 6374 7d2f 7b73 6368 6564 756c 652e  ject}/{schedule.
+0000b230: 6e61 6d65 7d22 0a20 2020 2020 2020 2073  name}".        s
+0000b240: 656c 662e 6170 695f 6361 6c6c 2822 504f  elf.api_call("PO
+0000b250: 5354 222c 2070 6174 682c 2065 7272 6f72  ST", path, error
+0000b260: 5f6d 6573 7361 6765 2c20 626f 6479 3d64  _message, body=d
+0000b270: 6963 745f 746f 5f6a 736f 6e28 7363 6865  ict_to_json(sche
+0000b280: 6475 6c65 2e64 6963 7428 2929 290a 0a20  dule.dict())).. 
+0000b290: 2020 2064 6566 2075 7064 6174 655f 7363     def update_sc
+0000b2a0: 6865 6475 6c65 280a 2020 2020 2020 2020  hedule(.        
+0000b2b0: 7365 6c66 2c20 7072 6f6a 6563 743a 2073  self, project: s
+0000b2c0: 7472 2c20 6e61 6d65 3a20 7374 722c 2073  tr, name: str, s
+0000b2d0: 6368 6564 756c 653a 2073 6368 656d 6173  chedule: schemas
+0000b2e0: 2e53 6368 6564 756c 6555 7064 6174 650a  .ScheduleUpdate.
+0000b2f0: 2020 2020 293a 0a20 2020 2020 2020 2022      ):.        "
+0000b300: 2222 5570 6461 7465 2061 6e20 6578 6973  ""Update an exis
+0000b310: 7469 6e67 2073 6368 6564 756c 652c 2072  ting schedule, r
+0000b320: 6570 6c61 6365 2069 7420 7769 7468 2074  eplace it with t
+0000b330: 6865 2064 6574 6169 6c73 2063 6f6e 7461  he details conta
+0000b340: 696e 6564 2069 6e20 7468 6520 7363 6865  ined in the sche
+0000b350: 6475 6c65 206f 626a 6563 742e 2222 220a  dule object.""".
+0000b360: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
+0000b370: 203d 2070 726f 6a65 6374 206f 7220 636f   = project or co
+0000b380: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
+0000b390: 6a65 6374 0a20 2020 2020 2020 2070 6174  ject.        pat
+0000b3a0: 6820 3d20 6622 7072 6f6a 6563 7473 2f7b  h = f"projects/{
+0000b3b0: 7072 6f6a 6563 747d 2f73 6368 6564 756c  project}/schedul
+0000b3c0: 6573 2f7b 6e61 6d65 7d22 0a0a 2020 2020  es/{name}"..    
+0000b3d0: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+0000b3e0: 6520 3d20 6622 4661 696c 6564 2075 7064  e = f"Failed upd
+0000b3f0: 6174 696e 6720 7363 6865 6475 6c65 207b  ating schedule {
+0000b400: 7072 6f6a 6563 747d 2f7b 6e61 6d65 7d22  project}/{name}"
+0000b410: 0a20 2020 2020 2020 2073 656c 662e 6170  .        self.ap
+0000b420: 695f 6361 6c6c 2822 5055 5422 2c20 7061  i_call("PUT", pa
+0000b430: 7468 2c20 6572 726f 725f 6d65 7373 6167  th, error_messag
+0000b440: 652c 2062 6f64 793d 6469 6374 5f74 6f5f  e, body=dict_to_
+0000b450: 6a73 6f6e 2873 6368 6564 756c 652e 6469  json(schedule.di
+0000b460: 6374 2829 2929 0a0a 2020 2020 6465 6620  ct()))..    def 
+0000b470: 6765 745f 7363 6865 6475 6c65 280a 2020  get_schedule(.  
+0000b480: 2020 2020 2020 7365 6c66 2c20 7072 6f6a        self, proj
+0000b490: 6563 743a 2073 7472 2c20 6e61 6d65 3a20  ect: str, name: 
+0000b4a0: 7374 722c 2069 6e63 6c75 6465 5f6c 6173  str, include_las
+0000b4b0: 745f 7275 6e3a 2062 6f6f 6c20 3d20 4661  t_run: bool = Fa
+0000b4c0: 6c73 650a 2020 2020 2920 2d3e 2073 6368  lse.    ) -> sch
+0000b4d0: 656d 6173 2e53 6368 6564 756c 654f 7574  emas.ScheduleOut
+0000b4e0: 7075 743a 0a20 2020 2020 2020 2022 2222  put:.        """
+0000b4f0: 5265 7472 6965 7665 2064 6574 6169 6c73  Retrieve details
+0000b500: 206f 6620 7468 6520 7363 6865 6475 6c65   of the schedule
+0000b510: 2069 6e20 7175 6573 7469 6f6e 2e20 4265   in question. Be
+0000b520: 7369 6465 7320 7265 7475 726e 696e 6720  sides returning 
+0000b530: 7468 6520 6465 7461 696c 7320 6f66 2074  the details of t
+0000b540: 6865 2073 6368 6564 756c 6520 6f62 6a65  he schedule obje
+0000b550: 6374 2069 7473 656c 662c 0a20 2020 2020  ct itself,.     
+0000b560: 2020 2074 6869 7320 6675 6e63 7469 6f6e     this function
+0000b570: 2061 6c73 6f20 7265 7475 726e 7320 7468   also returns th
+0000b580: 6520 6e65 7874 2073 6368 6564 756c 6564  e next scheduled
+0000b590: 2072 756e 2066 6f72 2074 6869 7320 7370   run for this sp
+0000b5a0: 6563 6966 6963 2073 6368 6564 756c 652c  ecific schedule,
+0000b5b0: 2061 7320 7765 6c6c 2061 7320 706f 7465   as well as pote
+0000b5c0: 6e74 6961 6c6c 7920 7468 650a 2020 2020  ntially the.    
+0000b5d0: 2020 2020 7265 7375 6c74 7320 6f66 2074      results of t
+0000b5e0: 6865 206c 6173 7420 7275 6e20 6578 6563  he last run exec
+0000b5f0: 7574 6564 2074 6872 6f75 6768 2074 6869  uted through thi
+0000b600: 7320 7363 6865 6475 6c65 2e0a 0a20 2020  s schedule...   
+0000b610: 2020 2020 203a 7061 7261 6d20 7072 6f6a       :param proj
+0000b620: 6563 743a 2050 726f 6a65 6374 206e 616d  ect: Project nam
+0000b630: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
+0000b640: 6d20 6e61 6d65 3a20 4e61 6d65 206f 6620  m name: Name of 
+0000b650: 7468 6520 7363 6865 6475 6c65 206f 626a  the schedule obj
+0000b660: 6563 7420 746f 2071 7565 7279 2e0a 2020  ect to query..  
+0000b670: 2020 2020 2020 3a70 6172 616d 2069 6e63        :param inc
+0000b680: 6c75 6465 5f6c 6173 745f 7275 6e3a 2057  lude_last_run: W
+0000b690: 6865 7468 6572 2074 6f20 696e 636c 7564  hether to includ
+0000b6a0: 6520 7468 6520 7265 7375 6c74 7320 6f66  e the results of
+0000b6b0: 2074 6865 2073 6368 6564 756c 6527 7320   the schedule's 
+0000b6c0: 6c61 7374 2072 756e 2069 6e20 7468 6520  last run in the 
+0000b6d0: 7265 7370 6f6e 7365 2e0a 2020 2020 2020  response..      
+0000b6e0: 2020 2222 220a 0a20 2020 2020 2020 2070    """..        p
+0000b6f0: 726f 6a65 6374 203d 2070 726f 6a65 6374  roject = project
+0000b700: 206f 7220 636f 6e66 6967 2e64 6566 6175   or config.defau
+0000b710: 6c74 5f70 726f 6a65 6374 0a20 2020 2020  lt_project.     
+0000b720: 2020 2070 6174 6820 3d20 6622 7072 6f6a     path = f"proj
+0000b730: 6563 7473 2f7b 7072 6f6a 6563 747d 2f73  ects/{project}/s
+0000b740: 6368 6564 756c 6573 2f7b 6e61 6d65 7d22  chedules/{name}"
+0000b750: 0a20 2020 2020 2020 2065 7272 6f72 5f6d  .        error_m
+0000b760: 6573 7361 6765 203d 2066 2246 6169 6c65  essage = f"Faile
+0000b770: 6420 6765 7474 696e 6720 7363 6865 6475  d getting schedu
+0000b780: 6c65 2066 6f72 207b 7072 6f6a 6563 747d  le for {project}
+0000b790: 2f7b 6e61 6d65 7d22 0a20 2020 2020 2020  /{name}".       
+0000b7a0: 2072 6573 7020 3d20 7365 6c66 2e61 7069   resp = self.api
+0000b7b0: 5f63 616c 6c28 0a20 2020 2020 2020 2020  _call(.         
+0000b7c0: 2020 2022 4745 5422 2c20 7061 7468 2c20     "GET", path, 
+0000b7d0: 6572 726f 725f 6d65 7373 6167 652c 2070  error_message, p
+0000b7e0: 6172 616d 733d 7b22 696e 636c 7564 655f  arams={"include_
+0000b7f0: 6c61 7374 5f72 756e 223a 2069 6e63 6c75  last_run": inclu
+0000b800: 6465 5f6c 6173 745f 7275 6e7d 0a20 2020  de_last_run}.   
+0000b810: 2020 2020 2029 0a20 2020 2020 2020 2072       ).        r
+0000b820: 6574 7572 6e20 7363 6865 6d61 732e 5363  eturn schemas.Sc
+0000b830: 6865 6475 6c65 4f75 7470 7574 282a 2a72  heduleOutput(**r
+0000b840: 6573 702e 6a73 6f6e 2829 290a 0a20 2020  esp.json())..   
+0000b850: 2064 6566 206c 6973 745f 7363 6865 6475   def list_schedu
+0000b860: 6c65 7328 0a20 2020 2020 2020 2073 656c  les(.        sel
+0000b870: 662c 0a20 2020 2020 2020 2070 726f 6a65  f,.        proje
+0000b880: 6374 3a20 7374 722c 0a20 2020 2020 2020  ct: str,.       
+0000b890: 206e 616d 653a 2073 7472 203d 204e 6f6e   name: str = Non
+0000b8a0: 652c 0a20 2020 2020 2020 206b 696e 643a  e,.        kind:
+0000b8b0: 2073 6368 656d 6173 2e53 6368 6564 756c   schemas.Schedul
+0000b8c0: 654b 696e 6473 203d 204e 6f6e 652c 0a20  eKinds = None,. 
+0000b8d0: 2020 2020 2020 2069 6e63 6c75 6465 5f6c         include_l
+0000b8e0: 6173 745f 7275 6e3a 2062 6f6f 6c20 3d20  ast_run: bool = 
+0000b8f0: 4661 6c73 652c 0a20 2020 2029 202d 3e20  False,.    ) -> 
+0000b900: 7363 6865 6d61 732e 5363 6865 6475 6c65  schemas.Schedule
+0000b910: 734f 7574 7075 743a 0a20 2020 2020 2020  sOutput:.       
+0000b920: 2022 2222 5265 7472 6965 7665 206c 6973   """Retrieve lis
+0000b930: 7420 6f66 2073 6368 6564 756c 6573 206f  t of schedules o
+0000b940: 6620 7370 6563 6966 6963 206e 616d 6520  f specific name 
+0000b950: 6f72 206b 696e 642e 0a0a 2020 2020 2020  or kind...      
+0000b960: 2020 3a70 6172 616d 2070 726f 6a65 6374    :param project
+0000b970: 3a20 5072 6f6a 6563 7420 6e61 6d65 2e0a  : Project name..
+0000b980: 2020 2020 2020 2020 3a70 6172 616d 206e          :param n
+0000b990: 616d 653a 204e 616d 6520 6f66 2073 6368  ame: Name of sch
+0000b9a0: 6564 756c 6520 746f 2072 6574 7269 6576  edule to retriev
+0000b9b0: 652e 2043 616e 2062 6520 6f6d 6974 7465  e. Can be omitte
+0000b9c0: 6420 746f 206c 6973 7420 616c 6c20 7363  d to list all sc
+0000b9d0: 6865 6475 6c65 732e 0a20 2020 2020 2020  hedules..       
+0000b9e0: 203a 7061 7261 6d20 6b69 6e64 3a20 4b69   :param kind: Ki
+0000b9f0: 6e64 206f 6620 7363 6865 6475 6c65 206f  nd of schedule o
+0000ba00: 626a 6563 7473 2074 6f20 7265 7472 6965  bjects to retrie
+0000ba10: 7665 2c20 6361 6e20 6265 2065 6974 6865  ve, can be eithe
+0000ba20: 7220 6060 6a6f 6260 6020 6f72 2060 6070  r ``job`` or ``p
+0000ba30: 6970 656c 696e 6560 602e 0a20 2020 2020  ipeline``..     
+0000ba40: 2020 203a 7061 7261 6d20 696e 636c 7564     :param includ
+0000ba50: 655f 6c61 7374 5f72 756e 3a20 5768 6574  e_last_run: Whet
+0000ba60: 6865 7220 746f 2072 6574 7572 6e20 666f  her to return fo
+0000ba70: 7220 6561 6368 2073 6368 6564 756c 6520  r each schedule 
+0000ba80: 7265 7475 726e 6564 2061 6c73 6f20 7468  returned also th
+0000ba90: 6520 7265 7375 6c74 7320 6f66 2074 6865  e results of the
+0000baa0: 206c 6173 7420 7275 6e20 6f66 0a20 2020   last run of.   
+0000bab0: 2020 2020 2020 2020 2074 6861 7420 7363           that sc
+0000bac0: 6865 6475 6c65 2e0a 2020 2020 2020 2020  hedule..        
+0000bad0: 2222 220a 0a20 2020 2020 2020 2070 726f  """..        pro
+0000bae0: 6a65 6374 203d 2070 726f 6a65 6374 206f  ject = project o
+0000baf0: 7220 636f 6e66 6967 2e64 6566 6175 6c74  r config.default
+0000bb00: 5f70 726f 6a65 6374 0a20 2020 2020 2020  _project.       
+0000bb10: 2070 6172 616d 7320 3d20 7b22 6b69 6e64   params = {"kind
+0000bb20: 223a 206b 696e 642c 2022 6e61 6d65 223a  ": kind, "name":
+0000bb30: 206e 616d 652c 2022 696e 636c 7564 655f   name, "include_
+0000bb40: 6c61 7374 5f72 756e 223a 2069 6e63 6c75  last_run": inclu
+0000bb50: 6465 5f6c 6173 745f 7275 6e7d 0a20 2020  de_last_run}.   
+0000bb60: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
+0000bb70: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
+0000bb80: 2f73 6368 6564 756c 6573 220a 2020 2020  /schedules".    
+0000bb90: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+0000bba0: 6520 3d20 6622 4661 696c 6564 206c 6973  e = f"Failed lis
+0000bbb0: 7469 6e67 2073 6368 6564 756c 6573 2066  ting schedules f
+0000bbc0: 6f72 207b 7072 6f6a 6563 747d 203f 207b  or {project} ? {
+0000bbd0: 6b69 6e64 7d20 7b6e 616d 657d 220a 2020  kind} {name}".  
+0000bbe0: 2020 2020 2020 7265 7370 203d 2073 656c        resp = sel
+0000bbf0: 662e 6170 695f 6361 6c6c 2822 4745 5422  f.api_call("GET"
+0000bc00: 2c20 7061 7468 2c20 6572 726f 725f 6d65  , path, error_me
+0000bc10: 7373 6167 652c 2070 6172 616d 733d 7061  ssage, params=pa
+0000bc20: 7261 6d73 290a 2020 2020 2020 2020 7265  rams).        re
+0000bc30: 7475 726e 2073 6368 656d 6173 2e53 6368  turn schemas.Sch
+0000bc40: 6564 756c 6573 4f75 7470 7574 282a 2a72  edulesOutput(**r
+0000bc50: 6573 702e 6a73 6f6e 2829 290a 0a20 2020  esp.json())..   
+0000bc60: 2064 6566 2064 656c 6574 655f 7363 6865   def delete_sche
+0000bc70: 6475 6c65 2873 656c 662c 2070 726f 6a65  dule(self, proje
+0000bc80: 6374 3a20 7374 722c 206e 616d 653a 2073  ct: str, name: s
+0000bc90: 7472 293a 0a20 2020 2020 2020 2022 2222  tr):.        """
+0000bca0: 4465 6c65 7465 2061 2073 7065 6369 6669  Delete a specifi
+0000bcb0: 6320 7363 6865 6475 6c65 2062 7920 6e61  c schedule by na
+0000bcc0: 6d65 2e22 2222 0a0a 2020 2020 2020 2020  me."""..        
+0000bcd0: 7072 6f6a 6563 7420 3d20 7072 6f6a 6563  project = projec
+0000bce0: 7420 6f72 2063 6f6e 6669 672e 6465 6661  t or config.defa
+0000bcf0: 756c 745f 7072 6f6a 6563 740a 2020 2020  ult_project.    
+0000bd00: 2020 2020 7061 7468 203d 2066 2270 726f      path = f"pro
+0000bd10: 6a65 6374 732f 7b70 726f 6a65 6374 7d2f  jects/{project}/
+0000bd20: 7363 6865 6475 6c65 732f 7b6e 616d 657d  schedules/{name}
+0000bd30: 220a 2020 2020 2020 2020 6572 726f 725f  ".        error_
+0000bd40: 6d65 7373 6167 6520 3d20 6622 4661 696c  message = f"Fail
+0000bd50: 6564 2064 656c 6574 696e 6720 7363 6865  ed deleting sche
+0000bd60: 6475 6c65 207b 7072 6f6a 6563 747d 2f7b  dule {project}/{
+0000bd70: 6e61 6d65 7d22 0a20 2020 2020 2020 2073  name}".        s
+0000bd80: 656c 662e 6170 695f 6361 6c6c 2822 4445  elf.api_call("DE
+0000bd90: 4c45 5445 222c 2070 6174 682c 2065 7272  LETE", path, err
+0000bda0: 6f72 5f6d 6573 7361 6765 290a 0a20 2020  or_message)..   
+0000bdb0: 2064 6566 2069 6e76 6f6b 655f 7363 6865   def invoke_sche
+0000bdc0: 6475 6c65 2873 656c 662c 2070 726f 6a65  dule(self, proje
+0000bdd0: 6374 3a20 7374 722c 206e 616d 653a 2073  ct: str, name: s
+0000bde0: 7472 293a 0a20 2020 2020 2020 2022 2222  tr):.        """
+0000bdf0: 4578 6563 7574 6520 7468 6520 6f62 6a65  Execute the obje
+0000be00: 6374 2072 6566 6572 656e 6365 6420 6279  ct referenced by
+0000be10: 2074 6865 2073 6368 6564 756c 6520 696d   the schedule im
+0000be20: 6d65 6469 6174 656c 792e 2222 220a 0a20  mediately.""".. 
+0000be30: 2020 2020 2020 2070 726f 6a65 6374 203d         project =
+0000be40: 2070 726f 6a65 6374 206f 7220 636f 6e66   project or conf
+0000be50: 6967 2e64 6566 6175 6c74 5f70 726f 6a65  ig.default_proje
+0000be60: 6374 0a20 2020 2020 2020 2070 6174 6820  ct.        path 
+0000be70: 3d20 6622 7072 6f6a 6563 7473 2f7b 7072  = f"projects/{pr
+0000be80: 6f6a 6563 747d 2f73 6368 6564 756c 6573  oject}/schedules
+0000be90: 2f7b 6e61 6d65 7d2f 696e 766f 6b65 220a  /{name}/invoke".
+0000bea0: 2020 2020 2020 2020 6572 726f 725f 6d65          error_me
+0000beb0: 7373 6167 6520 3d20 6622 4661 696c 6564  ssage = f"Failed
+0000bec0: 2069 6e76 6f6b 696e 6720 7363 6865 6475   invoking schedu
+0000bed0: 6c65 207b 7072 6f6a 6563 747d 2f7b 6e61  le {project}/{na
+0000bee0: 6d65 7d22 0a20 2020 2020 2020 2073 656c  me}".        sel
+0000bef0: 662e 6170 695f 6361 6c6c 2822 504f 5354  f.api_call("POST
+0000bf00: 222c 2070 6174 682c 2065 7272 6f72 5f6d  ", path, error_m
+0000bf10: 6573 7361 6765 290a 0a20 2020 2064 6566  essage)..    def
+0000bf20: 2072 656d 6f74 655f 6275 696c 6465 7228   remote_builder(
+0000bf30: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+0000bf40: 2020 2020 2020 2066 756e 632c 0a20 2020         func,.   
+0000bf50: 2020 2020 2077 6974 685f 6d6c 7275 6e2c       with_mlrun,
+0000bf60: 0a20 2020 2020 2020 206d 6c72 756e 5f76  .        mlrun_v
+0000bf70: 6572 7369 6f6e 5f73 7065 6369 6669 6572  ersion_specifier
+0000bf80: 3d4e 6f6e 652c 0a20 2020 2020 2020 2073  =None,.        s
+0000bf90: 6b69 705f 6465 706c 6f79 6564 3d46 616c  kip_deployed=Fal
+0000bfa0: 7365 2c0a 2020 2020 2020 2020 6275 696c  se,.        buil
+0000bfb0: 6465 725f 656e 763d 4e6f 6e65 2c0a 2020  der_env=None,.  
+0000bfc0: 2020 293a 0a20 2020 2020 2020 2022 2222    ):.        """
+0000bfd0: 4275 696c 6420 7468 6520 706f 6420 696d  Build the pod im
+0000bfe0: 6167 6520 666f 7220 6120 6675 6e63 7469  age for a functi
+0000bff0: 6f6e 2c20 666f 7220 6578 6563 7574 696f  on, for executio
+0000c000: 6e20 6f6e 2061 2072 656d 6f74 6520 636c  n on a remote cl
+0000c010: 7573 7465 722e 2054 6869 7320 6973 2065  uster. This is e
+0000c020: 7865 6375 7465 6420 6279 2074 6865 204d  xecuted by the M
+0000c030: 4c52 756e 0a20 2020 2020 2020 2041 5049  LRun.        API
+0000c040: 2073 6572 7665 722c 2061 6e64 2063 7265   server, and cre
+0000c050: 6174 6573 2061 2044 6f63 6b65 7220 696d  ates a Docker im
+0000c060: 6167 6520 6f75 7420 6f66 2074 6865 2066  age out of the f
+0000c070: 756e 6374 696f 6e20 7072 6f76 6964 6564  unction provided
+0000c080: 2061 6e64 2061 6e79 2073 7065 6369 6669   and any specifi
+0000c090: 6320 6275 696c 640a 2020 2020 2020 2020  c build.        
+0000c0a0: 696e 7374 7275 6374 696f 6e73 2070 726f  instructions pro
+0000c0b0: 7669 6465 6420 7769 7468 696e 2e20 5468  vided within. Th
+0000c0c0: 6973 2069 7320 6120 7072 652d 7265 7175  is is a pre-requ
+0000c0d0: 6973 6974 6520 666f 7220 7265 6d6f 7465  isite for remote
+0000c0e0: 6c79 2065 7865 6375 7469 6e67 2061 2066  ly executing a f
+0000c0f0: 756e 6374 696f 6e2c 2075 6e6c 6573 7320  unction, unless 
+0000c100: 7573 696e 670a 2020 2020 2020 2020 6120  using.        a 
+0000c110: 7072 652d 6465 706c 6f79 6564 2069 6d61  pre-deployed ima
+0000c120: 6765 2e0a 0a20 2020 2020 2020 203a 7061  ge...        :pa
+0000c130: 7261 6d20 6675 6e63 3a20 4675 6e63 7469  ram func: Functi
+0000c140: 6f6e 2074 6f20 6275 696c 642e 0a20 2020  on to build..   
+0000c150: 2020 2020 203a 7061 7261 6d20 7769 7468       :param with
+0000c160: 5f6d 6c72 756e 3a20 5768 6574 6865 7220  _mlrun: Whether 
+0000c170: 746f 2061 6464 204d 4c52 756e 2070 6163  to add MLRun pac
+0000c180: 6b61 6765 2074 6f20 7468 6520 6275 696c  kage to the buil
+0000c190: 7420 7061 636b 6167 652e 2054 6869 7320  t package. This 
+0000c1a0: 6973 206e 6f74 2072 6571 7569 7265 6420  is not required 
+0000c1b0: 6966 2075 7369 6e67 2061 2062 6173 650a  if using a base.
+0000c1c0: 2020 2020 2020 2020 2020 2020 696d 6167              imag
+0000c1d0: 6520 7468 6174 2061 6c72 6561 6479 2068  e that already h
+0000c1e0: 6173 204d 4c52 756e 2069 6e20 6974 2e0a  as MLRun in it..
+0000c1f0: 2020 2020 2020 2020 3a70 6172 616d 206d          :param m
+0000c200: 6c72 756e 5f76 6572 7369 6f6e 5f73 7065  lrun_version_spe
+0000c210: 6369 6669 6572 3a20 5665 7273 696f 6e20  cifier: Version 
+0000c220: 6f66 204d 4c52 756e 2074 6f20 696e 636c  of MLRun to incl
+0000c230: 7564 6520 696e 2074 6865 2062 7569 6c74  ude in the built
+0000c240: 2069 6d61 6765 2e0a 2020 2020 2020 2020   image..        
+0000c250: 3a70 6172 616d 2073 6b69 705f 6465 706c  :param skip_depl
+0000c260: 6f79 6564 3a20 536b 6970 2074 6865 2062  oyed: Skip the b
+0000c270: 7569 6c64 2069 6620 7765 2061 6c72 6561  uild if we alrea
+0000c280: 6479 2068 6176 6520 616e 2069 6d61 6765  dy have an image
+0000c290: 2066 6f72 2074 6865 2066 756e 6374 696f   for the functio
+0000c2a0: 6e2e 0a20 2020 2020 2020 203a 7061 7261  n..        :para
+0000c2b0: 6d20 6275 696c 6465 725f 656e 763a 2020  m builder_env:  
+0000c2c0: 204b 616e 696b 6f20 6275 696c 6465 7220   Kaniko builder 
+0000c2d0: 706f 6420 656e 7620 7661 7273 2064 6963  pod env vars dic
+0000c2e0: 7420 2866 6f72 2063 6f6e 6669 672f 6372  t (for config/cr
+0000c2f0: 6564 656e 7469 616c 7329 0a20 2020 2020  edentials).     
+0000c300: 2020 2022 2222 0a0a 2020 2020 2020 2020     """..        
+0000c310: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
+0000c320: 2072 6571 203d 207b 0a20 2020 2020 2020   req = {.       
+0000c330: 2020 2020 2020 2020 2022 6675 6e63 7469           "functi
+0000c340: 6f6e 223a 2066 756e 632e 746f 5f64 6963  on": func.to_dic
+0000c350: 7428 292c 0a20 2020 2020 2020 2020 2020  t(),.           
+0000c360: 2020 2020 2022 7769 7468 5f6d 6c72 756e       "with_mlrun
+0000c370: 223a 2062 6f6f 6c32 7374 7228 7769 7468  ": bool2str(with
+0000c380: 5f6d 6c72 756e 292c 0a20 2020 2020 2020  _mlrun),.       
+0000c390: 2020 2020 2020 2020 2022 736b 6970 5f64           "skip_d
+0000c3a0: 6570 6c6f 7965 6422 3a20 736b 6970 5f64  eployed": skip_d
+0000c3b0: 6570 6c6f 7965 642c 0a20 2020 2020 2020  eployed,.       
+0000c3c0: 2020 2020 207d 0a20 2020 2020 2020 2020       }.         
+0000c3d0: 2020 2069 6620 6d6c 7275 6e5f 7665 7273     if mlrun_vers
+0000c3e0: 696f 6e5f 7370 6563 6966 6965 723a 0a20  ion_specifier:. 
+0000c3f0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0000c400: 6571 5b22 6d6c 7275 6e5f 7665 7273 696f  eq["mlrun_versio
+0000c410: 6e5f 7370 6563 6966 6965 7222 5d20 3d20  n_specifier"] = 
+0000c420: 6d6c 7275 6e5f 7665 7273 696f 6e5f 7370  mlrun_version_sp
+0000c430: 6563 6966 6965 720a 2020 2020 2020 2020  ecifier.        
+0000c440: 2020 2020 6966 2062 7569 6c64 6572 5f65      if builder_e
+0000c450: 6e76 3a0a 2020 2020 2020 2020 2020 2020  nv:.            
+0000c460: 2020 2020 7265 715b 2262 7569 6c64 6572      req["builder
+0000c470: 5f65 6e76 225d 203d 2062 7569 6c64 6572  _env"] = builder
+0000c480: 5f65 6e76 0a20 2020 2020 2020 2020 2020  _env.           
+0000c490: 2072 6573 7020 3d20 7365 6c66 2e61 7069   resp = self.api
+0000c4a0: 5f63 616c 6c28 2250 4f53 5422 2c20 2262  _call("POST", "b
+0000c4b0: 7569 6c64 2f66 756e 6374 696f 6e22 2c20  uild/function", 
+0000c4c0: 6a73 6f6e 3d72 6571 290a 2020 2020 2020  json=req).      
+0000c4d0: 2020 6578 6365 7074 204f 5345 7272 6f72    except OSError
+0000c4e0: 2061 7320 6572 723a 0a20 2020 2020 2020   as err:.       
+0000c4f0: 2020 2020 206c 6f67 6765 722e 6572 726f       logger.erro
+0000c500: 7228 6622 6572 726f 7220 7375 626d 6974  r(f"error submit
+0000c510: 7469 6e67 2062 7569 6c64 2074 6173 6b3a  ting build task:
+0000c520: 207b 6572 725f 746f 5f73 7472 2865 7272   {err_to_str(err
+0000c530: 297d 2229 0a20 2020 2020 2020 2020 2020  )}").           
+0000c540: 2072 6169 7365 204f 5345 7272 6f72 2866   raise OSError(f
+0000c550: 2265 7272 6f72 3a20 6361 6e6e 6f74 2073  "error: cannot s
+0000c560: 7562 6d69 7420 6275 696c 642c 207b 6572  ubmit build, {er
+0000c570: 725f 746f 5f73 7472 2865 7272 297d 2229  r_to_str(err)}")
+0000c580: 0a0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+0000c590: 2072 6573 702e 6f6b 3a0a 2020 2020 2020   resp.ok:.      
+0000c5a0: 2020 2020 2020 6c6f 6767 6572 2e65 7272        logger.err
+0000c5b0: 6f72 2866 2262 6164 2072 6573 7021 215c  or(f"bad resp!!\
+0000c5c0: 6e7b 7265 7370 2e74 6578 747d 2229 0a20  n{resp.text}"). 
+0000c5d0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000c5e0: 2056 616c 7565 4572 726f 7228 2262 6164   ValueError("bad
+0000c5f0: 2066 756e 6374 696f 6e20 7275 6e20 7265   function run re
+0000c600: 7370 6f6e 7365 2229 0a0a 2020 2020 2020  sponse")..      
+0000c610: 2020 7265 7475 726e 2072 6573 702e 6a73    return resp.js
+0000c620: 6f6e 2829 0a0a 2020 2020 6465 6620 6765  on()..    def ge
+0000c630: 745f 6275 696c 6465 725f 7374 6174 7573  t_builder_status
+0000c640: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
+0000c650: 2020 2020 2020 2020 6675 6e63 3a20 4261          func: Ba
+0000c660: 7365 5275 6e74 696d 652c 0a20 2020 2020  seRuntime,.     
+0000c670: 2020 206f 6666 7365 743d 302c 0a20 2020     offset=0,.   
+0000c680: 2020 2020 206c 6f67 733d 5472 7565 2c0a       logs=True,.
+0000c690: 2020 2020 2020 2020 6c61 7374 5f6c 6f67          last_log
+0000c6a0: 5f74 696d 6573 7461 6d70 3d30 2c0a 2020  _timestamp=0,.  
+0000c6b0: 2020 2020 2020 7665 7262 6f73 653d 4661        verbose=Fa
+0000c6c0: 6c73 652c 0a20 2020 2029 3a0a 2020 2020  lse,.    ):.    
+0000c6d0: 2020 2020 2222 2252 6574 7269 6576 6520      """Retrieve 
+0000c6e0: 7468 6520 7374 6174 7573 206f 6620 6120  the status of a 
+0000c6f0: 6275 696c 6420 6f70 6572 6174 696f 6e20  build operation 
+0000c700: 6375 7272 656e 746c 7920 696e 2070 726f  currently in pro
+0000c710: 6772 6573 732e 0a0a 2020 2020 2020 2020  gress...        
+0000c720: 3a70 6172 616d 2066 756e 633a 2046 756e  :param func: Fun
+0000c730: 6374 696f 6e20 6f62 6a65 6374 2074 6861  ction object tha
+0000c740: 7420 6973 2062 6569 6e67 2062 7569 6c74  t is being built
+0000c750: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+0000c760: 206f 6666 7365 743a 204f 6666 7365 7420   offset: Offset 
+0000c770: 696e 746f 2074 6865 2062 7569 6c64 206c  into the build l
+0000c780: 6f67 7320 746f 2072 6574 7269 6576 6520  ogs to retrieve 
+0000c790: 6c6f 6773 2066 726f 6d2e 0a20 2020 2020  logs from..     
+0000c7a0: 2020 203a 7061 7261 6d20 6c6f 6773 3a20     :param logs: 
+0000c7b0: 5368 6f75 6c64 2062 7569 6c64 206c 6f67  Should build log
+0000c7c0: 7320 6265 2072 6574 7269 6576 6564 2e0a  s be retrieved..
+0000c7d0: 2020 2020 2020 2020 3a70 6172 616d 206c          :param l
+0000c7e0: 6173 745f 6c6f 675f 7469 6d65 7374 616d  ast_log_timestam
+0000c7f0: 703a 204c 6173 7420 7469 6d65 7374 616d  p: Last timestam
+0000c800: 7020 6f66 206c 6f67 7320 7468 6174 2077  p of logs that w
+0000c810: 6572 6520 616c 7265 6164 7920 7265 7472  ere already retr
+0000c820: 6965 7665 642e 2046 756e 6374 696f 6e20  ieved. Function 
+0000c830: 7769 6c6c 2072 6574 7572 6e20 6f6e 6c79  will return only
+0000c840: 206c 6f67 730a 2020 2020 2020 2020 2020   logs.          
+0000c850: 2020 6c61 7465 7220 7468 616e 2074 6869    later than thi
+0000c860: 7320 7061 7261 6d65 7465 722e 0a20 2020  s parameter..   
+0000c870: 2020 2020 203a 7061 7261 6d20 7665 7262       :param verb
+0000c880: 6f73 653a 2041 6464 2076 6572 626f 7365  ose: Add verbose
+0000c890: 206c 6f67 7320 696e 746f 2074 6865 206f   logs into the o
+0000c8a0: 7574 7075 742e 0a20 2020 2020 2020 203a  utput..        :
+0000c8b0: 7265 7475 726e 733a 2054 6865 2066 6f6c  returns: The fol
+0000c8c0: 6c6f 7769 6e67 2070 6172 616d 6574 6572  lowing parameter
+0000c8d0: 733a 0a0a 2020 2020 2020 2020 2020 2020  s:..            
+0000c8e0: 2d20 5465 7874 206f 6620 6275 696c 6465  - Text of builde
+0000c8f0: 7220 6c6f 6773 2e0a 2020 2020 2020 2020  r logs..        
+0000c900: 2020 2020 2d20 5469 6d65 7374 616d 7020      - Timestamp 
+0000c910: 6f66 206c 6173 7420 6c6f 6720 7265 7472  of last log retr
+0000c920: 6965 7665 642c 2074 6f20 6265 2075 7365  ieved, to be use
+0000c930: 6420 696e 2073 7562 7365 7175 656e 7420  d in subsequent 
+0000c940: 6361 6c6c 7320 746f 2074 6869 7320 6675  calls to this fu
+0000c950: 6e63 7469 6f6e 2e0a 0a20 2020 2020 2020  nction...       
+0000c960: 2020 2020 2054 6865 2066 756e 6374 696f       The functio
+0000c970: 6e20 616c 736f 2075 7064 6174 6573 2069  n also updates i
+0000c980: 6e74 6572 6e61 6c20 6d65 6d62 6572 7320  nternal members 
+0000c990: 6f66 2074 6865 2060 6066 756e 6360 6020  of the ``func`` 
+0000c9a0: 6f62 6a65 6374 2074 6f20 7265 666c 6563  object to reflec
+0000c9b0: 7420 6275 696c 6420 7072 6f63 6573 7320  t build process 
+0000c9c0: 696e 666f 2e0a 2020 2020 2020 2020 2222  info..        ""
+0000c9d0: 220a 0a20 2020 2020 2020 2074 7279 3a0a  "..        try:.
+0000c9e0: 2020 2020 2020 2020 2020 2020 7061 7261              para
+0000c9f0: 6d73 203d 207b 0a20 2020 2020 2020 2020  ms = {.         
+0000ca00: 2020 2020 2020 2022 6e61 6d65 223a 206e         "name": n
+0000ca10: 6f72 6d61 6c69 7a65 5f6e 616d 6528 6675  ormalize_name(fu
+0000ca20: 6e63 2e6d 6574 6164 6174 612e 6e61 6d65  nc.metadata.name
+0000ca30: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
+0000ca40: 2020 2022 7072 6f6a 6563 7422 3a20 6675     "project": fu
+0000ca50: 6e63 2e6d 6574 6164 6174 612e 7072 6f6a  nc.metadata.proj
+0000ca60: 6563 742c 0a20 2020 2020 2020 2020 2020  ect,.           
+0000ca70: 2020 2020 2022 7461 6722 3a20 6675 6e63       "tag": func
+0000ca80: 2e6d 6574 6164 6174 612e 7461 672c 0a20  .metadata.tag,. 
+0000ca90: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000caa0: 6c6f 6773 223a 2062 6f6f 6c32 7374 7228  logs": bool2str(
+0000cab0: 6c6f 6773 292c 0a20 2020 2020 2020 2020  logs),.         
+0000cac0: 2020 2020 2020 2022 6f66 6673 6574 223a         "offset":
+0000cad0: 2073 7472 286f 6666 7365 7429 2c0a 2020   str(offset),.  
+0000cae0: 2020 2020 2020 2020 2020 2020 2020 226c                "l
+0000caf0: 6173 745f 6c6f 675f 7469 6d65 7374 616d  ast_log_timestam
+0000cb00: 7022 3a20 7374 7228 6c61 7374 5f6c 6f67  p": str(last_log
+0000cb10: 5f74 696d 6573 7461 6d70 292c 0a20 2020  _timestamp),.   
+0000cb20: 2020 2020 2020 2020 2020 2020 2022 7665               "ve
+0000cb30: 7262 6f73 6522 3a20 626f 6f6c 3273 7472  rbose": bool2str
+0000cb40: 2876 6572 626f 7365 292c 0a20 2020 2020  (verbose),.     
+0000cb50: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+0000cb60: 2020 2020 2072 6573 7020 3d20 7365 6c66       resp = self
+0000cb70: 2e61 7069 5f63 616c 6c28 2247 4554 222c  .api_call("GET",
+0000cb80: 2022 6275 696c 642f 7374 6174 7573 222c   "build/status",
+0000cb90: 2070 6172 616d 733d 7061 7261 6d73 290a   params=params).
+0000cba0: 2020 2020 2020 2020 6578 6365 7074 204f          except O
+0000cbb0: 5345 7272 6f72 2061 7320 6572 723a 0a20  SError as err:. 
+0000cbc0: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+0000cbd0: 722e 6572 726f 7228 6622 6572 726f 7220  r.error(f"error 
+0000cbe0: 6765 7474 696e 6720 6275 696c 6420 7374  getting build st
+0000cbf0: 6174 7573 3a20 7b65 7272 5f74 6f5f 7374  atus: {err_to_st
+0000cc00: 7228 6572 7229 7d22 290a 2020 2020 2020  r(err)}").      
+0000cc10: 2020 2020 2020 7261 6973 6520 4f53 4572        raise OSEr
+0000cc20: 726f 7228 6622 6572 726f 723a 2063 616e  ror(f"error: can
+0000cc30: 6e6f 7420 6765 7420 6275 696c 6420 7374  not get build st
+0000cc40: 6174 7573 2c20 7b65 7272 5f74 6f5f 7374  atus, {err_to_st
+0000cc50: 7228 6572 7229 7d22 290a 0a20 2020 2020  r(err)}")..     
+0000cc60: 2020 2069 6620 6e6f 7420 7265 7370 2e6f     if not resp.o
+0000cc70: 6b3a 0a20 2020 2020 2020 2020 2020 206c  k:.            l
+0000cc80: 6f67 6765 722e 7761 726e 696e 6728 6622  ogger.warning(f"
+0000cc90: 6661 696c 6564 2072 6573 702c 207b 7265  failed resp, {re
+0000cca0: 7370 2e74 6578 747d 2229 0a20 2020 2020  sp.text}").     
+0000ccb0: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
+0000ccc0: 4442 4572 726f 7228 2262 6164 2066 756e  DBError("bad fun
+0000ccd0: 6374 696f 6e20 6275 696c 6420 7265 7370  ction build resp
+0000cce0: 6f6e 7365 2229 0a0a 2020 2020 2020 2020  onse")..        
+0000ccf0: 6966 2072 6573 702e 6865 6164 6572 733a  if resp.headers:
+0000cd00: 0a20 2020 2020 2020 2020 2020 2066 756e  .            fun
+0000cd10: 632e 7374 6174 7573 2e73 7461 7465 203d  c.status.state =
+0000cd20: 2072 6573 702e 6865 6164 6572 732e 6765   resp.headers.ge
+0000cd30: 7428 2278 2d6d 6c72 756e 2d66 756e 6374  t("x-mlrun-funct
+0000cd40: 696f 6e2d 7374 6174 7573 222c 2022 2229  ion-status", "")
+0000cd50: 0a20 2020 2020 2020 2020 2020 206c 6173  .            las
+0000cd60: 745f 6c6f 675f 7469 6d65 7374 616d 7020  t_log_timestamp 
+0000cd70: 3d20 666c 6f61 7428 0a20 2020 2020 2020  = float(.       
+0000cd80: 2020 2020 2020 2020 2072 6573 702e 6865           resp.he
+0000cd90: 6164 6572 732e 6765 7428 2278 2d6d 6c72  aders.get("x-mlr
+0000cda0: 756e 2d6c 6173 742d 7469 6d65 7374 616d  un-last-timestam
+0000cdb0: 7022 2c20 2230 2e30 2229 0a20 2020 2020  p", "0.0").     
+0000cdc0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0000cdd0: 2020 2020 2069 6620 6675 6e63 2e6b 696e       if func.kin
+0000cde0: 6420 696e 206d 6c72 756e 2e72 756e 7469  d in mlrun.runti
+0000cdf0: 6d65 732e 5275 6e74 696d 654b 696e 6473  mes.RuntimeKinds
+0000ce00: 2e6e 7563 6c69 6f5f 7275 6e74 696d 6573  .nuclio_runtimes
+0000ce10: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+0000ce20: 2020 2020 6675 6e63 2e73 7461 7475 732e      func.status.
+0000ce30: 6164 6472 6573 7320 3d20 7265 7370 2e68  address = resp.h
+0000ce40: 6561 6465 7273 2e67 6574 2822 782d 6d6c  eaders.get("x-ml
+0000ce50: 7275 6e2d 6164 6472 6573 7322 2c20 2222  run-address", ""
+0000ce60: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0000ce70: 2020 6675 6e63 2e73 7461 7475 732e 6e75    func.status.nu
+0000ce80: 636c 696f 5f6e 616d 6520 3d20 7265 7370  clio_name = resp
+0000ce90: 2e68 6561 6465 7273 2e67 6574 2822 782d  .headers.get("x-
+0000cea0: 6d6c 7275 6e2d 6e61 6d65 222c 2022 2229  mlrun-name", "")
+0000ceb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000cec0: 2066 756e 632e 7374 6174 7573 2e69 6e74   func.status.int
+0000ced0: 6572 6e61 6c5f 696e 766f 6361 7469 6f6e  ernal_invocation
+0000cee0: 5f75 726c 7320 3d20 7265 7370 2e68 6561  _urls = resp.hea
+0000cef0: 6465 7273 2e67 6574 280a 2020 2020 2020  ders.get(.      
+0000cf00: 2020 2020 2020 2020 2020 2020 2020 2278                "x
+0000cf10: 2d6d 6c72 756e 2d69 6e74 6572 6e61 6c2d  -mlrun-internal-
+0000cf20: 696e 766f 6361 7469 6f6e 2d75 726c 7322  invocation-urls"
+0000cf30: 2c20 2222 0a20 2020 2020 2020 2020 2020  , "".           
+0000cf40: 2020 2020 2029 2e73 706c 6974 2822 2c22       ).split(","
+0000cf50: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0000cf60: 2020 6675 6e63 2e73 7461 7475 732e 6578    func.status.ex
+0000cf70: 7465 726e 616c 5f69 6e76 6f63 6174 696f  ternal_invocatio
+0000cf80: 6e5f 7572 6c73 203d 2072 6573 702e 6865  n_urls = resp.he
+0000cf90: 6164 6572 732e 6765 7428 0a20 2020 2020  aders.get(.     
+0000cfa0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000cfb0: 782d 6d6c 7275 6e2d 6578 7465 726e 616c  x-mlrun-external
+0000cfc0: 2d69 6e76 6f63 6174 696f 6e2d 7572 6c73  -invocation-urls
+0000cfd0: 222c 2022 220a 2020 2020 2020 2020 2020  ", "".          
+0000cfe0: 2020 2020 2020 292e 7370 6c69 7428 222c        ).split(",
+0000cff0: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+0000d000: 2020 2066 756e 632e 7374 6174 7573 2e63     func.status.c
+0000d010: 6f6e 7461 696e 6572 5f69 6d61 6765 203d  ontainer_image =
+0000d020: 2072 6573 702e 6865 6164 6572 732e 6765   resp.headers.ge
+0000d030: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
+0000d040: 2020 2020 2020 2022 782d 6d6c 7275 6e2d         "x-mlrun-
+0000d050: 636f 6e74 6169 6e65 722d 696d 6167 6522  container-image"
+0000d060: 2c20 2222 0a20 2020 2020 2020 2020 2020  , "".           
+0000d070: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+0000d080: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0000d090: 2020 2020 2020 2020 2066 756e 632e 7374           func.st
+0000d0a0: 6174 7573 2e62 7569 6c64 5f70 6f64 203d  atus.build_pod =
+0000d0b0: 2072 6573 702e 6865 6164 6572 732e 6765   resp.headers.ge
+0000d0c0: 7428 2262 7569 6c64 6572 5f70 6f64 222c  t("builder_pod",
+0000d0d0: 2022 2229 0a20 2020 2020 2020 2020 2020   "").           
+0000d0e0: 2020 2020 2066 756e 632e 7370 6563 2e69       func.spec.i
+0000d0f0: 6d61 6765 203d 2072 6573 702e 6865 6164  mage = resp.head
+0000d100: 6572 732e 6765 7428 2266 756e 6374 696f  ers.get("functio
+0000d110: 6e5f 696d 6167 6522 2c20 2222 290a 0a20  n_image", "").. 
+0000d120: 2020 2020 2020 2074 6578 7420 3d20 2222         text = ""
+0000d130: 0a20 2020 2020 2020 2069 6620 7265 7370  .        if resp
+0000d140: 2e63 6f6e 7465 6e74 3a0a 2020 2020 2020  .content:.      
+0000d150: 2020 2020 2020 7465 7874 203d 2072 6573        text = res
+0000d160: 702e 636f 6e74 656e 742e 6465 636f 6465  p.content.decode
+0000d170: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+0000d180: 6e20 7465 7874 2c20 6c61 7374 5f6c 6f67  n text, last_log
+0000d190: 5f74 696d 6573 7461 6d70 0a0a 2020 2020  _timestamp..    
+0000d1a0: 6465 6620 7265 6d6f 7465 5f73 7461 7274  def remote_start
+0000d1b0: 2873 656c 662c 2066 756e 635f 7572 6c29  (self, func_url)
+0000d1c0: 202d 3e20 7363 6865 6d61 732e 4261 636b   -> schemas.Back
+0000d1d0: 6772 6f75 6e64 5461 736b 3a0a 2020 2020  groundTask:.    
+0000d1e0: 2020 2020 2222 2245 7865 6375 7465 2061      """Execute a
+0000d1f0: 2066 756e 6374 696f 6e20 7265 6d6f 7465   function remote
+0000d200: 6c79 2c20 5573 6564 2066 6f72 2060 6064  ly, Used for ``d
+0000d210: 6173 6b60 6020 6675 6e63 7469 6f6e 732e  ask`` functions.
+0000d220: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+0000d230: 2066 756e 635f 7572 6c3a 2055 524c 2074   func_url: URL t
+0000d240: 6f20 7468 6520 6675 6e63 7469 6f6e 2074  o the function t
+0000d250: 6f20 6265 2065 7865 6375 7465 642e 0a20  o be executed.. 
+0000d260: 2020 2020 2020 203a 7265 7475 726e 733a         :returns:
+0000d270: 2041 2042 6163 6b67 726f 756e 6454 6173   A BackgroundTas
+0000d280: 6b20 6f62 6a65 6374 2c20 7769 7468 2064  k object, with d
+0000d290: 6574 6169 6c73 206f 6e20 6578 6563 7574  etails on execut
+0000d2a0: 696f 6e20 7072 6f63 6573 7320 616e 6420  ion process and 
+0000d2b0: 6974 7320 7374 6174 7573 2e0a 2020 2020  its status..    
+0000d2c0: 2020 2020 2222 220a 0a20 2020 2020 2020      """..       
+0000d2d0: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
+0000d2e0: 2020 7265 7120 3d20 7b22 6675 6e63 7469    req = {"functi
+0000d2f0: 6f6e 5572 6c22 3a20 6675 6e63 5f75 726c  onUrl": func_url
+0000d300: 7d0a 2020 2020 2020 2020 2020 2020 7265  }.            re
+0000d310: 7370 203d 2073 656c 662e 6170 695f 6361  sp = self.api_ca
+0000d320: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
+0000d330: 2020 2020 2250 4f53 5422 2c0a 2020 2020      "POST",.    
+0000d340: 2020 2020 2020 2020 2020 2020 2273 7461              "sta
+0000d350: 7274 2f66 756e 6374 696f 6e22 2c0a 2020  rt/function",.  
+0000d360: 2020 2020 2020 2020 2020 2020 2020 6a73                js
+0000d370: 6f6e 3d72 6571 2c0a 2020 2020 2020 2020  on=req,.        
+0000d380: 2020 2020 2020 2020 7469 6d65 6f75 743d          timeout=
+0000d390: 696e 7428 636f 6e66 6967 2e73 7562 6d69  int(config.submi
+0000d3a0: 745f 7469 6d65 6f75 7429 206f 7220 3630  t_timeout) or 60
+0000d3b0: 2c0a 2020 2020 2020 2020 2020 2020 290a  ,.            ).
+0000d3c0: 2020 2020 2020 2020 6578 6365 7074 204f          except O
+0000d3d0: 5345 7272 6f72 2061 7320 6572 723a 0a20  SError as err:. 
+0000d3e0: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+0000d3f0: 722e 6572 726f 7228 6622 6572 726f 7220  r.error(f"error 
+0000d400: 7374 6172 7469 6e67 2066 756e 6374 696f  starting functio
+0000d410: 6e3a 207b 6572 725f 746f 5f73 7472 2865  n: {err_to_str(e
+0000d420: 7272 297d 2229 0a20 2020 2020 2020 2020  rr)}").         
+0000d430: 2020 2072 6169 7365 204f 5345 7272 6f72     raise OSError
+0000d440: 2866 2265 7272 6f72 3a20 6361 6e6e 6f74  (f"error: cannot
+0000d450: 2073 7461 7274 2066 756e 6374 696f 6e2c   start function,
+0000d460: 207b 6572 725f 746f 5f73 7472 2865 7272   {err_to_str(err
+0000d470: 297d 2229 0a0a 2020 2020 2020 2020 6966  )}")..        if
+0000d480: 206e 6f74 2072 6573 702e 6f6b 3a0a 2020   not resp.ok:.  
+0000d490: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+0000d4a0: 2e65 7272 6f72 2866 2262 6164 2072 6573  .error(f"bad res
+0000d4b0: 7021 215c 6e7b 7265 7370 2e74 6578 747d  p!!\n{resp.text}
+0000d4c0: 2229 0a20 2020 2020 2020 2020 2020 2072  ").            r
+0000d4d0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+0000d4e0: 2262 6164 2066 756e 6374 696f 6e20 7374  "bad function st
+0000d4f0: 6172 7420 7265 7370 6f6e 7365 2229 0a0a  art response")..
+0000d500: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0000d510: 6368 656d 6173 2e42 6163 6b67 726f 756e  chemas.Backgroun
+0000d520: 6454 6173 6b28 2a2a 7265 7370 2e6a 736f  dTask(**resp.jso
+0000d530: 6e28 2929 0a0a 2020 2020 6465 6620 6765  n())..    def ge
+0000d540: 745f 7072 6f6a 6563 745f 6261 636b 6772  t_project_backgr
+0000d550: 6f75 6e64 5f74 6173 6b28 0a20 2020 2020  ound_task(.     
+0000d560: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+0000d570: 2070 726f 6a65 6374 3a20 7374 722c 0a20   project: str,. 
+0000d580: 2020 2020 2020 206e 616d 653a 2073 7472         name: str
+0000d590: 2c0a 2020 2020 2920 2d3e 2073 6368 656d  ,.    ) -> schem
+0000d5a0: 6173 2e42 6163 6b67 726f 756e 6454 6173  as.BackgroundTas
+0000d5b0: 6b3a 0a20 2020 2020 2020 2022 2222 5265  k:.        """Re
+0000d5c0: 7472 6965 7665 2075 7064 6174 6564 2069  trieve updated i
+0000d5d0: 6e66 6f72 6d61 7469 6f6e 206f 6e20 6120  nformation on a 
+0000d5e0: 7072 6f6a 6563 7420 6261 636b 6772 6f75  project backgrou
+0000d5f0: 6e64 2074 6173 6b20 6265 696e 6720 6578  nd task being ex
+0000d600: 6563 7574 6564 2e22 2222 0a0a 2020 2020  ecuted."""..    
+0000d610: 2020 2020 7072 6f6a 6563 7420 3d20 7072      project = pr
+0000d620: 6f6a 6563 7420 6f72 2063 6f6e 6669 672e  oject or config.
+0000d630: 6465 6661 756c 745f 7072 6f6a 6563 740a  default_project.
+0000d640: 2020 2020 2020 2020 7061 7468 203d 2066          path = f
+0000d650: 2270 726f 6a65 6374 732f 7b70 726f 6a65  "projects/{proje
+0000d660: 6374 7d2f 6261 636b 6772 6f75 6e64 2d74  ct}/background-t
+0000d670: 6173 6b73 2f7b 6e61 6d65 7d22 0a20 2020  asks/{name}".   
+0000d680: 2020 2020 2065 7272 6f72 5f6d 6573 7361       error_messa
+0000d690: 6765 203d 2028 0a20 2020 2020 2020 2020  ge = (.         
+0000d6a0: 2020 2066 2246 6169 6c65 6420 6765 7474     f"Failed gett
+0000d6b0: 696e 6720 7072 6f6a 6563 7420 6261 636b  ing project back
+0000d6c0: 6772 6f75 6e64 2074 6173 6b2e 2070 726f  ground task. pro
+0000d6d0: 6a65 6374 3d7b 7072 6f6a 6563 747d 2c20  ject={project}, 
+0000d6e0: 6e61 6d65 3d7b 6e61 6d65 7d22 0a20 2020  name={name}".   
+0000d6f0: 2020 2020 2029 0a20 2020 2020 2020 2072       ).        r
+0000d700: 6573 706f 6e73 6520 3d20 7365 6c66 2e61  esponse = self.a
+0000d710: 7069 5f63 616c 6c28 2247 4554 222c 2070  pi_call("GET", p
+0000d720: 6174 682c 2065 7272 6f72 5f6d 6573 7361  ath, error_messa
+0000d730: 6765 290a 2020 2020 2020 2020 7265 7475  ge).        retu
+0000d740: 726e 2073 6368 656d 6173 2e42 6163 6b67  rn schemas.Backg
+0000d750: 726f 756e 6454 6173 6b28 2a2a 7265 7370  roundTask(**resp
+0000d760: 6f6e 7365 2e6a 736f 6e28 2929 0a0a 2020  onse.json())..  
+0000d770: 2020 6465 6620 6765 745f 6261 636b 6772    def get_backgr
+0000d780: 6f75 6e64 5f74 6173 6b28 7365 6c66 2c20  ound_task(self, 
+0000d790: 6e61 6d65 3a20 7374 7229 202d 3e20 7363  name: str) -> sc
+0000d7a0: 6865 6d61 732e 4261 636b 6772 6f75 6e64  hemas.Background
+0000d7b0: 5461 736b 3a0a 2020 2020 2020 2020 2222  Task:.        ""
+0000d7c0: 2252 6574 7269 6576 6520 7570 6461 7465  "Retrieve update
+0000d7d0: 6420 696e 666f 726d 6174 696f 6e20 6f6e  d information on
+0000d7e0: 2061 2062 6163 6b67 726f 756e 6420 7461   a background ta
+0000d7f0: 736b 2062 6569 6e67 2065 7865 6375 7465  sk being execute
+0000d800: 642e 2222 220a 0a20 2020 2020 2020 2070  d."""..        p
+0000d810: 6174 6820 3d20 6622 6261 636b 6772 6f75  ath = f"backgrou
+0000d820: 6e64 2d74 6173 6b73 2f7b 6e61 6d65 7d22  nd-tasks/{name}"
+0000d830: 0a20 2020 2020 2020 2065 7272 6f72 5f6d  .        error_m
+0000d840: 6573 7361 6765 203d 2066 2246 6169 6c65  essage = f"Faile
+0000d850: 6420 6765 7474 696e 6720 6261 636b 6772  d getting backgr
+0000d860: 6f75 6e64 2074 6173 6b2e 206e 616d 653d  ound task. name=
+0000d870: 7b6e 616d 657d 220a 2020 2020 2020 2020  {name}".        
+0000d880: 7265 7370 6f6e 7365 203d 2073 656c 662e  response = self.
+0000d890: 6170 695f 6361 6c6c 2822 4745 5422 2c20  api_call("GET", 
+0000d8a0: 7061 7468 2c20 6572 726f 725f 6d65 7373  path, error_mess
+0000d8b0: 6167 6529 0a20 2020 2020 2020 2072 6574  age).        ret
+0000d8c0: 7572 6e20 7363 6865 6d61 732e 4261 636b  urn schemas.Back
+0000d8d0: 6772 6f75 6e64 5461 736b 282a 2a72 6573  groundTask(**res
+0000d8e0: 706f 6e73 652e 6a73 6f6e 2829 290a 0a20  ponse.json()).. 
+0000d8f0: 2020 2064 6566 2072 656d 6f74 655f 7374     def remote_st
+0000d900: 6174 7573 2873 656c 662c 2070 726f 6a65  atus(self, proje
+0000d910: 6374 2c20 6e61 6d65 2c20 6b69 6e64 2c20  ct, name, kind, 
+0000d920: 7365 6c65 6374 6f72 293a 0a20 2020 2020  selector):.     
+0000d930: 2020 2022 2222 5265 7472 6965 7665 2073     """Retrieve s
+0000d940: 7461 7475 7320 6f66 2061 2066 756e 6374  tatus of a funct
+0000d950: 696f 6e20 6265 696e 6720 6578 6563 7574  ion being execut
+0000d960: 6564 2072 656d 6f74 656c 7920 2872 656c  ed remotely (rel
+0000d970: 6576 616e 7420 746f 2060 6064 6173 6b60  evant to ``dask`
+0000d980: 6020 6675 6e63 7469 6f6e 7329 2e0a 0a20  ` functions)... 
+0000d990: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
+0000d9a0: 6f6a 6563 743a 2054 6865 2070 726f 6a65  oject: The proje
+0000d9b0: 6374 206f 6620 7468 6520 6675 6e63 7469  ct of the functi
+0000d9c0: 6f6e 0a20 2020 2020 2020 203a 7061 7261  on.        :para
+0000d9d0: 6d20 6e61 6d65 3a20 5468 6520 6e61 6d65  m name: The name
+0000d9e0: 206f 6620 7468 6520 6675 6e63 7469 6f6e   of the function
+0000d9f0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0000da00: 6b69 6e64 3a20 5468 6520 6b69 6e64 206f  kind: The kind o
+0000da10: 6620 7468 6520 6675 6e63 7469 6f6e 2c20  f the function, 
+0000da20: 6375 7272 656e 746c 7920 6060 6461 736b  currently ``dask
+0000da30: 6060 2069 7320 7375 7070 6f72 7465 642e  `` is supported.
+0000da40: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0000da50: 7365 6c65 6374 6f72 3a20 5365 6c65 6374  selector: Select
+0000da60: 6f72 2063 6c61 7573 6520 746f 2062 6520  or clause to be 
+0000da70: 6170 706c 6965 6420 746f 2074 6865 204b  applied to the K
+0000da80: 7562 6572 6e65 7465 7320 7374 6174 7573  ubernetes status
+0000da90: 2071 7565 7279 2074 6f20 6669 6c74 6572   query to filter
+0000daa0: 2074 6865 2072 6573 756c 7473 2e0a 2020   the results..  
+0000dab0: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
+0000dac0: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+0000dad0: 2020 2020 7265 7120 3d20 7b22 6b69 6e64      req = {"kind
+0000dae0: 223a 206b 696e 642c 2022 7365 6c65 6374  ": kind, "select
+0000daf0: 6f72 223a 2073 656c 6563 746f 722c 2022  or": selector, "
+0000db00: 7072 6f6a 6563 7422 3a20 7072 6f6a 6563  project": projec
+0000db10: 742c 2022 6e61 6d65 223a 206e 616d 657d  t, "name": name}
+0000db20: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
+0000db30: 7020 3d20 7365 6c66 2e61 7069 5f63 616c  p = self.api_cal
+0000db40: 6c28 2250 4f53 5422 2c20 2273 7461 7475  l("POST", "statu
+0000db50: 732f 6675 6e63 7469 6f6e 222c 206a 736f  s/function", jso
+0000db60: 6e3d 7265 7129 0a20 2020 2020 2020 2065  n=req).        e
+0000db70: 7863 6570 7420 4f53 4572 726f 7220 6173  xcept OSError as
+0000db80: 2065 7272 3a0a 2020 2020 2020 2020 2020   err:.          
+0000db90: 2020 6c6f 6767 6572 2e65 7272 6f72 2866    logger.error(f
+0000dba0: 2265 7272 6f72 2073 7461 7274 696e 6720  "error starting 
+0000dbb0: 6675 6e63 7469 6f6e 3a20 7b65 7272 5f74  function: {err_t
+0000dbc0: 6f5f 7374 7228 6572 7229 7d22 290a 2020  o_str(err)}").  
+0000dbd0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000dbe0: 4f53 4572 726f 7228 6622 6572 726f 723a  OSError(f"error:
+0000dbf0: 2063 616e 6e6f 7420 7374 6172 7420 6675   cannot start fu
+0000dc00: 6e63 7469 6f6e 2c20 7b65 7272 5f74 6f5f  nction, {err_to_
+0000dc10: 7374 7228 6572 7229 7d22 290a 0a20 2020  str(err)}")..   
+0000dc20: 2020 2020 2069 6620 6e6f 7420 7265 7370       if not resp
+0000dc30: 2e6f 6b3a 0a20 2020 2020 2020 2020 2020  .ok:.           
+0000dc40: 206c 6f67 6765 722e 6572 726f 7228 6622   logger.error(f"
+0000dc50: 6261 6420 7265 7370 2121 5c6e 7b72 6573  bad resp!!\n{res
+0000dc60: 702e 7465 7874 7d22 290a 2020 2020 2020  p.text}").      
+0000dc70: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+0000dc80: 6545 7272 6f72 2822 6261 6420 6675 6e63  eError("bad func
+0000dc90: 7469 6f6e 2073 7461 7475 7320 7265 7370  tion status resp
+0000dca0: 6f6e 7365 2229 0a0a 2020 2020 2020 2020  onse")..        
+0000dcb0: 7265 7475 726e 2072 6573 702e 6a73 6f6e  return resp.json
+0000dcc0: 2829 5b22 6461 7461 225d 0a0a 2020 2020  ()["data"]..    
+0000dcd0: 6465 6620 7375 626d 6974 5f6a 6f62 280a  def submit_job(.
+0000dce0: 2020 2020 2020 2020 7365 6c66 2c20 7275          self, ru
+0000dcf0: 6e73 7065 632c 2073 6368 6564 756c 653a  nspec, schedule:
+0000dd00: 2055 6e69 6f6e 5b73 7472 2c20 7363 6865   Union[str, sche
+0000dd10: 6d61 732e 5363 6865 6475 6c65 4372 6f6e  mas.ScheduleCron
+0000dd20: 5472 6967 6765 725d 203d 204e 6f6e 650a  Trigger] = None.
+0000dd30: 2020 2020 293a 0a20 2020 2020 2020 2022      ):.        "
+0000dd40: 2222 5375 626d 6974 2061 206a 6f62 2066  ""Submit a job f
+0000dd50: 6f72 2072 656d 6f74 6520 6578 6563 7574  or remote execut
+0000dd60: 696f 6e2e 0a0a 2020 2020 2020 2020 3a70  ion...        :p
+0000dd70: 6172 616d 2072 756e 7370 6563 3a20 5468  aram runspec: Th
+0000dd80: 6520 7275 6e74 696d 6520 6f62 6a65 6374  e runtime object
+0000dd90: 2073 7065 6320 2854 6173 6b29 2074 6f20   spec (Task) to 
+0000dda0: 6578 6563 7574 652e 0a20 2020 2020 2020  execute..       
+0000ddb0: 203a 7061 7261 6d20 7363 6865 6475 6c65   :param schedule
+0000ddc0: 3a20 5768 6574 6865 7220 746f 2073 6368  : Whether to sch
+0000ddd0: 6564 756c 6520 7468 6973 206a 6f62 2075  edule this job u
+0000dde0: 7369 6e67 2061 2043 726f 6e20 7472 6967  sing a Cron trig
+0000ddf0: 6765 722e 2049 6620 6e6f 7420 7370 6563  ger. If not spec
+0000de00: 6966 6965 642c 2074 6865 206a 6f62 2077  ified, the job w
+0000de10: 696c 6c20 6265 2073 7562 6d69 7474 6564  ill be submitted
+0000de20: 0a20 2020 2020 2020 2020 2020 2069 6d6d  .            imm
+0000de30: 6564 6961 7465 6c79 2e0a 2020 2020 2020  ediately..      
+0000de40: 2020 2222 220a 0a20 2020 2020 2020 2074    """..        t
+0000de50: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
+0000de60: 7265 7120 3d20 7b22 7461 736b 223a 2072  req = {"task": r
+0000de70: 756e 7370 6563 2e74 6f5f 6469 6374 2829  unspec.to_dict()
+0000de80: 7d0a 2020 2020 2020 2020 2020 2020 6966  }.            if
+0000de90: 2073 6368 6564 756c 653a 0a20 2020 2020   schedule:.     
+0000dea0: 2020 2020 2020 2020 2020 2069 6620 6973             if is
+0000deb0: 696e 7374 616e 6365 2873 6368 6564 756c  instance(schedul
+0000dec0: 652c 2073 6368 656d 6173 2e53 6368 6564  e, schemas.Sched
+0000ded0: 756c 6543 726f 6e54 7269 6767 6572 293a  uleCronTrigger):
+0000dee0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000def0: 2020 2020 2073 6368 6564 756c 6520 3d20       schedule = 
+0000df00: 7363 6865 6475 6c65 2e64 6963 7428 290a  schedule.dict().
+0000df10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000df20: 7265 715b 2273 6368 6564 756c 6522 5d20  req["schedule"] 
+0000df30: 3d20 7363 6865 6475 6c65 0a20 2020 2020  = schedule.     
+0000df40: 2020 2020 2020 2074 696d 656f 7574 203d         timeout =
+0000df50: 2028 696e 7428 636f 6e66 6967 2e73 7562   (int(config.sub
+0000df60: 6d69 745f 7469 6d65 6f75 7429 206f 7220  mit_timeout) or 
+0000df70: 3132 3029 202b 2032 300a 2020 2020 2020  120) + 20.      
+0000df80: 2020 2020 2020 7265 7370 203d 2073 656c        resp = sel
+0000df90: 662e 6170 695f 6361 6c6c 2822 504f 5354  f.api_call("POST
+0000dfa0: 222c 2022 7375 626d 6974 5f6a 6f62 222c  ", "submit_job",
+0000dfb0: 206a 736f 6e3d 7265 712c 2074 696d 656f   json=req, timeo
+0000dfc0: 7574 3d74 696d 656f 7574 290a 0a20 2020  ut=timeout)..   
+0000dfd0: 2020 2020 2065 7863 6570 7420 7265 7175       except requ
+0000dfe0: 6573 7473 2e48 5454 5045 7272 6f72 2061  ests.HTTPError a
+0000dff0: 7320 6572 723a 0a20 2020 2020 2020 2020  s err:.         
+0000e000: 2020 206c 6f67 6765 722e 6572 726f 7228     logger.error(
+0000e010: 6622 6572 726f 7220 7375 626d 6974 7469  f"error submitti
+0000e020: 6e67 2074 6173 6b3a 207b 6572 725f 746f  ng task: {err_to
+0000e030: 5f73 7472 2865 7272 297d 2229 0a20 2020  _str(err)}").   
+0000e040: 2020 2020 2020 2020 2023 206e 6f74 2063           # not c
+0000e050: 7265 6174 696e 6720 6120 6e65 7720 6578  reating a new ex
+0000e060: 6365 7074 696f 6e20 6865 7265 2c20 696e  ception here, in
+0000e070: 206f 7264 6572 2074 6f20 6b65 6570 2074   order to keep t
+0000e080: 6865 2072 6573 706f 6e73 6520 616e 6420  he response and 
+0000e090: 7374 6174 7573 2063 6f64 6520 696e 2074  status code in t
+0000e0a0: 6865 2065 7863 6570 7469 6f6e 0a20 2020  he exception.   
+0000e0b0: 2020 2020 2020 2020 2072 6169 7365 0a0a           raise..
+0000e0c0: 2020 2020 2020 2020 6578 6365 7074 204f          except O
+0000e0d0: 5345 7272 6f72 2061 7320 6572 723a 0a20  SError as err:. 
+0000e0e0: 2020 2020 2020 2020 2020 206c 6f67 6765             logge
+0000e0f0: 722e 6572 726f 7228 6622 6572 726f 7220  r.error(f"error 
+0000e100: 7375 626d 6974 7469 6e67 2074 6173 6b3a  submitting task:
+0000e110: 207b 6572 725f 746f 5f73 7472 2865 7272   {err_to_str(err
+0000e120: 297d 2229 0a20 2020 2020 2020 2020 2020  )}").           
+0000e130: 2072 6169 7365 204f 5345 7272 6f72 2822   raise OSError("
+0000e140: 6572 726f 723a 2063 616e 6e6f 7420 7375  error: cannot su
+0000e150: 626d 6974 2074 6173 6b22 2920 6672 6f6d  bmit task") from
+0000e160: 2065 7272 0a0a 2020 2020 2020 2020 6966   err..        if
+0000e170: 206e 6f74 2072 6573 702e 6f6b 3a0a 2020   not resp.ok:.  
+0000e180: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+0000e190: 2e65 7272 6f72 2866 2262 6164 2072 6573  .error(f"bad res
+0000e1a0: 7021 215c 6e7b 7265 7370 2e74 6578 747d  p!!\n{resp.text}
+0000e1b0: 2229 0a20 2020 2020 2020 2020 2020 2072  ").            r
+0000e1c0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+0000e1d0: 6622 6261 6420 6675 6e63 7469 6f6e 2072  f"bad function r
+0000e1e0: 756e 2072 6573 706f 6e73 652c 207b 7265  un response, {re
+0000e1f0: 7370 2e74 6578 747d 2229 0a0a 2020 2020  sp.text}")..    
+0000e200: 2020 2020 7265 7370 203d 2072 6573 702e      resp = resp.
+0000e210: 6a73 6f6e 2829 0a20 2020 2020 2020 2072  json().        r
+0000e220: 6574 7572 6e20 7265 7370 5b22 6461 7461  eturn resp["data
+0000e230: 225d 0a0a 2020 2020 6465 6620 7375 626d  "]..    def subm
+0000e240: 6974 5f70 6970 656c 696e 6528 0a20 2020  it_pipeline(.   
+0000e250: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+0000e260: 2020 2070 726f 6a65 6374 2c0a 2020 2020     project,.    
+0000e270: 2020 2020 7069 7065 6c69 6e65 2c0a 2020      pipeline,.  
+0000e280: 2020 2020 2020 6172 6775 6d65 6e74 733d        arguments=
+0000e290: 4e6f 6e65 2c0a 2020 2020 2020 2020 6578  None,.        ex
+0000e2a0: 7065 7269 6d65 6e74 3d4e 6f6e 652c 0a20  periment=None,. 
+0000e2b0: 2020 2020 2020 2072 756e 3d4e 6f6e 652c         run=None,
+0000e2c0: 0a20 2020 2020 2020 206e 616d 6573 7061  .        namespa
+0000e2d0: 6365 3d4e 6f6e 652c 0a20 2020 2020 2020  ce=None,.       
+0000e2e0: 2061 7274 6966 6163 745f 7061 7468 3d4e   artifact_path=N
+0000e2f0: 6f6e 652c 0a20 2020 2020 2020 206f 7073  one,.        ops
+0000e300: 3d4e 6f6e 652c 0a20 2020 2020 2020 2023  =None,.        #
+0000e310: 2054 4f44 4f3a 2064 6570 7265 6361 7465   TODO: deprecate
+0000e320: 642c 2072 656d 6f76 6520 696e 2031 2e35  d, remove in 1.5
+0000e330: 2e30 0a20 2020 2020 2020 2074 746c 3d4e  .0.        ttl=N
+0000e340: 6f6e 652c 0a20 2020 2020 2020 2063 6c65  one,.        cle
+0000e350: 616e 7570 5f74 746c 3d4e 6f6e 652c 0a20  anup_ttl=None,. 
+0000e360: 2020 2029 3a0a 2020 2020 2020 2020 2222     ):.        ""
+0000e370: 2253 7562 6d69 7420 6120 4b46 5020 7069  "Submit a KFP pi
+0000e380: 7065 6c69 6e65 2066 6f72 2065 7865 6375  peline for execu
+0000e390: 7469 6f6e 2e0a 0a20 2020 2020 2020 203a  tion...        :
+0000e3a0: 7061 7261 6d20 7072 6f6a 6563 743a 2054  param project: T
+0000e3b0: 6865 2070 726f 6a65 6374 206f 6620 7468  he project of th
+0000e3c0: 6520 7069 7065 6c69 6e65 0a20 2020 2020  e pipeline.     
+0000e3d0: 2020 203a 7061 7261 6d20 7069 7065 6c69     :param pipeli
+0000e3e0: 6e65 3a20 5069 7065 6c69 6e65 2066 756e  ne: Pipeline fun
+0000e3f0: 6374 696f 6e20 6f72 2070 6174 6820 746f  ction or path to
+0000e400: 202e 7961 6d6c 2f2e 7a69 7020 7069 7065   .yaml/.zip pipe
+0000e410: 6c69 6e65 2066 696c 652e 0a20 2020 2020  line file..     
+0000e420: 2020 203a 7061 7261 6d20 6172 6775 6d65     :param argume
+0000e430: 6e74 733a 2041 2064 6963 7469 6f6e 6172  nts: A dictionar
+0000e440: 7920 6f66 2061 7267 756d 656e 7473 2074  y of arguments t
+0000e450: 6f20 7061 7373 2074 6f20 7468 6520 7069  o pass to the pi
+0000e460: 7065 6c69 6e65 2e0a 2020 2020 2020 2020  peline..        
+0000e470: 3a70 6172 616d 2065 7870 6572 696d 656e  :param experimen
+0000e480: 743a 2041 206e 616d 6520 746f 2061 7373  t: A name to ass
+0000e490: 6967 6e20 666f 7220 7468 6520 7370 6563  ign for the spec
+0000e4a0: 6966 6963 2065 7870 6572 696d 656e 742e  ific experiment.
+0000e4b0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0000e4c0: 7275 6e3a 2041 206e 616d 6520 666f 7220  run: A name for 
+0000e4d0: 7468 6973 2073 7065 6369 6669 6320 7275  this specific ru
+0000e4e0: 6e2e 0a20 2020 2020 2020 203a 7061 7261  n..        :para
+0000e4f0: 6d20 6e61 6d65 7370 6163 653a 204b 7562  m namespace: Kub
+0000e500: 6572 6e65 7465 7320 6e61 6d65 7370 6163  ernetes namespac
+0000e510: 6520 746f 2065 7865 6375 7465 2074 6865  e to execute the
+0000e520: 2070 6970 656c 696e 6520 696e 2e0a 2020   pipeline in..  
+0000e530: 2020 2020 2020 3a70 6172 616d 2061 7274        :param art
+0000e540: 6966 6163 745f 7061 7468 3a20 4120 7061  ifact_path: A pa
+0000e550: 7468 2074 6f20 6172 7469 6661 6374 7320  th to artifacts 
+0000e560: 7573 6564 2062 7920 7468 6973 2070 6970  used by this pip
+0000e570: 656c 696e 652e 0a20 2020 2020 2020 203a  eline..        :
+0000e580: 7061 7261 6d20 6f70 733a 2054 7261 6e73  param ops: Trans
+0000e590: 666f 726d 6572 7320 746f 2061 7070 6c79  formers to apply
+0000e5a0: 206f 6e20 616c 6c20 6f70 7320 696e 2074   on all ops in t
+0000e5b0: 6865 2070 6970 656c 696e 652e 0a20 2020  he pipeline..   
+0000e5c0: 2020 2020 203a 7061 7261 6d20 7474 6c3a       :param ttl:
+0000e5d0: 2070 6970 656c 696e 6520 636c 6561 6e75   pipeline cleanu
+0000e5e0: 7020 7474 6c20 696e 2073 6563 7320 2874  p ttl in secs (t
+0000e5f0: 696d 6520 746f 2077 6169 7420 6166 7465  ime to wait afte
+0000e600: 7220 776f 726b 666c 6f77 2063 6f6d 706c  r workflow compl
+0000e610: 6574 696f 6e2c 2061 7420 7768 6963 6820  etion, at which 
+0000e620: 706f 696e 7420 7468 6520 776f 726b 666c  point the workfl
+0000e630: 6f77 0a20 2020 2020 2020 2020 2020 2020  ow.             
+0000e640: 2020 2020 2020 2061 6e64 2061 6c6c 2069         and all i
+0000e650: 7473 2072 6573 6f75 7263 6573 2061 7265  ts resources are
+0000e660: 2064 656c 6574 6564 2920 2864 6570 7265   deleted) (depre
+0000e670: 6361 7465 642c 2075 7365 2063 6c65 616e  cated, use clean
+0000e680: 7570 5f74 746c 2069 6e73 7465 6164 290a  up_ttl instead).
+0000e690: 2020 2020 2020 2020 3a70 6172 616d 2063          :param c
+0000e6a0: 6c65 616e 7570 5f74 746c 3a20 7069 7065  leanup_ttl: pipe
+0000e6b0: 6c69 6e65 2063 6c65 616e 7570 2074 746c  line cleanup ttl
+0000e6c0: 2069 6e20 7365 6373 2028 7469 6d65 2074   in secs (time t
+0000e6d0: 6f20 7761 6974 2061 6674 6572 2077 6f72  o wait after wor
+0000e6e0: 6b66 6c6f 7720 636f 6d70 6c65 7469 6f6e  kflow completion
+0000e6f0: 2c20 6174 2077 6869 6368 2070 6f69 6e74  , at which point
+0000e700: 2074 6865 0a20 2020 2020 2020 2020 2020   the.           
+0000e710: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e720: 2077 6f72 6b66 6c6f 7720 616e 6420 616c   workflow and al
+0000e730: 6c20 6974 7320 7265 736f 7572 6365 7320  l its resources 
+0000e740: 6172 6520 6465 6c65 7465 6429 0a20 2020  are deleted).   
+0000e750: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
+0000e760: 2020 6966 2074 746c 3a0a 2020 2020 2020    if ttl:.      
+0000e770: 2020 2020 2020 7761 726e 696e 6773 2e77        warnings.w
+0000e780: 6172 6e28 0a20 2020 2020 2020 2020 2020  arn(.           
+0000e790: 2020 2020 2022 2774 746c 2720 6973 2064       "'ttl' is d
+0000e7a0: 6570 7265 6361 7465 642c 2075 7365 2027  eprecated, use '
+0000e7b0: 636c 6561 6e75 705f 7474 6c27 2069 6e73  cleanup_ttl' ins
+0000e7c0: 7465 6164 2e20 220a 2020 2020 2020 2020  tead. ".        
+0000e7d0: 2020 2020 2020 2020 2254 6869 7320 7769          "This wi
+0000e7e0: 6c6c 2062 6520 7265 6d6f 7665 6420 696e  ll be removed in
+0000e7f0: 2031 2e35 2e30 222c 0a20 2020 2020 2020   1.5.0",.       
+0000e800: 2020 2020 2020 2020 2023 2054 4f44 4f3a           # TODO:
+0000e810: 2052 656d 6f76 6520 7468 6973 2069 6e20   Remove this in 
+0000e820: 312e 352e 300a 2020 2020 2020 2020 2020  1.5.0.          
+0000e830: 2020 2020 2020 4675 7475 7265 5761 726e        FutureWarn
+0000e840: 696e 672c 0a20 2020 2020 2020 2020 2020  ing,.           
+0000e850: 2029 0a0a 2020 2020 2020 2020 6966 2069   )..        if i
+0000e860: 7369 6e73 7461 6e63 6528 7069 7065 6c69  sinstance(pipeli
+0000e870: 6e65 2c20 7374 7229 3a0a 2020 2020 2020  ne, str):.      
+0000e880: 2020 2020 2020 7069 7065 5f66 696c 6520        pipe_file 
+0000e890: 3d20 7069 7065 6c69 6e65 0a20 2020 2020  = pipeline.     
+0000e8a0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0000e8b0: 2020 2020 2070 6970 655f 6669 6c65 203d       pipe_file =
+0000e8c0: 2074 656d 7066 696c 652e 4e61 6d65 6454   tempfile.NamedT
+0000e8d0: 656d 706f 7261 7279 4669 6c65 2873 7566  emporaryFile(suf
+0000e8e0: 6669 783d 222e 7961 6d6c 222c 2064 656c  fix=".yaml", del
+0000e8f0: 6574 653d 4661 6c73 6529 2e6e 616d 650a  ete=False).name.
+0000e900: 2020 2020 2020 2020 2020 2020 636f 6e66              conf
+0000e910: 203d 206e 6577 5f70 6970 655f 6d65 7461   = new_pipe_meta
+0000e920: 6461 7461 280a 2020 2020 2020 2020 2020  data(.          
+0000e930: 2020 2020 2020 6172 7469 6661 6374 5f70        artifact_p
+0000e940: 6174 683d 6172 7469 6661 6374 5f70 6174  ath=artifact_pat
+0000e950: 682c 0a20 2020 2020 2020 2020 2020 2020  h,.             
+0000e960: 2020 2063 6c65 616e 7570 5f74 746c 3d63     cleanup_ttl=c
+0000e970: 6c65 616e 7570 5f74 746c 206f 7220 7474  leanup_ttl or tt
+0000e980: 6c2c 0a20 2020 2020 2020 2020 2020 2020  l,.             
+0000e990: 2020 206f 705f 7472 616e 7366 6f72 6d65     op_transforme
+0000e9a0: 7273 3d6f 7073 2c0a 2020 2020 2020 2020  rs=ops,.        
+0000e9b0: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+0000e9c0: 2020 6b66 702e 636f 6d70 696c 6572 2e43    kfp.compiler.C
+0000e9d0: 6f6d 7069 6c65 7228 292e 636f 6d70 696c  ompiler().compil
+0000e9e0: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
+0000e9f0: 2020 2070 6970 656c 696e 652c 2070 6970     pipeline, pip
+0000ea00: 655f 6669 6c65 2c20 7479 7065 5f63 6865  e_file, type_che
+0000ea10: 636b 3d46 616c 7365 2c20 7069 7065 6c69  ck=False, pipeli
+0000ea20: 6e65 5f63 6f6e 663d 636f 6e66 0a20 2020  ne_conf=conf.   
+0000ea30: 2020 2020 2020 2020 2029 0a0a 2020 2020           )..    
+0000ea40: 2020 2020 6966 2070 6970 655f 6669 6c65      if pipe_file
+0000ea50: 2e65 6e64 7377 6974 6828 222e 7961 6d6c  .endswith(".yaml
+0000ea60: 2229 3a0a 2020 2020 2020 2020 2020 2020  "):.            
+0000ea70: 6865 6164 6572 7320 3d20 7b22 636f 6e74  headers = {"cont
+0000ea80: 656e 742d 7479 7065 223a 2022 6170 706c  ent-type": "appl
+0000ea90: 6963 6174 696f 6e2f 7961 6d6c 227d 0a20  ication/yaml"}. 
+0000eaa0: 2020 2020 2020 2065 6c69 6620 7069 7065         elif pipe
+0000eab0: 5f66 696c 652e 656e 6473 7769 7468 2822  _file.endswith("
+0000eac0: 2e7a 6970 2229 3a0a 2020 2020 2020 2020  .zip"):.        
+0000ead0: 2020 2020 6865 6164 6572 7320 3d20 7b22      headers = {"
+0000eae0: 636f 6e74 656e 742d 7479 7065 223a 2022  content-type": "
+0000eaf0: 6170 706c 6963 6174 696f 6e2f 7a69 7022  application/zip"
+0000eb00: 7d0a 2020 2020 2020 2020 656c 7365 3a0a  }.        else:.
+0000eb10: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0000eb20: 6520 5661 6c75 6545 7272 6f72 2822 7069  e ValueError("pi
+0000eb30: 7065 6c69 6e65 2066 696c 6520 6d75 7374  peline file must
+0000eb40: 2062 6520 2e79 616d 6c20 6f72 202e 7a69   be .yaml or .zi
+0000eb50: 7022 290a 2020 2020 2020 2020 6966 2061  p").        if a
+0000eb60: 7267 756d 656e 7473 3a0a 2020 2020 2020  rguments:.      
+0000eb70: 2020 2020 2020 6966 206e 6f74 2069 7369        if not isi
+0000eb80: 6e73 7461 6e63 6528 6172 6775 6d65 6e74  nstance(argument
+0000eb90: 732c 2064 6963 7429 3a0a 2020 2020 2020  s, dict):.      
+0000eba0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000ebb0: 5661 6c75 6545 7272 6f72 2822 6172 6775  ValueError("argu
+0000ebc0: 6d65 6e74 7320 6d75 7374 2062 6520 6469  ments must be di
+0000ebd0: 6374 2074 7970 6522 290a 2020 2020 2020  ct type").      
+0000ebe0: 2020 2020 2020 6865 6164 6572 735b 7363        headers[sc
+0000ebf0: 6865 6d61 732e 4865 6164 6572 4e61 6d65  hemas.HeaderName
+0000ec00: 732e 7069 7065 6c69 6e65 5f61 7267 756d  s.pipeline_argum
+0000ec10: 656e 7473 5d20 3d20 7374 7228 6172 6775  ents] = str(argu
+0000ec20: 6d65 6e74 7329 0a0a 2020 2020 2020 2020  ments)..        
+0000ec30: 6966 206e 6f74 2070 6174 682e 6973 6669  if not path.isfi
+0000ec40: 6c65 2870 6970 655f 6669 6c65 293a 0a20  le(pipe_file):. 
+0000ec50: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000ec60: 204f 5345 7272 6f72 2866 2266 696c 6520   OSError(f"file 
+0000ec70: 7b70 6970 655f 6669 6c65 7d20 646f 6573  {pipe_file} does
+0000ec80: 6e74 2065 7869 7374 2229 0a20 2020 2020  nt exist").     
+0000ec90: 2020 2077 6974 6820 6f70 656e 2870 6970     with open(pip
+0000eca0: 655f 6669 6c65 2c20 2272 6222 2920 6173  e_file, "rb") as
+0000ecb0: 2066 703a 0a20 2020 2020 2020 2020 2020   fp:.           
+0000ecc0: 2064 6174 6120 3d20 6670 2e72 6561 6428   data = fp.read(
+0000ecd0: 290a 2020 2020 2020 2020 6966 206e 6f74  ).        if not
+0000ece0: 2069 7369 6e73 7461 6e63 6528 7069 7065   isinstance(pipe
+0000ecf0: 6c69 6e65 2c20 7374 7229 3a0a 2020 2020  line, str):.    
+0000ed00: 2020 2020 2020 2020 7265 6d6f 7665 2870          remove(p
+0000ed10: 6970 655f 6669 6c65 290a 0a20 2020 2020  ipe_file)..     
+0000ed20: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+0000ed30: 2020 2020 7061 7261 6d73 203d 207b 226e      params = {"n
+0000ed40: 616d 6573 7061 6365 223a 206e 616d 6573  amespace": names
+0000ed50: 7061 6365 2c20 2265 7870 6572 696d 656e  pace, "experimen
+0000ed60: 7422 3a20 6578 7065 7269 6d65 6e74 2c20  t": experiment, 
+0000ed70: 2272 756e 223a 2072 756e 7d0a 2020 2020  "run": run}.    
+0000ed80: 2020 2020 2020 2020 7265 7370 203d 2073          resp = s
+0000ed90: 656c 662e 6170 695f 6361 6c6c 280a 2020  elf.api_call(.  
+0000eda0: 2020 2020 2020 2020 2020 2020 2020 2250                "P
+0000edb0: 4f53 5422 2c0a 2020 2020 2020 2020 2020  OST",.          
+0000edc0: 2020 2020 2020 6622 7072 6f6a 6563 7473        f"projects
+0000edd0: 2f7b 7072 6f6a 6563 747d 2f70 6970 656c  /{project}/pipel
+0000ede0: 696e 6573 222c 0a20 2020 2020 2020 2020  ines",.         
+0000edf0: 2020 2020 2020 2070 6172 616d 733d 7061         params=pa
+0000ee00: 7261 6d73 2c0a 2020 2020 2020 2020 2020  rams,.          
+0000ee10: 2020 2020 2020 7469 6d65 6f75 743d 3230        timeout=20
+0000ee20: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000ee30: 2020 626f 6479 3d64 6174 612c 0a20 2020    body=data,.   
+0000ee40: 2020 2020 2020 2020 2020 2020 2068 6561               hea
+0000ee50: 6465 7273 3d68 6561 6465 7273 2c0a 2020  ders=headers,.  
+0000ee60: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+0000ee70: 2020 2020 6578 6365 7074 204f 5345 7272      except OSErr
+0000ee80: 6f72 2061 7320 6572 723a 0a20 2020 2020  or as err:.     
+0000ee90: 2020 2020 2020 206c 6f67 6765 722e 6572         logger.er
+0000eea0: 726f 7228 6622 6572 726f 7220 6361 6e6e  ror(f"error cann
+0000eeb0: 6f74 2073 7562 6d69 7420 7069 7065 6c69  ot submit pipeli
+0000eec0: 6e65 3a20 7b65 7272 5f74 6f5f 7374 7228  ne: {err_to_str(
+0000eed0: 6572 7229 7d22 290a 2020 2020 2020 2020  err)}").        
+0000eee0: 2020 2020 7261 6973 6520 4f53 4572 726f      raise OSErro
+0000eef0: 7228 6622 6572 726f 723a 2063 616e 6e6f  r(f"error: canno
+0000ef00: 7420 6361 6e6e 6f74 2073 7562 6d69 7420  t cannot submit 
+0000ef10: 7069 7065 6c69 6e65 2c20 7b65 7272 5f74  pipeline, {err_t
+0000ef20: 6f5f 7374 7228 6572 7229 7d22 290a 0a20  o_str(err)}").. 
+0000ef30: 2020 2020 2020 2069 6620 6e6f 7420 7265         if not re
+0000ef40: 7370 2e6f 6b3a 0a20 2020 2020 2020 2020  sp.ok:.         
+0000ef50: 2020 206c 6f67 6765 722e 6572 726f 7228     logger.error(
+0000ef60: 6622 6261 6420 7265 7370 2121 5c6e 7b72  f"bad resp!!\n{r
+0000ef70: 6573 702e 7465 7874 7d22 290a 2020 2020  esp.text}").    
+0000ef80: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+0000ef90: 6c75 6545 7272 6f72 2866 2262 6164 2073  lueError(f"bad s
+0000efa0: 7562 6d69 7420 7069 7065 6c69 6e65 2072  ubmit pipeline r
+0000efb0: 6573 706f 6e73 652c 207b 7265 7370 2e74  esponse, {resp.t
+0000efc0: 6578 747d 2229 0a0a 2020 2020 2020 2020  ext}")..        
+0000efd0: 7265 7370 203d 2072 6573 702e 6a73 6f6e  resp = resp.json
+0000efe0: 2829 0a20 2020 2020 2020 206c 6f67 6765  ().        logge
+0000eff0: 722e 696e 666f 2866 2273 7562 6d69 7474  r.info(f"submitt
+0000f000: 6564 2070 6970 656c 696e 6520 7b72 6573  ed pipeline {res
+0000f010: 705b 276e 616d 6527 5d7d 2069 643d 7b72  p['name']} id={r
+0000f020: 6573 705b 2769 6427 5d7d 2229 0a20 2020  esp['id']}").   
+0000f030: 2020 2020 2072 6574 7572 6e20 7265 7370       return resp
+0000f040: 5b22 6964 225d 0a0a 2020 2020 6465 6620  ["id"]..    def 
+0000f050: 6c69 7374 5f70 6970 656c 696e 6573 280a  list_pipelines(.
+0000f060: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+0000f070: 2020 2020 2020 7072 6f6a 6563 743a 2073        project: s
+0000f080: 7472 2c0a 2020 2020 2020 2020 6e61 6d65  tr,.        name
+0000f090: 7370 6163 653a 2073 7472 203d 204e 6f6e  space: str = Non
+0000f0a0: 652c 0a20 2020 2020 2020 2073 6f72 745f  e,.        sort_
+0000f0b0: 6279 3a20 7374 7220 3d20 2222 2c0a 2020  by: str = "",.  
+0000f0c0: 2020 2020 2020 7061 6765 5f74 6f6b 656e        page_token
+0000f0d0: 3a20 7374 7220 3d20 2222 2c0a 2020 2020  : str = "",.    
+0000f0e0: 2020 2020 6669 6c74 6572 5f3a 2073 7472      filter_: str
+0000f0f0: 203d 2022 222c 0a20 2020 2020 2020 2066   = "",.        f
+0000f100: 6f72 6d61 745f 3a20 556e 696f 6e5b 0a20  ormat_: Union[. 
+0000f110: 2020 2020 2020 2020 2020 2073 7472 2c20             str, 
+0000f120: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
+0000f130: 732e 5069 7065 6c69 6e65 7346 6f72 6d61  s.PipelinesForma
+0000f140: 740a 2020 2020 2020 2020 5d20 3d20 6d6c  t.        ] = ml
+0000f150: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
+0000f160: 5069 7065 6c69 6e65 7346 6f72 6d61 742e  PipelinesFormat.
+0000f170: 6d65 7461 6461 7461 5f6f 6e6c 792c 0a20  metadata_only,. 
+0000f180: 2020 2020 2020 2070 6167 655f 7369 7a65         page_size
+0000f190: 3a20 696e 7420 3d20 4e6f 6e65 2c0a 2020  : int = None,.  
+0000f1a0: 2020 2920 2d3e 206d 6c72 756e 2e61 7069    ) -> mlrun.api
+0000f1b0: 2e73 6368 656d 6173 2e50 6970 656c 696e  .schemas.Pipelin
+0000f1c0: 6573 4f75 7470 7574 3a0a 2020 2020 2020  esOutput:.      
+0000f1d0: 2020 2222 2252 6574 7269 6576 6520 6120    """Retrieve a 
+0000f1e0: 6c69 7374 206f 6620 4b46 5020 7069 7065  list of KFP pipe
+0000f1f0: 6c69 6e65 732e 2054 6869 7320 6675 6e63  lines. This func
+0000f200: 7469 6f6e 2063 616e 2062 6520 696e 766f  tion can be invo
+0000f210: 6b65 6420 746f 2067 6574 2061 6c6c 2070  ked to get all p
+0000f220: 6970 656c 696e 6573 2066 726f 6d20 616c  ipelines from al
+0000f230: 6c20 7072 6f6a 6563 7473 2c0a 2020 2020  l projects,.    
+0000f240: 2020 2020 6279 2073 7065 6369 6679 696e      by specifyin
+0000f250: 6720 6060 7072 6f6a 6563 743d 2a60 602c  g ``project=*``,
+0000f260: 2069 6e20 7768 6963 6820 6361 7365 2070   in which case p
+0000f270: 6167 696e 6174 696f 6e20 6361 6e20 6265  agination can be
+0000f280: 2075 7365 6420 616e 6420 7468 6520 7661   used and the va
+0000f290: 7269 6f75 7320 736f 7274 696e 6720 616e  rious sorting an
+0000f2a0: 6420 7061 6769 6e61 7469 6f6e 0a20 2020  d pagination.   
+0000f2b0: 2020 2020 2070 726f 7065 7274 6965 7320       properties 
+0000f2c0: 6361 6e20 6265 2061 7070 6c69 6564 2e20  can be applied. 
+0000f2d0: 4966 2061 2073 7065 6369 6669 6320 7072  If a specific pr
+0000f2e0: 6f6a 6563 7420 6973 2072 6571 7565 7374  oject is request
+0000f2f0: 6564 2c20 7468 656e 2074 6865 2070 6167  ed, then the pag
+0000f300: 696e 6174 696f 6e20 6f70 7469 6f6e 7320  ination options 
+0000f310: 6361 6e6e 6f74 2062 650a 2020 2020 2020  cannot be.      
+0000f320: 2020 7573 6564 2061 6e64 2070 6167 696e    used and pagin
+0000f330: 6174 696f 6e20 6973 206e 6f74 2061 7070  ation is not app
+0000f340: 6c69 6564 2e0a 0a20 2020 2020 2020 203a  lied...        :
+0000f350: 7061 7261 6d20 7072 6f6a 6563 743a 2050  param project: P
+0000f360: 726f 6a65 6374 206e 616d 652e 2043 616e  roject name. Can
+0000f370: 2062 6520 6060 2a60 6020 666f 7220 7175   be ``*`` for qu
+0000f380: 6572 7920 6163 726f 7373 2061 6c6c 2070  ery across all p
+0000f390: 726f 6a65 6374 732e 0a20 2020 2020 2020  rojects..       
+0000f3a0: 203a 7061 7261 6d20 6e61 6d65 7370 6163   :param namespac
+0000f3b0: 653a 204b 7562 6572 6e65 7465 7320 6e61  e: Kubernetes na
+0000f3c0: 6d65 7370 6163 6520 696e 2077 6869 6368  mespace in which
+0000f3d0: 2074 6865 2070 6970 656c 696e 6573 2061   the pipelines a
+0000f3e0: 7265 2065 7865 6375 7469 6e67 2e0a 2020  re executing..  
+0000f3f0: 2020 2020 2020 3a70 6172 616d 2073 6f72        :param sor
+0000f400: 745f 6279 3a20 4669 656c 6420 746f 2073  t_by: Field to s
+0000f410: 6f72 7420 7468 6520 7265 7375 6c74 7320  ort the results 
+0000f420: 6279 2e0a 2020 2020 2020 2020 3a70 6172  by..        :par
+0000f430: 616d 2070 6167 655f 746f 6b65 6e3a 2055  am page_token: U
+0000f440: 7365 2066 6f72 2070 6167 696e 6174 696f  se for paginatio
+0000f450: 6e2c 2074 6f20 7265 7472 6965 7665 206e  n, to retrieve n
+0000f460: 6578 7420 7061 6765 2e0a 2020 2020 2020  ext page..      
+0000f470: 2020 3a70 6172 616d 2066 696c 7465 725f    :param filter_
+0000f480: 3a20 4b75 6265 726e 6574 6573 2066 696c  : Kubernetes fil
+0000f490: 7465 7220 746f 2061 7070 6c79 2074 6f20  ter to apply to 
+0000f4a0: 7468 6520 7175 6572 792c 2063 616e 2062  the query, can b
+0000f4b0: 6520 7573 6564 2074 6f20 6669 6c74 6572  e used to filter
+0000f4c0: 206f 6e20 7370 6563 6966 6963 206f 626a   on specific obj
+0000f4d0: 6563 7420 6669 656c 6473 2e0a 2020 2020  ect fields..    
+0000f4e0: 2020 2020 3a70 6172 616d 2066 6f72 6d61      :param forma
+0000f4f0: 745f 3a20 5265 7375 6c74 2066 6f72 6d61  t_: Result forma
+0000f500: 742e 2043 616e 2062 6520 6f6e 6520 6f66  t. Can be one of
+0000f510: 3a0a 0a20 2020 2020 2020 2020 2020 202d  :..            -
+0000f520: 2060 6066 756c 6c60 6020 2d20 7265 7475   ``full`` - retu
+0000f530: 726e 2074 6865 2066 756c 6c20 6f62 6a65  rn the full obje
+0000f540: 6374 732e 0a20 2020 2020 2020 2020 2020  cts..           
+0000f550: 202d 2060 606d 6574 6164 6174 615f 6f6e   - ``metadata_on
+0000f560: 6c79 6060 2028 6465 6661 756c 7429 202d  ly`` (default) -
+0000f570: 2072 6574 7572 6e20 6a75 7374 206d 6574   return just met
+0000f580: 6164 6174 6120 6f66 2074 6865 2070 6970  adata of the pip
+0000f590: 656c 696e 6573 206f 626a 6563 7473 2e0a  elines objects..
+0000f5a0: 2020 2020 2020 2020 2020 2020 2d20 6060              - ``
+0000f5b0: 6e61 6d65 5f6f 6e6c 7960 6020 2d20 7265  name_only`` - re
+0000f5c0: 7475 726e 206a 7573 7420 7468 6520 6e61  turn just the na
+0000f5d0: 6d65 7320 6f66 2074 6865 2070 6970 656c  mes of the pipel
+0000f5e0: 696e 6520 6f62 6a65 6374 732e 0a20 2020  ine objects..   
+0000f5f0: 2020 2020 203a 7061 7261 6d20 7061 6765       :param page
+0000f600: 5f73 697a 653a 2053 697a 6520 6f66 2061  _size: Size of a
+0000f610: 2073 696e 676c 6520 7061 6765 2077 6865   single page whe
+0000f620: 6e20 6170 706c 7969 6e67 2070 6167 696e  n applying pagin
+0000f630: 6174 696f 6e2e 0a20 2020 2020 2020 2022  ation..        "
+0000f640: 2222 0a0a 2020 2020 2020 2020 6966 2070  ""..        if p
+0000f650: 726f 6a65 6374 2021 3d20 222a 2220 616e  roject != "*" an
+0000f660: 6420 2870 6167 655f 746f 6b65 6e20 6f72  d (page_token or
+0000f670: 2070 6167 655f 7369 7a65 293a 0a20 2020   page_size):.   
+0000f680: 2020 2020 2020 2020 2072 6169 7365 206d           raise m
+0000f690: 6c72 756e 2e65 7272 6f72 732e 4d4c 5275  lrun.errors.MLRu
+0000f6a0: 6e49 6e76 616c 6964 4172 6775 6d65 6e74  nInvalidArgument
+0000f6b0: 4572 726f 7228 0a20 2020 2020 2020 2020  Error(.         
+0000f6c0: 2020 2020 2020 2022 4669 6c74 6572 696e         "Filterin
+0000f6d0: 6720 6279 2070 726f 6a65 6374 2063 616e  g by project can
+0000f6e0: 206e 6f74 2062 6520 7573 6564 2074 6f67   not be used tog
+0000f6f0: 6574 6865 7220 7769 7468 2070 6167 696e  ether with pagin
+0000f700: 6174 696f 6e22 0a20 2020 2020 2020 2020  ation".         
+0000f710: 2020 2029 0a20 2020 2020 2020 2070 6172     ).        par
+0000f720: 616d 7320 3d20 7b0a 2020 2020 2020 2020  ams = {.        
+0000f730: 2020 2020 226e 616d 6573 7061 6365 223a      "namespace":
+0000f740: 206e 616d 6573 7061 6365 2c0a 2020 2020   namespace,.    
+0000f750: 2020 2020 2020 2020 2273 6f72 745f 6279          "sort_by
+0000f760: 223a 2073 6f72 745f 6279 2c0a 2020 2020  ": sort_by,.    
+0000f770: 2020 2020 2020 2020 2270 6167 655f 746f          "page_to
+0000f780: 6b65 6e22 3a20 7061 6765 5f74 6f6b 656e  ken": page_token
+0000f790: 2c0a 2020 2020 2020 2020 2020 2020 2266  ,.            "f
+0000f7a0: 696c 7465 7222 3a20 6669 6c74 6572 5f2c  ilter": filter_,
+0000f7b0: 0a20 2020 2020 2020 2020 2020 2022 666f  .            "fo
+0000f7c0: 726d 6174 223a 2066 6f72 6d61 745f 2c0a  rmat": format_,.
+0000f7d0: 2020 2020 2020 2020 2020 2020 2270 6167              "pag
+0000f7e0: 655f 7369 7a65 223a 2070 6167 655f 7369  e_size": page_si
+0000f7f0: 7a65 2c0a 2020 2020 2020 2020 7d0a 0a20  ze,.        }.. 
+0000f800: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+0000f810: 7361 6765 203d 2066 2246 6169 6c65 6420  sage = f"Failed 
+0000f820: 6c69 7374 696e 6720 7069 7065 6c69 6e65  listing pipeline
+0000f830: 732c 2071 7565 7279 3a20 7b70 6172 616d  s, query: {param
+0000f840: 737d 220a 2020 2020 2020 2020 7265 7370  s}".        resp
+0000f850: 6f6e 7365 203d 2073 656c 662e 6170 695f  onse = self.api_
+0000f860: 6361 6c6c 280a 2020 2020 2020 2020 2020  call(.          
+0000f870: 2020 2247 4554 222c 2066 2270 726f 6a65    "GET", f"proje
+0000f880: 6374 732f 7b70 726f 6a65 6374 7d2f 7069  cts/{project}/pi
+0000f890: 7065 6c69 6e65 7322 2c20 6572 726f 725f  pelines", error_
+0000f8a0: 6d65 7373 6167 652c 2070 6172 616d 733d  message, params=
+0000f8b0: 7061 7261 6d73 0a20 2020 2020 2020 2029  params.        )
+0000f8c0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000f8d0: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
+0000f8e0: 732e 5069 7065 6c69 6e65 734f 7574 7075  s.PipelinesOutpu
+0000f8f0: 7428 2a2a 7265 7370 6f6e 7365 2e6a 736f  t(**response.jso
+0000f900: 6e28 2929 0a0a 2020 2020 6465 6620 6765  n())..    def ge
+0000f910: 745f 7069 7065 6c69 6e65 280a 2020 2020  t_pipeline(.    
+0000f920: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+0000f930: 2020 7275 6e5f 6964 3a20 7374 722c 0a20    run_id: str,. 
+0000f940: 2020 2020 2020 206e 616d 6573 7061 6365         namespace
+0000f950: 3a20 7374 7220 3d20 4e6f 6e65 2c0a 2020  : str = None,.  
+0000f960: 2020 2020 2020 7469 6d65 6f75 743a 2069        timeout: i
+0000f970: 6e74 203d 2031 302c 0a20 2020 2020 2020  nt = 10,.       
+0000f980: 2066 6f72 6d61 745f 3a20 556e 696f 6e5b   format_: Union[
+0000f990: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
+0000f9a0: 2c20 6d6c 7275 6e2e 6170 692e 7363 6865  , mlrun.api.sche
+0000f9b0: 6d61 732e 5069 7065 6c69 6e65 7346 6f72  mas.PipelinesFor
+0000f9c0: 6d61 740a 2020 2020 2020 2020 5d20 3d20  mat.        ] = 
+0000f9d0: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
+0000f9e0: 732e 5069 7065 6c69 6e65 7346 6f72 6d61  s.PipelinesForma
+0000f9f0: 742e 7375 6d6d 6172 792c 0a20 2020 2020  t.summary,.     
+0000fa00: 2020 2070 726f 6a65 6374 3a20 7374 7220     project: str 
+0000fa10: 3d20 4e6f 6e65 2c0a 2020 2020 293a 0a20  = None,.    ):. 
+0000fa20: 2020 2020 2020 2022 2222 5265 7472 6965         """Retrie
+0000fa30: 7665 2064 6574 6169 6c73 206f 6620 6120  ve details of a 
+0000fa40: 7370 6563 6966 6963 2070 6970 656c 696e  specific pipelin
+0000fa50: 6520 7573 696e 6720 6974 7320 7275 6e20  e using its run 
+0000fa60: 4944 2028 6173 2070 726f 7669 6465 6420  ID (as provided 
+0000fa70: 7768 656e 2074 6865 2070 6970 656c 696e  when the pipelin
+0000fa80: 6520 7761 7320 6578 6563 7574 6564 292e  e was executed).
+0000fa90: 2222 220a 0a20 2020 2020 2020 2074 7279  """..        try
+0000faa0: 3a0a 2020 2020 2020 2020 2020 2020 7061  :.            pa
+0000fab0: 7261 6d73 203d 207b 7d0a 2020 2020 2020  rams = {}.      
+0000fac0: 2020 2020 2020 6966 206e 616d 6573 7061        if namespa
+0000fad0: 6365 3a0a 2020 2020 2020 2020 2020 2020  ce:.            
+0000fae0: 2020 2020 7061 7261 6d73 5b22 6e61 6d65      params["name
+0000faf0: 7370 6163 6522 5d20 3d20 6e61 6d65 7370  space"] = namesp
+0000fb00: 6163 650a 2020 2020 2020 2020 2020 2020  ace.            
+0000fb10: 7061 7261 6d73 5b22 666f 726d 6174 225d  params["format"]
+0000fb20: 203d 2066 6f72 6d61 745f 0a20 2020 2020   = format_.     
+0000fb30: 2020 2020 2020 2070 726f 6a65 6374 5f70         project_p
+0000fb40: 6174 6820 3d20 7072 6f6a 6563 7420 6966  ath = project if
+0000fb50: 2070 726f 6a65 6374 2065 6c73 6520 222a   project else "*
+0000fb60: 220a 2020 2020 2020 2020 2020 2020 7265  ".            re
+0000fb70: 7370 203d 2073 656c 662e 6170 695f 6361  sp = self.api_ca
+0000fb80: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
+0000fb90: 2020 2020 2247 4554 222c 0a20 2020 2020      "GET",.     
+0000fba0: 2020 2020 2020 2020 2020 2066 2270 726f             f"pro
+0000fbb0: 6a65 6374 732f 7b70 726f 6a65 6374 5f70  jects/{project_p
+0000fbc0: 6174 687d 2f70 6970 656c 696e 6573 2f7b  ath}/pipelines/{
+0000fbd0: 7275 6e5f 6964 7d22 2c0a 2020 2020 2020  run_id}",.      
+0000fbe0: 2020 2020 2020 2020 2020 7061 7261 6d73            params
+0000fbf0: 3d70 6172 616d 732c 0a20 2020 2020 2020  =params,.       
+0000fc00: 2020 2020 2020 2020 2074 696d 656f 7574           timeout
+0000fc10: 3d74 696d 656f 7574 2c0a 2020 2020 2020  =timeout,.      
+0000fc20: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0000fc30: 6578 6365 7074 204f 5345 7272 6f72 2061  except OSError a
+0000fc40: 7320 6572 723a 0a20 2020 2020 2020 2020  s err:.         
+0000fc50: 2020 206c 6f67 6765 722e 6572 726f 7228     logger.error(
+0000fc60: 6622 6572 726f 7220 6361 6e6e 6f74 2067  f"error cannot g
+0000fc70: 6574 2070 6970 656c 696e 653a 207b 6572  et pipeline: {er
+0000fc80: 725f 746f 5f73 7472 2865 7272 297d 2229  r_to_str(err)}")
+0000fc90: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+0000fca0: 7365 204f 5345 7272 6f72 2866 2265 7272  se OSError(f"err
+0000fcb0: 6f72 3a20 6361 6e6e 6f74 2067 6574 2070  or: cannot get p
+0000fcc0: 6970 656c 696e 652c 207b 6572 725f 746f  ipeline, {err_to
+0000fcd0: 5f73 7472 2865 7272 297d 2229 0a0a 2020  _str(err)}")..  
+0000fce0: 2020 2020 2020 6966 206e 6f74 2072 6573        if not res
+0000fcf0: 702e 6f6b 3a0a 2020 2020 2020 2020 2020  p.ok:.          
+0000fd00: 2020 6c6f 6767 6572 2e65 7272 6f72 2866    logger.error(f
+0000fd10: 2262 6164 2072 6573 7021 215c 6e7b 7265  "bad resp!!\n{re
+0000fd20: 7370 2e74 6578 747d 2229 0a20 2020 2020  sp.text}").     
+0000fd30: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+0000fd40: 7565 4572 726f 7228 6622 6261 6420 6765  ueError(f"bad ge
+0000fd50: 7420 7069 7065 6c69 6e65 2072 6573 706f  t pipeline respo
+0000fd60: 6e73 652c 207b 7265 7370 2e74 6578 747d  nse, {resp.text}
+0000fd70: 2229 0a0a 2020 2020 2020 2020 7265 7475  ")..        retu
+0000fd80: 726e 2072 6573 702e 6a73 6f6e 2829 0a0a  rn resp.json()..
+0000fd90: 2020 2020 4073 7461 7469 636d 6574 686f      @staticmetho
+0000fda0: 640a 2020 2020 6465 6620 5f72 6573 6f6c  d.    def _resol
+0000fdb0: 7665 5f72 6566 6572 656e 6365 2874 6167  ve_reference(tag
+0000fdc0: 2c20 7569 6429 3a0a 2020 2020 2020 2020  , uid):.        
+0000fdd0: 6966 2075 6964 2061 6e64 2074 6167 3a0a  if uid and tag:.
+0000fde0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0000fdf0: 6520 4d4c 5275 6e49 6e76 616c 6964 4172  e MLRunInvalidAr
+0000fe00: 6775 6d65 6e74 4572 726f 7228 2262 6f74  gumentError("bot
+0000fe10: 6820 7569 6420 616e 6420 7461 6720 7765  h uid and tag we
+0000fe20: 7265 2070 726f 7669 6465 6422 290a 2020  re provided").  
+0000fe30: 2020 2020 2020 7265 7475 726e 2075 6964        return uid
+0000fe40: 206f 7220 7461 6720 6f72 2022 6c61 7465   or tag or "late
+0000fe50: 7374 220a 0a20 2020 2064 6566 2063 7265  st"..    def cre
+0000fe60: 6174 655f 6665 6174 7572 655f 7365 7428  ate_feature_set(
+0000fe70: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+0000fe80: 2020 2020 2020 2066 6561 7475 7265 5f73         feature_s
+0000fe90: 6574 3a20 556e 696f 6e5b 6469 6374 2c20  et: Union[dict, 
+0000fea0: 7363 6865 6d61 732e 4665 6174 7572 6553  schemas.FeatureS
+0000feb0: 6574 2c20 4665 6174 7572 6553 6574 5d2c  et, FeatureSet],
+0000fec0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
+0000fed0: 3d22 222c 0a20 2020 2020 2020 2076 6572  ="",.        ver
+0000fee0: 7369 6f6e 6564 3d54 7275 652c 0a20 2020  sioned=True,.   
+0000fef0: 2029 202d 3e20 6469 6374 3a0a 2020 2020   ) -> dict:.    
+0000ff00: 2020 2020 2222 2243 7265 6174 6520 6120      """Create a 
+0000ff10: 6e65 7720 3a70 793a 636c 6173 733a 607e  new :py:class:`~
+0000ff20: 6d6c 7275 6e2e 6665 6174 7572 655f 7374  mlrun.feature_st
+0000ff30: 6f72 652e 4665 6174 7572 6553 6574 6020  ore.FeatureSet` 
+0000ff40: 616e 6420 7361 7665 2069 6e20 7468 6520  and save in the 
+0000ff50: 3a70 793a 6d6f 643a 606d 6c72 756e 6020  :py:mod:`mlrun` 
+0000ff60: 4442 2e20 5468 650a 2020 2020 2020 2020  DB. The.        
+0000ff70: 6665 6174 7572 652d 7365 7420 6d75 7374  feature-set must
+0000ff80: 206e 6f74 2070 7265 7669 6f75 736c 7920   not previously 
+0000ff90: 6578 6973 7420 696e 2074 6865 2044 422e  exist in the DB.
+0000ffa0: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+0000ffb0: 2066 6561 7475 7265 5f73 6574 3a20 5468   feature_set: Th
+0000ffc0: 6520 6e65 7720 3a70 793a 636c 6173 733a  e new :py:class:
+0000ffd0: 607e 6d6c 7275 6e2e 6665 6174 7572 655f  `~mlrun.feature_
+0000ffe0: 7374 6f72 652e 4665 6174 7572 6553 6574  store.FeatureSet
+0000fff0: 6020 746f 2063 7265 6174 652e 0a20 2020  ` to create..   
+00010000: 2020 2020 203a 7061 7261 6d20 7072 6f6a       :param proj
+00010010: 6563 743a 204e 616d 6520 6f66 2070 726f  ect: Name of pro
+00010020: 6a65 6374 2074 6869 7320 6665 6174 7572  ject this featur
+00010030: 652d 7365 7420 6265 6c6f 6e67 7320 746f  e-set belongs to
+00010040: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+00010050: 2076 6572 7369 6f6e 6564 3a20 5768 6574   versioned: Whet
+00010060: 6865 7220 746f 206d 6169 6e74 6169 6e20  her to maintain 
+00010070: 7665 7273 696f 6e73 2066 6f72 2074 6869  versions for thi
+00010080: 7320 6665 6174 7572 652d 7365 742e 2041  s feature-set. A
+00010090: 6c6c 2076 6572 7369 6f6e 7320 6f66 2061  ll versions of a
+000100a0: 2076 6572 7369 6f6e 6564 206f 626a 6563   versioned objec
+000100b0: 740a 2020 2020 2020 2020 2020 2020 7769  t.            wi
+000100c0: 6c6c 2062 6520 6b65 7074 2069 6e20 7468  ll be kept in th
+000100d0: 6520 4442 2061 6e64 2063 616e 2062 6520  e DB and can be 
+000100e0: 7265 7472 6965 7665 6420 756e 7469 6c20  retrieved until 
+000100f0: 6578 706c 6963 6974 6c79 2064 656c 6574  explicitly delet
+00010100: 6564 2e0a 2020 2020 2020 2020 3a72 6574  ed..        :ret
+00010110: 7572 6e73 3a20 5468 6520 3a70 793a 636c  urns: The :py:cl
+00010120: 6173 733a 607e 6d6c 7275 6e2e 6665 6174  ass:`~mlrun.feat
+00010130: 7572 655f 7374 6f72 652e 4665 6174 7572  ure_store.Featur
+00010140: 6553 6574 6020 6f62 6a65 6374 2028 6173  eSet` object (as
+00010150: 2064 6963 7429 2e0a 2020 2020 2020 2020   dict)..        
+00010160: 2222 220a 2020 2020 2020 2020 6966 2069  """.        if i
+00010170: 7369 6e73 7461 6e63 6528 6665 6174 7572  sinstance(featur
+00010180: 655f 7365 742c 2073 6368 656d 6173 2e46  e_set, schemas.F
+00010190: 6561 7475 7265 5365 7429 3a0a 2020 2020  eatureSet):.    
+000101a0: 2020 2020 2020 2020 6665 6174 7572 655f          feature_
+000101b0: 7365 7420 3d20 6665 6174 7572 655f 7365  set = feature_se
+000101c0: 742e 6469 6374 2829 0a20 2020 2020 2020  t.dict().       
+000101d0: 2065 6c69 6620 6973 696e 7374 616e 6365   elif isinstance
+000101e0: 2866 6561 7475 7265 5f73 6574 2c20 4665  (feature_set, Fe
+000101f0: 6174 7572 6553 6574 293a 0a20 2020 2020  atureSet):.     
+00010200: 2020 2020 2020 2066 6561 7475 7265 5f73         feature_s
+00010210: 6574 203d 2066 6561 7475 7265 5f73 6574  et = feature_set
+00010220: 2e74 6f5f 6469 6374 2829 0a0a 2020 2020  .to_dict()..    
+00010230: 2020 2020 7072 6f6a 6563 7420 3d20 280a      project = (.
+00010240: 2020 2020 2020 2020 2020 2020 7072 6f6a              proj
+00010250: 6563 740a 2020 2020 2020 2020 2020 2020  ect.            
+00010260: 6f72 2066 6561 7475 7265 5f73 6574 5b22  or feature_set["
+00010270: 6d65 7461 6461 7461 225d 2e67 6574 2822  metadata"].get("
+00010280: 7072 6f6a 6563 7422 2c20 4e6f 6e65 290a  project", None).
+00010290: 2020 2020 2020 2020 2020 2020 6f72 2063              or c
+000102a0: 6f6e 6669 672e 6465 6661 756c 745f 7072  onfig.default_pr
+000102b0: 6f6a 6563 740a 2020 2020 2020 2020 290a  oject.        ).
+000102c0: 2020 2020 2020 2020 7061 7468 203d 2066          path = f
+000102d0: 2270 726f 6a65 6374 732f 7b70 726f 6a65  "projects/{proje
+000102e0: 6374 7d2f 6665 6174 7572 652d 7365 7473  ct}/feature-sets
+000102f0: 220a 2020 2020 2020 2020 7061 7261 6d73  ".        params
+00010300: 203d 207b 2276 6572 7369 6f6e 6564 223a   = {"versioned":
+00010310: 2076 6572 7369 6f6e 6564 7d0a 0a20 2020   versioned}..   
+00010320: 2020 2020 206e 616d 6520 3d20 6665 6174       name = feat
+00010330: 7572 655f 7365 745b 226d 6574 6164 6174  ure_set["metadat
+00010340: 6122 5d5b 226e 616d 6522 5d0a 2020 2020  a"]["name"].    
+00010350: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+00010360: 6520 3d20 6622 4661 696c 6564 2063 7265  e = f"Failed cre
+00010370: 6174 696e 6720 6665 6174 7572 652d 7365  ating feature-se
+00010380: 7420 7b70 726f 6a65 6374 7d2f 7b6e 616d  t {project}/{nam
+00010390: 657d 220a 2020 2020 2020 2020 7265 7370  e}".        resp
+000103a0: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
+000103b0: 280a 2020 2020 2020 2020 2020 2020 2250  (.            "P
+000103c0: 4f53 5422 2c0a 2020 2020 2020 2020 2020  OST",.          
+000103d0: 2020 7061 7468 2c0a 2020 2020 2020 2020    path,.        
+000103e0: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+000103f0: 652c 0a20 2020 2020 2020 2020 2020 2070  e,.            p
+00010400: 6172 616d 733d 7061 7261 6d73 2c0a 2020  arams=params,.  
+00010410: 2020 2020 2020 2020 2020 626f 6479 3d64            body=d
+00010420: 6963 745f 746f 5f6a 736f 6e28 6665 6174  ict_to_json(feat
+00010430: 7572 655f 7365 7429 2c0a 2020 2020 2020  ure_set),.      
+00010440: 2020 290a 2020 2020 2020 2020 7265 7475    ).        retu
+00010450: 726e 2072 6573 702e 6a73 6f6e 2829 0a0a  rn resp.json()..
+00010460: 2020 2020 6465 6620 6765 745f 6665 6174      def get_feat
+00010470: 7572 655f 7365 7428 0a20 2020 2020 2020  ure_set(.       
+00010480: 2073 656c 662c 206e 616d 653a 2073 7472   self, name: str
+00010490: 2c20 7072 6f6a 6563 743a 2073 7472 203d  , project: str =
+000104a0: 2022 222c 2074 6167 3a20 7374 7220 3d20   "", tag: str = 
+000104b0: 4e6f 6e65 2c20 7569 643a 2073 7472 203d  None, uid: str =
+000104c0: 204e 6f6e 650a 2020 2020 2920 2d3e 2046   None.    ) -> F
+000104d0: 6561 7475 7265 5365 743a 0a20 2020 2020  eatureSet:.     
+000104e0: 2020 2022 2222 5265 7472 6965 7665 2061     """Retrieve a
+000104f0: 207e 6d6c 7275 6e2e 6665 6174 7572 655f   ~mlrun.feature_
+00010500: 7374 6f72 652e 4665 6174 7572 6553 6574  store.FeatureSet
+00010510: 6020 6f62 6a65 6374 2e20 4966 2062 6f74  ` object. If bot
+00010520: 6820 6060 7461 6760 6020 616e 6420 6060  h ``tag`` and ``
+00010530: 7569 6460 6020 6172 6520 6e6f 7420 7370  uid`` are not sp
+00010540: 6563 6966 6965 642c 2074 6865 6e0a 2020  ecified, then.  
+00010550: 2020 2020 2020 7468 6520 6f62 6a65 6374        the object
+00010560: 2074 6167 6765 6420 6060 6c61 7465 7374   tagged ``latest
+00010570: 6060 2077 696c 6c20 6265 2072 6574 7269  `` will be retri
+00010580: 6576 6564 2e0a 0a20 2020 2020 2020 203a  eved...        :
+00010590: 7061 7261 6d20 6e61 6d65 3a20 4e61 6d65  param name: Name
+000105a0: 206f 6620 6f62 6a65 6374 2074 6f20 7265   of object to re
+000105b0: 7472 6965 7665 2e0a 2020 2020 2020 2020  trieve..        
+000105c0: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
+000105d0: 5072 6f6a 6563 7420 7468 6520 4665 6174  Project the Feat
+000105e0: 7572 6553 6574 2062 656c 6f6e 6773 2074  ureSet belongs t
+000105f0: 6f2e 0a20 2020 2020 2020 203a 7061 7261  o..        :para
+00010600: 6d20 7461 673a 2054 6167 206f 6620 7468  m tag: Tag of th
+00010610: 6520 7370 6563 6966 6963 206f 626a 6563  e specific objec
+00010620: 7420 7665 7273 696f 6e20 746f 2072 6574  t version to ret
+00010630: 7269 6576 652e 0a20 2020 2020 2020 203a  rieve..        :
+00010640: 7061 7261 6d20 7569 643a 2075 6964 206f  param uid: uid o
+00010650: 6620 7468 6520 6f62 6a65 6374 2074 6f20  f the object to 
+00010660: 7265 7472 6965 7665 2028 6361 6e20 6f6e  retrieve (can on
+00010670: 6c79 2062 6520 7573 6564 2066 6f72 2076  ly be used for v
+00010680: 6572 7369 6f6e 6564 206f 626a 6563 7473  ersioned objects
+00010690: 292e 0a20 2020 2020 2020 2022 2222 0a0a  )..        """..
+000106a0: 2020 2020 2020 2020 7072 6f6a 6563 7420          project 
+000106b0: 3d20 7072 6f6a 6563 7420 6f72 2063 6f6e  = project or con
+000106c0: 6669 672e 6465 6661 756c 745f 7072 6f6a  fig.default_proj
+000106d0: 6563 740a 2020 2020 2020 2020 7265 6665  ect.        refe
+000106e0: 7265 6e63 6520 3d20 7365 6c66 2e5f 7265  rence = self._re
+000106f0: 736f 6c76 655f 7265 6665 7265 6e63 6528  solve_reference(
+00010700: 7461 672c 2075 6964 290a 2020 2020 2020  tag, uid).      
+00010710: 2020 7061 7468 203d 2066 2270 726f 6a65    path = f"proje
+00010720: 6374 732f 7b70 726f 6a65 6374 7d2f 6665  cts/{project}/fe
+00010730: 6174 7572 652d 7365 7473 2f7b 6e61 6d65  ature-sets/{name
+00010740: 7d2f 7265 6665 7265 6e63 6573 2f7b 7265  }/references/{re
+00010750: 6665 7265 6e63 657d 220a 2020 2020 2020  ference}".      
+00010760: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
+00010770: 3d20 6622 4661 696c 6564 2072 6574 7269  = f"Failed retri
+00010780: 6576 696e 6720 6665 6174 7572 652d 7365  eving feature-se
+00010790: 7420 7b70 726f 6a65 6374 7d2f 7b6e 616d  t {project}/{nam
+000107a0: 657d 220a 2020 2020 2020 2020 7265 7370  e}".        resp
+000107b0: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
+000107c0: 2822 4745 5422 2c20 7061 7468 2c20 6572  ("GET", path, er
+000107d0: 726f 725f 6d65 7373 6167 6529 0a20 2020  ror_message).   
+000107e0: 2020 2020 2072 6574 7572 6e20 4665 6174       return Feat
+000107f0: 7572 6553 6574 2e66 726f 6d5f 6469 6374  ureSet.from_dict
+00010800: 2872 6573 702e 6a73 6f6e 2829 290a 0a20  (resp.json()).. 
+00010810: 2020 2064 6566 206c 6973 745f 6665 6174     def list_feat
+00010820: 7572 6573 280a 2020 2020 2020 2020 7365  ures(.        se
+00010830: 6c66 2c0a 2020 2020 2020 2020 7072 6f6a  lf,.        proj
+00010840: 6563 743a 2073 7472 2c0a 2020 2020 2020  ect: str,.      
+00010850: 2020 6e61 6d65 3a20 7374 7220 3d20 4e6f    name: str = No
+00010860: 6e65 2c0a 2020 2020 2020 2020 7461 673a  ne,.        tag:
+00010870: 2073 7472 203d 204e 6f6e 652c 0a20 2020   str = None,.   
+00010880: 2020 2020 2065 6e74 6974 6965 733a 204c       entities: L
+00010890: 6973 745b 7374 725d 203d 204e 6f6e 652c  ist[str] = None,
+000108a0: 0a20 2020 2020 2020 206c 6162 656c 733a  .        labels:
+000108b0: 204c 6973 745b 7374 725d 203d 204e 6f6e   List[str] = Non
+000108c0: 652c 0a20 2020 2029 202d 3e20 4c69 7374  e,.    ) -> List
+000108d0: 5b64 6963 745d 3a0a 2020 2020 2020 2020  [dict]:.        
+000108e0: 2222 224c 6973 7420 6665 6174 7572 652d  """List feature-
+000108f0: 7365 7473 2077 6869 6368 2063 6f6e 7461  sets which conta
+00010900: 696e 2073 7065 6369 6669 6320 6665 6174  in specific feat
+00010910: 7572 6573 2e20 5468 6973 2066 756e 6374  ures. This funct
+00010920: 696f 6e20 6d61 7920 7265 7475 726e 206d  ion may return m
+00010930: 756c 7469 706c 6520 7665 7273 696f 6e73  ultiple versions
+00010940: 206f 6620 7468 6520 7361 6d65 0a20 2020   of the same.   
+00010950: 2020 2020 2066 6561 7475 7265 2d73 6574       feature-set
+00010960: 2069 6620 6120 7370 6563 6966 6963 2074   if a specific t
+00010970: 6167 2069 7320 6e6f 7420 7265 7175 6573  ag is not reques
+00010980: 7465 642e 204e 6f74 6520 7468 6174 2074  ted. Note that t
+00010990: 6865 2076 6172 696f 7573 2066 696c 7465  he various filte
+000109a0: 7273 206f 6620 7468 6973 2066 756e 6374  rs of this funct
+000109b0: 696f 6e20 6163 7475 616c 6c79 0a20 2020  ion actually.   
+000109c0: 2020 2020 2072 6566 6572 2074 6f20 7468       refer to th
+000109d0: 6520 6665 6174 7572 652d 7365 7420 6f62  e feature-set ob
+000109e0: 6a65 6374 2063 6f6e 7461 696e 696e 6720  ject containing 
+000109f0: 7468 6520 6665 6174 7572 6573 2c20 6e6f  the features, no
+00010a00: 7420 746f 2074 6865 2066 6561 7475 7265  t to the feature
+00010a10: 7320 7468 656d 7365 6c76 6573 2e0a 0a20  s themselves... 
+00010a20: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
+00010a30: 6f6a 6563 743a 2050 726f 6a65 6374 2077  oject: Project w
+00010a40: 6869 6368 2063 6f6e 7461 696e 7320 7468  hich contains th
+00010a50: 6573 6520 6665 6174 7572 6573 2e0a 2020  ese features..  
+00010a60: 2020 2020 2020 3a70 6172 616d 206e 616d        :param nam
+00010a70: 653a 204e 616d 6520 6f66 2074 6865 2066  e: Name of the f
+00010a80: 6561 7475 7265 2074 6f20 6c6f 6f6b 2066  eature to look f
+00010a90: 6f72 2e20 5468 6520 6e61 6d65 2069 7320  or. The name is 
+00010aa0: 7573 6564 2069 6e20 6120 6c69 6b65 2071  used in a like q
+00010ab0: 7565 7279 2c20 616e 6420 6973 206e 6f74  uery, and is not
+00010ac0: 2063 6173 652d 7365 6e73 6974 6976 652e   case-sensitive.
+00010ad0: 2046 6f72 0a20 2020 2020 2020 2020 2020   For.           
+00010ae0: 2065 7861 6d70 6c65 2c20 6c6f 6f6b 696e   example, lookin
+00010af0: 6720 666f 7220 6060 6665 6174 6060 2077  g for ``feat`` w
+00010b00: 696c 6c20 7265 7475 726e 2066 6561 7475  ill return featu
+00010b10: 7265 7320 7768 6963 6820 6172 6520 6e61  res which are na
+00010b20: 6d65 6420 6060 4d79 4665 6174 7572 6560  med ``MyFeature`
+00010b30: 6020 6173 2077 656c 6c20 6173 2060 6064  ` as well as ``d
+00010b40: 6566 6561 7460 602e 0a20 2020 2020 2020  efeat``..       
+00010b50: 203a 7061 7261 6d20 7461 673a 2052 6574   :param tag: Ret
+00010b60: 7572 6e20 6665 6174 7572 652d 7365 7473  urn feature-sets
+00010b70: 2077 6869 6368 2063 6f6e 7461 696e 2074   which contain t
+00010b80: 6865 2066 6561 7475 7265 7320 6c6f 6f6b  he features look
+00010b90: 6564 2066 6f72 2c20 616e 6420 6172 6520  ed for, and are 
+00010ba0: 7461 6767 6564 2077 6974 6820 7468 6520  tagged with the 
+00010bb0: 7370 6563 6966 6963 2074 6167 2e0a 2020  specific tag..  
+00010bc0: 2020 2020 2020 3a70 6172 616d 2065 6e74        :param ent
+00010bd0: 6974 6965 733a 2052 6574 7572 6e20 6f6e  ities: Return on
+00010be0: 6c79 2066 6561 7475 7265 2d73 6574 7320  ly feature-sets 
+00010bf0: 7768 6963 6820 636f 6e74 6169 6e20 616e  which contain an
+00010c00: 2065 6e74 6974 7920 7768 6f73 6520 6e61   entity whose na
+00010c10: 6d65 2069 7320 636f 6e74 6169 6e65 6420  me is contained 
+00010c20: 696e 2074 6869 7320 6c69 7374 2e0a 2020  in this list..  
+00010c30: 2020 2020 2020 3a70 6172 616d 206c 6162        :param lab
+00010c40: 656c 733a 2052 6574 7572 6e20 6f6e 6c79  els: Return only
+00010c50: 2066 6561 7475 7265 2d73 6574 7320 7768   feature-sets wh
+00010c60: 6963 6820 6172 6520 6c61 6265 6c65 6420  ich are labeled 
+00010c70: 6173 2072 6571 7565 7374 6564 2e0a 2020  as requested..  
+00010c80: 2020 2020 2020 3a72 6574 7572 6e73 3a20        :returns: 
+00010c90: 4120 6c69 7374 206f 6620 6d61 7070 696e  A list of mappin
+00010ca0: 6720 6672 6f6d 2066 6561 7475 7265 2074  g from feature t
+00010cb0: 6f20 6120 6469 6765 7374 206f 6620 7468  o a digest of th
+00010cc0: 6520 6665 6174 7572 652d 7365 742c 2077  e feature-set, w
+00010cd0: 6869 6368 2063 6f6e 7461 696e 7320 7468  hich contains th
+00010ce0: 6520 6665 6174 7572 652d 7365 740a 2020  e feature-set.  
+00010cf0: 2020 2020 2020 2020 2020 6d65 7461 2d64            meta-d
+00010d00: 6174 612e 204d 756c 7469 706c 6520 656e  ata. Multiple en
+00010d10: 7472 6965 7320 6d61 7920 6265 2072 6574  tries may be ret
+00010d20: 7572 6e65 6420 666f 7220 616e 7920 7370  urned for any sp
+00010d30: 6563 6966 6963 2066 6561 7475 7265 2064  ecific feature d
+00010d40: 7565 2074 6f20 6d75 6c74 6970 6c65 2074  ue to multiple t
+00010d50: 6167 7320 6f72 2076 6572 7369 6f6e 730a  ags or versions.
+00010d60: 2020 2020 2020 2020 2020 2020 6f66 2074              of t
+00010d70: 6865 2066 6561 7475 7265 2d73 6574 2e0a  he feature-set..
+00010d80: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
+00010d90: 2020 2020 2070 726f 6a65 6374 203d 2070       project = p
+00010da0: 726f 6a65 6374 206f 7220 636f 6e66 6967  roject or config
+00010db0: 2e64 6566 6175 6c74 5f70 726f 6a65 6374  .default_project
+00010dc0: 0a20 2020 2020 2020 2070 6172 616d 7320  .        params 
+00010dd0: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
+00010de0: 226e 616d 6522 3a20 6e61 6d65 2c0a 2020  "name": name,.  
+00010df0: 2020 2020 2020 2020 2020 2274 6167 223a            "tag":
+00010e00: 2074 6167 2c0a 2020 2020 2020 2020 2020   tag,.          
+00010e10: 2020 2265 6e74 6974 7922 3a20 656e 7469    "entity": enti
+00010e20: 7469 6573 206f 7220 5b5d 2c0a 2020 2020  ties or [],.    
+00010e30: 2020 2020 2020 2020 226c 6162 656c 223a          "label":
+00010e40: 206c 6162 656c 7320 6f72 205b 5d2c 0a20   labels or [],. 
+00010e50: 2020 2020 2020 207d 0a0a 2020 2020 2020         }..      
+00010e60: 2020 7061 7468 203d 2066 2270 726f 6a65    path = f"proje
+00010e70: 6374 732f 7b70 726f 6a65 6374 7d2f 6665  cts/{project}/fe
+00010e80: 6174 7572 6573 220a 0a20 2020 2020 2020  atures"..       
+00010e90: 2065 7272 6f72 5f6d 6573 7361 6765 203d   error_message =
+00010ea0: 2066 2246 6169 6c65 6420 6c69 7374 696e   f"Failed listin
+00010eb0: 6720 6665 6174 7572 6573 2c20 7072 6f6a  g features, proj
+00010ec0: 6563 743a 207b 7072 6f6a 6563 747d 2c20  ect: {project}, 
+00010ed0: 7175 6572 793a 207b 7061 7261 6d73 7d22  query: {params}"
+00010ee0: 0a20 2020 2020 2020 2072 6573 7020 3d20  .        resp = 
+00010ef0: 7365 6c66 2e61 7069 5f63 616c 6c28 2247  self.api_call("G
+00010f00: 4554 222c 2070 6174 682c 2065 7272 6f72  ET", path, error
+00010f10: 5f6d 6573 7361 6765 2c20 7061 7261 6d73  _message, params
+00010f20: 3d70 6172 616d 7329 0a20 2020 2020 2020  =params).       
+00010f30: 2072 6574 7572 6e20 7265 7370 2e6a 736f   return resp.jso
+00010f40: 6e28 295b 2266 6561 7475 7265 7322 5d0a  n()["features"].
+00010f50: 0a20 2020 2064 6566 206c 6973 745f 656e  .    def list_en
+00010f60: 7469 7469 6573 280a 2020 2020 2020 2020  tities(.        
+00010f70: 7365 6c66 2c0a 2020 2020 2020 2020 7072  self,.        pr
+00010f80: 6f6a 6563 743a 2073 7472 2c0a 2020 2020  oject: str,.    
+00010f90: 2020 2020 6e61 6d65 3a20 7374 7220 3d20      name: str = 
+00010fa0: 4e6f 6e65 2c0a 2020 2020 2020 2020 7461  None,.        ta
+00010fb0: 673a 2073 7472 203d 204e 6f6e 652c 0a20  g: str = None,. 
+00010fc0: 2020 2020 2020 206c 6162 656c 733a 204c         labels: L
+00010fd0: 6973 745b 7374 725d 203d 204e 6f6e 652c  ist[str] = None,
+00010fe0: 0a20 2020 2029 202d 3e20 4c69 7374 5b64  .    ) -> List[d
+00010ff0: 6963 745d 3a0a 2020 2020 2020 2020 2222  ict]:.        ""
+00011000: 2252 6574 7269 6576 6520 6120 6c69 7374  "Retrieve a list
+00011010: 206f 6620 656e 7469 7469 6573 2061 6e64   of entities and
+00011020: 2074 6865 6972 206d 6170 7069 6e67 2074   their mapping t
+00011030: 6f20 7468 6520 636f 6e74 6169 6e69 6e67  o the containing
+00011040: 2066 6561 7475 7265 2d73 6574 732e 2054   feature-sets. T
+00011050: 6869 7320 6675 6e63 7469 6f6e 2069 7320  his function is 
+00011060: 7369 6d69 6c61 720a 2020 2020 2020 2020  similar.        
+00011070: 746f 2074 6865 203a 7079 3a66 756e 633a  to the :py:func:
+00011080: 607e 6c69 7374 5f66 6561 7475 7265 7360  `~list_features`
+00011090: 2066 756e 6374 696f 6e2c 2061 6e64 2075   function, and u
+000110a0: 7365 7320 7468 6520 7361 6d65 206c 6f67  ses the same log
+000110b0: 6963 2e20 486f 7765 7665 722c 2074 6865  ic. However, the
+000110c0: 2065 6e74 6974 6965 7320 6172 6520 6d61   entities are ma
+000110d0: 7463 6865 640a 2020 2020 2020 2020 6167  tched.        ag
+000110e0: 6169 6e73 7420 7468 6520 6e61 6d65 2072  ainst the name r
+000110f0: 6174 6865 7220 7468 616e 2074 6865 2066  ather than the f
+00011100: 6561 7475 7265 732e 0a20 2020 2020 2020  eatures..       
+00011110: 2022 2222 0a0a 2020 2020 2020 2020 7072   """..        pr
+00011120: 6f6a 6563 7420 3d20 7072 6f6a 6563 7420  oject = project 
+00011130: 6f72 2063 6f6e 6669 672e 6465 6661 756c  or config.defaul
+00011140: 745f 7072 6f6a 6563 740a 2020 2020 2020  t_project.      
+00011150: 2020 7061 7261 6d73 203d 207b 0a20 2020    params = {.   
+00011160: 2020 2020 2020 2020 2022 6e61 6d65 223a           "name":
+00011170: 206e 616d 652c 0a20 2020 2020 2020 2020   name,.         
+00011180: 2020 2022 7461 6722 3a20 7461 672c 0a20     "tag": tag,. 
+00011190: 2020 2020 2020 2020 2020 2022 6c61 6265             "labe
+000111a0: 6c22 3a20 6c61 6265 6c73 206f 7220 5b5d  l": labels or []
+000111b0: 2c0a 2020 2020 2020 2020 7d0a 0a20 2020  ,.        }..   
+000111c0: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
+000111d0: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
+000111e0: 2f65 6e74 6974 6965 7322 0a0a 2020 2020  /entities"..    
+000111f0: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+00011200: 6520 3d20 6622 4661 696c 6564 206c 6973  e = f"Failed lis
+00011210: 7469 6e67 2065 6e74 6974 6965 732c 2070  ting entities, p
+00011220: 726f 6a65 6374 3a20 7b70 726f 6a65 6374  roject: {project
+00011230: 7d2c 2071 7565 7279 3a20 7b70 6172 616d  }, query: {param
+00011240: 737d 220a 2020 2020 2020 2020 7265 7370  s}".        resp
+00011250: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
+00011260: 2822 4745 5422 2c20 7061 7468 2c20 6572  ("GET", path, er
+00011270: 726f 725f 6d65 7373 6167 652c 2070 6172  ror_message, par
+00011280: 616d 733d 7061 7261 6d73 290a 2020 2020  ams=params).    
+00011290: 2020 2020 7265 7475 726e 2072 6573 702e      return resp.
+000112a0: 6a73 6f6e 2829 5b22 656e 7469 7469 6573  json()["entities
+000112b0: 225d 0a0a 2020 2020 4073 7461 7469 636d  "]..    @staticm
+000112c0: 6574 686f 640a 2020 2020 6465 6620 5f67  ethod.    def _g
+000112d0: 656e 6572 6174 655f 7061 7274 6974 696f  enerate_partitio
+000112e0: 6e5f 6279 5f70 6172 616d 7328 0a20 2020  n_by_params(.   
+000112f0: 2020 2020 2070 6172 7469 7469 6f6e 5f62       partition_b
+00011300: 795f 636c 732c 0a20 2020 2020 2020 2070  y_cls,.        p
+00011310: 6172 7469 7469 6f6e 5f62 792c 0a20 2020  artition_by,.   
+00011320: 2020 2020 2072 6f77 735f 7065 725f 7061       rows_per_pa
+00011330: 7274 6974 696f 6e2c 0a20 2020 2020 2020  rtition,.       
+00011340: 2073 6f72 745f 6279 2c0a 2020 2020 2020   sort_by,.      
+00011350: 2020 6f72 6465 722c 0a20 2020 2020 2020    order,.       
+00011360: 206d 6178 5f70 6172 7469 7469 6f6e 733d   max_partitions=
+00011370: 4e6f 6e65 2c0a 2020 2020 293a 0a0a 2020  None,.    ):..  
+00011380: 2020 2020 2020 7061 7274 6974 696f 6e5f        partition_
+00011390: 7061 7261 6d73 203d 207b 0a20 2020 2020  params = {.     
+000113a0: 2020 2020 2020 2022 7061 7274 6974 696f         "partitio
+000113b0: 6e2d 6279 223a 2070 6172 7469 7469 6f6e  n-by": partition
+000113c0: 5f62 792c 0a20 2020 2020 2020 2020 2020  _by,.           
+000113d0: 2022 726f 7773 2d70 6572 2d70 6172 7469   "rows-per-parti
+000113e0: 7469 6f6e 223a 2072 6f77 735f 7065 725f  tion": rows_per_
+000113f0: 7061 7274 6974 696f 6e2c 0a20 2020 2020  partition,.     
+00011400: 2020 2020 2020 2022 7061 7274 6974 696f         "partitio
+00011410: 6e2d 736f 7274 2d62 7922 3a20 736f 7274  n-sort-by": sort
+00011420: 5f62 792c 0a20 2020 2020 2020 2020 2020  _by,.           
+00011430: 2022 7061 7274 6974 696f 6e2d 6f72 6465   "partition-orde
+00011440: 7222 3a20 6f72 6465 722c 0a20 2020 2020  r": order,.     
+00011450: 2020 207d 0a20 2020 2020 2020 2069 6620     }.        if 
+00011460: 6d61 785f 7061 7274 6974 696f 6e73 2069  max_partitions i
+00011470: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
+00011480: 2020 2020 2020 2020 7061 7274 6974 696f          partitio
+00011490: 6e5f 7061 7261 6d73 5b22 6d61 782d 7061  n_params["max-pa
+000114a0: 7274 6974 696f 6e73 225d 203d 206d 6178  rtitions"] = max
+000114b0: 5f70 6172 7469 7469 6f6e 730a 2020 2020  _partitions.    
+000114c0: 2020 2020 7265 7475 726e 2070 6172 7469      return parti
+000114d0: 7469 6f6e 5f70 6172 616d 730a 0a20 2020  tion_params..   
+000114e0: 2064 6566 206c 6973 745f 6665 6174 7572   def list_featur
+000114f0: 655f 7365 7473 280a 2020 2020 2020 2020  e_sets(.        
+00011500: 7365 6c66 2c0a 2020 2020 2020 2020 7072  self,.        pr
+00011510: 6f6a 6563 743a 2073 7472 203d 2022 222c  oject: str = "",
+00011520: 0a20 2020 2020 2020 206e 616d 653a 2073  .        name: s
+00011530: 7472 203d 204e 6f6e 652c 0a20 2020 2020  tr = None,.     
+00011540: 2020 2074 6167 3a20 7374 7220 3d20 4e6f     tag: str = No
+00011550: 6e65 2c0a 2020 2020 2020 2020 7374 6174  ne,.        stat
+00011560: 653a 2073 7472 203d 204e 6f6e 652c 0a20  e: str = None,. 
+00011570: 2020 2020 2020 2065 6e74 6974 6965 733a         entities:
+00011580: 204c 6973 745b 7374 725d 203d 204e 6f6e   List[str] = Non
+00011590: 652c 0a20 2020 2020 2020 2066 6561 7475  e,.        featu
+000115a0: 7265 733a 204c 6973 745b 7374 725d 203d  res: List[str] =
+000115b0: 204e 6f6e 652c 0a20 2020 2020 2020 206c   None,.        l
+000115c0: 6162 656c 733a 204c 6973 745b 7374 725d  abels: List[str]
+000115d0: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
+000115e0: 2070 6172 7469 7469 6f6e 5f62 793a 2055   partition_by: U
+000115f0: 6e69 6f6e 5b73 6368 656d 6173 2e46 6561  nion[schemas.Fea
+00011600: 7475 7265 5374 6f72 6550 6172 7469 7469  tureStorePartiti
+00011610: 6f6e 4279 4669 656c 642c 2073 7472 5d20  onByField, str] 
+00011620: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+00011630: 726f 7773 5f70 6572 5f70 6172 7469 7469  rows_per_partiti
+00011640: 6f6e 3a20 696e 7420 3d20 312c 0a20 2020  on: int = 1,.   
+00011650: 2020 2020 2070 6172 7469 7469 6f6e 5f73       partition_s
+00011660: 6f72 745f 6279 3a20 556e 696f 6e5b 7363  ort_by: Union[sc
+00011670: 6865 6d61 732e 536f 7274 4669 656c 642c  hemas.SortField,
+00011680: 2073 7472 5d20 3d20 4e6f 6e65 2c0a 2020   str] = None,.  
+00011690: 2020 2020 2020 7061 7274 6974 696f 6e5f        partition_
+000116a0: 6f72 6465 723a 2055 6e69 6f6e 5b73 6368  order: Union[sch
+000116b0: 656d 6173 2e4f 7264 6572 5479 7065 2c20  emas.OrderType, 
+000116c0: 7374 725d 203d 2073 6368 656d 6173 2e4f  str] = schemas.O
+000116d0: 7264 6572 5479 7065 2e64 6573 632c 0a20  rderType.desc,. 
+000116e0: 2020 2029 202d 3e20 4c69 7374 5b46 6561     ) -> List[Fea
+000116f0: 7475 7265 5365 745d 3a0a 2020 2020 2020  tureSet]:.      
+00011700: 2020 2222 2252 6574 7269 6576 6520 6120    """Retrieve a 
+00011710: 6c69 7374 206f 6620 6665 6174 7572 652d  list of feature-
+00011720: 7365 7473 206d 6174 6368 696e 6720 7468  sets matching th
+00011730: 6520 6372 6974 6572 6961 2070 726f 7669  e criteria provi
+00011740: 6465 642e 0a0a 2020 2020 2020 2020 3a70  ded...        :p
+00011750: 6172 616d 2070 726f 6a65 6374 3a20 5072  aram project: Pr
+00011760: 6f6a 6563 7420 6e61 6d65 2e0a 2020 2020  oject name..    
+00011770: 2020 2020 3a70 6172 616d 206e 616d 653a      :param name:
+00011780: 204e 616d 6520 6f66 2066 6561 7475 7265   Name of feature
+00011790: 2d73 6574 2074 6f20 6d61 7463 682e 2054  -set to match. T
+000117a0: 6869 7320 6973 2061 206c 696b 6520 7175  his is a like qu
+000117b0: 6572 792c 2061 6e64 2069 7320 6361 7365  ery, and is case
+000117c0: 2d69 6e73 656e 7369 7469 7665 2e0a 2020  -insensitive..  
+000117d0: 2020 2020 2020 3a70 6172 616d 2074 6167        :param tag
+000117e0: 3a20 4d61 7463 6820 6665 6174 7572 652d  : Match feature-
+000117f0: 7365 7473 2077 6974 6820 7370 6563 6966  sets with specif
+00011800: 6963 2074 6167 2e0a 2020 2020 2020 2020  ic tag..        
+00011810: 3a70 6172 616d 2073 7461 7465 3a20 4d61  :param state: Ma
+00011820: 7463 6820 6665 6174 7572 652d 7365 7473  tch feature-sets
+00011830: 2077 6974 6820 6120 7370 6563 6966 6963   with a specific
+00011840: 2073 7461 7465 2e0a 2020 2020 2020 2020   state..        
+00011850: 3a70 6172 616d 2065 6e74 6974 6965 733a  :param entities:
+00011860: 204d 6174 6368 2066 6561 7475 7265 2d73   Match feature-s
+00011870: 6574 7320 7768 6963 6820 636f 6e74 6169  ets which contai
+00011880: 6e20 656e 7469 7469 6573 2077 686f 7365  n entities whose
+00011890: 206e 616d 6520 6973 2069 6e20 7468 6973   name is in this
+000118a0: 206c 6973 742e 0a20 2020 2020 2020 203a   list..        :
+000118b0: 7061 7261 6d20 6665 6174 7572 6573 3a20  param features: 
+000118c0: 4d61 7463 6820 6665 6174 7572 652d 7365  Match feature-se
+000118d0: 7473 2077 6869 6368 2063 6f6e 7461 696e  ts which contain
+000118e0: 2066 6561 7475 7265 7320 7768 6f73 6520   features whose 
+000118f0: 6e61 6d65 2069 7320 696e 2074 6869 7320  name is in this 
+00011900: 6c69 7374 2e0a 2020 2020 2020 2020 3a70  list..        :p
+00011910: 6172 616d 206c 6162 656c 733a 204d 6174  aram labels: Mat
+00011920: 6368 2066 6561 7475 7265 2d73 6574 7320  ch feature-sets 
+00011930: 7768 6963 6820 6861 7665 2074 6865 7365  which have these
+00011940: 206c 6162 656c 732e 0a20 2020 2020 2020   labels..       
+00011950: 203a 7061 7261 6d20 7061 7274 6974 696f   :param partitio
+00011960: 6e5f 6279 3a20 4669 656c 6420 746f 2067  n_by: Field to g
+00011970: 726f 7570 2072 6573 756c 7473 2062 792e  roup results by.
+00011980: 204f 6e6c 7920 616c 6c6f 7765 6420 7661   Only allowed va
+00011990: 6c75 6520 6973 2060 6e61 6d65 602e 2057  lue is `name`. W
+000119a0: 6865 6e20 6070 6172 7469 7469 6f6e 5f62  hen `partition_b
+000119b0: 7960 2069 7320 7370 6563 6966 6965 642c  y` is specified,
+000119c0: 0a20 2020 2020 2020 2020 2020 2074 6865  .            the
+000119d0: 2060 7061 7274 6974 696f 6e5f 736f 7274   `partition_sort
+000119e0: 5f62 7960 2070 6172 616d 6574 6572 206d  _by` parameter m
+000119f0: 7573 7420 6265 2070 726f 7669 6465 6420  ust be provided 
+00011a00: 6173 2077 656c 6c2e 0a20 2020 2020 2020  as well..       
+00011a10: 203a 7061 7261 6d20 726f 7773 5f70 6572   :param rows_per
+00011a20: 5f70 6172 7469 7469 6f6e 3a20 486f 7720  _partition: How 
+00011a30: 6d61 6e79 2074 6f70 2072 6f77 7320 2870  many top rows (p
+00011a40: 6572 2073 6f72 7469 6e67 2064 6566 696e  er sorting defin
+00011a50: 6564 2062 7920 6070 6172 7469 7469 6f6e  ed by `partition
+00011a60: 5f73 6f72 745f 6279 6020 616e 6420 6070  _sort_by` and `p
+00011a70: 6172 7469 7469 6f6e 5f6f 7264 6572 6029  artition_order`)
+00011a80: 0a20 2020 2020 2020 2020 2020 2074 6f20  .            to 
+00011a90: 7265 7475 726e 2070 6572 2067 726f 7570  return per group
+00011aa0: 2e20 4465 6661 756c 7420 7661 6c75 6520  . Default value 
+00011ab0: 6973 2031 2e0a 2020 2020 2020 2020 3a70  is 1..        :p
+00011ac0: 6172 616d 2070 6172 7469 7469 6f6e 5f73  aram partition_s
+00011ad0: 6f72 745f 6279 3a20 5768 6174 2066 6965  ort_by: What fie
+00011ae0: 6c64 2074 6f20 736f 7274 2074 6865 2072  ld to sort the r
+00011af0: 6573 756c 7473 2062 792c 2077 6974 6869  esults by, withi
+00011b00: 6e20 6561 6368 2070 6172 7469 7469 6f6e  n each partition
+00011b10: 2064 6566 696e 6564 2062 7920 6070 6172   defined by `par
+00011b20: 7469 7469 6f6e 5f62 7960 2e0a 2020 2020  tition_by`..    
+00011b30: 2020 2020 2020 2020 4375 7272 656e 746c          Currentl
+00011b40: 7920 7468 6520 6f6e 6c79 2061 6c6c 6f77  y the only allow
+00011b50: 6564 2076 616c 7565 2061 7265 2060 6372  ed value are `cr
+00011b60: 6561 7465 6460 2061 6e64 2060 7570 6461  eated` and `upda
+00011b70: 7465 6460 2e0a 2020 2020 2020 2020 3a70  ted`..        :p
+00011b80: 6172 616d 2070 6172 7469 7469 6f6e 5f6f  aram partition_o
+00011b90: 7264 6572 3a20 4f72 6465 7220 6f66 2073  rder: Order of s
+00011ba0: 6f72 7469 6e67 2077 6974 6869 6e20 7061  orting within pa
+00011bb0: 7274 6974 696f 6e73 202d 2060 6173 6360  rtitions - `asc`
+00011bc0: 206f 7220 6064 6573 6360 2e20 4465 6661   or `desc`. Defa
+00011bd0: 756c 7420 6973 2060 6465 7363 602e 0a20  ult is `desc`.. 
+00011be0: 2020 2020 2020 203a 7265 7475 726e 733a         :returns:
+00011bf0: 204c 6973 7420 6f66 206d 6174 6368 696e   List of matchin
+00011c00: 6720 3a70 793a 636c 6173 733a 607e 6d6c  g :py:class:`~ml
+00011c10: 7275 6e2e 6665 6174 7572 655f 7374 6f72  run.feature_stor
+00011c20: 652e 4665 6174 7572 6553 6574 6020 6f62  e.FeatureSet` ob
+00011c30: 6a65 6374 732e 0a20 2020 2020 2020 2022  jects..        "
+00011c40: 2222 0a0a 2020 2020 2020 2020 7072 6f6a  ""..        proj
+00011c50: 6563 7420 3d20 7072 6f6a 6563 7420 6f72  ect = project or
+00011c60: 2063 6f6e 6669 672e 6465 6661 756c 745f   config.default_
+00011c70: 7072 6f6a 6563 740a 0a20 2020 2020 2020  project..       
+00011c80: 2070 6172 616d 7320 3d20 7b0a 2020 2020   params = {.    
+00011c90: 2020 2020 2020 2020 226e 616d 6522 3a20          "name": 
+00011ca0: 6e61 6d65 2c0a 2020 2020 2020 2020 2020  name,.          
+00011cb0: 2020 2273 7461 7465 223a 2073 7461 7465    "state": state
+00011cc0: 2c0a 2020 2020 2020 2020 2020 2020 2274  ,.            "t
+00011cd0: 6167 223a 2074 6167 2c0a 2020 2020 2020  ag": tag,.      
+00011ce0: 2020 2020 2020 2265 6e74 6974 7922 3a20        "entity": 
+00011cf0: 656e 7469 7469 6573 206f 7220 5b5d 2c0a  entities or [],.
+00011d00: 2020 2020 2020 2020 2020 2020 2266 6561              "fea
+00011d10: 7475 7265 223a 2066 6561 7475 7265 7320  ture": features 
+00011d20: 6f72 205b 5d2c 0a20 2020 2020 2020 2020  or [],.         
+00011d30: 2020 2022 6c61 6265 6c22 3a20 6c61 6265     "label": labe
+00011d40: 6c73 206f 7220 5b5d 2c0a 2020 2020 2020  ls or [],.      
+00011d50: 2020 7d0a 2020 2020 2020 2020 6966 2070    }.        if p
+00011d60: 6172 7469 7469 6f6e 5f62 793a 0a20 2020  artition_by:.   
+00011d70: 2020 2020 2020 2020 2070 6172 616d 732e           params.
+00011d80: 7570 6461 7465 280a 2020 2020 2020 2020  update(.        
+00011d90: 2020 2020 2020 2020 7365 6c66 2e5f 6765          self._ge
+00011da0: 6e65 7261 7465 5f70 6172 7469 7469 6f6e  nerate_partition
+00011db0: 5f62 795f 7061 7261 6d73 280a 2020 2020  _by_params(.    
+00011dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011dd0: 7363 6865 6d61 732e 4665 6174 7572 6553  schemas.FeatureS
+00011de0: 746f 7265 5061 7274 6974 696f 6e42 7946  torePartitionByF
+00011df0: 6965 6c64 2c0a 2020 2020 2020 2020 2020  ield,.          
+00011e00: 2020 2020 2020 2020 2020 7061 7274 6974            partit
+00011e10: 696f 6e5f 6279 2c0a 2020 2020 2020 2020  ion_by,.        
+00011e20: 2020 2020 2020 2020 2020 2020 726f 7773              rows
+00011e30: 5f70 6572 5f70 6172 7469 7469 6f6e 2c0a  _per_partition,.
+00011e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011e50: 2020 2020 7061 7274 6974 696f 6e5f 736f      partition_so
+00011e60: 7274 5f62 792c 0a20 2020 2020 2020 2020  rt_by,.         
+00011e70: 2020 2020 2020 2020 2020 2070 6172 7469             parti
+00011e80: 7469 6f6e 5f6f 7264 6572 2c0a 2020 2020  tion_order,.    
+00011e90: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00011ea0: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00011eb0: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
+00011ec0: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
+00011ed0: 2f66 6561 7475 7265 2d73 6574 7322 0a0a  /feature-sets"..
+00011ee0: 2020 2020 2020 2020 6572 726f 725f 6d65          error_me
+00011ef0: 7373 6167 6520 3d20 280a 2020 2020 2020  ssage = (.      
+00011f00: 2020 2020 2020 6622 4661 696c 6564 206c        f"Failed l
+00011f10: 6973 7469 6e67 2066 6561 7475 7265 2d73  isting feature-s
+00011f20: 6574 732c 2070 726f 6a65 6374 3a20 7b70  ets, project: {p
+00011f30: 726f 6a65 6374 7d2c 2071 7565 7279 3a20  roject}, query: 
+00011f40: 7b70 6172 616d 737d 220a 2020 2020 2020  {params}".      
+00011f50: 2020 290a 2020 2020 2020 2020 7265 7370    ).        resp
+00011f60: 203d 2073 656c 662e 6170 695f 6361 6c6c   = self.api_call
+00011f70: 2822 4745 5422 2c20 7061 7468 2c20 6572  ("GET", path, er
+00011f80: 726f 725f 6d65 7373 6167 652c 2070 6172  ror_message, par
+00011f90: 616d 733d 7061 7261 6d73 290a 2020 2020  ams=params).    
+00011fa0: 2020 2020 6665 6174 7572 655f 7365 7473      feature_sets
+00011fb0: 203d 2072 6573 702e 6a73 6f6e 2829 5b22   = resp.json()["
+00011fc0: 6665 6174 7572 655f 7365 7473 225d 0a20  feature_sets"]. 
+00011fd0: 2020 2020 2020 2069 6620 6665 6174 7572         if featur
+00011fe0: 655f 7365 7473 3a0a 2020 2020 2020 2020  e_sets:.        
+00011ff0: 2020 2020 7265 7475 726e 205b 4665 6174      return [Feat
+00012000: 7572 6553 6574 2e66 726f 6d5f 6469 6374  ureSet.from_dict
+00012010: 286f 626a 2920 666f 7220 6f62 6a20 696e  (obj) for obj in
+00012020: 2066 6561 7475 7265 5f73 6574 735d 0a0a   feature_sets]..
+00012030: 2020 2020 6465 6620 7374 6f72 655f 6665      def store_fe
+00012040: 6174 7572 655f 7365 7428 0a20 2020 2020  ature_set(.     
+00012050: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+00012060: 2066 6561 7475 7265 5f73 6574 3a20 556e   feature_set: Un
+00012070: 696f 6e5b 6469 6374 2c20 7363 6865 6d61  ion[dict, schema
+00012080: 732e 4665 6174 7572 6553 6574 2c20 4665  s.FeatureSet, Fe
+00012090: 6174 7572 6553 6574 5d2c 0a20 2020 2020  atureSet],.     
+000120a0: 2020 206e 616d 653d 4e6f 6e65 2c0a 2020     name=None,.  
+000120b0: 2020 2020 2020 7072 6f6a 6563 743d 2222        project=""
+000120c0: 2c0a 2020 2020 2020 2020 7461 673d 4e6f  ,.        tag=No
+000120d0: 6e65 2c0a 2020 2020 2020 2020 7569 643d  ne,.        uid=
+000120e0: 4e6f 6e65 2c0a 2020 2020 2020 2020 7665  None,.        ve
+000120f0: 7273 696f 6e65 643d 5472 7565 2c0a 2020  rsioned=True,.  
+00012100: 2020 2920 2d3e 2064 6963 743a 0a20 2020    ) -> dict:.   
+00012110: 2020 2020 2022 2222 5361 7665 2061 203a       """Save a :
+00012120: 7079 3a63 6c61 7373 3a60 7e6d 6c72 756e  py:class:`~mlrun
+00012130: 2e66 6561 7475 7265 5f73 746f 7265 2e46  .feature_store.F
+00012140: 6561 7475 7265 5365 7460 206f 626a 6563  eatureSet` objec
+00012150: 7420 696e 2074 6865 203a 7079 3a6d 6f64  t in the :py:mod
+00012160: 3a60 6d6c 7275 6e60 2044 422e 2054 6865  :`mlrun` DB. The
+00012170: 0a20 2020 2020 2020 2066 6561 7475 7265  .        feature
+00012180: 2d73 6574 2063 616e 2062 6520 6569 7468  -set can be eith
+00012190: 6572 2061 206e 6577 206f 626a 6563 7420  er a new object 
+000121a0: 6f72 2061 206d 6f64 6966 6963 6174 696f  or a modificatio
+000121b0: 6e20 746f 2065 7869 7374 696e 6720 6f62  n to existing ob
+000121c0: 6a65 6374 2072 6566 6572 656e 6365 6420  ject referenced 
+000121d0: 6279 2074 6865 2070 6172 616d 7320 6f66  by the params of
+000121e0: 0a20 2020 2020 2020 2074 6865 2066 756e  .        the fun
+000121f0: 6374 696f 6e2e 0a0a 2020 2020 2020 2020  ction...        
+00012200: 3a70 6172 616d 2066 6561 7475 7265 5f73  :param feature_s
+00012210: 6574 3a20 5468 6520 3a70 793a 636c 6173  et: The :py:clas
+00012220: 733a 607e 6d6c 7275 6e2e 6665 6174 7572  s:`~mlrun.featur
+00012230: 655f 7374 6f72 652e 4665 6174 7572 6553  e_store.FeatureS
+00012240: 6574 6020 746f 2073 746f 7265 2e0a 2020  et` to store..  
+00012250: 2020 2020 2020 3a70 6172 616d 206e 616d        :param nam
+00012260: 653a 2020 2020 4e61 6d65 206f 6620 6665  e:    Name of fe
+00012270: 6174 7572 6520 7365 742e 0a20 2020 2020  ature set..     
+00012280: 2020 203a 7061 7261 6d20 7072 6f6a 6563     :param projec
+00012290: 743a 204e 616d 6520 6f66 2070 726f 6a65  t: Name of proje
+000122a0: 6374 2074 6869 7320 6665 6174 7572 652d  ct this feature-
+000122b0: 7365 7420 6265 6c6f 6e67 7320 746f 2e0a  set belongs to..
+000122c0: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
+000122d0: 6167 3a20 5468 6520 6060 7461 6760 6020  ag: The ``tag`` 
+000122e0: 6f66 2074 6865 206f 626a 6563 7420 746f  of the object to
+000122f0: 2072 6570 6c61 6365 2069 6e20 7468 6520   replace in the 
+00012300: 4442 2c20 666f 7220 6578 616d 706c 6520  DB, for example 
+00012310: 6060 6c61 7465 7374 6060 2e0a 2020 2020  ``latest``..    
+00012320: 2020 2020 3a70 6172 616d 2075 6964 3a20      :param uid: 
+00012330: 5468 6520 6060 7569 6460 6020 6f66 2074  The ``uid`` of t
+00012340: 6865 206f 626a 6563 7420 746f 2072 6570  he object to rep
+00012350: 6c61 6365 2069 6e20 7468 6520 4442 2e20  lace in the DB. 
+00012360: 4966 2075 7369 6e67 2074 6869 7320 7061  If using this pa
+00012370: 7261 6d65 7465 722c 2074 6865 206d 6f64  rameter, the mod
+00012380: 6966 6965 6420 6f62 6a65 6374 0a20 2020  ified object.   
+00012390: 2020 2020 2020 2020 206d 7573 7420 6861           must ha
+000123a0: 7665 2074 6865 2073 616d 6520 6060 7569  ve the same ``ui
+000123b0: 6460 6020 6f66 2074 6865 2070 7265 7669  d`` of the previ
+000123c0: 6f75 736c 792d 6578 6973 7469 6e67 206f  ously-existing o
+000123d0: 626a 6563 742e 2054 6869 7320 6361 6e6e  bject. This cann
+000123e0: 6f74 2062 6520 7573 6564 2066 6f72 206e  ot be used for n
+000123f0: 6f6e 2d76 6572 7369 6f6e 6564 206f 626a  on-versioned obj
+00012400: 6563 7473 2e0a 2020 2020 2020 2020 3a70  ects..        :p
+00012410: 6172 616d 2076 6572 7369 6f6e 6564 3a20  aram versioned: 
+00012420: 5768 6574 6865 7220 746f 206d 6169 6e74  Whether to maint
+00012430: 6169 6e20 7665 7273 696f 6e73 2066 6f72  ain versions for
+00012440: 2074 6869 7320 6665 6174 7572 652d 7365   this feature-se
+00012450: 742e 2041 6c6c 2076 6572 7369 6f6e 7320  t. All versions 
+00012460: 6f66 2061 2076 6572 7369 6f6e 6564 206f  of a versioned o
+00012470: 626a 6563 740a 2020 2020 2020 2020 2020  bject.          
+00012480: 2020 7769 6c6c 2062 6520 6b65 7074 2069    will be kept i
+00012490: 6e20 7468 6520 4442 2061 6e64 2063 616e  n the DB and can
+000124a0: 2062 6520 7265 7472 6965 7665 6420 756e   be retrieved un
+000124b0: 7469 6c20 6578 706c 6963 6974 6c79 2064  til explicitly d
+000124c0: 656c 6574 6564 2e0a 2020 2020 2020 2020  eleted..        
+000124d0: 3a72 6574 7572 6e73 3a20 5468 6520 3a70  :returns: The :p
+000124e0: 793a 636c 6173 733a 607e 6d6c 7275 6e2e  y:class:`~mlrun.
+000124f0: 6665 6174 7572 655f 7374 6f72 652e 4665  feature_store.Fe
+00012500: 6174 7572 6553 6574 6020 6f62 6a65 6374  atureSet` object
+00012510: 2028 6173 2064 6963 7429 2e0a 2020 2020   (as dict)..    
+00012520: 2020 2020 2222 220a 0a20 2020 2020 2020      """..       
+00012530: 2072 6566 6572 656e 6365 203d 2073 656c   reference = sel
+00012540: 662e 5f72 6573 6f6c 7665 5f72 6566 6572  f._resolve_refer
+00012550: 656e 6365 2874 6167 2c20 7569 6429 0a20  ence(tag, uid). 
+00012560: 2020 2020 2020 2070 6172 616d 7320 3d20         params = 
+00012570: 7b22 7665 7273 696f 6e65 6422 3a20 7665  {"versioned": ve
+00012580: 7273 696f 6e65 647d 0a0a 2020 2020 2020  rsioned}..      
+00012590: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+000125a0: 6665 6174 7572 655f 7365 742c 2073 6368  feature_set, sch
+000125b0: 656d 6173 2e46 6561 7475 7265 5365 7429  emas.FeatureSet)
+000125c0: 3a0a 2020 2020 2020 2020 2020 2020 6665  :.            fe
+000125d0: 6174 7572 655f 7365 7420 3d20 6665 6174  ature_set = feat
+000125e0: 7572 655f 7365 742e 6469 6374 2829 0a20  ure_set.dict(). 
+000125f0: 2020 2020 2020 2065 6c69 6620 6973 696e         elif isin
+00012600: 7374 616e 6365 2866 6561 7475 7265 5f73  stance(feature_s
+00012610: 6574 2c20 4665 6174 7572 6553 6574 293a  et, FeatureSet):
+00012620: 0a20 2020 2020 2020 2020 2020 2066 6561  .            fea
+00012630: 7475 7265 5f73 6574 203d 2066 6561 7475  ture_set = featu
+00012640: 7265 5f73 6574 2e74 6f5f 6469 6374 2829  re_set.to_dict()
+00012650: 0a0a 2020 2020 2020 2020 6e61 6d65 203d  ..        name =
+00012660: 206e 616d 6520 6f72 2066 6561 7475 7265   name or feature
+00012670: 5f73 6574 5b22 6d65 7461 6461 7461 225d  _set["metadata"]
+00012680: 5b22 6e61 6d65 225d 0a20 2020 2020 2020  ["name"].       
+00012690: 2070 726f 6a65 6374 203d 2028 0a20 2020   project = (.   
+000126a0: 2020 2020 2020 2020 2070 726f 6a65 6374           project
+000126b0: 206f 7220 6665 6174 7572 655f 7365 745b   or feature_set[
+000126c0: 226d 6574 6164 6174 6122 5d2e 6765 7428  "metadata"].get(
+000126d0: 2270 726f 6a65 6374 2229 206f 7220 636f  "project") or co
+000126e0: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
+000126f0: 6a65 6374 0a20 2020 2020 2020 2029 0a20  ject.        ). 
+00012700: 2020 2020 2020 2070 6174 6820 3d20 6622         path = f"
+00012710: 7072 6f6a 6563 7473 2f7b 7072 6f6a 6563  projects/{projec
+00012720: 747d 2f66 6561 7475 7265 2d73 6574 732f  t}/feature-sets/
+00012730: 7b6e 616d 657d 2f72 6566 6572 656e 6365  {name}/reference
+00012740: 732f 7b72 6566 6572 656e 6365 7d22 0a20  s/{reference}". 
+00012750: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+00012760: 7361 6765 203d 2066 2246 6169 6c65 6420  sage = f"Failed 
+00012770: 7374 6f72 696e 6720 6665 6174 7572 652d  storing feature-
+00012780: 7365 7420 7b70 726f 6a65 6374 7d2f 7b6e  set {project}/{n
+00012790: 616d 657d 220a 2020 2020 2020 2020 7265  ame}".        re
+000127a0: 7370 203d 2073 656c 662e 6170 695f 6361  sp = self.api_ca
+000127b0: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
+000127c0: 2250 5554 222c 2070 6174 682c 2065 7272  "PUT", path, err
+000127d0: 6f72 5f6d 6573 7361 6765 2c20 7061 7261  or_message, para
+000127e0: 6d73 3d70 6172 616d 732c 2062 6f64 793d  ms=params, body=
+000127f0: 6469 6374 5f74 6f5f 6a73 6f6e 2866 6561  dict_to_json(fea
+00012800: 7475 7265 5f73 6574 290a 2020 2020 2020  ture_set).      
+00012810: 2020 290a 2020 2020 2020 2020 7265 7475    ).        retu
+00012820: 726e 2072 6573 702e 6a73 6f6e 2829 0a0a  rn resp.json()..
+00012830: 2020 2020 6465 6620 7061 7463 685f 6665      def patch_fe
+00012840: 6174 7572 655f 7365 7428 0a20 2020 2020  ature_set(.     
+00012850: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+00012860: 206e 616d 652c 0a20 2020 2020 2020 2066   name,.        f
+00012870: 6561 7475 7265 5f73 6574 5f75 7064 6174  eature_set_updat
+00012880: 653a 2064 6963 742c 0a20 2020 2020 2020  e: dict,.       
+00012890: 2070 726f 6a65 6374 3d22 222c 0a20 2020   project="",.   
+000128a0: 2020 2020 2074 6167 3d4e 6f6e 652c 0a20       tag=None,. 
+000128b0: 2020 2020 2020 2075 6964 3d4e 6f6e 652c         uid=None,
+000128c0: 0a20 2020 2020 2020 2070 6174 6368 5f6d  .        patch_m
+000128d0: 6f64 653a 2055 6e69 6f6e 5b73 7472 2c20  ode: Union[str, 
+000128e0: 7363 6865 6d61 732e 5061 7463 684d 6f64  schemas.PatchMod
+000128f0: 655d 203d 2073 6368 656d 6173 2e50 6174  e] = schemas.Pat
+00012900: 6368 4d6f 6465 2e72 6570 6c61 6365 2c0a  chMode.replace,.
+00012910: 2020 2020 293a 0a20 2020 2020 2020 2022      ):.        "
+00012920: 2222 4d6f 6469 6679 2028 7061 7463 6829  ""Modify (patch)
+00012930: 2061 6e20 6578 6973 7469 6e67 203a 7079   an existing :py
+00012940: 3a63 6c61 7373 3a60 7e6d 6c72 756e 2e66  :class:`~mlrun.f
+00012950: 6561 7475 7265 5f73 746f 7265 2e46 6561  eature_store.Fea
+00012960: 7475 7265 5365 7460 206f 626a 6563 742e  tureSet` object.
+00012970: 0a20 2020 2020 2020 2054 6865 206f 626a  .        The obj
+00012980: 6563 7420 6973 2069 6465 6e74 6966 6965  ect is identifie
+00012990: 6420 6279 2069 7473 206e 616d 6520 2861  d by its name (a
+000129a0: 6e64 2070 726f 6a65 6374 2069 7420 6265  nd project it be
+000129b0: 6c6f 6e67 7320 746f 292c 2061 7320 7765  longs to), as we
+000129c0: 6c6c 2061 7320 6f70 7469 6f6e 616c 6c79  ll as optionally
+000129d0: 2061 2060 6074 6167 6060 206f 7220 6974   a ``tag`` or it
+000129e0: 730a 2020 2020 2020 2020 6060 7569 6460  s.        ``uid`
+000129f0: 6020 2866 6f72 2076 6572 7369 6f6e 6564  ` (for versioned
+00012a00: 206f 626a 6563 7429 2e20 4966 2062 6f74   object). If bot
+00012a10: 6820 6060 7461 6760 6020 616e 6420 6060  h ``tag`` and ``
+00012a20: 7569 6460 6020 6172 6520 6f6d 6974 7465  uid`` are omitte
+00012a30: 6420 7468 656e 2074 6865 206f 626a 6563  d then the objec
+00012a40: 7420 7769 7468 2074 6167 2060 606c 6174  t with tag ``lat
+00012a50: 6573 7460 600a 2020 2020 2020 2020 6973  est``.        is
+00012a60: 206d 6f64 6966 6965 642e 0a0a 2020 2020   modified...    
+00012a70: 2020 2020 3a70 6172 616d 206e 616d 653a      :param name:
+00012a80: 204e 616d 6520 6f66 2074 6865 206f 626a   Name of the obj
+00012a90: 6563 7420 746f 2070 6174 6368 2e0a 2020  ect to patch..  
+00012aa0: 2020 2020 2020 3a70 6172 616d 2066 6561        :param fea
+00012ab0: 7475 7265 5f73 6574 5f75 7064 6174 653a  ture_set_update:
+00012ac0: 2054 6865 206d 6f64 6966 6963 6174 696f   The modificatio
+00012ad0: 6e73 206e 6565 6465 6420 696e 2074 6865  ns needed in the
+00012ae0: 206f 626a 6563 742e 2054 6869 7320 7061   object. This pa
+00012af0: 7261 6d65 7465 7220 6f6e 6c79 2068 6173  rameter only has
+00012b00: 2074 6865 2063 6861 6e67 6573 2069 6e20   the changes in 
+00012b10: 6974 2c0a 2020 2020 2020 2020 2020 2020  it,.            
+00012b20: 6e6f 7420 6120 6675 6c6c 206f 626a 6563  not a full objec
+00012b30: 742e 0a20 2020 2020 2020 2020 2020 2045  t..            E
+00012b40: 7861 6d70 6c65 3a3a 0a0a 2020 2020 2020  xample::..      
+00012b50: 2020 2020 2020 2020 2020 6665 6174 7572            featur
+00012b60: 655f 7365 745f 7570 6461 7465 203d 207b  e_set_update = {
+00012b70: 2273 7461 7475 7322 3a20 7b22 7072 6f63  "status": {"proc
+00012b80: 6573 7365 6422 203a 2054 7275 657d 7d0a  essed" : True}}.
+00012b90: 0a20 2020 2020 2020 2020 2020 2057 696c  .            Wil
+00012ba0: 6c20 6170 706c 7920 7468 6520 6669 656c  l apply the fiel
+00012bb0: 6420 6060 7374 6174 7573 2e70 726f 6365  d ``status.proce
+00012bc0: 7373 6564 6060 2074 6f20 7468 6520 6578  ssed`` to the ex
+00012bd0: 6973 7469 6e67 206f 626a 6563 742e 0a20  isting object.. 
+00012be0: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
+00012bf0: 6f6a 6563 743a 2050 726f 6a65 6374 2077  oject: Project w
+00012c00: 6869 6368 2063 6f6e 7461 696e 7320 7468  hich contains th
+00012c10: 6520 6d6f 6469 6669 6564 206f 626a 6563  e modified objec
+00012c20: 742e 0a20 2020 2020 2020 203a 7061 7261  t..        :para
+00012c30: 6d20 7461 673a 2054 6865 2074 6167 206f  m tag: The tag o
+00012c40: 6620 7468 6520 6f62 6a65 6374 2074 6f20  f the object to 
+00012c50: 6d6f 6469 6679 2e0a 2020 2020 2020 2020  modify..        
+00012c60: 3a70 6172 616d 2075 6964 3a20 7569 6420  :param uid: uid 
+00012c70: 6f66 2074 6865 206f 626a 6563 7420 746f  of the object to
+00012c80: 206d 6f64 6966 792e 0a20 2020 2020 2020   modify..       
+00012c90: 203a 7061 7261 6d20 7061 7463 685f 6d6f   :param patch_mo
+00012ca0: 6465 3a20 5468 6520 7374 7261 7465 6779  de: The strategy
+00012cb0: 2066 6f72 206d 6572 6769 6e67 2074 6865   for merging the
+00012cc0: 2063 6861 6e67 6573 2077 6974 6820 7468   changes with th
+00012cd0: 6520 6578 6973 7469 6e67 206f 626a 6563  e existing objec
+00012ce0: 742e 2043 616e 2062 6520 6569 7468 6572  t. Can be either
+00012cf0: 2060 6072 6570 6c61 6365 6060 0a20 2020   ``replace``.   
+00012d00: 2020 2020 2020 2020 206f 7220 6060 6164           or ``ad
+00012d10: 6469 7469 7665 6060 2e0a 2020 2020 2020  ditive``..      
+00012d20: 2020 2222 220a 2020 2020 2020 2020 7072    """.        pr
+00012d30: 6f6a 6563 7420 3d20 7072 6f6a 6563 7420  oject = project 
+00012d40: 6f72 2063 6f6e 6669 672e 6465 6661 756c  or config.defaul
+00012d50: 745f 7072 6f6a 6563 740a 2020 2020 2020  t_project.      
+00012d60: 2020 7265 6665 7265 6e63 6520 3d20 7365    reference = se
+00012d70: 6c66 2e5f 7265 736f 6c76 655f 7265 6665  lf._resolve_refe
+00012d80: 7265 6e63 6528 7461 672c 2075 6964 290a  rence(tag, uid).
+00012d90: 2020 2020 2020 2020 6865 6164 6572 7320          headers 
+00012da0: 3d20 7b73 6368 656d 6173 2e48 6561 6465  = {schemas.Heade
+00012db0: 724e 616d 6573 2e70 6174 6368 5f6d 6f64  rNames.patch_mod
+00012dc0: 653a 2070 6174 6368 5f6d 6f64 657d 0a20  e: patch_mode}. 
+00012dd0: 2020 2020 2020 2070 6174 6820 3d20 6622         path = f"
+00012de0: 7072 6f6a 6563 7473 2f7b 7072 6f6a 6563  projects/{projec
+00012df0: 747d 2f66 6561 7475 7265 2d73 6574 732f  t}/feature-sets/
+00012e00: 7b6e 616d 657d 2f72 6566 6572 656e 6365  {name}/reference
+00012e10: 732f 7b72 6566 6572 656e 6365 7d22 0a20  s/{reference}". 
+00012e20: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+00012e30: 7361 6765 203d 2066 2246 6169 6c65 6420  sage = f"Failed 
+00012e40: 7570 6461 7469 6e67 2066 6561 7475 7265  updating feature
+00012e50: 2d73 6574 207b 7072 6f6a 6563 747d 2f7b  -set {project}/{
+00012e60: 6e61 6d65 7d22 0a20 2020 2020 2020 2073  name}".        s
+00012e70: 656c 662e 6170 695f 6361 6c6c 280a 2020  elf.api_call(.  
+00012e80: 2020 2020 2020 2020 2020 2250 4154 4348            "PATCH
+00012e90: 222c 0a20 2020 2020 2020 2020 2020 2070  ",.            p
+00012ea0: 6174 682c 0a20 2020 2020 2020 2020 2020  ath,.           
+00012eb0: 2065 7272 6f72 5f6d 6573 7361 6765 2c0a   error_message,.
+00012ec0: 2020 2020 2020 2020 2020 2020 626f 6479              body
+00012ed0: 3d64 6963 745f 746f 5f6a 736f 6e28 6665  =dict_to_json(fe
+00012ee0: 6174 7572 655f 7365 745f 7570 6461 7465  ature_set_update
+00012ef0: 292c 0a20 2020 2020 2020 2020 2020 2068  ),.            h
+00012f00: 6561 6465 7273 3d68 6561 6465 7273 2c0a  eaders=headers,.
+00012f10: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
+00012f20: 6566 2064 656c 6574 655f 6665 6174 7572  ef delete_featur
+00012f30: 655f 7365 7428 7365 6c66 2c20 6e61 6d65  e_set(self, name
+00012f40: 2c20 7072 6f6a 6563 743d 2222 2c20 7461  , project="", ta
+00012f50: 673d 4e6f 6e65 2c20 7569 643d 4e6f 6e65  g=None, uid=None
+00012f60: 293a 0a20 2020 2020 2020 2022 2222 4465  ):.        """De
+00012f70: 6c65 7465 2061 203a 7079 3a63 6c61 7373  lete a :py:class
+00012f80: 3a60 7e6d 6c72 756e 2e66 6561 7475 7265  :`~mlrun.feature
+00012f90: 5f73 746f 7265 2e46 6561 7475 7265 5365  _store.FeatureSe
+00012fa0: 7460 206f 626a 6563 7420 6672 6f6d 2074  t` object from t
+00012fb0: 6865 2044 422e 0a20 2020 2020 2020 2049  he DB..        I
+00012fc0: 6620 6060 7461 6760 6020 6f72 2060 6075  f ``tag`` or ``u
+00012fd0: 6964 6060 2061 7265 2073 7065 6369 6669  id`` are specifi
+00012fe0: 6564 2c20 7468 656e 206a 7573 7420 7468  ed, then just th
+00012ff0: 6520 7665 7273 696f 6e20 7265 6665 7265  e version refere
+00013000: 6e63 6564 2062 7920 7468 656d 2077 696c  nced by them wil
+00013010: 6c20 6265 2064 656c 6574 6564 2e20 5573  l be deleted. Us
+00013020: 696e 6720 626f 7468 0a20 2020 2020 2020  ing both.       
+00013030: 2069 7320 6e6f 7420 616c 6c6f 7765 642e   is not allowed.
+00013040: 0a20 2020 2020 2020 2049 6620 6e6f 6e65  .        If none
+00013050: 2061 7265 2073 7065 6369 6669 6564 2c20   are specified, 
+00013060: 7468 656e 2061 6c6c 2069 6e73 7461 6e63  then all instanc
+00013070: 6573 206f 6620 7468 6520 6f62 6a65 6374  es of the object
+00013080: 2077 686f 7365 206e 616d 6520 6973 2060   whose name is `
+00013090: 606e 616d 6560 6020 7769 6c6c 2062 6520  `name`` will be 
+000130a0: 6465 6c65 7465 642e 0a20 2020 2020 2020  deleted..       
+000130b0: 2022 2222 0a20 2020 2020 2020 2070 726f   """.        pro
+000130c0: 6a65 6374 203d 2070 726f 6a65 6374 206f  ject = project o
+000130d0: 7220 636f 6e66 6967 2e64 6566 6175 6c74  r config.default
+000130e0: 5f70 726f 6a65 6374 0a20 2020 2020 2020  _project.       
+000130f0: 2070 6174 6820 3d20 6622 7072 6f6a 6563   path = f"projec
+00013100: 7473 2f7b 7072 6f6a 6563 747d 2f66 6561  ts/{project}/fea
+00013110: 7475 7265 2d73 6574 732f 7b6e 616d 657d  ture-sets/{name}
+00013120: 220a 0a20 2020 2020 2020 2069 6620 7461  "..        if ta
+00013130: 6720 6f72 2075 6964 3a0a 2020 2020 2020  g or uid:.      
+00013140: 2020 2020 2020 7265 6665 7265 6e63 6520        reference 
+00013150: 3d20 7365 6c66 2e5f 7265 736f 6c76 655f  = self._resolve_
+00013160: 7265 6665 7265 6e63 6528 7461 672c 2075  reference(tag, u
+00013170: 6964 290a 2020 2020 2020 2020 2020 2020  id).            
+00013180: 7061 7468 203d 2070 6174 6820 2b20 6622  path = path + f"
+00013190: 2f72 6566 6572 656e 6365 732f 7b72 6566  /references/{ref
+000131a0: 6572 656e 6365 7d22 0a0a 2020 2020 2020  erence}"..      
+000131b0: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
+000131c0: 3d20 6622 4661 696c 6564 2064 656c 6574  = f"Failed delet
+000131d0: 696e 6720 6665 6174 7572 652d 7365 7420  ing feature-set 
+000131e0: 7b6e 616d 657d 220a 2020 2020 2020 2020  {name}".        
+000131f0: 7365 6c66 2e61 7069 5f63 616c 6c28 2244  self.api_call("D
+00013200: 454c 4554 4522 2c20 7061 7468 2c20 6572  ELETE", path, er
+00013210: 726f 725f 6d65 7373 6167 6529 0a0a 2020  ror_message)..  
+00013220: 2020 6465 6620 6372 6561 7465 5f66 6561    def create_fea
+00013230: 7475 7265 5f76 6563 746f 7228 0a20 2020  ture_vector(.   
+00013240: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+00013250: 2020 2066 6561 7475 7265 5f76 6563 746f     feature_vecto
+00013260: 723a 2055 6e69 6f6e 5b64 6963 742c 2073  r: Union[dict, s
+00013270: 6368 656d 6173 2e46 6561 7475 7265 5665  chemas.FeatureVe
+00013280: 6374 6f72 2c20 4665 6174 7572 6556 6563  ctor, FeatureVec
+00013290: 746f 725d 2c0a 2020 2020 2020 2020 7072  tor],.        pr
+000132a0: 6f6a 6563 743d 2222 2c0a 2020 2020 2020  oject="",.      
+000132b0: 2020 7665 7273 696f 6e65 643d 5472 7565    versioned=True
+000132c0: 2c0a 2020 2020 2920 2d3e 2064 6963 743a  ,.    ) -> dict:
+000132d0: 0a20 2020 2020 2020 2022 2222 4372 6561  .        """Crea
+000132e0: 7465 2061 206e 6577 203a 7079 3a63 6c61  te a new :py:cla
+000132f0: 7373 3a60 7e6d 6c72 756e 2e66 6561 7475  ss:`~mlrun.featu
+00013300: 7265 5f73 746f 7265 2e46 6561 7475 7265  re_store.Feature
+00013310: 5665 6374 6f72 6020 616e 6420 7361 7665  Vector` and save
+00013320: 2069 6e20 7468 6520 3a70 793a 6d6f 643a   in the :py:mod:
+00013330: 606d 6c72 756e 6020 4442 2e0a 0a20 2020  `mlrun` DB...   
+00013340: 2020 2020 203a 7061 7261 6d20 6665 6174       :param feat
+00013350: 7572 655f 7665 6374 6f72 3a20 5468 6520  ure_vector: The 
+00013360: 6e65 7720 3a70 793a 636c 6173 733a 607e  new :py:class:`~
+00013370: 6d6c 7275 6e2e 6665 6174 7572 655f 7374  mlrun.feature_st
+00013380: 6f72 652e 4665 6174 7572 6556 6563 746f  ore.FeatureVecto
+00013390: 7260 2074 6f20 6372 6561 7465 2e0a 2020  r` to create..  
+000133a0: 2020 2020 2020 3a70 6172 616d 2070 726f        :param pro
+000133b0: 6a65 6374 3a20 4e61 6d65 206f 6620 7072  ject: Name of pr
+000133c0: 6f6a 6563 7420 7468 6973 2066 6561 7475  oject this featu
+000133d0: 7265 2d76 6563 746f 7220 6265 6c6f 6e67  re-vector belong
+000133e0: 7320 746f 2e0a 2020 2020 2020 2020 3a70  s to..        :p
+000133f0: 6172 616d 2076 6572 7369 6f6e 6564 3a20  aram versioned: 
+00013400: 5768 6574 6865 7220 746f 206d 6169 6e74  Whether to maint
+00013410: 6169 6e20 7665 7273 696f 6e73 2066 6f72  ain versions for
+00013420: 2074 6869 7320 6665 6174 7572 652d 7665   this feature-ve
+00013430: 6374 6f72 2e20 416c 6c20 7665 7273 696f  ctor. All versio
+00013440: 6e73 206f 6620 6120 7665 7273 696f 6e65  ns of a versione
+00013450: 6420 6f62 6a65 6374 0a20 2020 2020 2020  d object.       
+00013460: 2020 2020 2077 696c 6c20 6265 206b 6570       will be kep
+00013470: 7420 696e 2074 6865 2044 4220 616e 6420  t in the DB and 
+00013480: 6361 6e20 6265 2072 6574 7269 6576 6564  can be retrieved
+00013490: 2075 6e74 696c 2065 7870 6c69 6369 746c   until explicitl
+000134a0: 7920 6465 6c65 7465 642e 0a20 2020 2020  y deleted..     
+000134b0: 2020 203a 7265 7475 726e 733a 2054 6865     :returns: The
+000134c0: 203a 7079 3a63 6c61 7373 3a60 7e6d 6c72   :py:class:`~mlr
+000134d0: 756e 2e66 6561 7475 7265 5f73 746f 7265  un.feature_store
+000134e0: 2e46 6561 7475 7265 5665 6374 6f72 6020  .FeatureVector` 
+000134f0: 6f62 6a65 6374 2028 6173 2064 6963 7429  object (as dict)
+00013500: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
+00013510: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+00013520: 6e63 6528 6665 6174 7572 655f 7665 6374  nce(feature_vect
+00013530: 6f72 2c20 7363 6865 6d61 732e 4665 6174  or, schemas.Feat
+00013540: 7572 6556 6563 746f 7229 3a0a 2020 2020  ureVector):.    
+00013550: 2020 2020 2020 2020 6665 6174 7572 655f          feature_
+00013560: 7665 6374 6f72 203d 2066 6561 7475 7265  vector = feature
+00013570: 5f76 6563 746f 722e 6469 6374 2829 0a20  _vector.dict(). 
+00013580: 2020 2020 2020 2065 6c69 6620 6973 696e         elif isin
+00013590: 7374 616e 6365 2866 6561 7475 7265 5f76  stance(feature_v
+000135a0: 6563 746f 722c 2046 6561 7475 7265 5665  ector, FeatureVe
+000135b0: 6374 6f72 293a 0a20 2020 2020 2020 2020  ctor):.         
+000135c0: 2020 2066 6561 7475 7265 5f76 6563 746f     feature_vecto
+000135d0: 7220 3d20 6665 6174 7572 655f 7665 6374  r = feature_vect
+000135e0: 6f72 2e74 6f5f 6469 6374 2829 0a0a 2020  or.to_dict()..  
+000135f0: 2020 2020 2020 7072 6f6a 6563 7420 3d20        project = 
+00013600: 280a 2020 2020 2020 2020 2020 2020 7072  (.            pr
+00013610: 6f6a 6563 740a 2020 2020 2020 2020 2020  oject.          
+00013620: 2020 6f72 2066 6561 7475 7265 5f76 6563    or feature_vec
+00013630: 746f 725b 226d 6574 6164 6174 6122 5d2e  tor["metadata"].
+00013640: 6765 7428 2270 726f 6a65 6374 222c 204e  get("project", N
+00013650: 6f6e 6529 0a20 2020 2020 2020 2020 2020  one).           
+00013660: 206f 7220 636f 6e66 6967 2e64 6566 6175   or config.defau
+00013670: 6c74 5f70 726f 6a65 6374 0a20 2020 2020  lt_project.     
+00013680: 2020 2029 0a20 2020 2020 2020 2070 6174     ).        pat
+00013690: 6820 3d20 6622 7072 6f6a 6563 7473 2f7b  h = f"projects/{
+000136a0: 7072 6f6a 6563 747d 2f66 6561 7475 7265  project}/feature
+000136b0: 2d76 6563 746f 7273 220a 2020 2020 2020  -vectors".      
+000136c0: 2020 7061 7261 6d73 203d 207b 2276 6572    params = {"ver
+000136d0: 7369 6f6e 6564 223a 2076 6572 7369 6f6e  sioned": version
+000136e0: 6564 7d0a 0a20 2020 2020 2020 206e 616d  ed}..        nam
+000136f0: 6520 3d20 6665 6174 7572 655f 7665 6374  e = feature_vect
+00013700: 6f72 5b22 6d65 7461 6461 7461 225d 5b22  or["metadata"]["
+00013710: 6e61 6d65 225d 0a20 2020 2020 2020 2065  name"].        e
+00013720: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
+00013730: 2246 6169 6c65 6420 6372 6561 7469 6e67  "Failed creating
+00013740: 2066 6561 7475 7265 2d76 6563 746f 7220   feature-vector 
+00013750: 7b70 726f 6a65 6374 7d2f 7b6e 616d 657d  {project}/{name}
+00013760: 220a 2020 2020 2020 2020 7265 7370 203d  ".        resp =
+00013770: 2073 656c 662e 6170 695f 6361 6c6c 280a   self.api_call(.
+00013780: 2020 2020 2020 2020 2020 2020 2250 4f53              "POS
+00013790: 5422 2c0a 2020 2020 2020 2020 2020 2020  T",.            
+000137a0: 7061 7468 2c0a 2020 2020 2020 2020 2020  path,.          
+000137b0: 2020 6572 726f 725f 6d65 7373 6167 652c    error_message,
+000137c0: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
+000137d0: 616d 733d 7061 7261 6d73 2c0a 2020 2020  ams=params,.    
+000137e0: 2020 2020 2020 2020 626f 6479 3d64 6963          body=dic
+000137f0: 745f 746f 5f6a 736f 6e28 6665 6174 7572  t_to_json(featur
+00013800: 655f 7665 6374 6f72 292c 0a20 2020 2020  e_vector),.     
+00013810: 2020 2029 0a20 2020 2020 2020 2072 6574     ).        ret
+00013820: 7572 6e20 7265 7370 2e6a 736f 6e28 290a  urn resp.json().
+00013830: 0a20 2020 2064 6566 2067 6574 5f66 6561  .    def get_fea
+00013840: 7475 7265 5f76 6563 746f 7228 0a20 2020  ture_vector(.   
+00013850: 2020 2020 2073 656c 662c 206e 616d 653a       self, name:
+00013860: 2073 7472 2c20 7072 6f6a 6563 743a 2073   str, project: s
+00013870: 7472 203d 2022 222c 2074 6167 3a20 7374  tr = "", tag: st
+00013880: 7220 3d20 4e6f 6e65 2c20 7569 643a 2073  r = None, uid: s
+00013890: 7472 203d 204e 6f6e 650a 2020 2020 2920  tr = None.    ) 
+000138a0: 2d3e 2046 6561 7475 7265 5665 6374 6f72  -> FeatureVector
+000138b0: 3a0a 2020 2020 2020 2020 2222 2252 6574  :.        """Ret
+000138c0: 7572 6e20 6120 7370 6563 6966 6963 2066  urn a specific f
+000138d0: 6561 7475 7265 2d76 6563 746f 7220 7265  eature-vector re
+000138e0: 6665 7265 6e63 6564 2062 7920 6974 7320  ferenced by its 
+000138f0: 7461 6720 6f72 2075 6964 2e20 4966 206e  tag or uid. If n
+00013900: 6f6e 6520 6172 6520 7072 6f76 6964 6564  one are provided
+00013910: 2c20 6060 6c61 7465 7374 6060 2074 6167  , ``latest`` tag
+00013920: 2077 696c 6c0a 2020 2020 2020 2020 6265   will.        be
+00013930: 2075 7365 642e 2222 220a 0a20 2020 2020   used."""..     
+00013940: 2020 2070 726f 6a65 6374 203d 2070 726f     project = pro
+00013950: 6a65 6374 206f 7220 636f 6e66 6967 2e64  ject or config.d
+00013960: 6566 6175 6c74 5f70 726f 6a65 6374 0a20  efault_project. 
+00013970: 2020 2020 2020 2072 6566 6572 656e 6365         reference
+00013980: 203d 2073 656c 662e 5f72 6573 6f6c 7665   = self._resolve
+00013990: 5f72 6566 6572 656e 6365 2874 6167 2c20  _reference(tag, 
+000139a0: 7569 6429 0a20 2020 2020 2020 2070 6174  uid).        pat
+000139b0: 6820 3d20 6622 7072 6f6a 6563 7473 2f7b  h = f"projects/{
+000139c0: 7072 6f6a 6563 747d 2f66 6561 7475 7265  project}/feature
+000139d0: 2d76 6563 746f 7273 2f7b 6e61 6d65 7d2f  -vectors/{name}/
+000139e0: 7265 6665 7265 6e63 6573 2f7b 7265 6665  references/{refe
+000139f0: 7265 6e63 657d 220a 2020 2020 2020 2020  rence}".        
+00013a00: 6572 726f 725f 6d65 7373 6167 6520 3d20  error_message = 
+00013a10: 6622 4661 696c 6564 2072 6574 7269 6576  f"Failed retriev
+00013a20: 696e 6720 6665 6174 7572 652d 7665 6374  ing feature-vect
+00013a30: 6f72 207b 7072 6f6a 6563 747d 2f7b 6e61  or {project}/{na
+00013a40: 6d65 7d22 0a20 2020 2020 2020 2072 6573  me}".        res
+00013a50: 7020 3d20 7365 6c66 2e61 7069 5f63 616c  p = self.api_cal
+00013a60: 6c28 2247 4554 222c 2070 6174 682c 2065  l("GET", path, e
+00013a70: 7272 6f72 5f6d 6573 7361 6765 290a 2020  rror_message).  
+00013a80: 2020 2020 2020 7265 7475 726e 2046 6561        return Fea
+00013a90: 7475 7265 5665 6374 6f72 2e66 726f 6d5f  tureVector.from_
+00013aa0: 6469 6374 2872 6573 702e 6a73 6f6e 2829  dict(resp.json()
+00013ab0: 290a 0a20 2020 2064 6566 206c 6973 745f  )..    def list_
+00013ac0: 6665 6174 7572 655f 7665 6374 6f72 7328  feature_vectors(
+00013ad0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+00013ae0: 2020 2020 2020 2070 726f 6a65 6374 3a20         project: 
+00013af0: 7374 7220 3d20 2222 2c0a 2020 2020 2020  str = "",.      
+00013b00: 2020 6e61 6d65 3a20 7374 7220 3d20 4e6f    name: str = No
+00013b10: 6e65 2c0a 2020 2020 2020 2020 7461 673a  ne,.        tag:
+00013b20: 2073 7472 203d 204e 6f6e 652c 0a20 2020   str = None,.   
+00013b30: 2020 2020 2073 7461 7465 3a20 7374 7220       state: str 
+00013b40: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+00013b50: 6c61 6265 6c73 3a20 4c69 7374 5b73 7472  labels: List[str
+00013b60: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+00013b70: 2020 7061 7274 6974 696f 6e5f 6279 3a20    partition_by: 
+00013b80: 556e 696f 6e5b 7363 6865 6d61 732e 4665  Union[schemas.Fe
+00013b90: 6174 7572 6553 746f 7265 5061 7274 6974  atureStorePartit
+00013ba0: 696f 6e42 7946 6965 6c64 2c20 7374 725d  ionByField, str]
+00013bb0: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
+00013bc0: 2072 6f77 735f 7065 725f 7061 7274 6974   rows_per_partit
+00013bd0: 696f 6e3a 2069 6e74 203d 2031 2c0a 2020  ion: int = 1,.  
+00013be0: 2020 2020 2020 7061 7274 6974 696f 6e5f        partition_
+00013bf0: 736f 7274 5f62 793a 2055 6e69 6f6e 5b73  sort_by: Union[s
+00013c00: 6368 656d 6173 2e53 6f72 7446 6965 6c64  chemas.SortField
+00013c10: 2c20 7374 725d 203d 204e 6f6e 652c 0a20  , str] = None,. 
+00013c20: 2020 2020 2020 2070 6172 7469 7469 6f6e         partition
+00013c30: 5f6f 7264 6572 3a20 556e 696f 6e5b 7363  _order: Union[sc
+00013c40: 6865 6d61 732e 4f72 6465 7254 7970 652c  hemas.OrderType,
+00013c50: 2073 7472 5d20 3d20 7363 6865 6d61 732e   str] = schemas.
+00013c60: 4f72 6465 7254 7970 652e 6465 7363 2c0a  OrderType.desc,.
+00013c70: 2020 2020 2920 2d3e 204c 6973 745b 4665      ) -> List[Fe
+00013c80: 6174 7572 6556 6563 746f 725d 3a0a 2020  atureVector]:.  
+00013c90: 2020 2020 2020 2222 2252 6574 7269 6576        """Retriev
+00013ca0: 6520 6120 6c69 7374 206f 6620 6665 6174  e a list of feat
+00013cb0: 7572 652d 7665 6374 6f72 7320 6d61 7463  ure-vectors matc
+00013cc0: 6869 6e67 2074 6865 2063 7269 7465 7269  hing the criteri
+00013cd0: 6120 7072 6f76 6964 6564 2e0a 0a20 2020  a provided...   
+00013ce0: 2020 2020 203a 7061 7261 6d20 7072 6f6a       :param proj
+00013cf0: 6563 743a 2050 726f 6a65 6374 206e 616d  ect: Project nam
+00013d00: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
+00013d10: 6d20 6e61 6d65 3a20 4e61 6d65 206f 6620  m name: Name of 
+00013d20: 6665 6174 7572 652d 7665 6374 6f72 2074  feature-vector t
+00013d30: 6f20 6d61 7463 682e 2054 6869 7320 6973  o match. This is
+00013d40: 2061 206c 696b 6520 7175 6572 792c 2061   a like query, a
+00013d50: 6e64 2069 7320 6361 7365 2d69 6e73 656e  nd is case-insen
+00013d60: 7369 7469 7665 2e0a 2020 2020 2020 2020  sitive..        
+00013d70: 3a70 6172 616d 2074 6167 3a20 4d61 7463  :param tag: Matc
+00013d80: 6820 6665 6174 7572 652d 7665 6374 6f72  h feature-vector
+00013d90: 7320 7769 7468 2073 7065 6369 6669 6320  s with specific 
+00013da0: 7461 672e 0a20 2020 2020 2020 203a 7061  tag..        :pa
+00013db0: 7261 6d20 7374 6174 653a 204d 6174 6368  ram state: Match
+00013dc0: 2066 6561 7475 7265 2d76 6563 746f 7273   feature-vectors
+00013dd0: 2077 6974 6820 6120 7370 6563 6966 6963   with a specific
+00013de0: 2073 7461 7465 2e0a 2020 2020 2020 2020   state..        
+00013df0: 3a70 6172 616d 206c 6162 656c 733a 204d  :param labels: M
+00013e00: 6174 6368 2066 6561 7475 7265 2d76 6563  atch feature-vec
+00013e10: 746f 7273 2077 6869 6368 2068 6176 6520  tors which have 
+00013e20: 7468 6573 6520 6c61 6265 6c73 2e0a 2020  these labels..  
+00013e30: 2020 2020 2020 3a70 6172 616d 2070 6172        :param par
+00013e40: 7469 7469 6f6e 5f62 793a 2046 6965 6c64  tition_by: Field
+00013e50: 2074 6f20 6772 6f75 7020 7265 7375 6c74   to group result
+00013e60: 7320 6279 2e20 4f6e 6c79 2061 6c6c 6f77  s by. Only allow
+00013e70: 6564 2076 616c 7565 2069 7320 606e 616d  ed value is `nam
+00013e80: 6560 2e20 5768 656e 2060 7061 7274 6974  e`. When `partit
+00013e90: 696f 6e5f 6279 6020 6973 2073 7065 6369  ion_by` is speci
+00013ea0: 6669 6564 2c0a 2020 2020 2020 2020 2020  fied,.          
+00013eb0: 2020 7468 6520 6070 6172 7469 7469 6f6e    the `partition
+00013ec0: 5f73 6f72 745f 6279 6020 7061 7261 6d65  _sort_by` parame
+00013ed0: 7465 7220 6d75 7374 2062 6520 7072 6f76  ter must be prov
+00013ee0: 6964 6564 2061 7320 7765 6c6c 2e0a 2020  ided as well..  
+00013ef0: 2020 2020 2020 3a70 6172 616d 2072 6f77        :param row
+00013f00: 735f 7065 725f 7061 7274 6974 696f 6e3a  s_per_partition:
+00013f10: 2048 6f77 206d 616e 7920 746f 7020 726f   How many top ro
+00013f20: 7773 2028 7065 7220 736f 7274 696e 6720  ws (per sorting 
+00013f30: 6465 6669 6e65 6420 6279 2060 7061 7274  defined by `part
+00013f40: 6974 696f 6e5f 736f 7274 5f62 7960 2061  ition_sort_by` a
+00013f50: 6e64 2060 7061 7274 6974 696f 6e5f 6f72  nd `partition_or
+00013f60: 6465 7260 290a 2020 2020 2020 2020 2020  der`).          
+00013f70: 2020 746f 2072 6574 7572 6e20 7065 7220    to return per 
+00013f80: 6772 6f75 702e 2044 6566 6175 6c74 2076  group. Default v
+00013f90: 616c 7565 2069 7320 312e 0a20 2020 2020  alue is 1..     
+00013fa0: 2020 203a 7061 7261 6d20 7061 7274 6974     :param partit
+00013fb0: 696f 6e5f 736f 7274 5f62 793a 2057 6861  ion_sort_by: Wha
+00013fc0: 7420 6669 656c 6420 746f 2073 6f72 7420  t field to sort 
+00013fd0: 7468 6520 7265 7375 6c74 7320 6279 2c20  the results by, 
+00013fe0: 7769 7468 696e 2065 6163 6820 7061 7274  within each part
+00013ff0: 6974 696f 6e20 6465 6669 6e65 6420 6279  ition defined by
+00014000: 2060 7061 7274 6974 696f 6e5f 6279 602e   `partition_by`.
+00014010: 0a20 2020 2020 2020 2020 2020 2043 7572  .            Cur
+00014020: 7265 6e74 6c79 2074 6865 206f 6e6c 7920  rently the only 
+00014030: 616c 6c6f 7765 6420 7661 6c75 6573 2061  allowed values a
+00014040: 7265 2060 6372 6561 7465 6460 2061 6e64  re `created` and
+00014050: 2060 7570 6461 7465 6460 2e0a 2020 2020   `updated`..    
+00014060: 2020 2020 3a70 6172 616d 2070 6172 7469      :param parti
+00014070: 7469 6f6e 5f6f 7264 6572 3a20 4f72 6465  tion_order: Orde
+00014080: 7220 6f66 2073 6f72 7469 6e67 2077 6974  r of sorting wit
+00014090: 6869 6e20 7061 7274 6974 696f 6e73 202d  hin partitions -
+000140a0: 2060 6173 6360 206f 7220 6064 6573 6360   `asc` or `desc`
+000140b0: 2e20 4465 6661 756c 7420 6973 2060 6465  . Default is `de
+000140c0: 7363 602e 0a20 2020 2020 2020 203a 7265  sc`..        :re
+000140d0: 7475 726e 733a 204c 6973 7420 6f66 206d  turns: List of m
+000140e0: 6174 6368 696e 6720 3a70 793a 636c 6173  atching :py:clas
+000140f0: 733a 607e 6d6c 7275 6e2e 6665 6174 7572  s:`~mlrun.featur
+00014100: 655f 7374 6f72 652e 4665 6174 7572 6556  e_store.FeatureV
+00014110: 6563 746f 7260 206f 626a 6563 7473 2e0a  ector` objects..
+00014120: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
+00014130: 2020 2020 2070 726f 6a65 6374 203d 2070       project = p
+00014140: 726f 6a65 6374 206f 7220 636f 6e66 6967  roject or config
+00014150: 2e64 6566 6175 6c74 5f70 726f 6a65 6374  .default_project
+00014160: 0a0a 2020 2020 2020 2020 7061 7261 6d73  ..        params
+00014170: 203d 207b 0a20 2020 2020 2020 2020 2020   = {.           
+00014180: 2022 6e61 6d65 223a 206e 616d 652c 0a20   "name": name,. 
+00014190: 2020 2020 2020 2020 2020 2022 7374 6174             "stat
+000141a0: 6522 3a20 7374 6174 652c 0a20 2020 2020  e": state,.     
+000141b0: 2020 2020 2020 2022 7461 6722 3a20 7461         "tag": ta
+000141c0: 672c 0a20 2020 2020 2020 2020 2020 2022  g,.            "
+000141d0: 6c61 6265 6c22 3a20 6c61 6265 6c73 206f  label": labels o
+000141e0: 7220 5b5d 2c0a 2020 2020 2020 2020 7d0a  r [],.        }.
+000141f0: 2020 2020 2020 2020 6966 2070 6172 7469          if parti
+00014200: 7469 6f6e 5f62 793a 0a20 2020 2020 2020  tion_by:.       
+00014210: 2020 2020 2070 6172 616d 732e 7570 6461       params.upda
+00014220: 7465 280a 2020 2020 2020 2020 2020 2020  te(.            
+00014230: 2020 2020 7365 6c66 2e5f 6765 6e65 7261      self._genera
+00014240: 7465 5f70 6172 7469 7469 6f6e 5f62 795f  te_partition_by_
+00014250: 7061 7261 6d73 280a 2020 2020 2020 2020  params(.        
+00014260: 2020 2020 2020 2020 2020 2020 7363 6865              sche
+00014270: 6d61 732e 4665 6174 7572 6553 746f 7265  mas.FeatureStore
+00014280: 5061 7274 6974 696f 6e42 7946 6965 6c64  PartitionByField
+00014290: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000142a0: 2020 2020 2020 7061 7274 6974 696f 6e5f        partition_
+000142b0: 6279 2c0a 2020 2020 2020 2020 2020 2020  by,.            
+000142c0: 2020 2020 2020 2020 726f 7773 5f70 6572          rows_per
+000142d0: 5f70 6172 7469 7469 6f6e 2c0a 2020 2020  _partition,.    
+000142e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000142f0: 7061 7274 6974 696f 6e5f 736f 7274 5f62  partition_sort_b
+00014300: 792c 0a20 2020 2020 2020 2020 2020 2020  y,.             
+00014310: 2020 2020 2020 2070 6172 7469 7469 6f6e         partition
+00014320: 5f6f 7264 6572 2c0a 2020 2020 2020 2020  _order,.        
+00014330: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00014340: 2020 2020 2020 290a 0a20 2020 2020 2020        )..       
+00014350: 2070 6174 6820 3d20 6622 7072 6f6a 6563   path = f"projec
+00014360: 7473 2f7b 7072 6f6a 6563 747d 2f66 6561  ts/{project}/fea
+00014370: 7475 7265 2d76 6563 746f 7273 220a 0a20  ture-vectors".. 
+00014380: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+00014390: 7361 6765 203d 2028 0a20 2020 2020 2020  sage = (.       
+000143a0: 2020 2020 2066 2246 6169 6c65 6420 6c69       f"Failed li
+000143b0: 7374 696e 6720 6665 6174 7572 652d 7665  sting feature-ve
+000143c0: 6374 6f72 732c 2070 726f 6a65 6374 3a20  ctors, project: 
+000143d0: 7b70 726f 6a65 6374 7d2c 2071 7565 7279  {project}, query
+000143e0: 3a20 7b70 6172 616d 737d 220a 2020 2020  : {params}".    
+000143f0: 2020 2020 290a 2020 2020 2020 2020 7265      ).        re
+00014400: 7370 203d 2073 656c 662e 6170 695f 6361  sp = self.api_ca
+00014410: 6c6c 2822 4745 5422 2c20 7061 7468 2c20  ll("GET", path, 
+00014420: 6572 726f 725f 6d65 7373 6167 652c 2070  error_message, p
+00014430: 6172 616d 733d 7061 7261 6d73 290a 2020  arams=params).  
+00014440: 2020 2020 2020 6665 6174 7572 655f 7665        feature_ve
+00014450: 6374 6f72 7320 3d20 7265 7370 2e6a 736f  ctors = resp.jso
+00014460: 6e28 295b 2266 6561 7475 7265 5f76 6563  n()["feature_vec
+00014470: 746f 7273 225d 0a20 2020 2020 2020 2069  tors"].        i
+00014480: 6620 6665 6174 7572 655f 7665 6374 6f72  f feature_vector
+00014490: 733a 0a20 2020 2020 2020 2020 2020 2072  s:.            r
+000144a0: 6574 7572 6e20 5b46 6561 7475 7265 5665  eturn [FeatureVe
+000144b0: 6374 6f72 2e66 726f 6d5f 6469 6374 286f  ctor.from_dict(o
+000144c0: 626a 2920 666f 7220 6f62 6a20 696e 2066  bj) for obj in f
+000144d0: 6561 7475 7265 5f76 6563 746f 7273 5d0a  eature_vectors].
+000144e0: 0a20 2020 2064 6566 2073 746f 7265 5f66  .    def store_f
+000144f0: 6561 7475 7265 5f76 6563 746f 7228 0a20  eature_vector(. 
+00014500: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
+00014510: 2020 2020 2066 6561 7475 7265 5f76 6563       feature_vec
+00014520: 746f 723a 2055 6e69 6f6e 5b64 6963 742c  tor: Union[dict,
+00014530: 2073 6368 656d 6173 2e46 6561 7475 7265   schemas.Feature
+00014540: 5665 6374 6f72 2c20 4665 6174 7572 6556  Vector, FeatureV
+00014550: 6563 746f 725d 2c0a 2020 2020 2020 2020  ector],.        
+00014560: 6e61 6d65 3d4e 6f6e 652c 0a20 2020 2020  name=None,.     
+00014570: 2020 2070 726f 6a65 6374 3d22 222c 0a20     project="",. 
+00014580: 2020 2020 2020 2074 6167 3d4e 6f6e 652c         tag=None,
+00014590: 0a20 2020 2020 2020 2075 6964 3d4e 6f6e  .        uid=Non
+000145a0: 652c 0a20 2020 2020 2020 2076 6572 7369  e,.        versi
+000145b0: 6f6e 6564 3d54 7275 652c 0a20 2020 2029  oned=True,.    )
+000145c0: 202d 3e20 6469 6374 3a0a 2020 2020 2020   -> dict:.      
+000145d0: 2020 2222 2253 746f 7265 2061 203a 7079    """Store a :py
+000145e0: 3a63 6c61 7373 3a60 7e6d 6c72 756e 2e66  :class:`~mlrun.f
+000145f0: 6561 7475 7265 5f73 746f 7265 2e46 6561  eature_store.Fea
+00014600: 7475 7265 5665 6374 6f72 6020 6f62 6a65  tureVector` obje
+00014610: 6374 2069 6e20 7468 6520 3a70 793a 6d6f  ct in the :py:mo
+00014620: 643a 606d 6c72 756e 6020 4442 2e20 5468  d:`mlrun` DB. Th
+00014630: 650a 2020 2020 2020 2020 6665 6174 7572  e.        featur
+00014640: 652d 7665 6374 6f72 2063 616e 2062 6520  e-vector can be 
+00014650: 6569 7468 6572 2061 206e 6577 206f 626a  either a new obj
+00014660: 6563 7420 6f72 2061 206d 6f64 6966 6963  ect or a modific
+00014670: 6174 696f 6e20 746f 2065 7869 7374 696e  ation to existin
+00014680: 6720 6f62 6a65 6374 2072 6566 6572 656e  g object referen
+00014690: 6365 6420 6279 2074 6865 2070 6172 616d  ced by the param
+000146a0: 730a 2020 2020 2020 2020 6f66 2074 6865  s.        of the
+000146b0: 2066 756e 6374 696f 6e2e 0a0a 2020 2020   function...    
+000146c0: 2020 2020 3a70 6172 616d 2066 6561 7475      :param featu
+000146d0: 7265 5f76 6563 746f 723a 2054 6865 203a  re_vector: The :
+000146e0: 7079 3a63 6c61 7373 3a60 7e6d 6c72 756e  py:class:`~mlrun
+000146f0: 2e66 6561 7475 7265 5f73 746f 7265 2e46  .feature_store.F
+00014700: 6561 7475 7265 5665 6374 6f72 6020 746f  eatureVector` to
+00014710: 2073 746f 7265 2e0a 2020 2020 2020 2020   store..        
+00014720: 3a70 6172 616d 206e 616d 653a 2020 2020  :param name:    
+00014730: 4e61 6d65 206f 6620 6665 6174 7572 6520  Name of feature 
+00014740: 7665 6374 6f72 2e0a 2020 2020 2020 2020  vector..        
+00014750: 3a70 6172 616d 2070 726f 6a65 6374 3a20  :param project: 
+00014760: 4e61 6d65 206f 6620 7072 6f6a 6563 7420  Name of project 
+00014770: 7468 6973 2066 6561 7475 7265 2d76 6563  this feature-vec
+00014780: 746f 7220 6265 6c6f 6e67 7320 746f 2e0a  tor belongs to..
+00014790: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
+000147a0: 6167 3a20 5468 6520 6060 7461 6760 6020  ag: The ``tag`` 
+000147b0: 6f66 2074 6865 206f 626a 6563 7420 746f  of the object to
+000147c0: 2072 6570 6c61 6365 2069 6e20 7468 6520   replace in the 
+000147d0: 4442 2c20 666f 7220 6578 616d 706c 6520  DB, for example 
+000147e0: 6060 6c61 7465 7374 6060 2e0a 2020 2020  ``latest``..    
+000147f0: 2020 2020 3a70 6172 616d 2075 6964 3a20      :param uid: 
+00014800: 5468 6520 6060 7569 6460 6020 6f66 2074  The ``uid`` of t
+00014810: 6865 206f 626a 6563 7420 746f 2072 6570  he object to rep
+00014820: 6c61 6365 2069 6e20 7468 6520 4442 2e20  lace in the DB. 
+00014830: 4966 2075 7369 6e67 2074 6869 7320 7061  If using this pa
+00014840: 7261 6d65 7465 722c 2074 6865 206d 6f64  rameter, the mod
+00014850: 6966 6965 6420 6f62 6a65 6374 0a20 2020  ified object.   
+00014860: 2020 2020 2020 2020 206d 7573 7420 6861           must ha
+00014870: 7665 2074 6865 2073 616d 6520 6060 7569  ve the same ``ui
+00014880: 6460 6020 6f66 2074 6865 2070 7265 7669  d`` of the previ
+00014890: 6f75 736c 792d 6578 6973 7469 6e67 206f  ously-existing o
+000148a0: 626a 6563 742e 2054 6869 7320 6361 6e6e  bject. This cann
+000148b0: 6f74 2062 6520 7573 6564 2066 6f72 206e  ot be used for n
+000148c0: 6f6e 2d76 6572 7369 6f6e 6564 206f 626a  on-versioned obj
+000148d0: 6563 7473 2e0a 2020 2020 2020 2020 3a70  ects..        :p
+000148e0: 6172 616d 2076 6572 7369 6f6e 6564 3a20  aram versioned: 
+000148f0: 5768 6574 6865 7220 746f 206d 6169 6e74  Whether to maint
+00014900: 6169 6e20 7665 7273 696f 6e73 2066 6f72  ain versions for
+00014910: 2074 6869 7320 6665 6174 7572 652d 7665   this feature-ve
+00014920: 6374 6f72 2e20 416c 6c20 7665 7273 696f  ctor. All versio
+00014930: 6e73 206f 6620 6120 7665 7273 696f 6e65  ns of a versione
+00014940: 6420 6f62 6a65 6374 0a20 2020 2020 2020  d object.       
+00014950: 2020 2020 2077 696c 6c20 6265 206b 6570       will be kep
+00014960: 7420 696e 2074 6865 2044 4220 616e 6420  t in the DB and 
+00014970: 6361 6e20 6265 2072 6574 7269 6576 6564  can be retrieved
+00014980: 2075 6e74 696c 2065 7870 6c69 6369 746c   until explicitl
+00014990: 7920 6465 6c65 7465 642e 0a20 2020 2020  y deleted..     
+000149a0: 2020 203a 7265 7475 726e 733a 2054 6865     :returns: The
+000149b0: 203a 7079 3a63 6c61 7373 3a60 7e6d 6c72   :py:class:`~mlr
+000149c0: 756e 2e66 6561 7475 7265 5f73 746f 7265  un.feature_store
+000149d0: 2e46 6561 7475 7265 5665 6374 6f72 6020  .FeatureVector` 
+000149e0: 6f62 6a65 6374 2028 6173 2064 6963 7429  object (as dict)
+000149f0: 2e0a 2020 2020 2020 2020 2222 220a 0a20  ..        """.. 
+00014a00: 2020 2020 2020 2072 6566 6572 656e 6365         reference
+00014a10: 203d 2073 656c 662e 5f72 6573 6f6c 7665   = self._resolve
+00014a20: 5f72 6566 6572 656e 6365 2874 6167 2c20  _reference(tag, 
+00014a30: 7569 6429 0a20 2020 2020 2020 2070 6172  uid).        par
+00014a40: 616d 7320 3d20 7b22 7665 7273 696f 6e65  ams = {"versione
+00014a50: 6422 3a20 7665 7273 696f 6e65 647d 0a0a  d": versioned}..
+00014a60: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
+00014a70: 7461 6e63 6528 6665 6174 7572 655f 7665  tance(feature_ve
+00014a80: 6374 6f72 2c20 7363 6865 6d61 732e 4665  ctor, schemas.Fe
+00014a90: 6174 7572 6556 6563 746f 7229 3a0a 2020  atureVector):.  
+00014aa0: 2020 2020 2020 2020 2020 6665 6174 7572            featur
+00014ab0: 655f 7665 6374 6f72 203d 2066 6561 7475  e_vector = featu
+00014ac0: 7265 5f76 6563 746f 722e 6469 6374 2829  re_vector.dict()
+00014ad0: 0a20 2020 2020 2020 2065 6c69 6620 6973  .        elif is
+00014ae0: 696e 7374 616e 6365 2866 6561 7475 7265  instance(feature
+00014af0: 5f76 6563 746f 722c 2046 6561 7475 7265  _vector, Feature
+00014b00: 5665 6374 6f72 293a 0a20 2020 2020 2020  Vector):.       
+00014b10: 2020 2020 2066 6561 7475 7265 5f76 6563       feature_vec
+00014b20: 746f 7220 3d20 6665 6174 7572 655f 7665  tor = feature_ve
+00014b30: 6374 6f72 2e74 6f5f 6469 6374 2829 0a0a  ctor.to_dict()..
+00014b40: 2020 2020 2020 2020 6e61 6d65 203d 206e          name = n
+00014b50: 616d 6520 6f72 2066 6561 7475 7265 5f76  ame or feature_v
+00014b60: 6563 746f 725b 226d 6574 6164 6174 6122  ector["metadata"
+00014b70: 5d5b 226e 616d 6522 5d0a 2020 2020 2020  ]["name"].      
+00014b80: 2020 7072 6f6a 6563 7420 3d20 280a 2020    project = (.  
+00014b90: 2020 2020 2020 2020 2020 7072 6f6a 6563            projec
+00014ba0: 740a 2020 2020 2020 2020 2020 2020 6f72  t.            or
+00014bb0: 2066 6561 7475 7265 5f76 6563 746f 725b   feature_vector[
+00014bc0: 226d 6574 6164 6174 6122 5d2e 6765 7428  "metadata"].get(
+00014bd0: 2270 726f 6a65 6374 2229 0a20 2020 2020  "project").     
+00014be0: 2020 2020 2020 206f 7220 636f 6e66 6967         or config
+00014bf0: 2e64 6566 6175 6c74 5f70 726f 6a65 6374  .default_project
+00014c00: 0a20 2020 2020 2020 2029 0a20 2020 2020  .        ).     
+00014c10: 2020 2070 6174 6820 3d20 6622 7072 6f6a     path = f"proj
+00014c20: 6563 7473 2f7b 7072 6f6a 6563 747d 2f66  ects/{project}/f
+00014c30: 6561 7475 7265 2d76 6563 746f 7273 2f7b  eature-vectors/{
+00014c40: 6e61 6d65 7d2f 7265 6665 7265 6e63 6573  name}/references
+00014c50: 2f7b 7265 6665 7265 6e63 657d 220a 2020  /{reference}".  
+00014c60: 2020 2020 2020 6572 726f 725f 6d65 7373        error_mess
+00014c70: 6167 6520 3d20 6622 4661 696c 6564 2073  age = f"Failed s
+00014c80: 746f 7269 6e67 2066 6561 7475 7265 2d76  toring feature-v
+00014c90: 6563 746f 7220 7b70 726f 6a65 6374 7d2f  ector {project}/
+00014ca0: 7b6e 616d 657d 220a 2020 2020 2020 2020  {name}".        
+00014cb0: 7265 7370 203d 2073 656c 662e 6170 695f  resp = self.api_
+00014cc0: 6361 6c6c 280a 2020 2020 2020 2020 2020  call(.          
+00014cd0: 2020 2250 5554 222c 2070 6174 682c 2065    "PUT", path, e
+00014ce0: 7272 6f72 5f6d 6573 7361 6765 2c20 7061  rror_message, pa
+00014cf0: 7261 6d73 3d70 6172 616d 732c 2062 6f64  rams=params, bod
+00014d00: 793d 6469 6374 5f74 6f5f 6a73 6f6e 2866  y=dict_to_json(f
+00014d10: 6561 7475 7265 5f76 6563 746f 7229 0a20  eature_vector). 
+00014d20: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00014d30: 2072 6574 7572 6e20 7265 7370 2e6a 736f   return resp.jso
+00014d40: 6e28 290a 0a20 2020 2064 6566 2070 6174  n()..    def pat
+00014d50: 6368 5f66 6561 7475 7265 5f76 6563 746f  ch_feature_vecto
+00014d60: 7228 0a20 2020 2020 2020 2073 656c 662c  r(.        self,
+00014d70: 0a20 2020 2020 2020 206e 616d 652c 0a20  .        name,. 
+00014d80: 2020 2020 2020 2066 6561 7475 7265 5f76         feature_v
+00014d90: 6563 746f 725f 7570 6461 7465 3a20 6469  ector_update: di
+00014da0: 6374 2c0a 2020 2020 2020 2020 7072 6f6a  ct,.        proj
+00014db0: 6563 743d 2222 2c0a 2020 2020 2020 2020  ect="",.        
+00014dc0: 7461 673d 4e6f 6e65 2c0a 2020 2020 2020  tag=None,.      
+00014dd0: 2020 7569 643d 4e6f 6e65 2c0a 2020 2020    uid=None,.    
+00014de0: 2020 2020 7061 7463 685f 6d6f 6465 3a20      patch_mode: 
+00014df0: 556e 696f 6e5b 7374 722c 2073 6368 656d  Union[str, schem
+00014e00: 6173 2e50 6174 6368 4d6f 6465 5d20 3d20  as.PatchMode] = 
+00014e10: 7363 6865 6d61 732e 5061 7463 684d 6f64  schemas.PatchMod
+00014e20: 652e 7265 706c 6163 652c 0a20 2020 2029  e.replace,.    )
+00014e30: 3a0a 2020 2020 2020 2020 2222 224d 6f64  :.        """Mod
+00014e40: 6966 7920 2870 6174 6368 2920 616e 2065  ify (patch) an e
+00014e50: 7869 7374 696e 6720 3a70 793a 636c 6173  xisting :py:clas
+00014e60: 733a 607e 6d6c 7275 6e2e 6665 6174 7572  s:`~mlrun.featur
+00014e70: 655f 7374 6f72 652e 4665 6174 7572 6556  e_store.FeatureV
+00014e80: 6563 746f 7260 206f 626a 6563 742e 0a20  ector` object.. 
+00014e90: 2020 2020 2020 2054 6865 206f 626a 6563         The objec
+00014ea0: 7420 6973 2069 6465 6e74 6966 6965 6420  t is identified 
+00014eb0: 6279 2069 7473 206e 616d 6520 2861 6e64  by its name (and
+00014ec0: 2070 726f 6a65 6374 2069 7420 6265 6c6f   project it belo
+00014ed0: 6e67 7320 746f 292c 2061 7320 7765 6c6c  ngs to), as well
+00014ee0: 2061 7320 6f70 7469 6f6e 616c 6c79 2061   as optionally a
+00014ef0: 2060 6074 6167 6060 206f 7220 6974 730a   ``tag`` or its.
+00014f00: 2020 2020 2020 2020 6060 7569 6460 6020          ``uid`` 
+00014f10: 2866 6f72 2076 6572 7369 6f6e 6564 206f  (for versioned o
+00014f20: 626a 6563 7429 2e20 4966 2062 6f74 6820  bject). If both 
+00014f30: 6060 7461 6760 6020 616e 6420 6060 7569  ``tag`` and ``ui
+00014f40: 6460 6020 6172 6520 6f6d 6974 7465 6420  d`` are omitted 
+00014f50: 7468 656e 2074 6865 206f 626a 6563 7420  then the object 
+00014f60: 7769 7468 2074 6167 2060 606c 6174 6573  with tag ``lates
+00014f70: 7460 600a 2020 2020 2020 2020 6973 206d  t``.        is m
+00014f80: 6f64 6966 6965 642e 0a0a 2020 2020 2020  odified...      
+00014f90: 2020 3a70 6172 616d 206e 616d 653a 204e    :param name: N
+00014fa0: 616d 6520 6f66 2074 6865 206f 626a 6563  ame of the objec
+00014fb0: 7420 746f 2070 6174 6368 2e0a 2020 2020  t to patch..    
+00014fc0: 2020 2020 3a70 6172 616d 2066 6561 7475      :param featu
+00014fd0: 7265 5f76 6563 746f 725f 7570 6461 7465  re_vector_update
+00014fe0: 3a20 5468 6520 6d6f 6469 6669 6361 7469  : The modificati
+00014ff0: 6f6e 7320 6e65 6564 6564 2069 6e20 7468  ons needed in th
+00015000: 6520 6f62 6a65 6374 2e20 5468 6973 2070  e object. This p
+00015010: 6172 616d 6574 6572 206f 6e6c 7920 6861  arameter only ha
+00015020: 7320 7468 6520 6368 616e 6765 7320 696e  s the changes in
+00015030: 2069 742c 0a20 2020 2020 2020 2020 2020   it,.           
+00015040: 206e 6f74 2061 2066 756c 6c20 6f62 6a65   not a full obje
+00015050: 6374 2e0a 2020 2020 2020 2020 3a70 6172  ct..        :par
+00015060: 616d 2070 726f 6a65 6374 3a20 5072 6f6a  am project: Proj
+00015070: 6563 7420 7768 6963 6820 636f 6e74 6169  ect which contai
+00015080: 6e73 2074 6865 206d 6f64 6966 6965 6420  ns the modified 
+00015090: 6f62 6a65 6374 2e0a 2020 2020 2020 2020  object..        
+000150a0: 3a70 6172 616d 2074 6167 3a20 5468 6520  :param tag: The 
+000150b0: 7461 6720 6f66 2074 6865 206f 626a 6563  tag of the objec
+000150c0: 7420 746f 206d 6f64 6966 792e 0a20 2020  t to modify..   
+000150d0: 2020 2020 203a 7061 7261 6d20 7569 643a       :param uid:
+000150e0: 2075 6964 206f 6620 7468 6520 6f62 6a65   uid of the obje
+000150f0: 6374 2074 6f20 6d6f 6469 6679 2e0a 2020  ct to modify..  
+00015100: 2020 2020 2020 3a70 6172 616d 2070 6174        :param pat
+00015110: 6368 5f6d 6f64 653a 2054 6865 2073 7472  ch_mode: The str
+00015120: 6174 6567 7920 666f 7220 6d65 7267 696e  ategy for mergin
+00015130: 6720 7468 6520 6368 616e 6765 7320 7769  g the changes wi
+00015140: 7468 2074 6865 2065 7869 7374 696e 6720  th the existing 
+00015150: 6f62 6a65 6374 2e20 4361 6e20 6265 2065  object. Can be e
+00015160: 6974 6865 7220 6060 7265 706c 6163 6560  ither ``replace`
+00015170: 600a 2020 2020 2020 2020 2020 2020 6f72  `.            or
+00015180: 2060 6061 6464 6974 6976 6560 602e 0a20   ``additive``.. 
+00015190: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+000151a0: 2020 2072 6566 6572 656e 6365 203d 2073     reference = s
+000151b0: 656c 662e 5f72 6573 6f6c 7665 5f72 6566  elf._resolve_ref
+000151c0: 6572 656e 6365 2874 6167 2c20 7569 6429  erence(tag, uid)
+000151d0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
+000151e0: 203d 2070 726f 6a65 6374 206f 7220 636f   = project or co
+000151f0: 6e66 6967 2e64 6566 6175 6c74 5f70 726f  nfig.default_pro
+00015200: 6a65 6374 0a20 2020 2020 2020 2068 6561  ject.        hea
+00015210: 6465 7273 203d 207b 7363 6865 6d61 732e  ders = {schemas.
+00015220: 4865 6164 6572 4e61 6d65 732e 7061 7463  HeaderNames.patc
+00015230: 685f 6d6f 6465 3a20 7061 7463 685f 6d6f  h_mode: patch_mo
+00015240: 6465 7d0a 2020 2020 2020 2020 7061 7468  de}.        path
+00015250: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
+00015260: 726f 6a65 6374 7d2f 6665 6174 7572 652d  roject}/feature-
+00015270: 7665 6374 6f72 732f 7b6e 616d 657d 2f72  vectors/{name}/r
+00015280: 6566 6572 656e 6365 732f 7b72 6566 6572  eferences/{refer
+00015290: 656e 6365 7d22 0a20 2020 2020 2020 2065  ence}".        e
+000152a0: 7272 6f72 5f6d 6573 7361 6765 203d 2066  rror_message = f
+000152b0: 2246 6169 6c65 6420 7570 6461 7469 6e67  "Failed updating
+000152c0: 2066 6561 7475 7265 2d76 6563 746f 7220   feature-vector 
+000152d0: 7b70 726f 6a65 6374 7d2f 7b6e 616d 657d  {project}/{name}
+000152e0: 220a 2020 2020 2020 2020 7365 6c66 2e61  ".        self.a
+000152f0: 7069 5f63 616c 6c28 0a20 2020 2020 2020  pi_call(.       
+00015300: 2020 2020 2022 5041 5443 4822 2c0a 2020       "PATCH",.  
+00015310: 2020 2020 2020 2020 2020 7061 7468 2c0a            path,.
+00015320: 2020 2020 2020 2020 2020 2020 6572 726f              erro
+00015330: 725f 6d65 7373 6167 652c 0a20 2020 2020  r_message,.     
+00015340: 2020 2020 2020 2062 6f64 793d 6469 6374         body=dict
+00015350: 5f74 6f5f 6a73 6f6e 2866 6561 7475 7265  _to_json(feature
+00015360: 5f76 6563 746f 725f 7570 6461 7465 292c  _vector_update),
+00015370: 0a20 2020 2020 2020 2020 2020 2068 6561  .            hea
+00015380: 6465 7273 3d68 6561 6465 7273 2c0a 2020  ders=headers,.  
+00015390: 2020 2020 2020 290a 0a20 2020 2064 6566        )..    def
+000153a0: 2064 656c 6574 655f 6665 6174 7572 655f   delete_feature_
+000153b0: 7665 6374 6f72 2873 656c 662c 206e 616d  vector(self, nam
+000153c0: 652c 2070 726f 6a65 6374 3d22 222c 2074  e, project="", t
+000153d0: 6167 3d4e 6f6e 652c 2075 6964 3d4e 6f6e  ag=None, uid=Non
+000153e0: 6529 3a0a 2020 2020 2020 2020 2222 2244  e):.        """D
+000153f0: 656c 6574 6520 6120 3a70 793a 636c 6173  elete a :py:clas
+00015400: 733a 607e 6d6c 7275 6e2e 6665 6174 7572  s:`~mlrun.featur
+00015410: 655f 7374 6f72 652e 4665 6174 7572 6556  e_store.FeatureV
+00015420: 6563 746f 7260 206f 626a 6563 7420 6672  ector` object fr
+00015430: 6f6d 2074 6865 2044 422e 0a20 2020 2020  om the DB..     
+00015440: 2020 2049 6620 6060 7461 6760 6020 6f72     If ``tag`` or
+00015450: 2060 6075 6964 6060 2061 7265 2073 7065   ``uid`` are spe
+00015460: 6369 6669 6564 2c20 7468 656e 206a 7573  cified, then jus
+00015470: 7420 7468 6520 7665 7273 696f 6e20 7265  t the version re
+00015480: 6665 7265 6e63 6564 2062 7920 7468 656d  ferenced by them
+00015490: 2077 696c 6c20 6265 2064 656c 6574 6564   will be deleted
+000154a0: 2e20 5573 696e 6720 626f 7468 0a20 2020  . Using both.   
+000154b0: 2020 2020 2069 7320 6e6f 7420 616c 6c6f       is not allo
+000154c0: 7765 642e 0a20 2020 2020 2020 2049 6620  wed..        If 
+000154d0: 6e6f 6e65 2061 7265 2073 7065 6369 6669  none are specifi
+000154e0: 6564 2c20 7468 656e 2061 6c6c 2069 6e73  ed, then all ins
+000154f0: 7461 6e63 6573 206f 6620 7468 6520 6f62  tances of the ob
+00015500: 6a65 6374 2077 686f 7365 206e 616d 6520  ject whose name 
+00015510: 6973 2060 606e 616d 6560 6020 7769 6c6c  is ``name`` will
+00015520: 2062 6520 6465 6c65 7465 642e 0a20 2020   be deleted..   
+00015530: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00015540: 2070 726f 6a65 6374 203d 2070 726f 6a65   project = proje
+00015550: 6374 206f 7220 636f 6e66 6967 2e64 6566  ct or config.def
+00015560: 6175 6c74 5f70 726f 6a65 6374 0a20 2020  ault_project.   
+00015570: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
+00015580: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
+00015590: 2f66 6561 7475 7265 2d76 6563 746f 7273  /feature-vectors
+000155a0: 2f7b 6e61 6d65 7d22 0a20 2020 2020 2020  /{name}".       
+000155b0: 2069 6620 7461 6720 6f72 2075 6964 3a0a   if tag or uid:.
+000155c0: 2020 2020 2020 2020 2020 2020 7265 6665              refe
+000155d0: 7265 6e63 6520 3d20 7365 6c66 2e5f 7265  rence = self._re
+000155e0: 736f 6c76 655f 7265 6665 7265 6e63 6528  solve_reference(
+000155f0: 7461 672c 2075 6964 290a 2020 2020 2020  tag, uid).      
+00015600: 2020 2020 2020 7061 7468 203d 2070 6174        path = pat
+00015610: 6820 2b20 6622 2f72 6566 6572 656e 6365  h + f"/reference
+00015620: 732f 7b72 6566 6572 656e 6365 7d22 0a0a  s/{reference}"..
+00015630: 2020 2020 2020 2020 6572 726f 725f 6d65          error_me
+00015640: 7373 6167 6520 3d20 6622 4661 696c 6564  ssage = f"Failed
+00015650: 2064 656c 6574 696e 6720 6665 6174 7572   deleting featur
+00015660: 652d 7665 6374 6f72 207b 6e61 6d65 7d22  e-vector {name}"
+00015670: 0a20 2020 2020 2020 2073 656c 662e 6170  .        self.ap
+00015680: 695f 6361 6c6c 2822 4445 4c45 5445 222c  i_call("DELETE",
+00015690: 2070 6174 682c 2065 7272 6f72 5f6d 6573   path, error_mes
+000156a0: 7361 6765 290a 0a20 2020 2064 6566 2074  sage)..    def t
+000156b0: 6167 5f6f 626a 6563 7473 280a 2020 2020  ag_objects(.    
+000156c0: 2020 2020 7365 6c66 2c0a 2020 2020 2020      self,.      
+000156d0: 2020 7072 6f6a 6563 743a 2073 7472 2c0a    project: str,.
+000156e0: 2020 2020 2020 2020 7461 675f 6e61 6d65          tag_name
+000156f0: 3a20 7374 722c 0a20 2020 2020 2020 206f  : str,.        o
+00015700: 626a 6563 7473 3a20 556e 696f 6e5b 6d6c  bjects: Union[ml
+00015710: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
+00015720: 5461 674f 626a 6563 7473 2c20 6469 6374  TagObjects, dict
+00015730: 5d2c 0a20 2020 2020 2020 2072 6570 6c61  ],.        repla
+00015740: 6365 3a20 626f 6f6c 203d 2046 616c 7365  ce: bool = False
+00015750: 2c0a 2020 2020 293a 0a20 2020 2020 2020  ,.    ):.       
+00015760: 2022 2222 5461 6720 6120 6c69 7374 206f   """Tag a list o
+00015770: 6620 6f62 6a65 6374 732e 0a0a 2020 2020  f objects...    
+00015780: 2020 2020 3a70 6172 616d 2070 726f 6a65      :param proje
+00015790: 6374 3a20 5072 6f6a 6563 7420 7768 6963  ct: Project whic
+000157a0: 6820 636f 6e74 6169 6e73 2074 6865 206f  h contains the o
+000157b0: 626a 6563 7473 2e0a 2020 2020 2020 2020  bjects..        
+000157c0: 3a70 6172 616d 2074 6167 5f6e 616d 653a  :param tag_name:
+000157d0: 2054 6865 2074 6167 2074 6f20 7365 7420   The tag to set 
+000157e0: 6f6e 2074 6865 206f 626a 6563 7473 2e0a  on the objects..
+000157f0: 2020 2020 2020 2020 3a70 6172 616d 206f          :param o
+00015800: 626a 6563 7473 3a20 5468 6520 6f62 6a65  bjects: The obje
+00015810: 6374 7320 746f 2074 6167 2e0a 2020 2020  cts to tag..    
+00015820: 2020 2020 3a70 6172 616d 2072 6570 6c61      :param repla
+00015830: 6365 3a20 5768 6574 6865 7220 746f 2072  ce: Whether to r
+00015840: 6570 6c61 6365 2074 6865 2065 7869 7374  eplace the exist
+00015850: 696e 6720 7461 6773 206f 6620 7468 6520  ing tags of the 
+00015860: 6f62 6a65 6374 7320 6f72 2074 6f20 6164  objects or to ad
+00015870: 6420 7468 6520 6e65 7720 7461 6720 746f  d the new tag to
+00015880: 2074 6865 6d2e 0a20 2020 2020 2020 2022   them..        "
+00015890: 2222 0a0a 2020 2020 2020 2020 7061 7468  ""..        path
+000158a0: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
+000158b0: 726f 6a65 6374 7d2f 7461 6773 2f7b 7461  roject}/tags/{ta
+000158c0: 675f 6e61 6d65 7d22 0a20 2020 2020 2020  g_name}".       
+000158d0: 2065 7272 6f72 5f6d 6573 7361 6765 203d   error_message =
+000158e0: 2066 2246 6169 6c65 6420 746f 2074 6167   f"Failed to tag
+000158f0: 207b 7461 675f 6e61 6d65 7d20 6f6e 206f   {tag_name} on o
+00015900: 626a 6563 7473 207b 6f62 6a65 6374 737d  bjects {objects}
+00015910: 220a 2020 2020 2020 2020 6d65 7468 6f64  ".        method
+00015920: 203d 2022 504f 5354 2220 6966 2072 6570   = "POST" if rep
+00015930: 6c61 6365 2065 6c73 6520 2250 5554 220a  lace else "PUT".
+00015940: 2020 2020 2020 2020 7365 6c66 2e61 7069          self.api
+00015950: 5f63 616c 6c28 0a20 2020 2020 2020 2020  _call(.         
+00015960: 2020 206d 6574 686f 642c 0a20 2020 2020     method,.     
+00015970: 2020 2020 2020 2070 6174 682c 0a20 2020         path,.   
+00015980: 2020 2020 2020 2020 2065 7272 6f72 5f6d           error_m
+00015990: 6573 7361 6765 2c0a 2020 2020 2020 2020  essage,.        
+000159a0: 2020 2020 626f 6479 3d64 6963 745f 746f      body=dict_to
+000159b0: 5f6a 736f 6e28 0a20 2020 2020 2020 2020  _json(.         
+000159c0: 2020 2020 2020 206f 626a 6563 7473 2e64         objects.d
+000159d0: 6963 7428 290a 2020 2020 2020 2020 2020  ict().          
+000159e0: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+000159f0: 6e63 6528 6f62 6a65 6374 732c 206d 6c72  nce(objects, mlr
+00015a00: 756e 2e61 7069 2e73 6368 656d 6173 2e54  un.api.schemas.T
+00015a10: 6167 4f62 6a65 6374 7329 0a20 2020 2020  agObjects).     
+00015a20: 2020 2020 2020 2020 2020 2065 6c73 6520             else 
+00015a30: 6f62 6a65 6374 730a 2020 2020 2020 2020  objects.        
+00015a40: 2020 2020 292c 0a20 2020 2020 2020 2029      ),.        )
+00015a50: 0a0a 2020 2020 6465 6620 6465 6c65 7465  ..    def delete
+00015a60: 5f6f 626a 6563 7473 5f74 6167 280a 2020  _objects_tag(.  
+00015a70: 2020 2020 2020 7365 6c66 2c0a 2020 2020        self,.    
+00015a80: 2020 2020 7072 6f6a 6563 743a 2073 7472      project: str
+00015a90: 2c0a 2020 2020 2020 2020 7461 675f 6e61  ,.        tag_na
+00015aa0: 6d65 3a20 7374 722c 0a20 2020 2020 2020  me: str,.       
+00015ab0: 2074 6167 5f6f 626a 6563 7473 3a20 556e   tag_objects: Un
+00015ac0: 696f 6e5b 6d6c 7275 6e2e 6170 692e 7363  ion[mlrun.api.sc
+00015ad0: 6865 6d61 732e 5461 674f 626a 6563 7473  hemas.TagObjects
+00015ae0: 2c20 6469 6374 5d2c 0a20 2020 2029 3a0a  , dict],.    ):.
+00015af0: 2020 2020 2020 2020 2222 2244 656c 6574          """Delet
+00015b00: 6520 6120 7461 6720 6672 6f6d 2061 206c  e a tag from a l
+00015b10: 6973 7420 6f66 206f 626a 6563 7473 2e0a  ist of objects..
+00015b20: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00015b30: 7072 6f6a 6563 743a 2050 726f 6a65 6374  project: Project
+00015b40: 2077 6869 6368 2063 6f6e 7461 696e 7320   which contains 
+00015b50: 7468 6520 6f62 6a65 6374 732e 0a20 2020  the objects..   
+00015b60: 2020 2020 203a 7061 7261 6d20 7461 675f       :param tag_
+00015b70: 6e61 6d65 3a20 5468 6520 7461 6720 746f  name: The tag to
+00015b80: 2064 656c 6574 6520 6672 6f6d 2074 6865   delete from the
+00015b90: 206f 626a 6563 7473 2e0a 2020 2020 2020   objects..      
+00015ba0: 2020 3a70 6172 616d 2074 6167 5f6f 626a    :param tag_obj
+00015bb0: 6563 7473 3a20 5468 6520 6f62 6a65 6374  ects: The object
+00015bc0: 7320 746f 2064 656c 6574 6520 7468 6520  s to delete the 
+00015bd0: 7461 6720 6672 6f6d 2e0a 0a20 2020 2020  tag from...     
+00015be0: 2020 2022 2222 0a20 2020 2020 2020 2070     """.        p
+00015bf0: 6174 6820 3d20 6622 7072 6f6a 6563 7473  ath = f"projects
+00015c00: 2f7b 7072 6f6a 6563 747d 2f74 6167 732f  /{project}/tags/
+00015c10: 7b74 6167 5f6e 616d 657d 220a 2020 2020  {tag_name}".    
+00015c20: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+00015c30: 6520 3d20 6622 4661 696c 6564 2064 656c  e = f"Failed del
+00015c40: 6574 696e 6720 7461 6720 6672 6f6d 207b  eting tag from {
+00015c50: 7461 675f 6e61 6d65 7d22 0a20 2020 2020  tag_name}".     
+00015c60: 2020 2073 656c 662e 6170 695f 6361 6c6c     self.api_call
+00015c70: 280a 2020 2020 2020 2020 2020 2020 2244  (.            "D
+00015c80: 454c 4554 4522 2c0a 2020 2020 2020 2020  ELETE",.        
+00015c90: 2020 2020 7061 7468 2c0a 2020 2020 2020      path,.      
+00015ca0: 2020 2020 2020 6572 726f 725f 6d65 7373        error_mess
+00015cb0: 6167 652c 0a20 2020 2020 2020 2020 2020  age,.           
+00015cc0: 2062 6f64 793d 6469 6374 5f74 6f5f 6a73   body=dict_to_js
+00015cd0: 6f6e 280a 2020 2020 2020 2020 2020 2020  on(.            
+00015ce0: 2020 2020 7461 675f 6f62 6a65 6374 732e      tag_objects.
+00015cf0: 6469 6374 2829 0a20 2020 2020 2020 2020  dict().         
+00015d00: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+00015d10: 616e 6365 2874 6167 5f6f 626a 6563 7473  ance(tag_objects
+00015d20: 2c20 6d6c 7275 6e2e 6170 692e 7363 6865  , mlrun.api.sche
+00015d30: 6d61 732e 5461 674f 626a 6563 7473 290a  mas.TagObjects).
+00015d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015d50: 656c 7365 2074 6167 5f6f 626a 6563 7473  else tag_objects
+00015d60: 0a20 2020 2020 2020 2020 2020 2029 2c0a  .            ),.
+00015d70: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
+00015d80: 6566 2074 6167 5f61 7274 6966 6163 7473  ef tag_artifacts
+00015d90: 280a 2020 2020 2020 2020 7365 6c66 2c0a  (.        self,.
+00015da0: 2020 2020 2020 2020 6172 7469 6661 6374          artifact
+00015db0: 733a 2055 6e69 6f6e 5b4c 6973 745b 4172  s: Union[List[Ar
+00015dc0: 7469 6661 6374 5d2c 204c 6973 745b 6469  tifact], List[di
+00015dd0: 6374 5d2c 2041 7274 6966 6163 742c 2064  ct], Artifact, d
+00015de0: 6963 745d 2c0a 2020 2020 2020 2020 7072  ict],.        pr
+00015df0: 6f6a 6563 743a 2073 7472 2c0a 2020 2020  oject: str,.    
+00015e00: 2020 2020 7461 675f 6e61 6d65 3a20 7374      tag_name: st
+00015e10: 722c 0a20 2020 2020 2020 2072 6570 6c61  r,.        repla
+00015e20: 6365 3a20 626f 6f6c 203d 2046 616c 7365  ce: bool = False
+00015e30: 2c0a 2020 2020 293a 0a20 2020 2020 2020  ,.    ):.       
+00015e40: 2022 2222 5461 6720 6120 6c69 7374 206f   """Tag a list o
+00015e50: 6620 6172 7469 6661 6374 732e 0a0a 2020  f artifacts...  
+00015e60: 2020 2020 2020 3a70 6172 616d 2061 7274        :param art
+00015e70: 6966 6163 7473 3a20 5468 6520 6172 7469  ifacts: The arti
+00015e80: 6661 6374 7320 746f 2074 6167 2e20 4361  facts to tag. Ca
+00015e90: 6e20 6265 2061 206c 6973 7420 6f66 203a  n be a list of :
+00015ea0: 7079 3a63 6c61 7373 3a60 7e6d 6c72 756e  py:class:`~mlrun
+00015eb0: 2e61 7274 6966 6163 7473 2e41 7274 6966  .artifacts.Artif
+00015ec0: 6163 7460 206f 626a 6563 7473 206f 720a  act` objects or.
+00015ed0: 2020 2020 2020 2020 2020 2020 6469 6374              dict
+00015ee0: 696f 6e61 7269 6573 2c20 6f72 2061 2073  ionaries, or a s
+00015ef0: 696e 676c 6520 6f62 6a65 6374 2e0a 2020  ingle object..  
+00015f00: 2020 2020 2020 3a70 6172 616d 2070 726f        :param pro
+00015f10: 6a65 6374 3a20 5072 6f6a 6563 7420 7768  ject: Project wh
+00015f20: 6963 6820 636f 6e74 6169 6e73 2074 6865  ich contains the
+00015f30: 2061 7274 6966 6163 7473 2e0a 2020 2020   artifacts..    
+00015f40: 2020 2020 3a70 6172 616d 2074 6167 5f6e      :param tag_n
+00015f50: 616d 653a 2054 6865 2074 6167 2074 6f20  ame: The tag to 
+00015f60: 7365 7420 6f6e 2074 6865 2061 7274 6966  set on the artif
+00015f70: 6163 7473 2e0a 2020 2020 2020 2020 3a70  acts..        :p
+00015f80: 6172 616d 2072 6570 6c61 6365 3a20 4966  aram replace: If
+00015f90: 2054 7275 652c 2072 6570 6c61 6365 2065   True, replace e
+00015fa0: 7869 7374 696e 6720 7461 6773 2c20 6f74  xisting tags, ot
+00015fb0: 6865 7277 6973 6520 6170 7065 6e64 2074  herwise append t
+00015fc0: 6f20 6578 6973 7469 6e67 2074 6167 732e  o existing tags.
+00015fd0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00015fe0: 2020 2020 2074 6167 5f6f 626a 6563 7473       tag_objects
+00015ff0: 203d 2073 656c 662e 5f72 6573 6f6c 7665   = self._resolve
+00016000: 5f61 7274 6966 6163 7473 5f74 6f5f 7461  _artifacts_to_ta
+00016010: 675f 6f62 6a65 6374 7328 6172 7469 6661  g_objects(artifa
+00016020: 6374 7329 0a20 2020 2020 2020 2073 656c  cts).        sel
+00016030: 662e 7461 675f 6f62 6a65 6374 7328 7072  f.tag_objects(pr
+00016040: 6f6a 6563 742c 2074 6167 5f6e 616d 652c  oject, tag_name,
+00016050: 206f 626a 6563 7473 3d74 6167 5f6f 626a   objects=tag_obj
+00016060: 6563 7473 2c20 7265 706c 6163 653d 7265  ects, replace=re
+00016070: 706c 6163 6529 0a0a 2020 2020 6465 6620  place)..    def 
+00016080: 6465 6c65 7465 5f61 7274 6966 6163 7473  delete_artifacts
+00016090: 5f74 6167 7328 0a20 2020 2020 2020 2073  _tags(.        s
+000160a0: 656c 662c 0a20 2020 2020 2020 2061 7274  elf,.        art
+000160b0: 6966 6163 7473 2c0a 2020 2020 2020 2020  ifacts,.        
+000160c0: 7072 6f6a 6563 743a 2073 7472 2c0a 2020  project: str,.  
+000160d0: 2020 2020 2020 7461 675f 6e61 6d65 3a20        tag_name: 
+000160e0: 7374 722c 0a20 2020 2029 3a0a 2020 2020  str,.    ):.    
+000160f0: 2020 2020 2222 2244 656c 6574 6520 7461      """Delete ta
+00016100: 6720 6672 6f6d 2061 206c 6973 7420 6f66  g from a list of
+00016110: 2061 7274 6966 6163 7473 2e0a 0a20 2020   artifacts...   
+00016120: 2020 2020 203a 7061 7261 6d20 6172 7469       :param arti
+00016130: 6661 6374 733a 2054 6865 2061 7274 6966  facts: The artif
+00016140: 6163 7473 2074 6f20 6465 6c65 7465 2074  acts to delete t
+00016150: 6865 2074 6167 2066 726f 6d2e 2043 616e  he tag from. Can
+00016160: 2062 6520 6120 6c69 7374 206f 6620 3a70   be a list of :p
+00016170: 793a 636c 6173 733a 607e 6d6c 7275 6e2e  y:class:`~mlrun.
+00016180: 6172 7469 6661 6374 732e 4172 7469 6661  artifacts.Artifa
+00016190: 6374 600a 2020 2020 2020 2020 2020 2020  ct`.            
+000161a0: 6f62 6a65 6374 7320 6f72 2064 6963 7469  objects or dicti
+000161b0: 6f6e 6172 6965 732c 206f 7220 6120 7369  onaries, or a si
+000161c0: 6e67 6c65 206f 626a 6563 742e 0a20 2020  ngle object..   
+000161d0: 2020 2020 203a 7061 7261 6d20 7072 6f6a       :param proj
+000161e0: 6563 743a 2050 726f 6a65 6374 2077 6869  ect: Project whi
+000161f0: 6368 2063 6f6e 7461 696e 7320 7468 6520  ch contains the 
+00016200: 6172 7469 6661 6374 732e 0a20 2020 2020  artifacts..     
+00016210: 2020 203a 7061 7261 6d20 7461 675f 6e61     :param tag_na
+00016220: 6d65 3a20 5468 6520 7461 6720 746f 2073  me: The tag to s
+00016230: 6574 206f 6e20 7468 6520 6172 7469 6661  et on the artifa
+00016240: 6374 732e 0a20 2020 2020 2020 2022 2222  cts..        """
+00016250: 0a20 2020 2020 2020 2074 6167 5f6f 626a  .        tag_obj
+00016260: 6563 7473 203d 2073 656c 662e 5f72 6573  ects = self._res
+00016270: 6f6c 7665 5f61 7274 6966 6163 7473 5f74  olve_artifacts_t
+00016280: 6f5f 7461 675f 6f62 6a65 6374 7328 6172  o_tag_objects(ar
+00016290: 7469 6661 6374 7329 0a20 2020 2020 2020  tifacts).       
+000162a0: 2073 656c 662e 6465 6c65 7465 5f6f 626a   self.delete_obj
+000162b0: 6563 7473 5f74 6167 2870 726f 6a65 6374  ects_tag(project
+000162c0: 2c20 7461 675f 6e61 6d65 2c20 7461 675f  , tag_name, tag_
+000162d0: 6f62 6a65 6374 7329 0a0a 2020 2020 6465  objects)..    de
+000162e0: 6620 6c69 7374 5f70 726f 6a65 6374 7328  f list_projects(
+000162f0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+00016300: 2020 2020 2020 206f 776e 6572 3a20 7374         owner: st
+00016310: 7220 3d20 4e6f 6e65 2c0a 2020 2020 2020  r = None,.      
+00016320: 2020 666f 726d 6174 5f3a 2055 6e69 6f6e    format_: Union
+00016330: 5b0a 2020 2020 2020 2020 2020 2020 7374  [.            st
+00016340: 722c 206d 6c72 756e 2e61 7069 2e73 6368  r, mlrun.api.sch
+00016350: 656d 6173 2e50 726f 6a65 6374 7346 6f72  emas.ProjectsFor
+00016360: 6d61 740a 2020 2020 2020 2020 5d20 3d20  mat.        ] = 
+00016370: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
+00016380: 732e 5072 6f6a 6563 7473 466f 726d 6174  s.ProjectsFormat
+00016390: 2e66 756c 6c2c 0a20 2020 2020 2020 206c  .full,.        l
+000163a0: 6162 656c 733a 204c 6973 745b 7374 725d  abels: List[str]
+000163b0: 203d 204e 6f6e 652c 0a20 2020 2020 2020   = None,.       
+000163c0: 2073 7461 7465 3a20 556e 696f 6e5b 7374   state: Union[st
+000163d0: 722c 206d 6c72 756e 2e61 7069 2e73 6368  r, mlrun.api.sch
+000163e0: 656d 6173 2e50 726f 6a65 6374 5374 6174  emas.ProjectStat
+000163f0: 655d 203d 204e 6f6e 652c 0a20 2020 2029  e] = None,.    )
+00016400: 202d 3e20 4c69 7374 5b55 6e69 6f6e 5b6d   -> List[Union[m
+00016410: 6c72 756e 2e70 726f 6a65 6374 732e 4d6c  lrun.projects.Ml
+00016420: 7275 6e50 726f 6a65 6374 2c20 7374 725d  runProject, str]
+00016430: 5d3a 0a20 2020 2020 2020 2022 2222 5265  ]:.        """Re
+00016440: 7475 726e 2061 206c 6973 7420 6f66 2074  turn a list of t
+00016450: 6865 2065 7869 7374 696e 6720 7072 6f6a  he existing proj
+00016460: 6563 7473 2c20 706f 7465 6e74 6961 6c6c  ects, potentiall
+00016470: 7920 6669 6c74 6572 6564 2062 7920 7370  y filtered by sp
+00016480: 6563 6966 6963 2063 7269 7465 7269 612e  ecific criteria.
+00016490: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+000164a0: 206f 776e 6572 3a20 4c69 7374 206f 6e6c   owner: List onl
+000164b0: 7920 7072 6f6a 6563 7473 2062 656c 6f6e  y projects belon
+000164c0: 6769 6e67 2074 6f20 7468 6973 2073 7065  ging to this spe
+000164d0: 6369 6669 6320 6f77 6e65 722e 0a20 2020  cific owner..   
+000164e0: 2020 2020 203a 7061 7261 6d20 666f 726d       :param form
+000164f0: 6174 5f3a 2046 6f72 6d61 7420 6f66 2074  at_: Format of t
+00016500: 6865 2072 6573 756c 7473 2e20 506f 7373  he results. Poss
+00016510: 6962 6c65 2076 616c 7565 7320 6172 653a  ible values are:
+00016520: 0a0a 2020 2020 2020 2020 2020 2020 2d20  ..            - 
+00016530: 6060 6675 6c6c 6060 2028 6465 6661 756c  ``full`` (defaul
+00016540: 7420 7661 6c75 6529 202d 2052 6574 7572  t value) - Retur
+00016550: 6e20 6675 6c6c 2070 726f 6a65 6374 206f  n full project o
+00016560: 626a 6563 7473 2e0a 2020 2020 2020 2020  bjects..        
+00016570: 2020 2020 2d20 6060 6e61 6d65 5f6f 6e6c      - ``name_onl
+00016580: 7960 6020 2d20 5265 7475 726e 206a 7573  y`` - Return jus
+00016590: 7420 7468 6520 6e61 6d65 7320 6f66 2074  t the names of t
+000165a0: 6865 2070 726f 6a65 6374 732e 0a0a 2020  he projects...  
+000165b0: 2020 2020 2020 3a70 6172 616d 206c 6162        :param lab
+000165c0: 656c 733a 2046 696c 7465 7220 6279 206c  els: Filter by l
+000165d0: 6162 656c 7320 6174 7461 6368 6564 2074  abels attached t
+000165e0: 6f20 7468 6520 7072 6f6a 6563 742e 0a20  o the project.. 
+000165f0: 2020 2020 2020 203a 7061 7261 6d20 7374         :param st
+00016600: 6174 653a 2046 696c 7465 7220 6279 2070  ate: Filter by p
+00016610: 726f 6a65 6374 2773 2073 7461 7465 2e20  roject's state. 
+00016620: 4361 6e20 6265 2065 6974 6865 7220 6060  Can be either ``
+00016630: 6f6e 6c69 6e65 6060 206f 7220 6060 6172  online`` or ``ar
+00016640: 6368 6976 6564 6060 2e0a 2020 2020 2020  chived``..      
+00016650: 2020 2222 220a 0a20 2020 2020 2020 2070    """..        p
+00016660: 6172 616d 7320 3d20 7b0a 2020 2020 2020  arams = {.      
+00016670: 2020 2020 2020 226f 776e 6572 223a 206f        "owner": o
+00016680: 776e 6572 2c0a 2020 2020 2020 2020 2020  wner,.          
+00016690: 2020 2273 7461 7465 223a 2073 7461 7465    "state": state
+000166a0: 2c0a 2020 2020 2020 2020 2020 2020 2266  ,.            "f
+000166b0: 6f72 6d61 7422 3a20 666f 726d 6174 5f2c  ormat": format_,
+000166c0: 0a20 2020 2020 2020 2020 2020 2022 6c61  .            "la
+000166d0: 6265 6c22 3a20 6c61 6265 6c73 206f 7220  bel": labels or 
+000166e0: 5b5d 2c0a 2020 2020 2020 2020 7d0a 0a20  [],.        }.. 
+000166f0: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+00016700: 7361 6765 203d 2066 2246 6169 6c65 6420  sage = f"Failed 
+00016710: 6c69 7374 696e 6720 7072 6f6a 6563 7473  listing projects
+00016720: 2c20 7175 6572 793a 207b 7061 7261 6d73  , query: {params
+00016730: 7d22 0a20 2020 2020 2020 2072 6573 706f  }".        respo
+00016740: 6e73 6520 3d20 7365 6c66 2e61 7069 5f63  nse = self.api_c
+00016750: 616c 6c28 2247 4554 222c 2022 7072 6f6a  all("GET", "proj
+00016760: 6563 7473 222c 2065 7272 6f72 5f6d 6573  ects", error_mes
+00016770: 7361 6765 2c20 7061 7261 6d73 3d70 6172  sage, params=par
+00016780: 616d 7329 0a20 2020 2020 2020 2069 6620  ams).        if 
+00016790: 666f 726d 6174 5f20 3d3d 206d 6c72 756e  format_ == mlrun
+000167a0: 2e61 7069 2e73 6368 656d 6173 2e50 726f  .api.schemas.Pro
+000167b0: 6a65 6374 7346 6f72 6d61 742e 6e61 6d65  jectsFormat.name
+000167c0: 5f6f 6e6c 793a 0a20 2020 2020 2020 2020  _only:.         
+000167d0: 2020 2072 6574 7572 6e20 7265 7370 6f6e     return respon
+000167e0: 7365 2e6a 736f 6e28 295b 2270 726f 6a65  se.json()["proje
+000167f0: 6374 7322 5d0a 2020 2020 2020 2020 656c  cts"].        el
+00016800: 6966 2066 6f72 6d61 745f 203d 3d20 6d6c  if format_ == ml
+00016810: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
+00016820: 5072 6f6a 6563 7473 466f 726d 6174 2e66  ProjectsFormat.f
+00016830: 756c 6c3a 0a20 2020 2020 2020 2020 2020  ull:.           
+00016840: 2072 6574 7572 6e20 5b0a 2020 2020 2020   return [.      
+00016850: 2020 2020 2020 2020 2020 6d6c 7275 6e2e            mlrun.
+00016860: 7072 6f6a 6563 7473 2e4d 6c72 756e 5072  projects.MlrunPr
+00016870: 6f6a 6563 742e 6672 6f6d 5f64 6963 7428  oject.from_dict(
+00016880: 7072 6f6a 6563 745f 6469 6374 290a 2020  project_dict).  
+00016890: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+000168a0: 7220 7072 6f6a 6563 745f 6469 6374 2069  r project_dict i
+000168b0: 6e20 7265 7370 6f6e 7365 2e6a 736f 6e28  n response.json(
+000168c0: 295b 2270 726f 6a65 6374 7322 5d0a 2020  )["projects"].  
+000168d0: 2020 2020 2020 2020 2020 5d0a 2020 2020            ].    
+000168e0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000168f0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+00016900: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+00016910: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016920: 2066 2250 726f 7669 6465 6420 666f 726d   f"Provided form
+00016930: 6174 2069 7320 6e6f 7420 7375 7070 6f72  at is not suppor
+00016940: 7465 642e 2066 6f72 6d61 743d 7b66 6f72  ted. format={for
+00016950: 6d61 745f 7d22 0a20 2020 2020 2020 2020  mat_}".         
+00016960: 2020 2029 0a0a 2020 2020 6465 6620 6765     )..    def ge
+00016970: 745f 7072 6f6a 6563 7428 7365 6c66 2c20  t_project(self, 
+00016980: 6e61 6d65 3a20 7374 7229 202d 3e20 6d6c  name: str) -> ml
+00016990: 7275 6e2e 7072 6f6a 6563 7473 2e4d 6c72  run.projects.Mlr
+000169a0: 756e 5072 6f6a 6563 743a 0a20 2020 2020  unProject:.     
+000169b0: 2020 2022 2222 4765 7420 6465 7461 696c     """Get detail
+000169c0: 7320 666f 7220 6120 7370 6563 6966 6963  s for a specific
+000169d0: 2070 726f 6a65 6374 2e22 2222 0a0a 2020   project."""..  
+000169e0: 2020 2020 2020 6966 206e 6f74 206e 616d        if not nam
+000169f0: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+00016a00: 6169 7365 204d 4c52 756e 496e 7661 6c69  aise MLRunInvali
+00016a10: 6441 7267 756d 656e 7445 7272 6f72 2822  dArgumentError("
+00016a20: 4e61 6d65 206d 7573 7420 6265 2070 726f  Name must be pro
+00016a30: 7669 6465 6422 290a 0a20 2020 2020 2020  vided")..       
+00016a40: 2070 6174 6820 3d20 6622 7072 6f6a 6563   path = f"projec
+00016a50: 7473 2f7b 6e61 6d65 7d22 0a20 2020 2020  ts/{name}".     
+00016a60: 2020 2065 7272 6f72 5f6d 6573 7361 6765     error_message
+00016a70: 203d 2066 2246 6169 6c65 6420 7265 7472   = f"Failed retr
+00016a80: 6965 7669 6e67 2070 726f 6a65 6374 207b  ieving project {
+00016a90: 6e61 6d65 7d22 0a20 2020 2020 2020 2072  name}".        r
+00016aa0: 6573 706f 6e73 6520 3d20 7365 6c66 2e61  esponse = self.a
+00016ab0: 7069 5f63 616c 6c28 2247 4554 222c 2070  pi_call("GET", p
+00016ac0: 6174 682c 2065 7272 6f72 5f6d 6573 7361  ath, error_messa
+00016ad0: 6765 290a 2020 2020 2020 2020 7265 7475  ge).        retu
+00016ae0: 726e 206d 6c72 756e 2e70 726f 6a65 6374  rn mlrun.project
+00016af0: 732e 4d6c 7275 6e50 726f 6a65 6374 2e66  s.MlrunProject.f
+00016b00: 726f 6d5f 6469 6374 2872 6573 706f 6e73  rom_dict(respons
+00016b10: 652e 6a73 6f6e 2829 290a 0a20 2020 2064  e.json())..    d
+00016b20: 6566 2064 656c 6574 655f 7072 6f6a 6563  ef delete_projec
+00016b30: 7428 0a20 2020 2020 2020 2073 656c 662c  t(.        self,
+00016b40: 0a20 2020 2020 2020 206e 616d 653a 2073  .        name: s
+00016b50: 7472 2c0a 2020 2020 2020 2020 6465 6c65  tr,.        dele
+00016b60: 7469 6f6e 5f73 7472 6174 6567 793a 2055  tion_strategy: U
+00016b70: 6e69 6f6e 5b0a 2020 2020 2020 2020 2020  nion[.          
+00016b80: 2020 7374 722c 206d 6c72 756e 2e61 7069    str, mlrun.api
+00016b90: 2e73 6368 656d 6173 2e44 656c 6574 696f  .schemas.Deletio
+00016ba0: 6e53 7472 6174 6567 790a 2020 2020 2020  nStrategy.      
+00016bb0: 2020 5d20 3d20 6d6c 7275 6e2e 6170 692e    ] = mlrun.api.
+00016bc0: 7363 6865 6d61 732e 4465 6c65 7469 6f6e  schemas.Deletion
+00016bd0: 5374 7261 7465 6779 2e64 6566 6175 6c74  Strategy.default
+00016be0: 2829 2c0a 2020 2020 293a 0a20 2020 2020  (),.    ):.     
+00016bf0: 2020 2022 2222 4465 6c65 7465 2061 2070     """Delete a p
+00016c00: 726f 6a65 6374 2e0a 0a20 2020 2020 2020  roject...       
+00016c10: 203a 7061 7261 6d20 6e61 6d65 3a20 4e61   :param name: Na
+00016c20: 6d65 206f 6620 7468 6520 7072 6f6a 6563  me of the projec
+00016c30: 7420 746f 2064 656c 6574 652e 0a20 2020  t to delete..   
+00016c40: 2020 2020 203a 7061 7261 6d20 6465 6c65       :param dele
+00016c50: 7469 6f6e 5f73 7472 6174 6567 793a 2048  tion_strategy: H
+00016c60: 6f77 2074 6f20 7472 6561 7420 6368 696c  ow to treat chil
+00016c70: 6420 6f62 6a65 6374 7320 6f66 2074 6865  d objects of the
+00016c80: 2070 726f 6a65 6374 2e20 506f 7373 6962   project. Possib
+00016c90: 6c65 2076 616c 7565 7320 6172 653a 0a0a  le values are:..
+00016ca0: 2020 2020 2020 2020 2020 2020 2d20 6060              - ``
+00016cb0: 7265 7374 7269 6374 6060 2028 6465 6661  restrict`` (defa
+00016cc0: 756c 7429 202d 2050 726f 6a65 6374 206d  ult) - Project m
+00016cd0: 7573 7420 6e6f 7420 6861 7665 2061 6e79  ust not have any
+00016ce0: 2063 6869 6c64 206f 626a 6563 7473 2077   child objects w
+00016cf0: 6865 6e20 6465 6c65 7465 642e 2049 6620  hen deleted. If 
+00016d00: 7573 696e 6720 7468 6973 206d 6f64 6520  using this mode 
+00016d10: 7768 696c 650a 2020 2020 2020 2020 2020  while.          
+00016d20: 2020 2020 6368 696c 6420 6f62 6a65 6374      child object
+00016d30: 7320 6578 6973 742c 2074 6865 206f 7065  s exist, the ope
+00016d40: 7261 7469 6f6e 2077 696c 6c20 6661 696c  ration will fail
+00016d50: 2e0a 2020 2020 2020 2020 2020 2020 2d20  ..            - 
+00016d60: 6060 6361 7363 6164 6560 6020 2d20 4175  ``cascade`` - Au
+00016d70: 746f 6d61 7469 6361 6c6c 7920 6465 6c65  tomatically dele
+00016d80: 7465 2061 6c6c 2063 6869 6c64 206f 626a  te all child obj
+00016d90: 6563 7473 2077 6865 6e20 6465 6c65 7469  ects when deleti
+00016da0: 6e67 2074 6865 2070 726f 6a65 6374 2e0a  ng the project..
+00016db0: 2020 2020 2020 2020 2222 220a 0a20 2020          """..   
+00016dc0: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
+00016dd0: 6f6a 6563 7473 2f7b 6e61 6d65 7d22 0a20  ojects/{name}". 
+00016de0: 2020 2020 2020 2068 6561 6465 7273 203d         headers =
+00016df0: 207b 7363 6865 6d61 732e 4865 6164 6572   {schemas.Header
+00016e00: 4e61 6d65 732e 6465 6c65 7469 6f6e 5f73  Names.deletion_s
+00016e10: 7472 6174 6567 793a 2064 656c 6574 696f  trategy: deletio
+00016e20: 6e5f 7374 7261 7465 6779 7d0a 2020 2020  n_strategy}.    
+00016e30: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+00016e40: 6520 3d20 6622 4661 696c 6564 2064 656c  e = f"Failed del
+00016e50: 6574 696e 6720 7072 6f6a 6563 7420 7b6e  eting project {n
+00016e60: 616d 657d 220a 2020 2020 2020 2020 7265  ame}".        re
+00016e70: 7370 6f6e 7365 203d 2073 656c 662e 6170  sponse = self.ap
+00016e80: 695f 6361 6c6c 2822 4445 4c45 5445 222c  i_call("DELETE",
+00016e90: 2070 6174 682c 2065 7272 6f72 5f6d 6573   path, error_mes
+00016ea0: 7361 6765 2c20 6865 6164 6572 733d 6865  sage, headers=he
+00016eb0: 6164 6572 7329 0a20 2020 2020 2020 2069  aders).        i
+00016ec0: 6620 7265 7370 6f6e 7365 2e73 7461 7475  f response.statu
+00016ed0: 735f 636f 6465 203d 3d20 6874 7470 2e48  s_code == http.H
+00016ee0: 5454 5053 7461 7475 732e 4143 4345 5054  TTPStatus.ACCEPT
+00016ef0: 4544 3a0a 2020 2020 2020 2020 2020 2020  ED:.            
+00016f00: 7265 7475 726e 2073 656c 662e 5f77 6169  return self._wai
+00016f10: 745f 666f 725f 7072 6f6a 6563 745f 746f  t_for_project_to
+00016f20: 5f62 655f 6465 6c65 7465 6428 6e61 6d65  _be_deleted(name
+00016f30: 290a 0a20 2020 2064 6566 2073 746f 7265  )..    def store
+00016f40: 5f70 726f 6a65 6374 280a 2020 2020 2020  _project(.      
+00016f50: 2020 7365 6c66 2c0a 2020 2020 2020 2020    self,.        
+00016f60: 6e61 6d65 3a20 7374 722c 0a20 2020 2020  name: str,.     
+00016f70: 2020 2070 726f 6a65 6374 3a20 556e 696f     project: Unio
+00016f80: 6e5b 6469 6374 2c20 6d6c 7275 6e2e 7072  n[dict, mlrun.pr
+00016f90: 6f6a 6563 7473 2e4d 6c72 756e 5072 6f6a  ojects.MlrunProj
+00016fa0: 6563 742c 206d 6c72 756e 2e61 7069 2e73  ect, mlrun.api.s
+00016fb0: 6368 656d 6173 2e50 726f 6a65 6374 5d2c  chemas.Project],
+00016fc0: 0a20 2020 2029 202d 3e20 6d6c 7275 6e2e  .    ) -> mlrun.
+00016fd0: 7072 6f6a 6563 7473 2e4d 6c72 756e 5072  projects.MlrunPr
+00016fe0: 6f6a 6563 743a 0a20 2020 2020 2020 2022  oject:.        "
+00016ff0: 2222 5374 6f72 6520 6120 7072 6f6a 6563  ""Store a projec
+00017000: 7420 696e 2074 6865 2044 422e 2054 6869  t in the DB. Thi
+00017010: 7320 6f70 6572 6174 696f 6e20 7769 6c6c  s operation will
+00017020: 206f 7665 7277 7269 7465 2065 7869 7374   overwrite exist
+00017030: 696e 6720 7072 6f6a 6563 7420 6f66 2074  ing project of t
+00017040: 6865 2073 616d 6520 6e61 6d65 2069 6620  he same name if 
+00017050: 6578 6973 7473 2e22 2222 0a0a 2020 2020  exists."""..    
+00017060: 2020 2020 7061 7468 203d 2066 2270 726f      path = f"pro
+00017070: 6a65 6374 732f 7b6e 616d 657d 220a 2020  jects/{name}".  
+00017080: 2020 2020 2020 6572 726f 725f 6d65 7373        error_mess
+00017090: 6167 6520 3d20 6622 4661 696c 6564 2073  age = f"Failed s
+000170a0: 746f 7269 6e67 2070 726f 6a65 6374 207b  toring project {
+000170b0: 6e61 6d65 7d22 0a20 2020 2020 2020 2069  name}".        i
+000170c0: 6620 6973 696e 7374 616e 6365 2870 726f  f isinstance(pro
+000170d0: 6a65 6374 2c20 6d6c 7275 6e2e 6170 692e  ject, mlrun.api.
+000170e0: 7363 6865 6d61 732e 5072 6f6a 6563 7429  schemas.Project)
+000170f0: 3a0a 2020 2020 2020 2020 2020 2020 7072  :.            pr
+00017100: 6f6a 6563 7420 3d20 7072 6f6a 6563 742e  oject = project.
+00017110: 6469 6374 2829 0a20 2020 2020 2020 2065  dict().        e
+00017120: 6c69 6620 6973 696e 7374 616e 6365 2870  lif isinstance(p
+00017130: 726f 6a65 6374 2c20 6d6c 7275 6e2e 7072  roject, mlrun.pr
+00017140: 6f6a 6563 7473 2e4d 6c72 756e 5072 6f6a  ojects.MlrunProj
+00017150: 6563 7429 3a0a 2020 2020 2020 2020 2020  ect):.          
+00017160: 2020 7072 6f6a 6563 7420 3d20 7072 6f6a    project = proj
+00017170: 6563 742e 746f 5f64 6963 7428 290a 2020  ect.to_dict().  
+00017180: 2020 2020 2020 7265 7370 6f6e 7365 203d        response =
+00017190: 2073 656c 662e 6170 695f 6361 6c6c 280a   self.api_call(.
+000171a0: 2020 2020 2020 2020 2020 2020 2250 5554              "PUT
+000171b0: 222c 0a20 2020 2020 2020 2020 2020 2070  ",.            p
+000171c0: 6174 682c 0a20 2020 2020 2020 2020 2020  ath,.           
+000171d0: 2065 7272 6f72 5f6d 6573 7361 6765 2c0a   error_message,.
+000171e0: 2020 2020 2020 2020 2020 2020 626f 6479              body
+000171f0: 3d64 6963 745f 746f 5f6a 736f 6e28 7072  =dict_to_json(pr
+00017200: 6f6a 6563 7429 2c0a 2020 2020 2020 2020  oject),.        
+00017210: 290a 2020 2020 2020 2020 6966 2072 6573  ).        if res
+00017220: 706f 6e73 652e 7374 6174 7573 5f63 6f64  ponse.status_cod
+00017230: 6520 3d3d 2068 7474 702e 4854 5450 5374  e == http.HTTPSt
+00017240: 6174 7573 2e41 4343 4550 5445 443a 0a20  atus.ACCEPTED:. 
+00017250: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00017260: 6e20 7365 6c66 2e5f 7761 6974 5f66 6f72  n self._wait_for
+00017270: 5f70 726f 6a65 6374 5f74 6f5f 7265 6163  _project_to_reac
+00017280: 685f 7465 726d 696e 616c 5f73 7461 7465  h_terminal_state
+00017290: 286e 616d 6529 0a20 2020 2020 2020 2072  (name).        r
+000172a0: 6574 7572 6e20 6d6c 7275 6e2e 7072 6f6a  eturn mlrun.proj
+000172b0: 6563 7473 2e4d 6c72 756e 5072 6f6a 6563  ects.MlrunProjec
+000172c0: 742e 6672 6f6d 5f64 6963 7428 7265 7370  t.from_dict(resp
+000172d0: 6f6e 7365 2e6a 736f 6e28 2929 0a0a 2020  onse.json())..  
+000172e0: 2020 6465 6620 7061 7463 685f 7072 6f6a    def patch_proj
+000172f0: 6563 7428 0a20 2020 2020 2020 2073 656c  ect(.        sel
+00017300: 662c 0a20 2020 2020 2020 206e 616d 653a  f,.        name:
+00017310: 2073 7472 2c0a 2020 2020 2020 2020 7072   str,.        pr
+00017320: 6f6a 6563 743a 2064 6963 742c 0a20 2020  oject: dict,.   
+00017330: 2020 2020 2070 6174 6368 5f6d 6f64 653a       patch_mode:
+00017340: 2055 6e69 6f6e 5b73 7472 2c20 7363 6865   Union[str, sche
+00017350: 6d61 732e 5061 7463 684d 6f64 655d 203d  mas.PatchMode] =
+00017360: 2073 6368 656d 6173 2e50 6174 6368 4d6f   schemas.PatchMo
+00017370: 6465 2e72 6570 6c61 6365 2c0a 2020 2020  de.replace,.    
+00017380: 2920 2d3e 206d 6c72 756e 2e70 726f 6a65  ) -> mlrun.proje
+00017390: 6374 732e 4d6c 7275 6e50 726f 6a65 6374  cts.MlrunProject
+000173a0: 3a0a 2020 2020 2020 2020 2222 2250 6174  :.        """Pat
+000173b0: 6368 2061 6e20 6578 6973 7469 6e67 2070  ch an existing p
+000173c0: 726f 6a65 6374 206f 626a 6563 742e 0a0a  roject object...
+000173d0: 2020 2020 2020 2020 3a70 6172 616d 206e          :param n
+000173e0: 616d 653a 204e 616d 6520 6f66 2070 726f  ame: Name of pro
+000173f0: 6a65 6374 2074 6f20 7061 7463 682e 0a20  ject to patch.. 
+00017400: 2020 2020 2020 203a 7061 7261 6d20 7072         :param pr
+00017410: 6f6a 6563 743a 2054 6865 2061 6374 7561  oject: The actua
+00017420: 6c20 6368 616e 6765 7320 746f 2074 6865  l changes to the
+00017430: 2070 726f 6a65 6374 206f 626a 6563 742e   project object.
+00017440: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00017450: 7061 7463 685f 6d6f 6465 3a20 5468 6520  patch_mode: The 
+00017460: 7374 7261 7465 6779 2066 6f72 206d 6572  strategy for mer
+00017470: 6769 6e67 2074 6865 2063 6861 6e67 6573  ging the changes
+00017480: 2077 6974 6820 7468 6520 6578 6973 7469   with the existi
+00017490: 6e67 206f 626a 6563 742e 2043 616e 2062  ng object. Can b
+000174a0: 6520 6569 7468 6572 2060 6072 6570 6c61  e either ``repla
+000174b0: 6365 6060 0a20 2020 2020 2020 2020 2020  ce``.           
+000174c0: 206f 7220 6060 6164 6469 7469 7665 6060   or ``additive``
+000174d0: 2e0a 2020 2020 2020 2020 2222 220a 0a20  ..        """.. 
+000174e0: 2020 2020 2020 2070 6174 6820 3d20 6622         path = f"
+000174f0: 7072 6f6a 6563 7473 2f7b 6e61 6d65 7d22  projects/{name}"
+00017500: 0a20 2020 2020 2020 2068 6561 6465 7273  .        headers
+00017510: 203d 207b 7363 6865 6d61 732e 4865 6164   = {schemas.Head
+00017520: 6572 4e61 6d65 732e 7061 7463 685f 6d6f  erNames.patch_mo
+00017530: 6465 3a20 7061 7463 685f 6d6f 6465 7d0a  de: patch_mode}.
+00017540: 2020 2020 2020 2020 6572 726f 725f 6d65          error_me
+00017550: 7373 6167 6520 3d20 6622 4661 696c 6564  ssage = f"Failed
+00017560: 2070 6174 6368 696e 6720 7072 6f6a 6563   patching projec
+00017570: 7420 7b6e 616d 657d 220a 2020 2020 2020  t {name}".      
+00017580: 2020 7265 7370 6f6e 7365 203d 2073 656c    response = sel
+00017590: 662e 6170 695f 6361 6c6c 280a 2020 2020  f.api_call(.    
+000175a0: 2020 2020 2020 2020 2250 4154 4348 222c          "PATCH",
+000175b0: 2070 6174 682c 2065 7272 6f72 5f6d 6573   path, error_mes
+000175c0: 7361 6765 2c20 626f 6479 3d64 6963 745f  sage, body=dict_
+000175d0: 746f 5f6a 736f 6e28 7072 6f6a 6563 7429  to_json(project)
+000175e0: 2c20 6865 6164 6572 733d 6865 6164 6572  , headers=header
+000175f0: 730a 2020 2020 2020 2020 290a 2020 2020  s.        ).    
+00017600: 2020 2020 7265 7475 726e 206d 6c72 756e      return mlrun
+00017610: 2e70 726f 6a65 6374 732e 4d6c 7275 6e50  .projects.MlrunP
+00017620: 726f 6a65 6374 2e66 726f 6d5f 6469 6374  roject.from_dict
+00017630: 2872 6573 706f 6e73 652e 6a73 6f6e 2829  (response.json()
+00017640: 290a 0a20 2020 2064 6566 2063 7265 6174  )..    def creat
+00017650: 655f 7072 6f6a 6563 7428 0a20 2020 2020  e_project(.     
+00017660: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+00017670: 2070 726f 6a65 6374 3a20 556e 696f 6e5b   project: Union[
+00017680: 6469 6374 2c20 6d6c 7275 6e2e 7072 6f6a  dict, mlrun.proj
+00017690: 6563 7473 2e4d 6c72 756e 5072 6f6a 6563  ects.MlrunProjec
+000176a0: 742c 206d 6c72 756e 2e61 7069 2e73 6368  t, mlrun.api.sch
+000176b0: 656d 6173 2e50 726f 6a65 6374 5d2c 0a20  emas.Project],. 
+000176c0: 2020 2029 202d 3e20 6d6c 7275 6e2e 7072     ) -> mlrun.pr
+000176d0: 6f6a 6563 7473 2e4d 6c72 756e 5072 6f6a  ojects.MlrunProj
+000176e0: 6563 743a 0a20 2020 2020 2020 2022 2222  ect:.        """
+000176f0: 4372 6561 7465 2061 206e 6577 2070 726f  Create a new pro
+00017700: 6a65 6374 2e20 4120 7072 6f6a 6563 7420  ject. A project 
+00017710: 7769 7468 2074 6865 2073 616d 6520 6e61  with the same na
+00017720: 6d65 206d 7573 7420 6e6f 7420 6578 6973  me must not exis
+00017730: 7420 7072 696f 7220 746f 2063 7265 6174  t prior to creat
+00017740: 696f 6e2e 2222 220a 0a20 2020 2020 2020  ion."""..       
+00017750: 2069 6620 6973 696e 7374 616e 6365 2870   if isinstance(p
+00017760: 726f 6a65 6374 2c20 6d6c 7275 6e2e 6170  roject, mlrun.ap
+00017770: 692e 7363 6865 6d61 732e 5072 6f6a 6563  i.schemas.Projec
+00017780: 7429 3a0a 2020 2020 2020 2020 2020 2020  t):.            
+00017790: 7072 6f6a 6563 7420 3d20 7072 6f6a 6563  project = projec
+000177a0: 742e 6469 6374 2829 0a20 2020 2020 2020  t.dict().       
+000177b0: 2065 6c69 6620 6973 696e 7374 616e 6365   elif isinstance
+000177c0: 2870 726f 6a65 6374 2c20 6d6c 7275 6e2e  (project, mlrun.
+000177d0: 7072 6f6a 6563 7473 2e4d 6c72 756e 5072  projects.MlrunPr
+000177e0: 6f6a 6563 7429 3a0a 2020 2020 2020 2020  oject):.        
+000177f0: 2020 2020 7072 6f6a 6563 7420 3d20 7072      project = pr
+00017800: 6f6a 6563 742e 746f 5f64 6963 7428 290a  oject.to_dict().
+00017810: 2020 2020 2020 2020 7072 6f6a 6563 745f          project_
+00017820: 6e61 6d65 203d 2070 726f 6a65 6374 5b22  name = project["
+00017830: 6d65 7461 6461 7461 225d 5b22 6e61 6d65  metadata"]["name
+00017840: 225d 0a20 2020 2020 2020 2065 7272 6f72  "].        error
+00017850: 5f6d 6573 7361 6765 203d 2066 2246 6169  _message = f"Fai
+00017860: 6c65 6420 6372 6561 7469 6e67 2070 726f  led creating pro
+00017870: 6a65 6374 207b 7072 6f6a 6563 745f 6e61  ject {project_na
+00017880: 6d65 7d22 0a20 2020 2020 2020 2072 6573  me}".        res
+00017890: 706f 6e73 6520 3d20 7365 6c66 2e61 7069  ponse = self.api
+000178a0: 5f63 616c 6c28 0a20 2020 2020 2020 2020  _call(.         
+000178b0: 2020 2022 504f 5354 222c 0a20 2020 2020     "POST",.     
+000178c0: 2020 2020 2020 2022 7072 6f6a 6563 7473         "projects
+000178d0: 222c 0a20 2020 2020 2020 2020 2020 2065  ",.            e
+000178e0: 7272 6f72 5f6d 6573 7361 6765 2c0a 2020  rror_message,.  
+000178f0: 2020 2020 2020 2020 2020 626f 6479 3d64            body=d
+00017900: 6963 745f 746f 5f6a 736f 6e28 7072 6f6a  ict_to_json(proj
+00017910: 6563 7429 2c0a 2020 2020 2020 2020 290a  ect),.        ).
+00017920: 2020 2020 2020 2020 6966 2072 6573 706f          if respo
+00017930: 6e73 652e 7374 6174 7573 5f63 6f64 6520  nse.status_code 
+00017940: 3d3d 2068 7474 702e 4854 5450 5374 6174  == http.HTTPStat
+00017950: 7573 2e41 4343 4550 5445 443a 0a20 2020  us.ACCEPTED:.   
+00017960: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00017970: 7365 6c66 2e5f 7761 6974 5f66 6f72 5f70  self._wait_for_p
+00017980: 726f 6a65 6374 5f74 6f5f 7265 6163 685f  roject_to_reach_
+00017990: 7465 726d 696e 616c 5f73 7461 7465 2870  terminal_state(p
+000179a0: 726f 6a65 6374 5f6e 616d 6529 0a20 2020  roject_name).   
+000179b0: 2020 2020 2072 6574 7572 6e20 6d6c 7275       return mlru
+000179c0: 6e2e 7072 6f6a 6563 7473 2e4d 6c72 756e  n.projects.Mlrun
+000179d0: 5072 6f6a 6563 742e 6672 6f6d 5f64 6963  Project.from_dic
+000179e0: 7428 7265 7370 6f6e 7365 2e6a 736f 6e28  t(response.json(
+000179f0: 2929 0a0a 2020 2020 6465 6620 5f77 6169  ))..    def _wai
+00017a00: 745f 666f 725f 7072 6f6a 6563 745f 746f  t_for_project_to
+00017a10: 5f72 6561 6368 5f74 6572 6d69 6e61 6c5f  _reach_terminal_
+00017a20: 7374 6174 6528 0a20 2020 2020 2020 2073  state(.        s
+00017a30: 656c 662c 2070 726f 6a65 6374 5f6e 616d  elf, project_nam
+00017a40: 653a 2073 7472 0a20 2020 2029 202d 3e20  e: str.    ) -> 
+00017a50: 6d6c 7275 6e2e 7072 6f6a 6563 7473 2e4d  mlrun.projects.M
+00017a60: 6c72 756e 5072 6f6a 6563 743a 0a20 2020  lrunProject:.   
+00017a70: 2020 2020 2064 6566 205f 7665 7269 6679       def _verify
+00017a80: 5f70 726f 6a65 6374 5f69 6e5f 7465 726d  _project_in_term
+00017a90: 696e 616c 5f73 7461 7465 2829 3a0a 2020  inal_state():.  
+00017aa0: 2020 2020 2020 2020 2020 7072 6f6a 6563            projec
+00017ab0: 7420 3d20 7365 6c66 2e67 6574 5f70 726f  t = self.get_pro
+00017ac0: 6a65 6374 2870 726f 6a65 6374 5f6e 616d  ject(project_nam
+00017ad0: 6529 0a20 2020 2020 2020 2020 2020 2069  e).            i
+00017ae0: 6620 280a 2020 2020 2020 2020 2020 2020  f (.            
+00017af0: 2020 2020 7072 6f6a 6563 742e 7374 6174      project.stat
+00017b00: 7573 2e73 7461 7465 0a20 2020 2020 2020  us.state.       
+00017b10: 2020 2020 2020 2020 206e 6f74 2069 6e20           not in 
+00017b20: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
+00017b30: 732e 5072 6f6a 6563 7453 7461 7465 2e74  s.ProjectState.t
+00017b40: 6572 6d69 6e61 6c5f 7374 6174 6573 2829  erminal_states()
+00017b50: 0a20 2020 2020 2020 2020 2020 2029 3a0a  .            ):.
+00017b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017b70: 7261 6973 6520 4578 6365 7074 696f 6e28  raise Exception(
+00017b80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017b90: 2020 2020 2066 2250 726f 6a65 6374 206e       f"Project n
+00017ba0: 6f74 2069 6e20 7465 726d 696e 616c 2073  ot in terminal s
+00017bb0: 7461 7465 2e20 5374 6174 653a 207b 7072  tate. State: {pr
+00017bc0: 6f6a 6563 742e 7374 6174 7573 2e73 7461  oject.status.sta
+00017bd0: 7465 7d22 0a20 2020 2020 2020 2020 2020  te}".           
+00017be0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00017bf0: 2020 2072 6574 7572 6e20 7072 6f6a 6563     return projec
+00017c00: 740a 0a20 2020 2020 2020 2072 6574 7572  t..        retur
+00017c10: 6e20 6d6c 7275 6e2e 7574 696c 732e 6865  n mlrun.utils.he
+00017c20: 6c70 6572 732e 7265 7472 795f 756e 7469  lpers.retry_unti
+00017c30: 6c5f 7375 6363 6573 7366 756c 280a 2020  l_successful(.  
+00017c40: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
+00017c50: 7761 6974 5f66 6f72 5f70 726f 6a65 6374  wait_for_project
+00017c60: 5f74 6572 6d69 6e61 6c5f 7374 6174 655f  _terminal_state_
+00017c70: 7265 7472 795f 696e 7465 7276 616c 2c0a  retry_interval,.
+00017c80: 2020 2020 2020 2020 2020 2020 3132 302c              120,
+00017c90: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
+00017ca0: 6765 722c 0a20 2020 2020 2020 2020 2020  ger,.           
+00017cb0: 2046 616c 7365 2c0a 2020 2020 2020 2020   False,.        
+00017cc0: 2020 2020 5f76 6572 6966 795f 7072 6f6a      _verify_proj
+00017cd0: 6563 745f 696e 5f74 6572 6d69 6e61 6c5f  ect_in_terminal_
+00017ce0: 7374 6174 652c 0a20 2020 2020 2020 2029  state,.        )
+00017cf0: 0a0a 2020 2020 6465 6620 5f77 6169 745f  ..    def _wait_
+00017d00: 666f 725f 6261 636b 6772 6f75 6e64 5f74  for_background_t
+00017d10: 6173 6b5f 746f 5f72 6561 6368 5f74 6572  ask_to_reach_ter
+00017d20: 6d69 6e61 6c5f 7374 6174 6528 0a20 2020  minal_state(.   
+00017d30: 2020 2020 2073 656c 662c 206e 616d 653a       self, name:
+00017d40: 2073 7472 0a20 2020 2029 202d 3e20 7363   str.    ) -> sc
+00017d50: 6865 6d61 732e 4261 636b 6772 6f75 6e64  hemas.Background
+00017d60: 5461 736b 3a0a 2020 2020 2020 2020 6465  Task:.        de
+00017d70: 6620 5f76 6572 6966 795f 6261 636b 6772  f _verify_backgr
+00017d80: 6f75 6e64 5f74 6173 6b5f 696e 5f74 6572  ound_task_in_ter
+00017d90: 6d69 6e61 6c5f 7374 6174 6528 293a 0a20  minal_state():. 
+00017da0: 2020 2020 2020 2020 2020 2062 6163 6b67             backg
+00017db0: 726f 756e 645f 7461 736b 203d 2073 656c  round_task = sel
+00017dc0: 662e 6765 745f 6261 636b 6772 6f75 6e64  f.get_background
+00017dd0: 5f74 6173 6b28 6e61 6d65 290a 2020 2020  _task(name).    
+00017de0: 2020 2020 2020 2020 7374 6174 6520 3d20          state = 
+00017df0: 6261 636b 6772 6f75 6e64 5f74 6173 6b2e  background_task.
+00017e00: 7374 6174 7573 2e73 7461 7465 0a20 2020  status.state.   
+00017e10: 2020 2020 2020 2020 2069 6620 7374 6174           if stat
+00017e20: 6520 6e6f 7420 696e 206d 6c72 756e 2e61  e not in mlrun.a
+00017e30: 7069 2e73 6368 656d 6173 2e42 6163 6b67  pi.schemas.Backg
+00017e40: 726f 756e 6454 6173 6b53 7461 7465 2e74  roundTaskState.t
+00017e50: 6572 6d69 6e61 6c5f 7374 6174 6573 2829  erminal_states()
+00017e60: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00017e70: 2020 7261 6973 6520 4578 6365 7074 696f    raise Exceptio
+00017e80: 6e28 0a20 2020 2020 2020 2020 2020 2020  n(.             
+00017e90: 2020 2020 2020 2066 2242 6163 6b67 726f         f"Backgro
+00017ea0: 756e 6420 7461 736b 206e 6f74 2069 6e20  und task not in 
+00017eb0: 7465 726d 696e 616c 2073 7461 7465 2e20  terminal state. 
+00017ec0: 6e61 6d65 3d7b 6e61 6d65 7d2c 2073 7461  name={name}, sta
+00017ed0: 7465 3d7b 7374 6174 657d 220a 2020 2020  te={state}".    
+00017ee0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00017ef0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00017f00: 2062 6163 6b67 726f 756e 645f 7461 736b   background_task
+00017f10: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00017f20: 206d 6c72 756e 2e75 7469 6c73 2e68 656c   mlrun.utils.hel
+00017f30: 7065 7273 2e72 6574 7279 5f75 6e74 696c  pers.retry_until
+00017f40: 5f73 7563 6365 7373 6675 6c28 0a20 2020  _successful(.   
+00017f50: 2020 2020 2020 2020 2073 656c 662e 5f77           self._w
+00017f60: 6169 745f 666f 725f 6261 636b 6772 6f75  ait_for_backgrou
+00017f70: 6e64 5f74 6173 6b5f 7465 726d 696e 616c  nd_task_terminal
+00017f80: 5f73 7461 7465 5f72 6574 7279 5f69 6e74  _state_retry_int
+00017f90: 6572 7661 6c2c 0a20 2020 2020 2020 2020  erval,.         
+00017fa0: 2020 2036 3020 2a20 3630 2c0a 2020 2020     60 * 60,.    
+00017fb0: 2020 2020 2020 2020 6c6f 6767 6572 2c0a          logger,.
+00017fc0: 2020 2020 2020 2020 2020 2020 4661 6c73              Fals
+00017fd0: 652c 0a20 2020 2020 2020 2020 2020 205f  e,.            _
+00017fe0: 7665 7269 6679 5f62 6163 6b67 726f 756e  verify_backgroun
+00017ff0: 645f 7461 736b 5f69 6e5f 7465 726d 696e  d_task_in_termin
+00018000: 616c 5f73 7461 7465 2c0a 2020 2020 2020  al_state,.      
+00018010: 2020 290a 0a20 2020 2064 6566 205f 7761    )..    def _wa
+00018020: 6974 5f66 6f72 5f70 726f 6a65 6374 5f74  it_for_project_t
+00018030: 6f5f 6265 5f64 656c 6574 6564 2873 656c  o_be_deleted(sel
+00018040: 662c 2070 726f 6a65 6374 5f6e 616d 653a  f, project_name:
+00018050: 2073 7472 293a 0a20 2020 2020 2020 2064   str):.        d
+00018060: 6566 205f 7665 7269 6679 5f70 726f 6a65  ef _verify_proje
+00018070: 6374 5f64 656c 6574 6564 2829 3a0a 2020  ct_deleted():.  
+00018080: 2020 2020 2020 2020 2020 7072 6f6a 6563            projec
+00018090: 7473 203d 2073 656c 662e 6c69 7374 5f70  ts = self.list_p
+000180a0: 726f 6a65 6374 7328 0a20 2020 2020 2020  rojects(.       
+000180b0: 2020 2020 2020 2020 2066 6f72 6d61 745f           format_
+000180c0: 3d6d 6c72 756e 2e61 7069 2e73 6368 656d  =mlrun.api.schem
+000180d0: 6173 2e50 726f 6a65 6374 7346 6f72 6d61  as.ProjectsForma
+000180e0: 742e 6e61 6d65 5f6f 6e6c 790a 2020 2020  t.name_only.    
+000180f0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00018100: 2020 2020 2020 6966 2070 726f 6a65 6374        if project
+00018110: 5f6e 616d 6520 696e 2070 726f 6a65 6374  _name in project
+00018120: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
+00018130: 2020 2072 6169 7365 2045 7863 6570 7469     raise Excepti
+00018140: 6f6e 2822 5072 6f6a 6563 7420 7374 696c  on("Project stil
+00018150: 6c20 6578 6973 7473 2229 0a0a 2020 2020  l exists")..    
+00018160: 2020 2020 7265 7475 726e 206d 6c72 756e      return mlrun
+00018170: 2e75 7469 6c73 2e68 656c 7065 7273 2e72  .utils.helpers.r
+00018180: 6574 7279 5f75 6e74 696c 5f73 7563 6365  etry_until_succe
+00018190: 7373 6675 6c28 0a20 2020 2020 2020 2020  ssful(.         
+000181a0: 2020 2073 656c 662e 5f77 6169 745f 666f     self._wait_fo
+000181b0: 725f 7072 6f6a 6563 745f 6465 6c65 7469  r_project_deleti
+000181c0: 6f6e 5f69 6e74 6572 7661 6c2c 0a20 2020  on_interval,.   
+000181d0: 2020 2020 2020 2020 2031 3230 2c0a 2020           120,.  
+000181e0: 2020 2020 2020 2020 2020 6c6f 6767 6572            logger
+000181f0: 2c0a 2020 2020 2020 2020 2020 2020 4661  ,.            Fa
+00018200: 6c73 652c 0a20 2020 2020 2020 2020 2020  lse,.           
+00018210: 205f 7665 7269 6679 5f70 726f 6a65 6374   _verify_project
+00018220: 5f64 656c 6574 6564 2c0a 2020 2020 2020  _deleted,.      
+00018230: 2020 290a 0a20 2020 2064 6566 2063 7265    )..    def cre
+00018240: 6174 655f 7072 6f6a 6563 745f 7365 6372  ate_project_secr
+00018250: 6574 7328 0a20 2020 2020 2020 2073 656c  ets(.        sel
+00018260: 662c 0a20 2020 2020 2020 2070 726f 6a65  f,.        proje
+00018270: 6374 3a20 7374 722c 0a20 2020 2020 2020  ct: str,.       
+00018280: 2070 726f 7669 6465 723a 2055 6e69 6f6e   provider: Union
+00018290: 5b0a 2020 2020 2020 2020 2020 2020 7374  [.            st
+000182a0: 722c 2073 6368 656d 6173 2e53 6563 7265  r, schemas.Secre
+000182b0: 7450 726f 7669 6465 724e 616d 650a 2020  tProviderName.  
+000182c0: 2020 2020 2020 5d20 3d20 7363 6865 6d61        ] = schema
+000182d0: 732e 5365 6372 6574 5072 6f76 6964 6572  s.SecretProvider
+000182e0: 4e61 6d65 2e6b 7562 6572 6e65 7465 732c  Name.kubernetes,
+000182f0: 0a20 2020 2020 2020 2073 6563 7265 7473  .        secrets
+00018300: 3a20 6469 6374 203d 204e 6f6e 652c 0a20  : dict = None,. 
+00018310: 2020 2029 3a0a 2020 2020 2020 2020 2222     ):.        ""
+00018320: 2243 7265 6174 6520 7072 6f6a 6563 742d  "Create project-
+00018330: 636f 6e74 6578 7420 7365 6372 6574 7320  context secrets 
+00018340: 7573 696e 6720 6569 7468 6572 2060 6076  using either ``v
+00018350: 6175 6c74 6060 206f 7220 6060 6b75 6265  ault`` or ``kube
+00018360: 726e 6574 6573 6060 2070 726f 7669 6465  rnetes`` provide
+00018370: 722e 0a20 2020 2020 2020 2057 6865 6e20  r..        When 
+00018380: 7573 696e 6720 7769 7468 2056 6175 6c74  using with Vault
+00018390: 2c20 7468 6973 2077 696c 6c20 6372 6561  , this will crea
+000183a0: 7465 206e 6565 6465 6420 5661 756c 7420  te needed Vault 
+000183b0: 7374 7275 6374 7572 6573 2066 6f72 2073  structures for s
+000183c0: 746f 7269 6e67 2073 6563 7265 7473 2069  toring secrets i
+000183d0: 6e20 7072 6f6a 6563 742d 636f 6e74 6578  n project-contex
+000183e0: 742c 2061 6e64 0a20 2020 2020 2020 2073  t, and.        s
+000183f0: 746f 7265 2061 2073 6574 206f 6620 7365  tore a set of se
+00018400: 6372 6574 2076 616c 7565 732e 2054 6865  cret values. The
+00018410: 206d 6574 686f 6420 6765 6e65 7261 7465   method generate
+00018420: 7320 4b75 6265 726e 6574 6573 2073 6572  s Kubernetes ser
+00018430: 7669 6365 2d61 6363 6f75 6e74 2061 6e64  vice-account and
+00018440: 2074 6865 2056 6175 6c74 2061 7574 6865   the Vault authe
+00018450: 6e74 6963 6174 696f 6e0a 2020 2020 2020  ntication.      
+00018460: 2020 7374 7275 6374 7572 6573 2074 6861    structures tha
+00018470: 7420 6172 6520 7265 7175 6972 6564 2066  t are required f
+00018480: 6f72 2066 756e 6374 696f 6e20 506f 6473  or function Pods
+00018490: 2074 6f20 6175 7468 656e 7469 6361 7465   to authenticate
+000184a0: 2077 6974 6820 5661 756c 7420 616e 6420   with Vault and 
+000184b0: 6265 2061 626c 6520 746f 2065 7874 7261  be able to extra
+000184c0: 6374 2073 6563 7265 7420 7661 6c75 6573  ct secret values
+000184d0: 0a20 2020 2020 2020 2070 6173 7365 6420  .        passed 
+000184e0: 6173 2070 6172 7420 6f66 2074 6865 6972  as part of their
+000184f0: 2063 6f6e 7465 7874 2e0a 0a20 2020 2020   context...     
+00018500: 2020 204e 6f74 653a 0a20 2020 2020 2020     Note:.       
+00018510: 2020 2020 2020 2020 2054 6869 7320 6d65           This me
+00018520: 7468 6f64 2075 7365 6420 7769 7468 2056  thod used with V
+00018530: 6175 6c74 2069 7320 6375 7272 656e 746c  ault is currentl
+00018540: 7920 696e 2074 6563 686e 6963 616c 2070  y in technical p
+00018550: 7265 7669 6577 2c20 616e 6420 7265 7175  review, and requ
+00018560: 6972 6573 2061 2048 6173 6869 436f 7270  ires a HashiCorp
+00018570: 2056 6175 6c74 0a20 2020 2020 2020 2020   Vault.         
+00018580: 2020 2020 2020 2069 6e66 7261 7374 7275         infrastru
+00018590: 6374 7572 6520 7072 6f70 6572 6c79 2073  cture properly s
+000185a0: 6574 2075 7020 616e 6420 636f 6e6e 6563  et up and connec
+000185b0: 7465 6420 746f 2074 6865 204d 4c52 756e  ted to the MLRun
+000185c0: 2041 5049 2073 6572 7665 722e 0a0a 2020   API server...  
+000185d0: 2020 2020 2020 5768 656e 2075 7365 6420        When used 
+000185e0: 7769 7468 204b 7562 6572 6e65 7465 732c  with Kubernetes,
+000185f0: 2074 6869 7320 7769 6c6c 206d 616b 6520   this will make 
+00018600: 7375 7265 2074 6861 7420 7468 6520 7072  sure that the pr
+00018610: 6f6a 6563 742d 7370 6563 6966 6963 206b  oject-specific k
+00018620: 3873 2073 6563 7265 7420 6973 2063 7265  8s secret is cre
+00018630: 6174 6564 2c20 616e 6420 7769 6c6c 0a20  ated, and will. 
+00018640: 2020 2020 2020 2070 6f70 756c 6174 6520         populate 
+00018650: 6974 2077 6974 6820 7468 6520 7365 6372  it with the secr
+00018660: 6574 7320 7072 6f76 6964 6564 2c20 7265  ets provided, re
+00018670: 706c 6163 696e 6720 7468 6569 7220 7661  placing their va
+00018680: 6c75 6573 2069 6620 7468 6579 2065 7869  lues if they exi
+00018690: 7374 2e0a 0a20 2020 2020 2020 203a 7061  st...        :pa
+000186a0: 7261 6d20 7072 6f6a 6563 743a 2054 6865  ram project: The
+000186b0: 2070 726f 6a65 6374 2063 6f6e 7465 7874   project context
+000186c0: 2066 6f72 2077 6869 6368 2074 6f20 6765   for which to ge
+000186d0: 6e65 7261 7465 2074 6865 2069 6e66 7261  nerate the infra
+000186e0: 2061 6e64 2073 746f 7265 2073 6563 7265   and store secre
+000186f0: 7473 2e0a 2020 2020 2020 2020 3a70 6172  ts..        :par
+00018700: 616d 2070 726f 7669 6465 723a 2054 6865  am provider: The
+00018710: 206e 616d 6520 6f66 2074 6865 2073 6563   name of the sec
+00018720: 7265 7473 2d70 726f 7669 6465 7220 746f  rets-provider to
+00018730: 2077 6f72 6b20 7769 7468 2e20 4163 6365   work with. Acce
+00018740: 7074 7320 610a 2020 2020 2020 2020 2020  pts a.          
+00018750: 2020 3a70 793a 636c 6173 733a 607e 6d6c    :py:class:`~ml
+00018760: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
+00018770: 7365 6372 6574 2e53 6563 7265 7450 726f  secret.SecretPro
+00018780: 7669 6465 724e 616d 6560 2065 6e75 6d2e  viderName` enum.
+00018790: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+000187a0: 7365 6372 6574 733a 2041 2073 6574 206f  secrets: A set o
+000187b0: 6620 7365 6372 6574 2076 616c 7565 7320  f secret values 
+000187c0: 746f 2073 746f 7265 2e0a 2020 2020 2020  to store..      
+000187d0: 2020 2020 2020 4578 616d 706c 653a 3a0a        Example::.
+000187e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000187f0: 2073 6563 7265 7473 203d 207b 2770 6173   secrets = {'pas
+00018800: 7377 6f72 6427 3a20 276d 7950 6173 7377  sword': 'myPassw
+00018810: 3072 6427 2c20 2761 7773 5f6b 6579 273a  0rd', 'aws_key':
+00018820: 2027 3131 3132 3232 3333 3327 7d0a 2020   '111222333'}.  
+00018830: 2020 2020 2020 2020 2020 2020 2020 6462                db
+00018840: 2e63 7265 6174 655f 7072 6f6a 6563 745f  .create_project_
+00018850: 7365 6372 6574 7328 0a20 2020 2020 2020  secrets(.       
+00018860: 2020 2020 2020 2020 2020 2020 2022 7072               "pr
+00018870: 6f6a 6563 7431 222c 0a20 2020 2020 2020  oject1",.       
+00018880: 2020 2020 2020 2020 2020 2020 2070 726f               pro
+00018890: 7669 6465 723d 6d6c 7275 6e2e 6170 692e  vider=mlrun.api.
+000188a0: 7363 6865 6d61 732e 5365 6372 6574 5072  schemas.SecretPr
+000188b0: 6f76 6964 6572 4e61 6d65 2e6b 7562 6572  oviderName.kuber
+000188c0: 6e65 7465 732c 0a20 2020 2020 2020 2020  netes,.         
+000188d0: 2020 2020 2020 2020 2020 2073 6563 7265             secre
+000188e0: 7473 3d73 6563 7265 7473 0a20 2020 2020  ts=secrets.     
+000188f0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00018900: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
+00018910: 2070 6174 6820 3d20 6622 7072 6f6a 6563   path = f"projec
+00018920: 7473 2f7b 7072 6f6a 6563 747d 2f73 6563  ts/{project}/sec
+00018930: 7265 7473 220a 2020 2020 2020 2020 7365  rets".        se
+00018940: 6372 6574 735f 696e 7075 7420 3d20 7363  crets_input = sc
+00018950: 6865 6d61 732e 5365 6372 6574 7344 6174  hemas.SecretsDat
+00018960: 6128 7365 6372 6574 733d 7365 6372 6574  a(secrets=secret
+00018970: 732c 2070 726f 7669 6465 723d 7072 6f76  s, provider=prov
+00018980: 6964 6572 290a 2020 2020 2020 2020 626f  ider).        bo
+00018990: 6479 203d 2073 6563 7265 7473 5f69 6e70  dy = secrets_inp
+000189a0: 7574 2e64 6963 7428 290a 2020 2020 2020  ut.dict().      
+000189b0: 2020 6572 726f 725f 6d65 7373 6167 6520    error_message 
+000189c0: 3d20 6622 4661 696c 6564 2063 7265 6174  = f"Failed creat
+000189d0: 696e 6720 7365 6372 6574 2070 726f 7669  ing secret provi
+000189e0: 6465 7220 7b70 726f 6a65 6374 7d2f 7b70  der {project}/{p
+000189f0: 726f 7669 6465 727d 220a 2020 2020 2020  rovider}".      
+00018a00: 2020 7365 6c66 2e61 7069 5f63 616c 6c28    self.api_call(
+00018a10: 0a20 2020 2020 2020 2020 2020 2022 504f  .            "PO
+00018a20: 5354 222c 0a20 2020 2020 2020 2020 2020  ST",.           
+00018a30: 2070 6174 682c 0a20 2020 2020 2020 2020   path,.         
+00018a40: 2020 2065 7272 6f72 5f6d 6573 7361 6765     error_message
+00018a50: 2c0a 2020 2020 2020 2020 2020 2020 626f  ,.            bo
+00018a60: 6479 3d64 6963 745f 746f 5f6a 736f 6e28  dy=dict_to_json(
+00018a70: 626f 6479 292c 0a20 2020 2020 2020 2029  body),.        )
+00018a80: 0a0a 2020 2020 6465 6620 6c69 7374 5f70  ..    def list_p
+00018a90: 726f 6a65 6374 5f73 6563 7265 7473 280a  roject_secrets(.
+00018aa0: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00018ab0: 2020 2020 2020 7072 6f6a 6563 743a 2073        project: s
+00018ac0: 7472 2c0a 2020 2020 2020 2020 746f 6b65  tr,.        toke
+00018ad0: 6e3a 2073 7472 203d 204e 6f6e 652c 0a20  n: str = None,. 
+00018ae0: 2020 2020 2020 2070 726f 7669 6465 723a         provider:
+00018af0: 2055 6e69 6f6e 5b0a 2020 2020 2020 2020   Union[.        
+00018b00: 2020 2020 7374 722c 2073 6368 656d 6173      str, schemas
+00018b10: 2e53 6563 7265 7450 726f 7669 6465 724e  .SecretProviderN
+00018b20: 616d 650a 2020 2020 2020 2020 5d20 3d20  ame.        ] = 
+00018b30: 7363 6865 6d61 732e 5365 6372 6574 5072  schemas.SecretPr
+00018b40: 6f76 6964 6572 4e61 6d65 2e6b 7562 6572  oviderName.kuber
+00018b50: 6e65 7465 732c 0a20 2020 2020 2020 2073  netes,.        s
+00018b60: 6563 7265 7473 3a20 4c69 7374 5b73 7472  ecrets: List[str
+00018b70: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2920  ] = None,.    ) 
+00018b80: 2d3e 2073 6368 656d 6173 2e53 6563 7265  -> schemas.Secre
+00018b90: 7473 4461 7461 3a0a 2020 2020 2020 2020  tsData:.        
+00018ba0: 2222 2252 6574 7269 6576 6520 7072 6f6a  """Retrieve proj
+00018bb0: 6563 742d 636f 6e74 6578 7420 7365 6372  ect-context secr
+00018bc0: 6574 7320 6672 6f6d 2056 6175 6c74 2e0a  ets from Vault..
+00018bd0: 0a20 2020 2020 2020 204e 6f74 653a 0a20  .        Note:. 
+00018be0: 2020 2020 2020 2020 2020 2020 2020 2054                 T
+00018bf0: 6869 7320 6d65 7468 6f64 2066 6f72 2056  his method for V
+00018c00: 6175 6c74 2066 756e 6374 696f 6e61 6c69  ault functionali
+00018c10: 7479 2069 7320 6375 7272 656e 746c 7920  ty is currently 
+00018c20: 696e 2074 6563 686e 6963 616c 2070 7265  in technical pre
+00018c30: 7669 6577 2c20 616e 6420 7265 7175 6972  view, and requir
+00018c40: 6573 2061 2048 6173 6869 436f 7270 2056  es a HashiCorp V
+00018c50: 6175 6c74 0a20 2020 2020 2020 2020 2020  ault.           
+00018c60: 2020 2020 2069 6e66 7261 7374 7275 6374       infrastruct
+00018c70: 7572 6520 7072 6f70 6572 6c79 2073 6574  ure properly set
+00018c80: 2075 7020 616e 6420 636f 6e6e 6563 7465   up and connecte
+00018c90: 6420 746f 2074 6865 204d 4c52 756e 2041  d to the MLRun A
+00018ca0: 5049 2073 6572 7665 722e 0a0a 2020 2020  PI server...    
+00018cb0: 2020 2020 3a70 6172 616d 2070 726f 6a65      :param proje
+00018cc0: 6374 3a20 5468 6520 7072 6f6a 6563 7420  ct: The project 
+00018cd0: 6e61 6d65 2e0a 2020 2020 2020 2020 3a70  name..        :p
+00018ce0: 6172 616d 2074 6f6b 656e 3a20 5661 756c  aram token: Vaul
+00018cf0: 7420 746f 6b65 6e20 746f 2075 7365 2066  t token to use f
+00018d00: 6f72 2072 6574 7269 6576 696e 6720 7365  or retrieving se
+00018d10: 6372 6574 732e 0a20 2020 2020 2020 2020  crets..         
+00018d20: 2020 204d 7573 7420 6265 2061 2076 616c     Must be a val
+00018d30: 6964 2056 6175 6c74 2074 6f6b 656e 2c20  id Vault token, 
+00018d40: 7769 7468 2070 6572 6d69 7373 696f 6e73  with permissions
+00018d50: 2074 6f20 7265 7472 6965 7665 2073 6563   to retrieve sec
+00018d60: 7265 7473 206f 6620 7468 6520 7072 6f6a  rets of the proj
+00018d70: 6563 7420 696e 2071 7565 7374 696f 6e2e  ect in question.
+00018d80: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+00018d90: 7072 6f76 6964 6572 3a20 5468 6520 6e61  provider: The na
+00018da0: 6d65 206f 6620 7468 6520 7365 6372 6574  me of the secret
+00018db0: 732d 7072 6f76 6964 6572 2074 6f20 776f  s-provider to wo
+00018dc0: 726b 2077 6974 682e 2043 7572 7265 6e74  rk with. Current
+00018dd0: 6c79 206f 6e6c 7920 6060 7661 756c 7460  ly only ``vault`
+00018de0: 6020 6973 2061 6363 6570 7465 642e 0a20  ` is accepted.. 
+00018df0: 2020 2020 2020 203a 7061 7261 6d20 7365         :param se
+00018e00: 6372 6574 733a 2041 206c 6973 7420 6f66  crets: A list of
+00018e10: 2073 6563 7265 7420 6e61 6d65 7320 746f   secret names to
+00018e20: 2072 6574 7269 6576 652e 2041 6e20 656d   retrieve. An em
+00018e30: 7074 7920 6c69 7374 2060 605b 5d60 6020  pty list ``[]`` 
+00018e40: 7769 6c6c 2072 6574 7269 6576 6520 616c  will retrieve al
+00018e50: 6c20 7365 6372 6574 7320 6173 7369 676e  l secrets assign
+00018e60: 6564 0a20 2020 2020 2020 2020 2020 2074  ed.            t
+00018e70: 6f20 7468 6973 2073 7065 6369 6669 6320  o this specific 
+00018e80: 7072 6f6a 6563 742e 2060 606b 7562 6572  project. ``kuber
+00018e90: 6e65 7465 7360 6020 7072 6f76 6964 6572  netes`` provider
+00018ea0: 206f 6e6c 7920 7375 7070 6f72 7473 2061   only supports a
+00018eb0: 6e20 656d 7074 7920 6c69 7374 2e0a 2020  n empty list..  
+00018ec0: 2020 2020 2020 2222 220a 0a20 2020 2020        """..     
+00018ed0: 2020 2069 6620 7072 6f76 6964 6572 203d     if provider =
+00018ee0: 3d20 7363 6865 6d61 732e 5365 6372 6574  = schemas.Secret
+00018ef0: 5072 6f76 6964 6572 4e61 6d65 2e76 6175  ProviderName.vau
+00018f00: 6c74 2e76 616c 7565 2061 6e64 206e 6f74  lt.value and not
+00018f10: 2074 6f6b 656e 3a0a 2020 2020 2020 2020   token:.        
+00018f20: 2020 2020 7261 6973 6520 4d4c 5275 6e49      raise MLRunI
+00018f30: 6e76 616c 6964 4172 6775 6d65 6e74 4572  nvalidArgumentEr
+00018f40: 726f 7228 0a20 2020 2020 2020 2020 2020  ror(.           
+00018f50: 2020 2020 2022 4120 7661 756c 7420 746f       "A vault to
+00018f60: 6b65 6e20 6d75 7374 2062 6520 7072 6f76  ken must be prov
+00018f70: 6964 6564 2077 6865 6e20 6163 6365 7373  ided when access
+00018f80: 696e 6720 7661 756c 7420 7365 6372 6574  ing vault secret
+00018f90: 7322 0a20 2020 2020 2020 2020 2020 2029  s".            )
+00018fa0: 0a0a 2020 2020 2020 2020 7061 7468 203d  ..        path =
+00018fb0: 2066 2270 726f 6a65 6374 732f 7b70 726f   f"projects/{pro
+00018fc0: 6a65 6374 7d2f 7365 6372 6574 7322 0a20  ject}/secrets". 
+00018fd0: 2020 2020 2020 2070 6172 616d 7320 3d20         params = 
+00018fe0: 7b22 7072 6f76 6964 6572 223a 2070 726f  {"provider": pro
+00018ff0: 7669 6465 722c 2022 7365 6372 6574 223a  vider, "secret":
+00019000: 2073 6563 7265 7473 7d0a 2020 2020 2020   secrets}.      
+00019010: 2020 6865 6164 6572 7320 3d20 7b73 6368    headers = {sch
+00019020: 656d 6173 2e48 6561 6465 724e 616d 6573  emas.HeaderNames
+00019030: 2e73 6563 7265 745f 7374 6f72 655f 746f  .secret_store_to
+00019040: 6b65 6e3a 2074 6f6b 656e 7d0a 2020 2020  ken: token}.    
+00019050: 2020 2020 6572 726f 725f 6d65 7373 6167      error_messag
+00019060: 6520 3d20 6622 4661 696c 6564 2072 6574  e = f"Failed ret
+00019070: 7269 6576 696e 6720 7365 6372 6574 7320  rieving secrets 
+00019080: 7b70 726f 6a65 6374 7d2f 7b70 726f 7669  {project}/{provi
+00019090: 6465 727d 220a 2020 2020 2020 2020 7265  der}".        re
+000190a0: 7375 6c74 203d 2073 656c 662e 6170 695f  sult = self.api_
+000190b0: 6361 6c6c 280a 2020 2020 2020 2020 2020  call(.          
+000190c0: 2020 2247 4554 222c 0a20 2020 2020 2020    "GET",.       
+000190d0: 2020 2020 2070 6174 682c 0a20 2020 2020       path,.     
+000190e0: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+000190f0: 7361 6765 2c0a 2020 2020 2020 2020 2020  sage,.          
+00019100: 2020 7061 7261 6d73 3d70 6172 616d 732c    params=params,
+00019110: 0a20 2020 2020 2020 2020 2020 2068 6561  .            hea
+00019120: 6465 7273 3d68 6561 6465 7273 2c0a 2020  ders=headers,.  
+00019130: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00019140: 7265 7475 726e 2073 6368 656d 6173 2e53  return schemas.S
+00019150: 6563 7265 7473 4461 7461 282a 2a72 6573  ecretsData(**res
+00019160: 756c 742e 6a73 6f6e 2829 290a 0a20 2020  ult.json())..   
+00019170: 2064 6566 206c 6973 745f 7072 6f6a 6563   def list_projec
+00019180: 745f 7365 6372 6574 5f6b 6579 7328 0a20  t_secret_keys(. 
+00019190: 2020 2020 2020 2073 656c 662c 0a20 2020         self,.   
+000191a0: 2020 2020 2070 726f 6a65 6374 3a20 7374       project: st
+000191b0: 722c 0a20 2020 2020 2020 2070 726f 7669  r,.        provi
+000191c0: 6465 723a 2055 6e69 6f6e 5b0a 2020 2020  der: Union[.    
+000191d0: 2020 2020 2020 2020 7374 722c 2073 6368          str, sch
+000191e0: 656d 6173 2e53 6563 7265 7450 726f 7669  emas.SecretProvi
+000191f0: 6465 724e 616d 650a 2020 2020 2020 2020  derName.        
+00019200: 5d20 3d20 7363 6865 6d61 732e 5365 6372  ] = schemas.Secr
+00019210: 6574 5072 6f76 6964 6572 4e61 6d65 2e6b  etProviderName.k
+00019220: 7562 6572 6e65 7465 732c 0a20 2020 2020  ubernetes,.     
+00019230: 2020 2074 6f6b 656e 3a20 7374 7220 3d20     token: str = 
+00019240: 4e6f 6e65 2c0a 2020 2020 2920 2d3e 2073  None,.    ) -> s
+00019250: 6368 656d 6173 2e53 6563 7265 744b 6579  chemas.SecretKey
+00019260: 7344 6174 613a 0a20 2020 2020 2020 2022  sData:.        "
+00019270: 2222 5265 7472 6965 7665 2070 726f 6a65  ""Retrieve proje
+00019280: 6374 2d63 6f6e 7465 7874 2073 6563 7265  ct-context secre
+00019290: 7420 6b65 7973 2066 726f 6d20 5661 756c  t keys from Vaul
+000192a0: 7420 6f72 204b 7562 6572 6e65 7465 732e  t or Kubernetes.
+000192b0: 0a0a 2020 2020 2020 2020 4e6f 7465 3a0a  ..        Note:.
+000192c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000192d0: 5468 6973 206d 6574 686f 6420 666f 7220  This method for 
+000192e0: 5661 756c 7420 6675 6e63 7469 6f6e 616c  Vault functional
+000192f0: 6974 7920 6973 2063 7572 7265 6e74 6c79  ity is currently
+00019300: 2069 6e20 7465 6368 6e69 6361 6c20 7072   in technical pr
+00019310: 6576 6965 772c 2061 6e64 2072 6571 7569  eview, and requi
+00019320: 7265 7320 6120 4861 7368 6943 6f72 7020  res a HashiCorp 
+00019330: 5661 756c 740a 2020 2020 2020 2020 2020  Vault.          
+00019340: 2020 2020 2020 696e 6672 6173 7472 7563        infrastruc
+00019350: 7475 7265 2070 726f 7065 726c 7920 7365  ture properly se
+00019360: 7420 7570 2061 6e64 2063 6f6e 6e65 6374  t up and connect
+00019370: 6564 2074 6f20 7468 6520 4d4c 5275 6e20  ed to the MLRun 
+00019380: 4150 4920 7365 7276 6572 2e0a 0a20 2020  API server...   
+00019390: 2020 2020 203a 7061 7261 6d20 7072 6f6a       :param proj
+000193a0: 6563 743a 2054 6865 2070 726f 6a65 6374  ect: The project
+000193b0: 206e 616d 652e 0a20 2020 2020 2020 203a   name..        :
+000193c0: 7061 7261 6d20 7072 6f76 6964 6572 3a20  param provider: 
+000193d0: 5468 6520 6e61 6d65 206f 6620 7468 6520  The name of the 
+000193e0: 7365 6372 6574 732d 7072 6f76 6964 6572  secrets-provider
+000193f0: 2074 6f20 776f 726b 2077 6974 682e 2041   to work with. A
+00019400: 6363 6570 7473 2061 0a20 2020 2020 2020  ccepts a.       
+00019410: 2020 2020 203a 7079 3a63 6c61 7373 3a60       :py:class:`
+00019420: 7e6d 6c72 756e 2e61 7069 2e73 6368 656d  ~mlrun.api.schem
+00019430: 6173 2e73 6563 7265 742e 5365 6372 6574  as.secret.Secret
+00019440: 5072 6f76 6964 6572 4e61 6d65 6020 656e  ProviderName` en
+00019450: 756d 2e0a 2020 2020 2020 2020 3a70 6172  um..        :par
+00019460: 616d 2074 6f6b 656e 3a20 5661 756c 7420  am token: Vault 
+00019470: 746f 6b65 6e20 746f 2075 7365 2066 6f72  token to use for
+00019480: 2072 6574 7269 6576 696e 6720 7365 6372   retrieving secr
+00019490: 6574 732e 204f 6e6c 7920 696e 2075 7365  ets. Only in use
+000194a0: 2069 6620 6060 7072 6f76 6964 6572 6060   if ``provider``
+000194b0: 2069 7320 6060 7661 756c 7460 602e 0a20   is ``vault``.. 
+000194c0: 2020 2020 2020 2020 2020 204d 7573 7420             Must 
+000194d0: 6265 2061 2076 616c 6964 2056 6175 6c74  be a valid Vault
+000194e0: 2074 6f6b 656e 2c20 7769 7468 2070 6572   token, with per
+000194f0: 6d69 7373 696f 6e73 2074 6f20 7265 7472  missions to retr
+00019500: 6965 7665 2073 6563 7265 7473 206f 6620  ieve secrets of 
+00019510: 7468 6520 7072 6f6a 6563 7420 696e 2071  the project in q
+00019520: 7565 7374 696f 6e2e 0a20 2020 2020 2020  uestion..       
+00019530: 2022 2222 0a0a 2020 2020 2020 2020 6966   """..        if
+00019540: 2070 726f 7669 6465 7220 3d3d 2073 6368   provider == sch
+00019550: 656d 6173 2e53 6563 7265 7450 726f 7669  emas.SecretProvi
+00019560: 6465 724e 616d 652e 7661 756c 742e 7661  derName.vault.va
+00019570: 6c75 6520 616e 6420 6e6f 7420 746f 6b65  lue and not toke
+00019580: 6e3a 0a20 2020 2020 2020 2020 2020 2072  n:.            r
+00019590: 6169 7365 204d 4c52 756e 496e 7661 6c69  aise MLRunInvali
+000195a0: 6441 7267 756d 656e 7445 7272 6f72 280a  dArgumentError(.
+000195b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000195c0: 2241 2076 6175 6c74 2074 6f6b 656e 206d  "A vault token m
+000195d0: 7573 7420 6265 2070 726f 7669 6465 6420  ust be provided 
+000195e0: 7768 656e 2061 6363 6573 7369 6e67 2076  when accessing v
+000195f0: 6175 6c74 2073 6563 7265 7473 220a 2020  ault secrets".  
+00019600: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+00019610: 2020 2020 2070 6174 6820 3d20 6622 7072       path = f"pr
+00019620: 6f6a 6563 7473 2f7b 7072 6f6a 6563 747d  ojects/{project}
+00019630: 2f73 6563 7265 742d 6b65 7973 220a 2020  /secret-keys".  
+00019640: 2020 2020 2020 7061 7261 6d73 203d 207b        params = {
+00019650: 2270 726f 7669 6465 7222 3a20 7072 6f76  "provider": prov
+00019660: 6964 6572 7d0a 2020 2020 2020 2020 6865  ider}.        he
+00019670: 6164 6572 7320 3d20 280a 2020 2020 2020  aders = (.      
+00019680: 2020 2020 2020 7b73 6368 656d 6173 2e48        {schemas.H
+00019690: 6561 6465 724e 616d 6573 2e73 6563 7265  eaderNames.secre
+000196a0: 745f 7374 6f72 655f 746f 6b65 6e3a 2074  t_store_token: t
+000196b0: 6f6b 656e 7d0a 2020 2020 2020 2020 2020  oken}.          
+000196c0: 2020 6966 2070 726f 7669 6465 7220 3d3d    if provider ==
+000196d0: 2073 6368 656d 6173 2e53 6563 7265 7450   schemas.SecretP
+000196e0: 726f 7669 6465 724e 616d 652e 7661 756c  roviderName.vaul
+000196f0: 742e 7661 6c75 650a 2020 2020 2020 2020  t.value.        
+00019700: 2020 2020 656c 7365 204e 6f6e 650a 2020      else None.  
+00019710: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00019720: 6572 726f 725f 6d65 7373 6167 6520 3d20  error_message = 
+00019730: 6622 4661 696c 6564 2072 6574 7269 6576  f"Failed retriev
+00019740: 696e 6720 7365 6372 6574 206b 6579 7320  ing secret keys 
+00019750: 7b70 726f 6a65 6374 7d2f 7b70 726f 7669  {project}/{provi
+00019760: 6465 727d 220a 2020 2020 2020 2020 7265  der}".        re
+00019770: 7375 6c74 203d 2073 656c 662e 6170 695f  sult = self.api_
+00019780: 6361 6c6c 280a 2020 2020 2020 2020 2020  call(.          
+00019790: 2020 2247 4554 222c 0a20 2020 2020 2020    "GET",.       
+000197a0: 2020 2020 2070 6174 682c 0a20 2020 2020       path,.     
+000197b0: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+000197c0: 7361 6765 2c0a 2020 2020 2020 2020 2020  sage,.          
+000197d0: 2020 7061 7261 6d73 3d70 6172 616d 732c    params=params,
+000197e0: 0a20 2020 2020 2020 2020 2020 2068 6561  .            hea
+000197f0: 6465 7273 3d68 6561 6465 7273 2c0a 2020  ders=headers,.  
+00019800: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00019810: 7265 7475 726e 2073 6368 656d 6173 2e53  return schemas.S
+00019820: 6563 7265 744b 6579 7344 6174 6128 2a2a  ecretKeysData(**
+00019830: 7265 7375 6c74 2e6a 736f 6e28 2929 0a0a  result.json())..
+00019840: 2020 2020 6465 6620 6465 6c65 7465 5f70      def delete_p
+00019850: 726f 6a65 6374 5f73 6563 7265 7473 280a  roject_secrets(.
+00019860: 2020 2020 2020 2020 7365 6c66 2c0a 2020          self,.  
+00019870: 2020 2020 2020 7072 6f6a 6563 743a 2073        project: s
+00019880: 7472 2c0a 2020 2020 2020 2020 7072 6f76  tr,.        prov
+00019890: 6964 6572 3a20 556e 696f 6e5b 0a20 2020  ider: Union[.   
+000198a0: 2020 2020 2020 2020 2073 7472 2c20 7363           str, sc
+000198b0: 6865 6d61 732e 5365 6372 6574 5072 6f76  hemas.SecretProv
+000198c0: 6964 6572 4e61 6d65 0a20 2020 2020 2020  iderName.       
+000198d0: 205d 203d 2073 6368 656d 6173 2e53 6563   ] = schemas.Sec
+000198e0: 7265 7450 726f 7669 6465 724e 616d 652e  retProviderName.
+000198f0: 6b75 6265 726e 6574 6573 2c0a 2020 2020  kubernetes,.    
+00019900: 2020 2020 7365 6372 6574 733a 204c 6973      secrets: Lis
+00019910: 745b 7374 725d 203d 204e 6f6e 652c 0a20  t[str] = None,. 
+00019920: 2020 2029 3a0a 2020 2020 2020 2020 2222     ):.        ""
+00019930: 2244 656c 6574 6520 7072 6f6a 6563 742d  "Delete project-
+00019940: 636f 6e74 6578 7420 7365 6372 6574 7320  context secrets 
+00019950: 6672 6f6d 204b 7562 6572 6e65 7465 732e  from Kubernetes.
+00019960: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+00019970: 2070 726f 6a65 6374 3a20 5468 6520 7072   project: The pr
+00019980: 6f6a 6563 7420 6e61 6d65 2e0a 2020 2020  oject name..    
+00019990: 2020 2020 3a70 6172 616d 2070 726f 7669      :param provi
+000199a0: 6465 723a 2054 6865 206e 616d 6520 6f66  der: The name of
+000199b0: 2074 6865 2073 6563 7265 7473 2d70 726f   the secrets-pro
+000199c0: 7669 6465 7220 746f 2077 6f72 6b20 7769  vider to work wi
+000199d0: 7468 2e20 4375 7272 656e 746c 7920 6f6e  th. Currently on
+000199e0: 6c79 2060 606b 7562 6572 6e65 7465 7360  ly ``kubernetes`
+000199f0: 6020 6973 2073 7570 706f 7274 6564 2e0a  ` is supported..
+00019a00: 2020 2020 2020 2020 3a70 6172 616d 2073          :param s
+00019a10: 6563 7265 7473 3a20 4120 6c69 7374 206f  ecrets: A list o
+00019a20: 6620 7365 6372 6574 206e 616d 6573 2074  f secret names t
+00019a30: 6f20 6465 6c65 7465 2e20 416e 2065 6d70  o delete. An emp
+00019a40: 7479 206c 6973 7420 7769 6c6c 2064 656c  ty list will del
+00019a50: 6574 6520 616c 6c20 7365 6372 6574 7320  ete all secrets 
+00019a60: 6173 7369 676e 6564 0a20 2020 2020 2020  assigned.       
+00019a70: 2020 2020 2074 6f20 7468 6973 2073 7065       to this spe
+00019a80: 6369 6669 6320 7072 6f6a 6563 742e 0a20  cific project.. 
+00019a90: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
+00019aa0: 2020 2020 7061 7468 203d 2066 2270 726f      path = f"pro
+00019ab0: 6a65 6374 732f 7b70 726f 6a65 6374 7d2f  jects/{project}/
+00019ac0: 7365 6372 6574 7322 0a20 2020 2020 2020  secrets".       
+00019ad0: 2070 6172 616d 7320 3d20 7b22 7072 6f76   params = {"prov
+00019ae0: 6964 6572 223a 2070 726f 7669 6465 722c  ider": provider,
+00019af0: 2022 7365 6372 6574 223a 2073 6563 7265   "secret": secre
+00019b00: 7473 7d0a 2020 2020 2020 2020 6572 726f  ts}.        erro
+00019b10: 725f 6d65 7373 6167 6520 3d20 6622 4661  r_message = f"Fa
+00019b20: 696c 6564 2064 656c 6574 696e 6720 7365  iled deleting se
+00019b30: 6372 6574 7320 7b70 726f 6a65 6374 7d2f  crets {project}/
+00019b40: 7b70 726f 7669 6465 727d 220a 2020 2020  {provider}".    
+00019b50: 2020 2020 7365 6c66 2e61 7069 5f63 616c      self.api_cal
+00019b60: 6c28 0a20 2020 2020 2020 2020 2020 2022  l(.            "
+00019b70: 4445 4c45 5445 222c 0a20 2020 2020 2020  DELETE",.       
+00019b80: 2020 2020 2070 6174 682c 0a20 2020 2020       path,.     
+00019b90: 2020 2020 2020 2065 7272 6f72 5f6d 6573         error_mes
+00019ba0: 7361 6765 2c0a 2020 2020 2020 2020 2020  sage,.          
+00019bb0: 2020 7061 7261 6d73 3d70 6172 616d 732c    params=params,
+00019bc0: 0a20 2020 2020 2020 2029 0a0a 2020 2020  .        )..    
+00019bd0: 6465 6620 6372 6561 7465 5f75 7365 725f  def create_user_
+00019be0: 7365 6372 6574 7328 0a20 2020 2020 2020  secrets(.       
+00019bf0: 2073 656c 662c 0a20 2020 2020 2020 2075   self,.        u
+00019c00: 7365 723a 2073 7472 2c0a 2020 2020 2020  ser: str,.      
+00019c10: 2020 7072 6f76 6964 6572 3a20 556e 696f    provider: Unio
+00019c20: 6e5b 0a20 2020 2020 2020 2020 2020 2073  n[.            s
+00019c30: 7472 2c20 7363 6865 6d61 732e 5365 6372  tr, schemas.Secr
+00019c40: 6574 5072 6f76 6964 6572 4e61 6d65 0a20  etProviderName. 
+00019c50: 2020 2020 2020 205d 203d 2073 6368 656d         ] = schem
+00019c60: 6173 2e53 6563 7265 7450 726f 7669 6465  as.SecretProvide
+00019c70: 724e 616d 652e 7661 756c 742c 0a20 2020  rName.vault,.   
+00019c80: 2020 2020 2073 6563 7265 7473 3a20 6469       secrets: di
+00019c90: 6374 203d 204e 6f6e 652c 0a20 2020 2029  ct = None,.    )
+00019ca0: 3a0a 2020 2020 2020 2020 2222 2243 7265  :.        """Cre
+00019cb0: 6174 6520 7573 6572 2d63 6f6e 7465 7874  ate user-context
+00019cc0: 2073 6563 7265 7420 696e 2056 6175 6c74   secret in Vault
+00019cd0: 2e20 506c 6561 7365 2072 6566 6572 2074  . Please refer t
+00019ce0: 6f20 3a70 793a 6675 6e63 3a60 6372 6561  o :py:func:`crea
+00019cf0: 7465 5f70 726f 6a65 6374 5f73 6563 7265  te_project_secre
+00019d00: 7473 6020 666f 7220 6d6f 7265 2064 6574  ts` for more det
+00019d10: 6169 6c73 0a20 2020 2020 2020 2061 6e64  ails.        and
+00019d20: 2073 7461 7475 7320 6f66 2074 6869 7320   status of this 
+00019d30: 6675 6e63 7469 6f6e 616c 6974 792e 0a0a  functionality...
+00019d40: 2020 2020 2020 2020 4e6f 7465 3a0a 2020          Note:.  
+00019d50: 2020 2020 2020 2020 2020 2020 2020 5468                Th
+00019d60: 6973 206d 6574 686f 6420 6973 2063 7572  is method is cur
+00019d70: 7265 6e74 6c79 2069 6e20 7465 6368 6e69  rently in techni
+00019d80: 6361 6c20 7072 6576 6965 772c 2061 6e64  cal preview, and
+00019d90: 2072 6571 7569 7265 7320 6120 4861 7368   requires a Hash
+00019da0: 6943 6f72 7020 5661 756c 7420 696e 6672  iCorp Vault infr
+00019db0: 6173 7472 7563 7475 7265 0a20 2020 2020  astructure.     
+00019dc0: 2020 2020 2020 2020 2020 2070 726f 7065             prope
+00019dd0: 726c 7920 7365 7420 7570 2061 6e64 2063  rly set up and c
+00019de0: 6f6e 6e65 6374 6564 2074 6f20 7468 6520  onnected to the 
+00019df0: 4d4c 5275 6e20 4150 4920 7365 7276 6572  MLRun API server
+00019e00: 2e0a 0a20 2020 2020 2020 203a 7061 7261  ...        :para
+00019e10: 6d20 7573 6572 3a20 5468 6520 7573 6572  m user: The user
+00019e20: 2063 6f6e 7465 7874 2066 6f72 2077 6869   context for whi
+00019e30: 6368 2074 6f20 6765 6e65 7261 7465 2074  ch to generate t
+00019e40: 6865 2069 6e66 7261 2061 6e64 2073 746f  he infra and sto
+00019e50: 7265 2073 6563 7265 7473 2e0a 2020 2020  re secrets..    
+00019e60: 2020 2020 3a70 6172 616d 2070 726f 7669      :param provi
+00019e70: 6465 723a 2054 6865 206e 616d 6520 6f66  der: The name of
+00019e80: 2074 6865 2073 6563 7265 7473 2d70 726f   the secrets-pro
+00019e90: 7669 6465 7220 746f 2077 6f72 6b20 7769  vider to work wi
+00019ea0: 7468 2e20 4375 7272 656e 746c 7920 6f6e  th. Currently on
+00019eb0: 6c79 2060 6076 6175 6c74 6060 2069 7320  ly ``vault`` is 
+00019ec0: 7375 7070 6f72 7465 642e 0a20 2020 2020  supported..     
+00019ed0: 2020 203a 7061 7261 6d20 7365 6372 6574     :param secret
+00019ee0: 733a 2041 2073 6574 206f 6620 7365 6372  s: A set of secr
+00019ef0: 6574 2076 616c 7565 7320 746f 2073 746f  et values to sto
+00019f00: 7265 2077 6974 6869 6e20 7468 6520 5661  re within the Va
+00019f10: 756c 742e 0a20 2020 2020 2020 2022 2222  ult..        """
+00019f20: 0a20 2020 2020 2020 2070 6174 6820 3d20  .        path = 
+00019f30: 2275 7365 722d 7365 6372 6574 7322 0a20  "user-secrets". 
+00019f40: 2020 2020 2020 2073 6563 7265 7473 5f63         secrets_c
+00019f50: 7265 6174 696f 6e5f 7265 7175 6573 7420  reation_request 
+00019f60: 3d20 7363 6865 6d61 732e 5573 6572 5365  = schemas.UserSe
+00019f70: 6372 6574 4372 6561 7469 6f6e 5265 7175  cretCreationRequ
+00019f80: 6573 7428 0a20 2020 2020 2020 2020 2020  est(.           
+00019f90: 2075 7365 723d 7573 6572 2c0a 2020 2020   user=user,.    
+00019fa0: 2020 2020 2020 2020 7072 6f76 6964 6572          provider
+00019fb0: 3d70 726f 7669 6465 722c 0a20 2020 2020  =provider,.     
+00019fc0: 2020 2020 2020 2073 6563 7265 7473 3d73         secrets=s
+00019fd0: 6563 7265 7473 2c0a 2020 2020 2020 2020  ecrets,.        
+00019fe0: 290a 2020 2020 2020 2020 626f 6479 203d  ).        body =
+00019ff0: 2073 6563 7265 7473 5f63 7265 6174 696f   secrets_creatio
+0001a000: 6e5f 7265 7175 6573 742e 6469 6374 2829  n_request.dict()
+0001a010: 0a20 2020 2020 2020 2065 7272 6f72 5f6d  .        error_m
+0001a020: 6573 7361 6765 203d 2066 2246 6169 6c65  essage = f"Faile
+0001a030: 6420 6372 6561 7469 6e67 2075 7365 7220  d creating user 
+0001a040: 7365 6372 6574 7320 2d20 7b75 7365 727d  secrets - {user}
+0001a050: 220a 2020 2020 2020 2020 7365 6c66 2e61  ".        self.a
+0001a060: 7069 5f63 616c 6c28 0a20 2020 2020 2020  pi_call(.       
+0001a070: 2020 2020 2022 504f 5354 222c 0a20 2020       "POST",.   
+0001a080: 2020 2020 2020 2020 2070 6174 682c 0a20           path,. 
+0001a090: 2020 2020 2020 2020 2020 2065 7272 6f72             error
+0001a0a0: 5f6d 6573 7361 6765 2c0a 2020 2020 2020  _message,.      
+0001a0b0: 2020 2020 2020 626f 6479 3d64 6963 745f        body=dict_
+0001a0c0: 746f 5f6a 736f 6e28 626f 6479 292c 0a20  to_json(body),. 
+0001a0d0: 2020 2020 2020 2029 0a0a 2020 2020 4073         )..    @s
+0001a0e0: 7461 7469 636d 6574 686f 640a 2020 2020  taticmethod.    
+0001a0f0: 6465 6620 5f76 616c 6964 6174 655f 7665  def _validate_ve
+0001a100: 7273 696f 6e5f 636f 6d70 6174 6962 696c  rsion_compatibil
+0001a110: 6974 7928 7365 7276 6572 5f76 6572 7369  ity(server_versi
+0001a120: 6f6e 2c20 636c 6965 6e74 5f76 6572 7369  on, client_versi
+0001a130: 6f6e 2920 2d3e 2062 6f6f 6c3a 0a20 2020  on) -> bool:.   
+0001a140: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
+0001a150: 2020 2020 2020 7061 7273 6564 5f73 6572        parsed_ser
+0001a160: 7665 725f 7665 7273 696f 6e20 3d20 7365  ver_version = se
+0001a170: 6d76 6572 2e56 6572 7369 6f6e 496e 666f  mver.VersionInfo
+0001a180: 2e70 6172 7365 2873 6572 7665 725f 7665  .parse(server_ve
+0001a190: 7273 696f 6e29 0a20 2020 2020 2020 2020  rsion).         
+0001a1a0: 2020 2070 6172 7365 645f 636c 6965 6e74     parsed_client
+0001a1b0: 5f76 6572 7369 6f6e 203d 2073 656d 7665  _version = semve
+0001a1c0: 722e 5665 7273 696f 6e49 6e66 6f2e 7061  r.VersionInfo.pa
+0001a1d0: 7273 6528 636c 6965 6e74 5f76 6572 7369  rse(client_versi
+0001a1e0: 6f6e 290a 2020 2020 2020 2020 6578 6365  on).        exce
+0001a1f0: 7074 2056 616c 7565 4572 726f 723a 0a20  pt ValueError:. 
+0001a200: 2020 2020 2020 2020 2020 2023 2054 6869             # Thi
+0001a210: 7320 7769 6c6c 206d 6f73 746c 7920 6861  s will mostly ha
+0001a220: 7070 656e 2069 6e20 6465 7620 7363 656e  ppen in dev scen
+0001a230: 6172 696f 7320 7768 656e 2074 6865 2076  arios when the v
+0001a240: 6572 7369 6f6e 2069 7320 756e 7374 6162  ersion is unstab
+0001a250: 6c65 2061 6e64 2073 7563 6820 2d20 7468  le and such - th
+0001a260: 6572 6566 6f72 6520 7765 2772 6520 6967  erefore we're ig
+0001a270: 6e6f 7269 6e67 0a20 2020 2020 2020 2020  noring.         
+0001a280: 2020 206c 6f67 6765 722e 7761 726e 696e     logger.warnin
+0001a290: 6728 0a20 2020 2020 2020 2020 2020 2020  g(.             
+0001a2a0: 2020 2022 556e 6162 6c65 2074 6f20 7061     "Unable to pa
+0001a2b0: 7273 6520 7365 7276 6572 206f 7220 636c  rse server or cl
+0001a2c0: 6965 6e74 2076 6572 7369 6f6e 2e20 4173  ient version. As
+0001a2d0: 7375 6d69 6e67 2063 6f6d 7061 7469 626c  suming compatibl
+0001a2e0: 6522 2c0a 2020 2020 2020 2020 2020 2020  e",.            
+0001a2f0: 2020 2020 7365 7276 6572 5f76 6572 7369      server_versi
+0001a300: 6f6e 3d73 6572 7665 725f 7665 7273 696f  on=server_versio
+0001a310: 6e2c 0a20 2020 2020 2020 2020 2020 2020  n,.             
+0001a320: 2020 2063 6c69 656e 745f 7665 7273 696f     client_versio
+0001a330: 6e3d 636c 6965 6e74 5f76 6572 7369 6f6e  n=client_version
+0001a340: 2c0a 2020 2020 2020 2020 2020 2020 290a  ,.            ).
+0001a350: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0001a360: 726e 2054 7275 650a 2020 2020 2020 2020  rn True.        
+0001a370: 6966 2028 7061 7273 6564 5f73 6572 7665  if (parsed_serve
+0001a380: 725f 7665 7273 696f 6e2e 6d61 6a6f 7220  r_version.major 
+0001a390: 3d3d 2030 2061 6e64 2070 6172 7365 645f  == 0 and parsed_
+0001a3a0: 7365 7276 6572 5f76 6572 7369 6f6e 2e6d  server_version.m
+0001a3b0: 696e 6f72 203d 3d20 3029 206f 7220 280a  inor == 0) or (.
+0001a3c0: 2020 2020 2020 2020 2020 2020 7061 7273              pars
+0001a3d0: 6564 5f63 6c69 656e 745f 7665 7273 696f  ed_client_versio
+0001a3e0: 6e2e 6d61 6a6f 7220 3d3d 2030 2061 6e64  n.major == 0 and
+0001a3f0: 2070 6172 7365 645f 636c 6965 6e74 5f76   parsed_client_v
+0001a400: 6572 7369 6f6e 2e6d 696e 6f72 203d 3d20  ersion.minor == 
+0001a410: 300a 2020 2020 2020 2020 293a 0a20 2020  0.        ):.   
+0001a420: 2020 2020 2020 2020 206c 6f67 6765 722e           logger.
+0001a430: 7761 726e 696e 6728 0a20 2020 2020 2020  warning(.       
+0001a440: 2020 2020 2020 2020 2022 5365 7276 6572           "Server
+0001a450: 206f 7220 636c 6965 6e74 2076 6572 7369   or client versi
+0001a460: 6f6e 2069 7320 756e 7374 6162 6c65 2e20  on is unstable. 
+0001a470: 4173 7375 6d69 6e67 2063 6f6d 7061 7469  Assuming compati
+0001a480: 626c 6522 2c0a 2020 2020 2020 2020 2020  ble",.          
+0001a490: 2020 2020 2020 7365 7276 6572 5f76 6572        server_ver
+0001a4a0: 7369 6f6e 3d73 6572 7665 725f 7665 7273  sion=server_vers
+0001a4b0: 696f 6e2c 0a20 2020 2020 2020 2020 2020  ion,.           
+0001a4c0: 2020 2020 2063 6c69 656e 745f 7665 7273       client_vers
+0001a4d0: 696f 6e3d 636c 6965 6e74 5f76 6572 7369  ion=client_versi
+0001a4e0: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
+0001a4f0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+0001a500: 7475 726e 2054 7275 650a 2020 2020 2020  turn True.      
+0001a510: 2020 6966 2070 6172 7365 645f 7365 7276    if parsed_serv
+0001a520: 6572 5f76 6572 7369 6f6e 2e6d 616a 6f72  er_version.major
+0001a530: 2021 3d20 7061 7273 6564 5f63 6c69 656e   != parsed_clien
+0001a540: 745f 7665 7273 696f 6e2e 6d61 6a6f 723a  t_version.major:
+0001a550: 0a20 2020 2020 2020 2020 2020 206c 6f67  .            log
+0001a560: 6765 722e 7761 726e 696e 6728 0a20 2020  ger.warning(.   
+0001a570: 2020 2020 2020 2020 2020 2020 2022 5365               "Se
+0001a580: 7276 6572 2061 6e64 2063 6c69 656e 7420  rver and client 
+0001a590: 7665 7273 696f 6e73 2061 7265 2069 6e63  versions are inc
+0001a5a0: 6f6d 7061 7469 626c 6522 2c0a 2020 2020  ompatible",.    
+0001a5b0: 2020 2020 2020 2020 2020 2020 7061 7273              pars
+0001a5c0: 6564 5f73 6572 7665 725f 7665 7273 696f  ed_server_versio
+0001a5d0: 6e3d 7061 7273 6564 5f73 6572 7665 725f  n=parsed_server_
+0001a5e0: 7665 7273 696f 6e2c 0a20 2020 2020 2020  version,.       
+0001a5f0: 2020 2020 2020 2020 2070 6172 7365 645f           parsed_
+0001a600: 636c 6965 6e74 5f76 6572 7369 6f6e 3d70  client_version=p
+0001a610: 6172 7365 645f 636c 6965 6e74 5f76 6572  arsed_client_ver
+0001a620: 7369 6f6e 2c0a 2020 2020 2020 2020 2020  sion,.          
+0001a630: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+0001a640: 7265 7475 726e 2046 616c 7365 0a20 2020  return False.   
+0001a650: 2020 2020 2069 6620 7061 7273 6564 5f73       if parsed_s
+0001a660: 6572 7665 725f 7665 7273 696f 6e2e 6d69  erver_version.mi
+0001a670: 6e6f 7220 3e20 7061 7273 6564 5f63 6c69  nor > parsed_cli
+0001a680: 656e 745f 7665 7273 696f 6e2e 6d69 6e6f  ent_version.mino
+0001a690: 7220 2b20 323a 0a20 2020 2020 2020 2020  r + 2:.         
+0001a6a0: 2020 206c 6f67 6765 722e 696e 666f 280a     logger.info(.
+0001a6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a6c0: 2242 6163 6b77 6172 6473 2063 6f6d 7061  "Backwards compa
+0001a6d0: 7469 6269 6c69 7479 206d 6967 6874 206e  tibility might n
+0001a6e0: 6f74 2061 7070 6c79 2062 6574 7765 656e  ot apply between
+0001a6f0: 2074 6865 2073 6572 7665 7220 616e 6420   the server and 
+0001a700: 636c 6965 6e74 2076 6572 7369 6f6e 222c  client version",
+0001a710: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001a720: 2070 6172 7365 645f 7365 7276 6572 5f76   parsed_server_v
+0001a730: 6572 7369 6f6e 3d70 6172 7365 645f 7365  ersion=parsed_se
+0001a740: 7276 6572 5f76 6572 7369 6f6e 2c0a 2020  rver_version,.  
+0001a750: 2020 2020 2020 2020 2020 2020 2020 7061                pa
+0001a760: 7273 6564 5f63 6c69 656e 745f 7665 7273  rsed_client_vers
+0001a770: 696f 6e3d 7061 7273 6564 5f63 6c69 656e  ion=parsed_clien
+0001a780: 745f 7665 7273 696f 6e2c 0a20 2020 2020  t_version,.     
+0001a790: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0001a7a0: 2020 2020 2072 6574 7572 6e20 4661 6c73       return Fals
+0001a7b0: 650a 2020 2020 2020 2020 6966 2070 6172  e.        if par
+0001a7c0: 7365 645f 636c 6965 6e74 5f76 6572 7369  sed_client_versi
+0001a7d0: 6f6e 2e6d 696e 6f72 203e 2070 6172 7365  on.minor > parse
+0001a7e0: 645f 7365 7276 6572 5f76 6572 7369 6f6e  d_server_version
+0001a7f0: 2e6d 696e 6f72 3a0a 2020 2020 2020 2020  .minor:.        
+0001a800: 2020 2020 6c6f 6767 6572 2e77 6172 6e69      logger.warni
+0001a810: 6e67 280a 2020 2020 2020 2020 2020 2020  ng(.            
+0001a820: 2020 2020 2243 6c69 656e 7420 7665 7273      "Client vers
+0001a830: 696f 6e20 7769 7468 2068 6967 6865 7220  ion with higher 
+0001a840: 7665 7273 696f 6e20 7468 616e 2073 6572  version than ser
+0001a850: 7665 7220 7665 7273 696f 6e20 6973 6e27  ver version isn'
+0001a860: 7420 7375 7070 6f72 7465 642c 220a 2020  t supported,".  
+0001a870: 2020 2020 2020 2020 2020 2020 2020 2220                " 
+0001a880: 616c 6967 6e20 796f 7572 2063 6c69 656e  align your clien
+0001a890: 7420 746f 2074 6865 2073 6572 7665 7220  t to the server 
+0001a8a0: 7665 7273 696f 6e22 2c0a 2020 2020 2020  version",.      
+0001a8b0: 2020 2020 2020 2020 2020 7061 7273 6564            parsed
+0001a8c0: 5f73 6572 7665 725f 7665 7273 696f 6e3d  _server_version=
+0001a8d0: 7061 7273 6564 5f73 6572 7665 725f 7665  parsed_server_ve
+0001a8e0: 7273 696f 6e2c 0a20 2020 2020 2020 2020  rsion,.         
+0001a8f0: 2020 2020 2020 2070 6172 7365 645f 636c         parsed_cl
+0001a900: 6965 6e74 5f76 6572 7369 6f6e 3d70 6172  ient_version=par
+0001a910: 7365 645f 636c 6965 6e74 5f76 6572 7369  sed_client_versi
+0001a920: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
+0001a930: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+0001a940: 7475 726e 2046 616c 7365 0a20 2020 2020  turn False.     
+0001a950: 2020 2069 6620 7061 7273 6564 5f73 6572     if parsed_ser
+0001a960: 7665 725f 7665 7273 696f 6e2e 6d69 6e6f  ver_version.mino
+0001a970: 7220 213d 2070 6172 7365 645f 636c 6965  r != parsed_clie
+0001a980: 6e74 5f76 6572 7369 6f6e 2e6d 696e 6f72  nt_version.minor
+0001a990: 3a0a 2020 2020 2020 2020 2020 2020 6c6f  :.            lo
+0001a9a0: 6767 6572 2e69 6e66 6f28 0a20 2020 2020  gger.info(.     
+0001a9b0: 2020 2020 2020 2020 2020 2022 5365 7276             "Serv
+0001a9c0: 6572 2061 6e64 2063 6c69 656e 7420 7665  er and client ve
+0001a9d0: 7273 696f 6e73 2061 7265 206e 6f74 2074  rsions are not t
+0001a9e0: 6865 2073 616d 6520 6275 7420 636f 6d70  he same but comp
+0001a9f0: 6174 6962 6c65 222c 0a20 2020 2020 2020  atible",.       
+0001aa00: 2020 2020 2020 2020 2070 6172 7365 645f           parsed_
+0001aa10: 7365 7276 6572 5f76 6572 7369 6f6e 3d70  server_version=p
+0001aa20: 6172 7365 645f 7365 7276 6572 5f76 6572  arsed_server_ver
+0001aa30: 7369 6f6e 2c0a 2020 2020 2020 2020 2020  sion,.          
+0001aa40: 2020 2020 2020 7061 7273 6564 5f63 6c69        parsed_cli
+0001aa50: 656e 745f 7665 7273 696f 6e3d 7061 7273  ent_version=pars
+0001aa60: 6564 5f63 6c69 656e 745f 7665 7273 696f  ed_client_versio
+0001aa70: 6e2c 0a20 2020 2020 2020 2020 2020 2029  n,.            )
+0001aa80: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001aa90: 5472 7565 0a0a 2020 2020 6465 6620 6372  True..    def cr
+0001aaa0: 6561 7465 5f6d 6f64 656c 5f65 6e64 706f  eate_model_endpo
+0001aab0: 696e 7428 0a20 2020 2020 2020 2073 656c  int(.        sel
+0001aac0: 662c 0a20 2020 2020 2020 2070 726f 6a65  f,.        proje
+0001aad0: 6374 3a20 7374 722c 0a20 2020 2020 2020  ct: str,.       
+0001aae0: 2065 6e64 706f 696e 745f 6964 3a20 7374   endpoint_id: st
+0001aaf0: 722c 0a20 2020 2020 2020 206d 6f64 656c  r,.        model
+0001ab00: 5f65 6e64 706f 696e 743a 2055 6e69 6f6e  _endpoint: Union
+0001ab10: 5b0a 2020 2020 2020 2020 2020 2020 6d6c  [.            ml
+0001ab20: 7275 6e2e 6d6f 6465 6c5f 6d6f 6e69 746f  run.model_monito
+0001ab30: 7269 6e67 2e6d 6f64 656c 5f65 6e64 706f  ring.model_endpo
+0001ab40: 696e 742e 4d6f 6465 6c45 6e64 706f 696e  int.ModelEndpoin
+0001ab50: 742c 2064 6963 740a 2020 2020 2020 2020  t, dict.        
+0001ab60: 5d2c 0a20 2020 2029 3a0a 2020 2020 2020  ],.    ):.      
+0001ab70: 2020 2222 220a 2020 2020 2020 2020 4372    """.        Cr
+0001ab80: 6561 7465 7320 6120 4442 2072 6563 6f72  eates a DB recor
+0001ab90: 6420 7769 7468 2074 6865 2067 6976 656e  d with the given
+0001aba0: 206d 6f64 656c 5f65 6e64 706f 696e 7420   model_endpoint 
+0001abb0: 7265 636f 7264 2e0a 0a20 2020 2020 2020  record...       
+0001abc0: 203a 7061 7261 6d20 7072 6f6a 6563 743a   :param project:
+0001abd0: 2054 6865 206e 616d 6520 6f66 2074 6865   The name of the
+0001abe0: 2070 726f 6a65 6374 2e0a 2020 2020 2020   project..      
+0001abf0: 2020 3a70 6172 616d 2065 6e64 706f 696e    :param endpoin
+0001ac00: 745f 6964 3a20 5468 6520 6964 206f 6620  t_id: The id of 
+0001ac10: 7468 6520 656e 6470 6f69 6e74 2e0a 2020  the endpoint..  
+0001ac20: 2020 2020 2020 3a70 6172 616d 206d 6f64        :param mod
+0001ac30: 656c 5f65 6e64 706f 696e 743a 2041 6e20  el_endpoint: An 
+0001ac40: 6f62 6a65 6374 2072 6570 7265 7365 6e74  object represent
+0001ac50: 696e 6720 7468 6520 6d6f 6465 6c20 656e  ing the model en
+0001ac60: 6470 6f69 6e74 2e0a 2020 2020 2020 2020  dpoint..        
+0001ac70: 2222 220a 0a20 2020 2020 2020 2069 6620  """..        if 
+0001ac80: 6973 696e 7374 616e 6365 280a 2020 2020  isinstance(.    
+0001ac90: 2020 2020 2020 2020 6d6f 6465 6c5f 656e          model_en
+0001aca0: 6470 6f69 6e74 2c20 6d6c 7275 6e2e 6d6f  dpoint, mlrun.mo
+0001acb0: 6465 6c5f 6d6f 6e69 746f 7269 6e67 2e6d  del_monitoring.m
+0001acc0: 6f64 656c 5f65 6e64 706f 696e 742e 4d6f  odel_endpoint.Mo
+0001acd0: 6465 6c45 6e64 706f 696e 740a 2020 2020  delEndpoint.    
+0001ace0: 2020 2020 293a 0a20 2020 2020 2020 2020      ):.         
+0001acf0: 2020 206d 6f64 656c 5f65 6e64 706f 696e     model_endpoin
+0001ad00: 7420 3d20 6d6f 6465 6c5f 656e 6470 6f69  t = model_endpoi
+0001ad10: 6e74 2e74 6f5f 6469 6374 2829 0a0a 2020  nt.to_dict()..  
+0001ad20: 2020 2020 2020 7061 7468 203d 2066 2270        path = f"p
+0001ad30: 726f 6a65 6374 732f 7b70 726f 6a65 6374  rojects/{project
+0001ad40: 7d2f 6d6f 6465 6c2d 656e 6470 6f69 6e74  }/model-endpoint
+0001ad50: 732f 7b65 6e64 706f 696e 745f 6964 7d22  s/{endpoint_id}"
+0001ad60: 0a20 2020 2020 2020 2073 656c 662e 6170  .        self.ap
+0001ad70: 695f 6361 6c6c 280a 2020 2020 2020 2020  i_call(.        
+0001ad80: 2020 2020 6d65 7468 6f64 3d22 504f 5354      method="POST
+0001ad90: 222c 0a20 2020 2020 2020 2020 2020 2070  ",.            p
+0001ada0: 6174 683d 7061 7468 2c0a 2020 2020 2020  ath=path,.      
+0001adb0: 2020 2020 2020 626f 6479 3d64 6963 745f        body=dict_
+0001adc0: 746f 5f6a 736f 6e28 6d6f 6465 6c5f 656e  to_json(model_en
+0001add0: 6470 6f69 6e74 292c 0a20 2020 2020 2020  dpoint),.       
+0001ade0: 2029 0a0a 2020 2020 6465 6620 6465 6c65   )..    def dele
+0001adf0: 7465 5f6d 6f64 656c 5f65 6e64 706f 696e  te_model_endpoin
+0001ae00: 7428 0a20 2020 2020 2020 2073 656c 662c  t(.        self,
+0001ae10: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
+0001ae20: 3a20 7374 722c 0a20 2020 2020 2020 2065  : str,.        e
+0001ae30: 6e64 706f 696e 745f 6964 3a20 7374 722c  ndpoint_id: str,
+0001ae40: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
+0001ae50: 2222 220a 2020 2020 2020 2020 4465 6c65  """.        Dele
+0001ae60: 7465 7320 7468 6520 4442 2072 6563 6f72  tes the DB recor
+0001ae70: 6420 6f66 2061 2067 6976 656e 206d 6f64  d of a given mod
+0001ae80: 656c 2065 6e64 706f 696e 742c 2070 726f  el endpoint, pro
+0001ae90: 6a65 6374 2061 6e64 2065 6e64 706f 696e  ject and endpoin
+0001aea0: 745f 6964 2061 7265 2075 7365 6420 666f  t_id are used fo
+0001aeb0: 7220 6c6f 6f6b 7570 0a0a 2020 2020 2020  r lookup..      
+0001aec0: 2020 3a70 6172 616d 2070 726f 6a65 6374    :param project
+0001aed0: 3a20 5468 6520 6e61 6d65 206f 6620 7468  : The name of th
+0001aee0: 6520 7072 6f6a 6563 740a 2020 2020 2020  e project.      
+0001aef0: 2020 3a70 6172 616d 2065 6e64 706f 696e    :param endpoin
+0001af00: 745f 6964 3a20 5468 6520 6964 206f 6620  t_id: The id of 
+0001af10: 7468 6520 656e 6470 6f69 6e74 0a20 2020  the endpoint.   
+0001af20: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
+0001af30: 2020 7061 7468 203d 2066 2270 726f 6a65    path = f"proje
+0001af40: 6374 732f 7b70 726f 6a65 6374 7d2f 6d6f  cts/{project}/mo
+0001af50: 6465 6c2d 656e 6470 6f69 6e74 732f 7b65  del-endpoints/{e
+0001af60: 6e64 706f 696e 745f 6964 7d22 0a20 2020  ndpoint_id}".   
+0001af70: 2020 2020 2073 656c 662e 6170 695f 6361       self.api_ca
+0001af80: 6c6c 280a 2020 2020 2020 2020 2020 2020  ll(.            
+0001af90: 6d65 7468 6f64 3d22 4445 4c45 5445 222c  method="DELETE",
+0001afa0: 0a20 2020 2020 2020 2020 2020 2070 6174  .            pat
+0001afb0: 683d 7061 7468 2c0a 2020 2020 2020 2020  h=path,.        
+0001afc0: 290a 0a20 2020 2064 6566 206c 6973 745f  )..    def list_
+0001afd0: 6d6f 6465 6c5f 656e 6470 6f69 6e74 7328  model_endpoints(
+0001afe0: 0a20 2020 2020 2020 2073 656c 662c 0a20  .        self,. 
+0001aff0: 2020 2020 2020 2070 726f 6a65 6374 3a20         project: 
+0001b000: 7374 722c 0a20 2020 2020 2020 206d 6f64  str,.        mod
+0001b010: 656c 3a20 4f70 7469 6f6e 616c 5b73 7472  el: Optional[str
+0001b020: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+0001b030: 2020 6675 6e63 7469 6f6e 3a20 4f70 7469    function: Opti
+0001b040: 6f6e 616c 5b73 7472 5d20 3d20 4e6f 6e65  onal[str] = None
+0001b050: 2c0a 2020 2020 2020 2020 6c61 6265 6c73  ,.        labels
+0001b060: 3a20 4c69 7374 5b73 7472 5d20 3d20 4e6f  : List[str] = No
+0001b070: 6e65 2c0a 2020 2020 2020 2020 7374 6172  ne,.        star
+0001b080: 743a 2073 7472 203d 2022 6e6f 772d 3168  t: str = "now-1h
+0001b090: 222c 0a20 2020 2020 2020 2065 6e64 3a20  ",.        end: 
+0001b0a0: 7374 7220 3d20 226e 6f77 222c 0a20 2020  str = "now",.   
+0001b0b0: 2020 2020 206d 6574 7269 6373 3a20 4f70       metrics: Op
+0001b0c0: 7469 6f6e 616c 5b4c 6973 745b 7374 725d  tional[List[str]
+0001b0d0: 5d20 3d20 4e6f 6e65 2c0a 2020 2020 2020  ] = None,.      
+0001b0e0: 2020 746f 705f 6c65 7665 6c3a 2062 6f6f    top_level: boo
+0001b0f0: 6c20 3d20 4661 6c73 652c 0a20 2020 2020  l = False,.     
+0001b100: 2020 2075 6964 733a 204f 7074 696f 6e61     uids: Optiona
+0001b110: 6c5b 4c69 7374 5b73 7472 5d5d 203d 204e  l[List[str]] = N
+0001b120: 6f6e 652c 0a20 2020 2029 202d 3e20 4c69  one,.    ) -> Li
+0001b130: 7374 5b6d 6c72 756e 2e6d 6f64 656c 5f6d  st[mlrun.model_m
+0001b140: 6f6e 6974 6f72 696e 672e 6d6f 6465 6c5f  onitoring.model_
+0001b150: 656e 6470 6f69 6e74 2e4d 6f64 656c 456e  endpoint.ModelEn
+0001b160: 6470 6f69 6e74 5d3a 0a20 2020 2020 2020  dpoint]:.       
+0001b170: 2022 2222 0a20 2020 2020 2020 2052 6574   """.        Ret
+0001b180: 7572 6e73 2061 206c 6973 7420 6f66 204d  urns a list of M
+0001b190: 6f64 656c 456e 6470 6f69 6e74 5374 6174  odelEndpointStat
+0001b1a0: 6520 6f62 6a65 6374 732e 2045 6163 6820  e objects. Each 
+0001b1b0: 6f62 6a65 6374 2072 6570 7265 7365 6e74  object represent
+0001b1c0: 7320 7468 6520 6375 7272 656e 7420 7374  s the current st
+0001b1d0: 6174 6520 6f66 2061 206d 6f64 656c 2065  ate of a model e
+0001b1e0: 6e64 706f 696e 742e 0a20 2020 2020 2020  ndpoint..       
+0001b1f0: 2054 6869 7320 6675 6e63 7469 6f6e 7320   This functions 
+0001b200: 7375 7070 6f72 7473 2066 696c 7465 7269  supports filteri
+0001b210: 6e67 2062 7920 7468 6520 666f 6c6c 6f77  ng by the follow
+0001b220: 696e 6720 7061 7261 6d65 7465 7273 3a0a  ing parameters:.
+0001b230: 2020 2020 2020 2020 3129 206d 6f64 656c          1) model
+0001b240: 0a20 2020 2020 2020 2032 2920 6675 6e63  .        2) func
+0001b250: 7469 6f6e 0a20 2020 2020 2020 2033 2920  tion.        3) 
+0001b260: 6c61 6265 6c73 0a20 2020 2020 2020 2042  labels.        B
+0001b270: 7920 6465 6661 756c 742c 2077 6865 6e20  y default, when 
+0001b280: 6e6f 2066 696c 7465 7273 2061 7265 2061  no filters are a
+0001b290: 7070 6c69 6564 2c20 616c 6c20 6176 6169  pplied, all avai
+0001b2a0: 6c61 626c 6520 656e 6470 6f69 6e74 7320  lable endpoints 
+0001b2b0: 666f 7220 7468 6520 6769 7665 6e20 7072  for the given pr
+0001b2c0: 6f6a 6563 7420 7769 6c6c 2062 6520 6c69  oject will be li
+0001b2d0: 7374 6564 2e0a 0a20 2020 2020 2020 2049  sted...        I
+0001b2e0: 6e20 6164 6469 7469 6f6e 2c20 7468 6973  n addition, this
+0001b2f0: 2066 756e 6374 696f 6e73 2070 726f 7669   functions provi
+0001b300: 6465 7320 6120 6661 6361 6465 2066 6f72  des a facade for
+0001b310: 206c 6973 7469 6e67 2065 6e64 706f 696e   listing endpoin
+0001b320: 7420 7265 6c61 7465 6420 6d65 7472 6963  t related metric
+0001b330: 732e 2054 6869 7320 6661 6361 6465 2069  s. This facade i
+0001b340: 7320 7469 6d65 2d62 6173 6564 0a20 2020  s time-based.   
+0001b350: 2020 2020 2061 6e64 2064 6570 656e 6473       and depends
+0001b360: 206f 6e20 7468 6520 2773 7461 7274 2720   on the 'start' 
+0001b370: 616e 6420 2765 6e64 2720 7061 7261 6d65  and 'end' parame
+0001b380: 7465 7273 2e20 4279 2064 6566 6175 6c74  ters. By default
+0001b390: 2c20 7768 656e 2074 6865 206d 6574 7269  , when the metri
+0001b3a0: 6373 2070 6172 616d 6574 6572 2069 7320  cs parameter is 
+0001b3b0: 4e6f 6e65 2c20 6e6f 206d 6574 7269 6373  None, no metrics
+0001b3c0: 2061 7265 0a20 2020 2020 2020 2061 6464   are.        add
+0001b3d0: 6564 2074 6f20 7468 6520 6f75 7470 7574  ed to the output
+0001b3e0: 206f 6620 7468 6973 2066 756e 6374 696f   of this functio
+0001b3f0: 6e2e 0a0a 2020 2020 2020 2020 3a70 6172  n...        :par
+0001b400: 616d 2070 726f 6a65 6374 3a20 5468 6520  am project: The 
+0001b410: 6e61 6d65 206f 6620 7468 6520 7072 6f6a  name of the proj
+0001b420: 6563 740a 2020 2020 2020 2020 3a70 6172  ect.        :par
+0001b430: 616d 206d 6f64 656c 3a20 5468 6520 6e61  am model: The na
+0001b440: 6d65 206f 6620 7468 6520 6d6f 6465 6c20  me of the model 
+0001b450: 746f 2066 696c 7465 7220 6279 0a20 2020  to filter by.   
+0001b460: 2020 2020 203a 7061 7261 6d20 6675 6e63       :param func
+0001b470: 7469 6f6e 3a20 5468 6520 6e61 6d65 206f  tion: The name o
+0001b480: 6620 7468 6520 6675 6e63 7469 6f6e 2074  f the function t
+0001b490: 6f20 6669 6c74 6572 2062 790a 2020 2020  o filter by.    
+0001b4a0: 2020 2020 3a70 6172 616d 206c 6162 656c      :param label
+0001b4b0: 733a 2041 206c 6973 7420 6f66 206c 6162  s: A list of lab
+0001b4c0: 656c 7320 746f 2066 696c 7465 7220 6279  els to filter by
+0001b4d0: 2e20 4c61 6265 6c20 6669 6c74 6572 7320  . Label filters 
+0001b4e0: 776f 726b 2062 7920 6569 7468 6572 2066  work by either f
+0001b4f0: 696c 7465 7269 6e67 2061 2073 7065 6369  iltering a speci
+0001b500: 6669 6320 7661 6c75 6520 6f66 2061 0a20  fic value of a. 
+0001b510: 2020 2020 2020 2020 6c61 6265 6c20 2869          label (i
+0001b520: 2e65 2e20 6c69 7374 2822 6b65 793d 7661  .e. list("key=va
+0001b530: 6c75 6522 2929 206f 7220 6279 206c 6f6f  lue")) or by loo
+0001b540: 6b69 6e67 2066 6f72 2074 6865 2065 7869  king for the exi
+0001b550: 7374 656e 6365 206f 6620 6120 6769 7665  stence of a give
+0001b560: 6e20 6b65 7920 2869 2e65 2e20 226b 6579  n key (i.e. "key
+0001b570: 2229 0a20 2020 2020 2020 203a 7061 7261  ").        :para
+0001b580: 6d20 6d65 7472 6963 733a 2041 206c 6973  m metrics: A lis
+0001b590: 7420 6f66 206d 6574 7269 6373 2074 6f20  t of metrics to 
+0001b5a0: 7265 7475 726e 2066 6f72 2065 6163 6820  return for each 
+0001b5b0: 656e 6470 6f69 6e74 2c20 7265 6164 206d  endpoint, read m
+0001b5c0: 6f72 6520 696e 2027 5469 6d65 4d65 7472  ore in 'TimeMetr
+0001b5d0: 6963 270a 2020 2020 2020 2020 3a70 6172  ic'.        :par
+0001b5e0: 616d 2073 7461 7274 3a20 5468 6520 7374  am start: The st
+0001b5f0: 6172 7420 7469 6d65 206f 6620 7468 6520  art time of the 
+0001b600: 6d65 7472 6963 732e 2043 616e 2062 6520  metrics. Can be 
+0001b610: 7265 7072 6573 656e 7465 6420 6279 2061  represented by a
+0001b620: 2073 7472 696e 6720 636f 6e74 6169 6e69   string containi
+0001b630: 6e67 2061 6e20 5246 4320 3333 3339 0a20  ng an RFC 3339. 
+0001b640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b660: 7469 6d65 2c20 6120 556e 6978 2074 696d  time, a Unix tim
+0001b670: 6573 7461 6d70 2069 6e20 6d69 6c6c 6973  estamp in millis
+0001b680: 6563 6f6e 6473 2c20 6120 7265 6c61 7469  econds, a relati
+0001b690: 7665 2074 696d 6520 2860 276e 6f77 2760  ve time (`'now'`
+0001b6a0: 206f 720a 2020 2020 2020 2020 2020 2020   or.            
+0001b6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b6c0: 2020 2020 2060 276e 6f77 2d5b 302d 395d       `'now-[0-9]
+0001b6d0: 2b5b 6d68 645d 2760 2c20 7768 6572 6520  +[mhd]'`, where 
+0001b6e0: 606d 6020 3d20 6d69 6e75 7465 732c 2060  `m` = minutes, `
+0001b6f0: 6860 203d 2068 6f75 7273 2c20 616e 6420  h` = hours, and 
+0001b700: 6027 6427 6020 3d0a 2020 2020 2020 2020  `'d'` =.        
+0001b710: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b720: 2020 2020 2020 2020 2064 6179 7329 2c20           days), 
+0001b730: 6f72 2030 2066 6f72 2074 6865 2065 6172  or 0 for the ear
+0001b740: 6c69 6573 7420 7469 6d65 2e0a 2020 2020  liest time..    
+0001b750: 2020 2020 3a70 6172 616d 2065 6e64 3a20      :param end: 
+0001b760: 5468 6520 656e 6420 7469 6d65 206f 6620  The end time of 
+0001b770: 7468 6520 6d65 7472 6963 732e 2043 616e  the metrics. Can
+0001b780: 2062 6520 7265 7072 6573 656e 7465 6420   be represented 
+0001b790: 6279 2061 2073 7472 696e 6720 636f 6e74  by a string cont
+0001b7a0: 6169 6e69 6e67 2061 6e20 5246 4320 3333  aining an RFC 33
+0001b7b0: 3339 0a20 2020 2020 2020 2020 2020 2020  39.             
+0001b7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b7d0: 2020 2020 7469 6d65 2c20 6120 556e 6978      time, a Unix
+0001b7e0: 2074 696d 6573 7461 6d70 2069 6e20 6d69   timestamp in mi
+0001b7f0: 6c6c 6973 6563 6f6e 6473 2c20 6120 7265  lliseconds, a re
+0001b800: 6c61 7469 7665 2074 696d 6520 2860 276e  lative time (`'n
+0001b810: 6f77 2760 206f 720a 2020 2020 2020 2020  ow'` or.        
+0001b820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b830: 2020 2020 2020 2020 2060 276e 6f77 2d5b           `'now-[
+0001b840: 302d 395d 2b5b 6d68 645d 2760 2c20 7768  0-9]+[mhd]'`, wh
+0001b850: 6572 6520 606d 6020 3d20 6d69 6e75 7465  ere `m` = minute
+0001b860: 732c 2060 6860 203d 2068 6f75 7273 2c20  s, `h` = hours, 
+0001b870: 616e 6420 6027 6427 6020 3d0a 2020 2020  and `'d'` =.    
+0001b880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b890: 2020 2020 2020 2020 2020 2020 2064 6179               day
+0001b8a0: 7329 2c20 6f72 2030 2066 6f72 2074 6865  s), or 0 for the
+0001b8b0: 2065 6172 6c69 6573 7420 7469 6d65 2e0a   earliest time..
+0001b8c0: 2020 2020 2020 2020 3a70 6172 616d 2074          :param t
+0001b8d0: 6f70 5f6c 6576 656c 3a20 6966 2074 7275  op_level: if tru
+0001b8e0: 6520 7769 6c6c 2072 6574 7572 6e20 6f6e  e will return on
+0001b8f0: 6c79 2072 6f75 7465 7273 2061 6e64 2065  ly routers and e
+0001b900: 6e64 706f 696e 7420 7468 6174 2061 7265  ndpoint that are
+0001b910: 204e 4f54 2063 6869 6c64 7265 6e20 6f66   NOT children of
+0001b920: 2061 6e79 2072 6f75 7465 720a 2020 2020   any router.    
+0001b930: 2020 2020 3a70 6172 616d 2075 6964 733a      :param uids:
+0001b940: 2069 6620 7061 7373 6564 2077 696c 6c20   if passed will 
+0001b950: 7265 7475 726e 2060 4d6f 6465 6c45 6e64  return `ModelEnd
+0001b960: 706f 696e 744c 6973 7460 206f 6620 656e  pointList` of en
+0001b970: 6470 6f69 6e74 7320 7769 7468 2075 6964  dpoints with uid
+0001b980: 2069 6e20 7569 6473 0a20 2020 2020 2020   in uids.       
+0001b990: 2022 2222 0a0a 2020 2020 2020 2020 7061   """..        pa
+0001b9a0: 7468 203d 2066 2270 726f 6a65 6374 732f  th = f"projects/
+0001b9b0: 7b70 726f 6a65 6374 7d2f 6d6f 6465 6c2d  {project}/model-
+0001b9c0: 656e 6470 6f69 6e74 7322 0a0a 2020 2020  endpoints"..    
+0001b9d0: 2020 2020 6966 206c 6162 656c 7320 616e      if labels an
+0001b9e0: 6420 6973 696e 7374 616e 6365 286c 6162  d isinstance(lab
+0001b9f0: 656c 732c 2064 6963 7429 3a0a 2020 2020  els, dict):.    
+0001ba00: 2020 2020 2020 2020 6c61 6265 6c73 203d          labels =
+0001ba10: 205b 6622 7b6b 6579 7d3d 7b76 616c 7565   [f"{key}={value
+0001ba20: 7d22 2066 6f72 206b 6579 2c20 7661 6c75  }" for key, valu
+0001ba30: 6520 696e 206c 6162 656c 732e 6974 656d  e in labels.item
+0001ba40: 7328 295d 0a0a 2020 2020 2020 2020 7265  s()]..        re
+0001ba50: 7370 6f6e 7365 203d 2073 656c 662e 6170  sponse = self.ap
+0001ba60: 695f 6361 6c6c 280a 2020 2020 2020 2020  i_call(.        
+0001ba70: 2020 2020 6d65 7468 6f64 3d22 4745 5422      method="GET"
+0001ba80: 2c0a 2020 2020 2020 2020 2020 2020 7061  ,.            pa
+0001ba90: 7468 3d70 6174 682c 0a20 2020 2020 2020  th=path,.       
+0001baa0: 2020 2020 2070 6172 616d 733d 7b0a 2020       params={.  
+0001bab0: 2020 2020 2020 2020 2020 2020 2020 226d                "m
+0001bac0: 6f64 656c 223a 206d 6f64 656c 2c0a 2020  odel": model,.  
+0001bad0: 2020 2020 2020 2020 2020 2020 2020 2266                "f
+0001bae0: 756e 6374 696f 6e22 3a20 6675 6e63 7469  unction": functi
+0001baf0: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
+0001bb00: 2020 2020 226c 6162 656c 223a 206c 6162      "label": lab
+0001bb10: 656c 7320 6f72 205b 5d2c 0a20 2020 2020  els or [],.     
+0001bb20: 2020 2020 2020 2020 2020 2022 7374 6172             "star
+0001bb30: 7422 3a20 7374 6172 742c 0a20 2020 2020  t": start,.     
+0001bb40: 2020 2020 2020 2020 2020 2022 656e 6422             "end"
+0001bb50: 3a20 656e 642c 0a20 2020 2020 2020 2020  : end,.         
+0001bb60: 2020 2020 2020 2022 6d65 7472 6963 223a         "metric":
+0001bb70: 206d 6574 7269 6373 206f 7220 5b5d 2c0a   metrics or [],.
+0001bb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001bb90: 2274 6f70 2d6c 6576 656c 223a 2074 6f70  "top-level": top
+0001bba0: 5f6c 6576 656c 2c0a 2020 2020 2020 2020  _level,.        
+0001bbb0: 2020 2020 2020 2020 2275 6964 223a 2075          "uid": u
+0001bbc0: 6964 732c 0a20 2020 2020 2020 2020 2020  ids,.           
+0001bbd0: 207d 2c0a 2020 2020 2020 2020 290a 0a20   },.        ).. 
+0001bbe0: 2020 2020 2020 2023 2047 656e 6572 6174         # Generat
+0001bbf0: 6520 6120 6c69 7374 206f 6620 6120 6d6f  e a list of a mo
+0001bc00: 6465 6c20 656e 6470 6f69 6e74 2064 6963  del endpoint dic
+0001bc10: 7469 6f6e 6172 6965 730a 2020 2020 2020  tionaries.      
+0001bc20: 2020 6d6f 6465 6c5f 656e 6470 6f69 6e74    model_endpoint
+0001bc30: 7320 3d20 7265 7370 6f6e 7365 2e6a 736f  s = response.jso
+0001bc40: 6e28 295b 2265 6e64 706f 696e 7473 225d  n()["endpoints"]
+0001bc50: 0a20 2020 2020 2020 2069 6620 6d6f 6465  .        if mode
+0001bc60: 6c5f 656e 6470 6f69 6e74 733a 0a20 2020  l_endpoints:.   
+0001bc70: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0001bc80: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+0001bc90: 2020 6d6c 7275 6e2e 6d6f 6465 6c5f 6d6f    mlrun.model_mo
+0001bca0: 6e69 746f 7269 6e67 2e6d 6f64 656c 5f65  nitoring.model_e
+0001bcb0: 6e64 706f 696e 742e 4d6f 6465 6c45 6e64  ndpoint.ModelEnd
+0001bcc0: 706f 696e 742e 6672 6f6d 5f64 6963 7428  point.from_dict(
+0001bcd0: 6f62 6a29 0a20 2020 2020 2020 2020 2020  obj).           
+0001bce0: 2020 2020 2066 6f72 206f 626a 2069 6e20       for obj in 
+0001bcf0: 6d6f 6465 6c5f 656e 6470 6f69 6e74 730a  model_endpoints.
+0001bd00: 2020 2020 2020 2020 2020 2020 5d0a 2020              ].  
+0001bd10: 2020 2020 2020 7265 7475 726e 205b 5d0a        return [].
+0001bd20: 0a20 2020 2064 6566 2067 6574 5f6d 6f64  .    def get_mod
+0001bd30: 656c 5f65 6e64 706f 696e 7428 0a20 2020  el_endpoint(.   
+0001bd40: 2020 2020 2073 656c 662c 0a20 2020 2020       self,.     
+0001bd50: 2020 2070 726f 6a65 6374 3a20 7374 722c     project: str,
+0001bd60: 0a20 2020 2020 2020 2065 6e64 706f 696e  .        endpoin
+0001bd70: 745f 6964 3a20 7374 722c 0a20 2020 2020  t_id: str,.     
+0001bd80: 2020 2073 7461 7274 3a20 4f70 7469 6f6e     start: Option
+0001bd90: 616c 5b73 7472 5d20 3d20 4e6f 6e65 2c0a  al[str] = None,.
+0001bda0: 2020 2020 2020 2020 656e 643a 204f 7074          end: Opt
+0001bdb0: 696f 6e61 6c5b 7374 725d 203d 204e 6f6e  ional[str] = Non
+0001bdc0: 652c 0a20 2020 2020 2020 206d 6574 7269  e,.        metri
+0001bdd0: 6373 3a20 4f70 7469 6f6e 616c 5b4c 6973  cs: Optional[Lis
+0001bde0: 745b 7374 725d 5d20 3d20 4e6f 6e65 2c0a  t[str]] = None,.
+0001bdf0: 2020 2020 2020 2020 6665 6174 7572 655f          feature_
+0001be00: 616e 616c 7973 6973 3a20 626f 6f6c 203d  analysis: bool =
+0001be10: 2046 616c 7365 2c0a 2020 2020 2920 2d3e   False,.    ) ->
+0001be20: 206d 6c72 756e 2e6d 6f64 656c 5f6d 6f6e   mlrun.model_mon
+0001be30: 6974 6f72 696e 672e 6d6f 6465 6c5f 656e  itoring.model_en
+0001be40: 6470 6f69 6e74 2e4d 6f64 656c 456e 6470  dpoint.ModelEndp
+0001be50: 6f69 6e74 3a0a 2020 2020 2020 2020 2222  oint:.        ""
+0001be60: 220a 2020 2020 2020 2020 5265 7475 726e  ".        Return
+0001be70: 7320 6120 7369 6e67 6c65 2060 4d6f 6465  s a single `Mode
+0001be80: 6c45 6e64 706f 696e 7460 206f 626a 6563  lEndpoint` objec
+0001be90: 7420 7769 7468 2061 6464 6974 696f 6e61  t with additiona
+0001bea0: 6c20 6d65 7472 6963 7320 616e 6420 6665  l metrics and fe
+0001beb0: 6174 7572 6520 7265 6c61 7465 6420 6461  ature related da
+0001bec0: 7461 2e0a 0a20 2020 2020 2020 203a 7061  ta...        :pa
+0001bed0: 7261 6d20 7072 6f6a 6563 743a 2020 2020  ram project:    
+0001bee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001bef0: 5468 6520 6e61 6d65 206f 6620 7468 6520  The name of the 
+0001bf00: 7072 6f6a 6563 740a 2020 2020 2020 2020  project.        
+0001bf10: 3a70 6172 616d 2065 6e64 706f 696e 745f  :param endpoint_
+0001bf20: 6964 3a20 2020 2020 2020 2020 2020 2020  id:             
+0001bf30: 2020 2054 6865 2075 6e69 7175 6520 6964     The unique id
+0001bf40: 206f 6620 7468 6520 6d6f 6465 6c20 656e   of the model en
+0001bf50: 6470 6f69 6e74 2e0a 2020 2020 2020 2020  dpoint..        
+0001bf60: 3a70 6172 616d 2073 7461 7274 3a20 2020  :param start:   
+0001bf70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001bf80: 2020 2054 6865 2073 7461 7274 2074 696d     The start tim
+0001bf90: 6520 6f66 2074 6865 206d 6574 7269 6373  e of the metrics
+0001bfa0: 2e20 4361 6e20 6265 2072 6570 7265 7365  . Can be represe
+0001bfb0: 6e74 6564 2062 7920 6120 7374 7269 6e67  nted by a string
+0001bfc0: 2063 6f6e 7461 696e 696e 6720 616e 0a20   containing an. 
+0001bfd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001bfe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001bff0: 2020 2020 2020 2020 2020 5246 4320 3333            RFC 33
+0001c000: 3339 2074 696d 652c 2061 2055 6e69 7820  39 time, a Unix 
+0001c010: 7469 6d65 7374 616d 7020 696e 206d 696c  timestamp in mil
+0001c020: 6c69 7365 636f 6e64 732c 2061 2072 656c  liseconds, a rel
+0001c030: 6174 6976 6520 7469 6d65 2028 6027 6e6f  ative time (`'no
+0001c040: 7727 6020 6f72 0a20 2020 2020 2020 2020  w'` or.         
+0001c050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c070: 2020 6027 6e6f 772d 5b30 2d39 5d2b 5b6d    `'now-[0-9]+[m
+0001c080: 6864 5d27 602c 2077 6865 7265 2060 6d60  hd]'`, where `m`
+0001c090: 203d 206d 696e 7574 6573 2c20 6068 6020   = minutes, `h` 
+0001c0a0: 3d20 686f 7572 732c 2061 6e64 2060 2764  = hours, and `'d
+0001c0b0: 2760 203d 2064 6179 7329 2c20 6f72 0a20  '` = days), or. 
+0001c0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c0e0: 2020 2020 2020 2020 2020 3020 666f 7220            0 for 
+0001c0f0: 7468 6520 6561 726c 6965 7374 2074 696d  the earliest tim
+0001c100: 652e 0a20 2020 2020 2020 203a 7061 7261  e..        :para
+0001c110: 6d20 656e 643a 2020 2020 2020 2020 2020  m end:          
+0001c120: 2020 2020 2020 2020 2020 2020 2020 5468                Th
+0001c130: 6520 656e 6420 7469 6d65 206f 6620 7468  e end time of th
+0001c140: 6520 6d65 7472 6963 732e 2043 616e 2062  e metrics. Can b
+0001c150: 6520 7265 7072 6573 656e 7465 6420 6279  e represented by
+0001c160: 2061 2073 7472 696e 6720 636f 6e74 6169   a string contai
+0001c170: 6e69 6e67 2061 6e0a 2020 2020 2020 2020  ning an.        
+0001c180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c1a0: 2020 2052 4643 2033 3333 3920 7469 6d65     RFC 3339 time
+0001c1b0: 2c20 6120 556e 6978 2074 696d 6573 7461  , a Unix timesta
+0001c1c0: 6d70 2069 6e20 6d69 6c6c 6973 6563 6f6e  mp in millisecon
+0001c1d0: 6473 2c20 6120 7265 6c61 7469 7665 2074  ds, a relative t
+0001c1e0: 696d 6520 2860 276e 6f77 2760 206f 720a  ime (`'now'` or.
+0001c1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c210: 2020 2020 2020 2020 2020 2060 276e 6f77             `'now
+0001c220: 2d5b 302d 395d 2b5b 6d68 645d 2760 2c20  -[0-9]+[mhd]'`, 
+0001c230: 7768 6572 6520 606d 6020 3d20 6d69 6e75  where `m` = minu
+0001c240: 7465 732c 2060 6860 203d 2068 6f75 7273  tes, `h` = hours
+0001c250: 2c20 616e 6420 6027 6427 6020 3d20 6461  , and `'d'` = da
+0001c260: 7973 292c 206f 720a 2020 2020 2020 2020  ys), or.        
+0001c270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c290: 2020 2030 2066 6f72 2074 6865 2065 6172     0 for the ear
+0001c2a0: 6c69 6573 7420 7469 6d65 2e0a 2020 2020  liest time..    
+0001c2b0: 2020 2020 3a70 6172 616d 206d 6574 7269      :param metri
+0001c2c0: 6373 3a20 2020 2020 2020 2020 2020 2020  cs:             
+0001c2d0: 2020 2020 2020 2041 206c 6973 7420 6f66         A list of
+0001c2e0: 206d 6574 7269 6373 2074 6f20 7265 7475   metrics to retu
+0001c2f0: 726e 2066 6f72 2074 6865 206d 6f64 656c  rn for the model
+0001c300: 2065 6e64 706f 696e 742e 2054 6865 7265   endpoint. There
+0001c310: 2061 7265 2070 7265 2d64 6566 696e 6564   are pre-defined
+0001c320: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c340: 2020 2020 2020 2020 2020 2020 6d65 7472              metr
+0001c350: 6963 7320 666f 7220 6d6f 6465 6c20 656e  ics for model en
+0001c360: 6470 6f69 6e74 7320 7375 6368 2061 7320  dpoints such as 
+0001c370: 7072 6564 6963 7469 6f6e 735f 7065 725f  predictions_per_
+0001c380: 7365 636f 6e64 2061 6e64 0a20 2020 2020  second and.     
+0001c390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c3b0: 2020 2020 2020 6c61 7465 6e63 795f 6176        latency_av
+0001c3c0: 675f 356d 2062 7574 2061 6c73 6f20 6375  g_5m but also cu
+0001c3d0: 7374 6f6d 206d 6574 7269 6373 2064 6566  stom metrics def
+0001c3e0: 696e 6564 2062 7920 7468 6520 7573 6572  ined by the user
+0001c3f0: 2e20 506c 6561 7365 206e 6f74 6520 7468  . Please note th
+0001c400: 6174 0a20 2020 2020 2020 2020 2020 2020  at.             
+0001c410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c420: 2020 2020 2020 2020 2020 2020 2020 7468                th
+0001c430: 6573 6520 6d65 7472 6963 7320 6172 6520  ese metrics are 
+0001c440: 7374 6f72 6564 2069 6e20 7468 6520 7469  stored in the ti
+0001c450: 6d65 2073 6572 6965 7320 4442 2061 6e64  me series DB and
+0001c460: 2074 6865 2072 6573 756c 7473 2077 696c   the results wil
+0001c470: 6c20 6265 0a20 2020 2020 2020 2020 2020  l be.           
+0001c480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c4a0: 6170 7065 6172 6564 2075 6e64 6572 206d  appeared under m
+0001c4b0: 6f64 656c 5f65 6e64 706f 696e 742e 7370  odel_endpoint.sp
+0001c4c0: 6563 2e6d 6574 7269 6373 2e0a 2020 2020  ec.metrics..    
+0001c4d0: 2020 2020 3a70 6172 616d 2066 6561 7475      :param featu
+0001c4e0: 7265 5f61 6e61 6c79 7369 733a 2020 2020  re_analysis:    
+0001c4f0: 2020 2020 2020 2057 6865 6e20 5472 7565         When True
+0001c500: 2c20 7468 6520 6261 7365 2066 6561 7475  , the base featu
+0001c510: 7265 2073 7461 7469 7374 6963 7320 616e  re statistics an
+0001c520: 6420 6375 7272 656e 7420 6665 6174 7572  d current featur
+0001c530: 6520 7374 6174 6973 7469 6373 2077 696c  e statistics wil
+0001c540: 6c0a 2020 2020 2020 2020 2020 2020 2020  l.              
+0001c550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c560: 2020 2020 2020 2020 2020 2020 2062 6520               be 
+0001c570: 6164 6465 6420 746f 2074 6865 206f 7574  added to the out
+0001c580: 7075 7420 6f66 2074 6865 2072 6573 756c  put of the resul
+0001c590: 7469 6e67 206f 626a 6563 742e 0a0a 2020  ting object...  
+0001c5a0: 2020 2020 2020 3a72 6574 7572 6e3a 2041        :return: A
+0001c5b0: 2060 4d6f 6465 6c45 6e64 706f 696e 7460   `ModelEndpoint`
+0001c5c0: 206f 626a 6563 742e 0a20 2020 2020 2020   object..       
+0001c5d0: 2022 2222 0a0a 2020 2020 2020 2020 7061   """..        pa
+0001c5e0: 7468 203d 2066 2270 726f 6a65 6374 732f  th = f"projects/
+0001c5f0: 7b70 726f 6a65 6374 7d2f 6d6f 6465 6c2d  {project}/model-
+0001c600: 656e 6470 6f69 6e74 732f 7b65 6e64 706f  endpoints/{endpo
+0001c610: 696e 745f 6964 7d22 0a20 2020 2020 2020  int_id}".       
+0001c620: 2072 6573 706f 6e73 6520 3d20 7365 6c66   response = self
+0001c630: 2e61 7069 5f63 616c 6c28 0a20 2020 2020  .api_call(.     
+0001c640: 2020 2020 2020 206d 6574 686f 643d 2247         method="G
+0001c650: 4554 222c 0a20 2020 2020 2020 2020 2020  ET",.           
+0001c660: 2070 6174 683d 7061 7468 2c0a 2020 2020   path=path,.    
+0001c670: 2020 2020 2020 2020 7061 7261 6d73 3d7b          params={
+0001c680: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c690: 2022 7374 6172 7422 3a20 7374 6172 742c   "start": start,
+0001c6a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c6b0: 2022 656e 6422 3a20 656e 642c 0a20 2020   "end": end,.   
+0001c6c0: 2020 2020 2020 2020 2020 2020 2022 6d65               "me
+0001c6d0: 7472 6963 223a 206d 6574 7269 6373 206f  tric": metrics o
+0001c6e0: 7220 5b5d 2c0a 2020 2020 2020 2020 2020  r [],.          
+0001c6f0: 2020 2020 2020 2266 6561 7475 7265 5f61        "feature_a
+0001c700: 6e61 6c79 7369 7322 3a20 6665 6174 7572  nalysis": featur
+0001c710: 655f 616e 616c 7973 6973 2c0a 2020 2020  e_analysis,.    
+0001c720: 2020 2020 2020 2020 7d2c 0a20 2020 2020          },.     
+0001c730: 2020 2029 0a0a 2020 2020 2020 2020 7265     )..        re
+0001c740: 7475 726e 206d 6c72 756e 2e6d 6f64 656c  turn mlrun.model
+0001c750: 5f6d 6f6e 6974 6f72 696e 672e 6d6f 6465  _monitoring.mode
+0001c760: 6c5f 656e 6470 6f69 6e74 2e4d 6f64 656c  l_endpoint.Model
+0001c770: 456e 6470 6f69 6e74 2e66 726f 6d5f 6469  Endpoint.from_di
+0001c780: 6374 280a 2020 2020 2020 2020 2020 2020  ct(.            
+0001c790: 7265 7370 6f6e 7365 2e6a 736f 6e28 290a  response.json().
+0001c7a0: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
+0001c7b0: 6566 2070 6174 6368 5f6d 6f64 656c 5f65  ef patch_model_e
+0001c7c0: 6e64 706f 696e 7428 0a20 2020 2020 2020  ndpoint(.       
+0001c7d0: 2073 656c 662c 0a20 2020 2020 2020 2070   self,.        p
+0001c7e0: 726f 6a65 6374 3a20 7374 722c 0a20 2020  roject: str,.   
+0001c7f0: 2020 2020 2065 6e64 706f 696e 745f 6964       endpoint_id
+0001c800: 3a20 7374 722c 0a20 2020 2020 2020 2061  : str,.        a
+0001c810: 7474 7269 6275 7465 733a 2064 6963 742c  ttributes: dict,
+0001c820: 0a20 2020 2029 3a0a 2020 2020 2020 2020  .    ):.        
+0001c830: 2222 220a 2020 2020 2020 2020 5570 6461  """.        Upda
+0001c840: 7465 7320 6d6f 6465 6c20 656e 6470 6f69  tes model endpoi
+0001c850: 6e74 2077 6974 6820 7072 6f76 6964 6564  nt with provided
+0001c860: 2061 7474 7269 6275 7465 732e 0a0a 2020   attributes...  
+0001c870: 2020 2020 2020 3a70 6172 616d 2070 726f        :param pro
+0001c880: 6a65 6374 3a20 5468 6520 6e61 6d65 206f  ject: The name o
+0001c890: 6620 7468 6520 7072 6f6a 6563 742e 0a20  f the project.. 
+0001c8a0: 2020 2020 2020 203a 7061 7261 6d20 656e         :param en
+0001c8b0: 6470 6f69 6e74 5f69 643a 2054 6865 2069  dpoint_id: The i
+0001c8c0: 6420 6f66 2074 6865 2065 6e64 706f 696e  d of the endpoin
+0001c8d0: 742e 0a20 2020 2020 2020 203a 7061 7261  t..        :para
+0001c8e0: 6d20 6174 7472 6962 7574 6573 3a20 4469  m attributes: Di
+0001c8f0: 6374 696f 6e61 7279 206f 6620 6174 7472  ctionary of attr
+0001c900: 6962 7574 6573 2074 6861 7420 7769 6c6c  ibutes that will
+0001c910: 2062 6520 7573 6564 2066 6f72 2075 7064   be used for upd
+0001c920: 6174 6520 7468 6520 6d6f 6465 6c20 656e  ate the model en
+0001c930: 6470 6f69 6e74 2e20 5468 6520 6b65 7973  dpoint. The keys
+0001c940: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c950: 2020 2020 2020 2020 2020 2020 6f66 2074              of t
+0001c960: 6869 7320 6469 6374 696f 6e61 7279 2073  his dictionary s
+0001c970: 686f 756c 6420 6578 6973 7420 696e 2074  hould exist in t
+0001c980: 6865 2074 6172 6765 7420 7461 626c 652e  he target table.
+0001c990: 204e 6f74 6520 7468 6174 2074 6865 2076   Note that the v
+0001c9a0: 616c 7565 7320 7368 6f75 6c64 2062 650a  alues should be.
+0001c9b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c9c0: 2020 2020 2020 2020 2020 2066 726f 6d20             from 
+0001c9d0: 7479 7065 2073 7472 696e 6720 6f72 2066  type string or f
+0001c9e0: 726f 6d20 6120 7661 6c69 6420 6e75 6d65  rom a valid nume
+0001c9f0: 7269 6361 6c20 7479 7065 2073 7563 6820  rical type such 
+0001ca00: 6173 2069 6e74 206f 7220 666c 6f61 742e  as int or float.
+0001ca10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ca20: 2020 2020 2020 2020 2020 2020 204d 6f72               Mor
+0001ca30: 6520 6465 7461 696c 7320 6162 6f75 7420  e details about 
+0001ca40: 7468 6520 6d6f 6465 6c20 656e 6470 6f69  the model endpoi
+0001ca50: 6e74 2061 7661 696c 6162 6c65 2061 7474  nt available att
+0001ca60: 7269 6275 7465 7320 6361 6e20 6265 2066  ributes can be f
+0001ca70: 6f75 6e64 2075 6e64 6572 0a20 2020 2020  ound under.     
+0001ca80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ca90: 2020 2020 2020 3a70 793a 636c 6173 733a        :py:class:
+0001caa0: 607e 6d6c 7275 6e2e 6170 692e 7363 6865  `~mlrun.api.sche
+0001cab0: 6d61 732e 4d6f 6465 6c45 6e64 706f 696e  mas.ModelEndpoin
+0001cac0: 7460 2e0a 0a20 2020 2020 2020 2020 2020  t`...           
+0001cad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cae0: 4578 616d 706c 653a 3a0a 0a20 2020 2020  Example::..     
+0001caf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cb00: 2020 2020 2020 2020 2020 2023 2047 656e             # Gen
+0001cb10: 6572 6174 6520 6375 7272 656e 7420 7374  erate current st
+0001cb20: 6174 7320 666f 7220 7477 6f20 6665 6174  ats for two feat
+0001cb30: 7572 6573 0a20 2020 2020 2020 2020 2020  ures.           
+0001cb40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cb50: 2020 2020 2063 7572 7265 6e74 5f73 7461       current_sta
+0001cb60: 7473 203d 207b 2774 7664 5f73 756d 273a  ts = {'tvd_sum':
+0001cb70: 2032 2e32 2c0a 2020 2020 2020 2020 2020   2.2,.          
+0001cb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cba0: 2020 2020 2020 2027 7476 645f 6d65 616e         'tvd_mean
+0001cbb0: 273a 2030 2e35 2c0a 2020 2020 2020 2020  ': 0.5,.        
+0001cbc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cbd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cbe0: 2020 2020 2020 2020 2027 6865 6c6c 696e           'hellin
+0001cbf0: 6765 725f 7375 6d27 3a20 332e 362c 0a20  ger_sum': 3.6,. 
+0001cc00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc30: 2768 656c 6c69 6e67 6572 5f6d 6561 6e27  'hellinger_mean'
+0001cc40: 3a20 302e 392c 0a20 2020 2020 2020 2020  : 0.9,.         
+0001cc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cc70: 2020 2020 2020 2020 276b 6c64 5f73 756d          'kld_sum
+0001cc80: 273a 2032 342e 322c 0a20 2020 2020 2020  ': 24.2,.       
+0001cc90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ccb0: 2020 2020 2020 2020 2020 276b 6c64 5f6d            'kld_m
+0001ccc0: 6561 6e27 3a20 362e 302c 0a20 2020 2020  ean': 6.0,.     
+0001ccd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ccf0: 2020 2020 2020 2020 2020 2020 2766 3127              'f1'
+0001cd00: 3a20 7b27 7476 6427 3a20 302e 352c 2027  : {'tvd': 0.5, '
+0001cd10: 6865 6c6c 696e 6765 7227 3a20 312e 302c  hellinger': 1.0,
+0001cd20: 2027 6b6c 6427 3a20 362e 347d 2c0a 2020   'kld': 6.4},.  
+0001cd30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cd40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cd50: 2020 2020 2020 2020 2020 2020 2020 2027                 '
+0001cd60: 6632 273a 207b 2774 7664 273a 2030 2e35  f2': {'tvd': 0.5
+0001cd70: 2c20 2768 656c 6c69 6e67 6572 273a 2031  , 'hellinger': 1
+0001cd80: 2e30 2c20 276b 6c64 273a 2036 2e35 7d7d  .0, 'kld': 6.5}}
+0001cd90: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001cda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cdb0: 2020 2320 4372 6561 7465 2061 7474 7269    # Create attri
+0001cdc0: 6275 7465 7320 6469 6374 696f 6e61 7279  butes dictionary
+0001cdd0: 2061 6363 6f72 6469 6e67 2074 6f20 7468   according to th
+0001cde0: 6520 7265 7175 6972 6564 2066 6f72 6d61  e required forma
+0001cdf0: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
+0001ce00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce10: 2020 6174 7472 6962 7574 6573 203d 207b    attributes = {
+0001ce20: 6063 7572 7265 6e74 5f73 7461 7473 603a  `current_stats`:
+0001ce30: 206a 736f 6e2e 6475 6d70 7328 6375 7272   json.dumps(curr
+0001ce40: 656e 745f 7374 6174 7329 2c0a 2020 2020  ent_stats),.    
+0001ce50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce70: 2020 2020 2020 2020 2020 6064 7269 6674            `drift
+0001ce80: 5f73 7461 7475 7360 3a20 2244 5249 4654  _status`: "DRIFT
+0001ce90: 5f44 4554 4543 5445 4422 7d0a 0a20 2020  _DETECTED"}..   
+0001cea0: 2020 2020 2022 2222 0a0a 2020 2020 2020       """..      
+0001ceb0: 2020 6174 7472 6962 7574 6573 203d 207b    attributes = {
+0001cec0: 2261 7474 7269 6275 7465 7322 3a20 5f61  "attributes": _a
+0001ced0: 735f 6a73 6f6e 2861 7474 7269 6275 7465  s_json(attribute
+0001cee0: 7329 7d0a 2020 2020 2020 2020 7061 7468  s)}.        path
+0001cef0: 203d 2066 2270 726f 6a65 6374 732f 7b70   = f"projects/{p
+0001cf00: 726f 6a65 6374 7d2f 6d6f 6465 6c2d 656e  roject}/model-en
+0001cf10: 6470 6f69 6e74 732f 7b65 6e64 706f 696e  dpoints/{endpoin
+0001cf20: 745f 6964 7d22 0a20 2020 2020 2020 2073  t_id}".        s
+0001cf30: 656c 662e 6170 695f 6361 6c6c 280a 2020  elf.api_call(.  
+0001cf40: 2020 2020 2020 2020 2020 6d65 7468 6f64            method
+0001cf50: 3d22 5041 5443 4822 2c0a 2020 2020 2020  ="PATCH",.      
+0001cf60: 2020 2020 2020 7061 7468 3d70 6174 682c        path=path,
+0001cf70: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
+0001cf80: 616d 733d 6174 7472 6962 7574 6573 2c0a  ams=attributes,.
+0001cf90: 2020 2020 2020 2020 290a 0a20 2020 2064          )..    d
+0001cfa0: 6566 2063 7265 6174 655f 6d61 726b 6574  ef create_market
+0001cfb0: 706c 6163 655f 736f 7572 6365 280a 2020  place_source(.  
+0001cfc0: 2020 2020 2020 7365 6c66 2c20 736f 7572        self, sour
+0001cfd0: 6365 3a20 556e 696f 6e5b 6469 6374 2c20  ce: Union[dict, 
+0001cfe0: 7363 6865 6d61 732e 496e 6465 7865 644d  schemas.IndexedM
+0001cff0: 6172 6b65 7470 6c61 6365 536f 7572 6365  arketplaceSource
+0001d000: 5d0a 2020 2020 293a 0a20 2020 2020 2020  ].    ):.       
+0001d010: 2022 2222 0a20 2020 2020 2020 2041 6464   """.        Add
+0001d020: 2061 206e 6577 206d 6172 6b65 7470 6c61   a new marketpla
+0001d030: 6365 2073 6f75 7263 652e 0a0a 2020 2020  ce source...    
+0001d040: 2020 2020 4d4c 5275 6e20 6d61 696e 7461      MLRun mainta
+0001d050: 696e 7320 616e 206f 7264 6572 6564 206c  ins an ordered l
+0001d060: 6973 7420 6f66 206d 6172 6b65 7470 6c61  ist of marketpla
+0001d070: 6365 2073 6f75 7263 6573 2028 e280 9c73  ce sources (...s
+0001d080: 6f75 7263 6573 e280 9d29 2045 6163 6820  ources...) Each 
+0001d090: 736f 7572 6365 2068 6173 0a20 2020 2020  source has.     
+0001d0a0: 2020 2069 7473 2064 6574 6169 6c73 2072     its details r
+0001d0b0: 6567 6973 7465 7265 6420 616e 6420 6974  egistered and it
+0001d0c0: 7320 6f72 6465 7220 7769 7468 696e 2074  s order within t
+0001d0d0: 6865 206c 6973 742e 2057 6865 6e20 6372  he list. When cr
+0001d0e0: 6561 7469 6e67 2061 206e 6577 2073 6f75  eating a new sou
+0001d0f0: 7263 652c 2074 6865 2073 7065 6369 616c  rce, the special
+0001d100: 206f 7264 6572 2060 602d 3160 600a 2020   order ``-1``.  
+0001d110: 2020 2020 2020 6361 6e20 6265 2075 7365        can be use
+0001d120: 6420 746f 206d 6172 6b20 7468 6973 2073  d to mark this s
+0001d130: 6f75 7263 6520 6173 206c 6173 7420 696e  ource as last in
+0001d140: 2074 6865 206c 6973 742e 2048 6f77 6576   the list. Howev
+0001d150: 6572 2c20 6f6e 6365 2074 6865 2073 6f75  er, once the sou
+0001d160: 7263 6520 6973 2069 6e20 7468 6520 4d4c  rce is in the ML
+0001d170: 5275 6e20 6c69 7374 2c0a 2020 2020 2020  Run list,.      
+0001d180: 2020 6974 7320 6f72 6465 7220 7769 6c6c    its order will
+0001d190: 2061 6c77 6179 7320 6265 2060 603e 3060   always be ``>0`
+0001d1a0: 602e 0a0a 2020 2020 2020 2020 5468 6520  `...        The 
+0001d1b0: 676c 6f62 616c 206d 6172 6b65 7470 6c61  global marketpla
+0001d1c0: 6365 2073 6f75 7263 6520 616c 7761 7973  ce source always
+0001d1d0: 2065 7869 7374 7320 696e 2074 6865 206c   exists in the l
+0001d1e0: 6973 742c 2061 6e64 2069 7320 616c 7761  ist, and is alwa
+0001d1f0: 7973 2074 6865 206c 6173 7420 736f 7572  ys the last sour
+0001d200: 6365 0a20 2020 2020 2020 2028 6060 6f72  ce.        (``or
+0001d210: 6465 7220 3d20 2d31 6060 292e 2049 7420  der = -1``). It 
+0001d220: 6361 6e6e 6f74 2062 6520 6d6f 6469 6669  cannot be modifi
+0001d230: 6564 206e 6f72 2063 616e 2069 7420 6265  ed nor can it be
+0001d240: 206d 6f76 6564 2074 6f20 616e 6f74 6865   moved to anothe
+0001d250: 7220 6f72 6465 7220 696e 2074 6865 206c  r order in the l
+0001d260: 6973 742e 0a0a 2020 2020 2020 2020 5468  ist...        Th
+0001d270: 6520 736f 7572 6365 206f 626a 6563 7420  e source object 
+0001d280: 6d61 7920 636f 6e74 6169 6e20 6372 6564  may contain cred
+0001d290: 656e 7469 616c 7320 7768 6963 6820 6172  entials which ar
+0001d2a0: 6520 6e65 6564 6564 2074 6f20 6163 6365  e needed to acce
+0001d2b0: 7373 2074 6865 2064 6174 6173 746f 7265  ss the datastore
+0001d2c0: 2077 6865 7265 2074 6865 2073 6f75 7263   where the sourc
+0001d2d0: 6520 6973 2073 746f 7265 642e 0a20 2020  e is stored..   
+0001d2e0: 2020 2020 2054 6865 7365 2063 7265 6465       These crede
+0001d2f0: 6e74 6961 6c73 2061 7265 206e 6f74 206b  ntials are not k
+0001d300: 6570 7420 696e 2074 6865 204d 4c52 756e  ept in the MLRun
+0001d310: 2044 422c 2062 7574 2061 7265 2073 746f   DB, but are sto
+0001d320: 7265 6420 696e 7369 6465 2061 206b 7562  red inside a kub
+0001d330: 6572 6e65 7465 7320 7365 6372 6574 206f  ernetes secret o
+0001d340: 626a 6563 7420 6d61 696e 7461 696e 6564  bject maintained
+0001d350: 2062 790a 2020 2020 2020 2020 4d4c 5275   by.        MLRu
+0001d360: 6e2e 2054 6865 7920 6172 6520 6e6f 7420  n. They are not 
+0001d370: 7265 7475 726e 6564 2074 6872 6f75 6768  returned through
+0001d380: 2061 6e79 2041 5049 2066 726f 6d20 4d4c   any API from ML
+0001d390: 5275 6e2e 0a0a 2020 2020 2020 2020 4578  Run...        Ex
+0001d3a0: 616d 706c 653a 3a0a 0a20 2020 2020 2020  ample::..       
+0001d3b0: 2020 2020 2069 6d70 6f72 7420 6d6c 7275       import mlru
+0001d3c0: 6e2e 6170 692e 7363 6865 6d61 730a 0a20  n.api.schemas.. 
+0001d3d0: 2020 2020 2020 2020 2020 2023 2041 6464             # Add
+0001d3e0: 2061 2070 7269 7661 7465 2073 6f75 7263   a private sourc
+0001d3f0: 6520 6173 2074 6865 206c 6173 7420 6f6e  e as the last on
+0001d400: 6520 2877 696c 6c20 6265 2023 3120 696e  e (will be #1 in
+0001d410: 2074 6865 206c 6973 7429 0a20 2020 2020   the list).     
+0001d420: 2020 2020 2020 2070 7269 7661 7465 5f73         private_s
+0001d430: 6f75 7263 6520 3d20 6d6c 7275 6e2e 6170  ource = mlrun.ap
+0001d440: 692e 7363 6865 6d61 732e 496e 6465 7865  i.schemas.Indexe
+0001d450: 644d 6172 6b65 7470 6c61 6365 536f 7572  dMarketplaceSour
+0001d460: 6365 280a 2020 2020 2020 2020 2020 2020  ce(.            
+0001d470: 2020 2020 6f72 6465 723d 2d31 2c0a 2020      order=-1,.  
+0001d480: 2020 2020 2020 2020 2020 2020 2020 736f                so
+0001d490: 7572 6365 3d6d 6c72 756e 2e61 7069 2e73  urce=mlrun.api.s
+0001d4a0: 6368 656d 6173 2e4d 6172 6b65 7470 6c61  chemas.Marketpla
+0001d4b0: 6365 536f 7572 6365 280a 2020 2020 2020  ceSource(.      
+0001d4c0: 2020 2020 2020 2020 2020 2020 2020 6d65                me
+0001d4d0: 7461 6461 7461 3d6d 6c72 756e 2e61 7069  tadata=mlrun.api
+0001d4e0: 2e73 6368 656d 6173 2e4d 6172 6b65 7470  .schemas.Marketp
+0001d4f0: 6c61 6365 4f62 6a65 6374 4d65 7461 6461  laceObjectMetada
+0001d500: 7461 286e 616d 653d 2270 7269 7622 2c20  ta(name="priv", 
+0001d510: 6465 7363 7269 7074 696f 6e3d 2261 2070  description="a p
+0001d520: 7269 7661 7465 2073 6f75 7263 6522 292c  rivate source"),
+0001d530: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001d540: 2020 2020 2073 7065 633d 6d6c 7275 6e2e       spec=mlrun.
+0001d550: 6170 692e 7363 6865 6d61 732e 4d61 726b  api.schemas.Mark
+0001d560: 6574 706c 6163 6553 6f75 7263 6553 7065  etplaceSourceSpe
+0001d570: 6328 7061 7468 3d22 2f6c 6f63 616c 2f70  c(path="/local/p
+0001d580: 6174 682f 746f 2f73 6f75 7263 6522 2c20  ath/to/source", 
+0001d590: 6368 616e 6e65 6c3d 2264 6576 656c 6f70  channel="develop
+0001d5a0: 6d65 6e74 2229 0a20 2020 2020 2020 2020  ment").         
+0001d5b0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0001d5c0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+0001d5d0: 2020 2064 622e 6372 6561 7465 5f6d 6172     db.create_mar
+0001d5e0: 6b65 7470 6c61 6365 5f73 6f75 7263 6528  ketplace_source(
+0001d5f0: 7072 6976 6174 655f 736f 7572 6365 290a  private_source).
+0001d600: 0a20 2020 2020 2020 2020 2020 2023 2041  .            # A
+0001d610: 6464 2061 6e6f 7468 6572 2073 6f75 7263  dd another sourc
+0001d620: 6520 6173 2031 7374 2069 6e20 7468 6520  e as 1st in the 
+0001d630: 6c69 7374 202d 2077 696c 6c20 7075 7368  list - will push
+0001d640: 2070 7265 7669 6f75 7320 6f6e 6520 746f   previous one to
+0001d650: 2062 6520 2332 0a20 2020 2020 2020 2020   be #2.         
+0001d660: 2020 2061 6e6f 7468 6572 5f73 6f75 7263     another_sourc
+0001d670: 6520 3d20 6d6c 7275 6e2e 6170 692e 7363  e = mlrun.api.sc
+0001d680: 6865 6d61 732e 496e 6465 7865 644d 6172  hemas.IndexedMar
+0001d690: 6b65 7470 6c61 6365 536f 7572 6365 280a  ketplaceSource(.
+0001d6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d6b0: 6f72 6465 723d 312c 0a20 2020 2020 2020  order=1,.       
+0001d6c0: 2020 2020 2020 2020 2073 6f75 7263 653d           source=
+0001d6d0: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
+0001d6e0: 732e 4d61 726b 6574 706c 6163 6553 6f75  s.MarketplaceSou
+0001d6f0: 7263 6528 0a20 2020 2020 2020 2020 2020  rce(.           
+0001d700: 2020 2020 2020 2020 206d 6574 6164 6174           metadat
+0001d710: 613d 6d6c 7275 6e2e 6170 692e 7363 6865  a=mlrun.api.sche
+0001d720: 6d61 732e 4d61 726b 6574 706c 6163 654f  mas.MarketplaceO
+0001d730: 626a 6563 744d 6574 6164 6174 6128 6e61  bjectMetadata(na
+0001d740: 6d65 3d22 7072 6976 2d32 222c 2064 6573  me="priv-2", des
+0001d750: 6372 6970 7469 6f6e 3d22 616e 6f74 6865  cription="anothe
+0001d760: 7220 736f 7572 6365 2229 2c0a 2020 2020  r source"),.    
+0001d770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d780: 7370 6563 3d6d 6c72 756e 2e61 7069 2e73  spec=mlrun.api.s
+0001d790: 6368 656d 6173 2e4d 6172 6b65 7470 6c61  chemas.Marketpla
+0001d7a0: 6365 536f 7572 6365 5370 6563 280a 2020  ceSourceSpec(.  
+0001d7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d7c0: 2020 2020 2020 7061 7468 3d22 2f6c 6f63        path="/loc
+0001d7d0: 616c 2f70 6174 682f 746f 2f73 6f75 7263  al/path/to/sourc
+0001d7e0: 652f 3222 2c0a 2020 2020 2020 2020 2020  e/2",.          
+0001d7f0: 2020 2020 2020 2020 2020 2020 2020 6368                ch
+0001d800: 616e 6e65 6c3d 2264 6576 656c 6f70 6d65  annel="developme
+0001d810: 6e74 222c 0a20 2020 2020 2020 2020 2020  nt",.           
+0001d820: 2020 2020 2020 2020 2020 2020 2063 7265               cre
+0001d830: 6465 6e74 6961 6c73 3d7b 2e2e 2e7d 0a20  dentials={...}. 
+0001d840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d850: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+0001d860: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+0001d870: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+0001d880: 2064 622e 6372 6561 7465 5f6d 6172 6b65   db.create_marke
+0001d890: 7470 6c61 6365 5f73 6f75 7263 6528 616e  tplace_source(an
+0001d8a0: 6f74 6865 725f 736f 7572 6365 290a 0a20  other_source).. 
+0001d8b0: 2020 2020 2020 203a 7061 7261 6d20 736f         :param so
+0001d8c0: 7572 6365 3a20 5468 6520 736f 7572 6365  urce: The source
+0001d8d0: 2061 6e64 2069 7473 206f 7264 6572 2c20   and its order, 
+0001d8e0: 6f66 2074 7970 650a 2020 2020 2020 2020  of type.        
+0001d8f0: 2020 2020 3a70 793a 636c 6173 733a 607e      :py:class:`~
+0001d900: 6d6c 7275 6e2e 6170 692e 7363 6865 6d61  mlrun.api.schema
+0001d910: 732e 6d61 726b 6574 706c 6163 652e 496e  s.marketplace.In
+0001d920: 6465 7865 644d 6172 6b65 7470 6c61 6365  dexedMarketplace
+0001d930: 536f 7572 6365 602c 206f 7220 696e 2064  Source`, or in d
+0001d940: 6963 7469 6f6e 6172 7920 666f 726d 2e0a  ictionary form..
+0001d950: 2020 2020 2020 2020 3a72 6574 7572 6e73          :returns
+0001d960: 3a20 5468 6520 736f 7572 6365 206f 626a  : The source obj
+0001d970: 6563 7420 6173 2069 6e73 6572 7465 6420  ect as inserted 
+0001d980: 696e 746f 2074 6865 2064 6174 6162 6173  into the databas
+0001d990: 652c 2077 6974 6820 6372 6564 656e 7469  e, with credenti
+0001d9a0: 616c 7320 7374 7269 7070 6564 2e0a 2020  als stripped..  
+0001d9b0: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0001d9c0: 2020 7061 7468 203d 2022 6d61 726b 6574    path = "market
+0001d9d0: 706c 6163 652f 736f 7572 6365 7322 0a20  place/sources". 
+0001d9e0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+0001d9f0: 616e 6365 2873 6f75 7263 652c 2073 6368  ance(source, sch
+0001da00: 656d 6173 2e49 6e64 6578 6564 4d61 726b  emas.IndexedMark
+0001da10: 6574 706c 6163 6553 6f75 7263 6529 3a0a  etplaceSource):.
+0001da20: 2020 2020 2020 2020 2020 2020 736f 7572              sour
+0001da30: 6365 203d 2073 6f75 7263 652e 6469 6374  ce = source.dict
+0001da40: 2829 0a20 2020 2020 2020 2072 6573 706f  ().        respo
+0001da50: 6e73 6520 3d20 7365 6c66 2e61 7069 5f63  nse = self.api_c
+0001da60: 616c 6c28 6d65 7468 6f64 3d22 504f 5354  all(method="POST
+0001da70: 222c 2070 6174 683d 7061 7468 2c20 6a73  ", path=path, js
+0001da80: 6f6e 3d73 6f75 7263 6529 0a20 2020 2020  on=source).     
+0001da90: 2020 2072 6574 7572 6e20 7363 6865 6d61     return schema
+0001daa0: 732e 496e 6465 7865 644d 6172 6b65 7470  s.IndexedMarketp
+0001dab0: 6c61 6365 536f 7572 6365 282a 2a72 6573  laceSource(**res
+0001dac0: 706f 6e73 652e 6a73 6f6e 2829 290a 0a20  ponse.json()).. 
+0001dad0: 2020 2064 6566 2073 746f 7265 5f6d 6172     def store_mar
+0001dae0: 6b65 7470 6c61 6365 5f73 6f75 7263 6528  ketplace_source(
+0001daf0: 0a20 2020 2020 2020 2073 656c 662c 2073  .        self, s
+0001db00: 6f75 7263 655f 6e61 6d65 3a20 7374 722c  ource_name: str,
+0001db10: 2073 6f75 7263 653a 2055 6e69 6f6e 5b64   source: Union[d
+0001db20: 6963 742c 2073 6368 656d 6173 2e49 6e64  ict, schemas.Ind
+0001db30: 6578 6564 4d61 726b 6574 706c 6163 6553  exedMarketplaceS
+0001db40: 6f75 7263 655d 0a20 2020 2029 3a0a 2020  ource].    ):.  
+0001db50: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+0001db60: 2020 4372 6561 7465 206f 7220 7265 706c    Create or repl
+0001db70: 6163 6520 6120 6d61 726b 6574 706c 6163  ace a marketplac
+0001db80: 6520 736f 7572 6365 2e0a 2020 2020 2020  e source..      
+0001db90: 2020 466f 7220 616e 2065 7861 6d70 6c65    For an example
+0001dba0: 206f 6620 7468 6520 736f 7572 6365 2066   of the source f
+0001dbb0: 6f72 6d61 7420 616e 6420 6578 706c 616e  ormat and explan
+0001dbc0: 6174 696f 6e20 6f66 2074 6865 2073 6f75  ation of the sou
+0001dbd0: 7263 6520 6f72 6465 7220 6c6f 6769 632c  rce order logic,
+0001dbe0: 0a20 2020 2020 2020 2070 6c65 6173 6520  .        please 
+0001dbf0: 7365 6520 3a70 793a 6675 6e63 3a60 7e63  see :py:func:`~c
+0001dc00: 7265 6174 655f 6d61 726b 6574 706c 6163  reate_marketplac
+0001dc10: 655f 736f 7572 6365 602e 2054 6869 7320  e_source`. This 
+0001dc20: 6d65 7468 6f64 2063 616e 2062 6520 7573  method can be us
+0001dc30: 6564 2074 6f20 6d6f 6469 6679 2074 6865  ed to modify the
+0001dc40: 2073 6f75 7263 6520 6974 7365 6c66 206f   source itself o
+0001dc50: 7220 6974 730a 2020 2020 2020 2020 6f72  r its.        or
+0001dc60: 6465 7220 696e 2074 6865 206c 6973 7420  der in the list 
+0001dc70: 6f66 2073 6f75 7263 6573 2e0a 0a20 2020  of sources...   
+0001dc80: 2020 2020 203a 7061 7261 6d20 736f 7572       :param sour
+0001dc90: 6365 5f6e 616d 653a 204e 616d 6520 6f66  ce_name: Name of
+0001dca0: 2074 6865 2073 6f75 7263 6520 6f62 6a65   the source obje
+0001dcb0: 6374 2074 6f20 6d6f 6469 6679 2f63 7265  ct to modify/cre
+0001dcc0: 6174 652e 2049 7420 6d75 7374 206d 6174  ate. It must mat
+0001dcd0: 6368 2074 6865 2060 6073 6f75 7263 652e  ch the ``source.
+0001dce0: 6d65 7461 6461 7461 2e6e 616d 6560 600a  metadata.name``.
+0001dcf0: 2020 2020 2020 2020 2020 2020 7061 7261              para
+0001dd00: 6d65 7465 7220 696e 2074 6865 2073 6f75  meter in the sou
+0001dd10: 7263 6520 6974 7365 6c66 2e0a 2020 2020  rce itself..    
+0001dd20: 2020 2020 3a70 6172 616d 2073 6f75 7263      :param sourc
+0001dd30: 653a 2053 6f75 7263 6520 6f62 6a65 6374  e: Source object
+0001dd40: 2074 6f20 7374 6f72 6520 696e 2074 6865   to store in the
+0001dd50: 2064 6174 6162 6173 652e 0a20 2020 2020   database..     
+0001dd60: 2020 203a 7265 7475 726e 733a 2054 6865     :returns: The
+0001dd70: 2073 6f75 7263 6520 6f62 6a65 6374 2061   source object a
+0001dd80: 7320 7374 6f72 6564 2069 6e20 7468 6520  s stored in the 
+0001dd90: 4442 2e0a 2020 2020 2020 2020 2222 220a  DB..        """.
+0001dda0: 2020 2020 2020 2020 7061 7468 203d 2066          path = f
+0001ddb0: 226d 6172 6b65 7470 6c61 6365 2f73 6f75  "marketplace/sou
+0001ddc0: 7263 6573 2f7b 736f 7572 6365 5f6e 616d  rces/{source_nam
+0001ddd0: 657d 220a 2020 2020 2020 2020 6966 2069  e}".        if i
+0001dde0: 7369 6e73 7461 6e63 6528 736f 7572 6365  sinstance(source
+0001ddf0: 2c20 7363 6865 6d61 732e 496e 6465 7865  , schemas.Indexe
+0001de00: 644d 6172 6b65 7470 6c61 6365 536f 7572  dMarketplaceSour
+0001de10: 6365 293a 0a20 2020 2020 2020 2020 2020  ce):.           
+0001de20: 2073 6f75 7263 6520 3d20 736f 7572 6365   source = source
+0001de30: 2e64 6963 7428 290a 0a20 2020 2020 2020  .dict()..       
+0001de40: 2072 6573 706f 6e73 6520 3d20 7365 6c66   response = self
+0001de50: 2e61 7069 5f63 616c 6c28 6d65 7468 6f64  .api_call(method
+0001de60: 3d22 5055 5422 2c20 7061 7468 3d70 6174  ="PUT", path=pat
+0001de70: 682c 206a 736f 6e3d 736f 7572 6365 290a  h, json=source).
+0001de80: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0001de90: 6368 656d 6173 2e49 6e64 6578 6564 4d61  chemas.IndexedMa
+0001dea0: 726b 6574 706c 6163 6553 6f75 7263 6528  rketplaceSource(
+0001deb0: 2a2a 7265 7370 6f6e 7365 2e6a 736f 6e28  **response.json(
+0001dec0: 2929 0a0a 2020 2020 6465 6620 6c69 7374  ))..    def list
+0001ded0: 5f6d 6172 6b65 7470 6c61 6365 5f73 6f75  _marketplace_sou
+0001dee0: 7263 6573 2873 656c 6629 3a0a 2020 2020  rces(self):.    
+0001def0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0001df00: 4c69 7374 206d 6172 6b65 7470 6c61 6365  List marketplace
+0001df10: 2073 6f75 7263 6573 2069 6e20 7468 6520   sources in the 
+0001df20: 4d4c 5275 6e20 4442 2e0a 2020 2020 2020  MLRun DB..      
+0001df30: 2020 2222 220a 2020 2020 2020 2020 7061    """.        pa
+0001df40: 7468 203d 2022 6d61 726b 6574 706c 6163  th = "marketplac
+0001df50: 652f 736f 7572 6365 7322 0a20 2020 2020  e/sources".     
+0001df60: 2020 2072 6573 706f 6e73 6520 3d20 7365     response = se
+0001df70: 6c66 2e61 7069 5f63 616c 6c28 6d65 7468  lf.api_call(meth
+0001df80: 6f64 3d22 4745 5422 2c20 7061 7468 3d70  od="GET", path=p
+0001df90: 6174 6829 2e6a 736f 6e28 290a 2020 2020  ath).json().    
+0001dfa0: 2020 2020 7265 7375 6c74 7320 3d20 5b5d      results = []
+0001dfb0: 0a20 2020 2020 2020 2066 6f72 2069 7465  .        for ite
+0001dfc0: 6d20 696e 2072 6573 706f 6e73 653a 0a20  m in response:. 
+0001dfd0: 2020 2020 2020 2020 2020 2072 6573 756c             resul
+0001dfe0: 7473 2e61 7070 656e 6428 7363 6865 6d61  ts.append(schema
+0001dff0: 732e 496e 6465 7865 644d 6172 6b65 7470  s.IndexedMarketp
+0001e000: 6c61 6365 536f 7572 6365 282a 2a69 7465  laceSource(**ite
+0001e010: 6d29 290a 2020 2020 2020 2020 7265 7475  m)).        retu
+0001e020: 726e 2072 6573 756c 7473 0a0a 2020 2020  rn results..    
+0001e030: 6465 6620 6765 745f 6d61 726b 6574 706c  def get_marketpl
+0001e040: 6163 655f 736f 7572 6365 2873 656c 662c  ace_source(self,
+0001e050: 2073 6f75 7263 655f 6e61 6d65 3a20 7374   source_name: st
+0001e060: 7229 3a0a 2020 2020 2020 2020 2222 220a  r):.        """.
+0001e070: 2020 2020 2020 2020 5265 7472 6965 7665          Retrieve
+0001e080: 2061 206d 6172 6b65 7470 6c61 6365 2073   a marketplace s
+0001e090: 6f75 7263 6520 6672 6f6d 2074 6865 2044  ource from the D
+0001e0a0: 422e 0a0a 2020 2020 2020 2020 3a70 6172  B...        :par
+0001e0b0: 616d 2073 6f75 7263 655f 6e61 6d65 3a20  am source_name: 
+0001e0c0: 4e61 6d65 206f 6620 7468 6520 6d61 726b  Name of the mark
+0001e0d0: 6574 706c 6163 6520 736f 7572 6365 2074  etplace source t
+0001e0e0: 6f20 7265 7472 6965 7665 2e0a 2020 2020  o retrieve..    
+0001e0f0: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0001e100: 7061 7468 203d 2066 226d 6172 6b65 7470  path = f"marketp
+0001e110: 6c61 6365 2f73 6f75 7263 6573 2f7b 736f  lace/sources/{so
+0001e120: 7572 6365 5f6e 616d 657d 220a 2020 2020  urce_name}".    
+0001e130: 2020 2020 7265 7370 6f6e 7365 203d 2073      response = s
+0001e140: 656c 662e 6170 695f 6361 6c6c 286d 6574  elf.api_call(met
+0001e150: 686f 643d 2247 4554 222c 2070 6174 683d  hod="GET", path=
+0001e160: 7061 7468 290a 2020 2020 2020 2020 7265  path).        re
+0001e170: 7475 726e 2073 6368 656d 6173 2e49 6e64  turn schemas.Ind
+0001e180: 6578 6564 4d61 726b 6574 706c 6163 6553  exedMarketplaceS
+0001e190: 6f75 7263 6528 2a2a 7265 7370 6f6e 7365  ource(**response
+0001e1a0: 2e6a 736f 6e28 2929 0a0a 2020 2020 6465  .json())..    de
+0001e1b0: 6620 6465 6c65 7465 5f6d 6172 6b65 7470  f delete_marketp
+0001e1c0: 6c61 6365 5f73 6f75 7263 6528 7365 6c66  lace_source(self
+0001e1d0: 2c20 736f 7572 6365 5f6e 616d 653a 2073  , source_name: s
+0001e1e0: 7472 293a 0a20 2020 2020 2020 2022 2222  tr):.        """
+0001e1f0: 0a20 2020 2020 2020 2044 656c 6574 6520  .        Delete 
+0001e200: 6120 6d61 726b 6574 706c 6163 6520 736f  a marketplace so
+0001e210: 7572 6365 2066 726f 6d20 7468 6520 4442  urce from the DB
+0001e220: 2e0a 2020 2020 2020 2020 5468 6520 736f  ..        The so
+0001e230: 7572 6365 2077 696c 6c20 6265 2064 656c  urce will be del
+0001e240: 6574 6564 2066 726f 6d20 7468 6520 6c69  eted from the li
+0001e250: 7374 2c20 616e 6420 616e 7920 666f 6c6c  st, and any foll
+0001e260: 6f77 696e 6720 736f 7572 6365 7320 7769  owing sources wi
+0001e270: 6c6c 2062 6520 7072 6f6d 6f74 6564 202d  ll be promoted -
+0001e280: 2066 6f72 2065 7861 6d70 6c65 2c20 6966   for example, if
+0001e290: 2074 6865 0a20 2020 2020 2020 2031 7374   the.        1st
+0001e2a0: 2073 6f75 7263 6520 6973 2064 656c 6574   source is delet
+0001e2b0: 6564 2c20 7468 6520 326e 6420 736f 7572  ed, the 2nd sour
+0001e2c0: 6365 2077 696c 6c20 6265 636f 6d65 2023  ce will become #
+0001e2d0: 3120 696e 2074 6865 206c 6973 742e 0a20  1 in the list.. 
+0001e2e0: 2020 2020 2020 2054 6865 2067 6c6f 6261         The globa
+0001e2f0: 6c20 6d61 726b 6574 706c 6163 6520 736f  l marketplace so
+0001e300: 7572 6365 2063 616e 6e6f 7420 6265 2064  urce cannot be d
+0001e310: 656c 6574 6564 2e0a 0a20 2020 2020 2020  eleted...       
+0001e320: 203a 7061 7261 6d20 736f 7572 6365 5f6e   :param source_n
+0001e330: 616d 653a 204e 616d 6520 6f66 2074 6865  ame: Name of the
+0001e340: 206d 6172 6b65 7470 6c61 6365 2073 6f75   marketplace sou
+0001e350: 7263 6520 746f 2064 656c 6574 652e 0a20  rce to delete.. 
+0001e360: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+0001e370: 2020 2070 6174 6820 3d20 6622 6d61 726b     path = f"mark
+0001e380: 6574 706c 6163 652f 736f 7572 6365 732f  etplace/sources/
+0001e390: 7b73 6f75 7263 655f 6e61 6d65 7d22 0a20  {source_name}". 
+0001e3a0: 2020 2020 2020 2073 656c 662e 6170 695f         self.api_
+0001e3b0: 6361 6c6c 286d 6574 686f 643d 2244 454c  call(method="DEL
+0001e3c0: 4554 4522 2c20 7061 7468 3d70 6174 6829  ETE", path=path)
+0001e3d0: 0a0a 2020 2020 6465 6620 6765 745f 6d61  ..    def get_ma
+0001e3e0: 726b 6574 706c 6163 655f 6361 7461 6c6f  rketplace_catalo
+0001e3f0: 6728 0a20 2020 2020 2020 2073 656c 662c  g(.        self,
+0001e400: 0a20 2020 2020 2020 2073 6f75 7263 655f  .        source_
+0001e410: 6e61 6d65 3a20 7374 722c 0a20 2020 2020  name: str,.     
+0001e420: 2020 2063 6861 6e6e 656c 3a20 7374 7220     channel: str 
+0001e430: 3d20 4e6f 6e65 2c0a 2020 2020 2020 2020  = None,.        
+0001e440: 7665 7273 696f 6e3a 2073 7472 203d 204e  version: str = N
+0001e450: 6f6e 652c 0a20 2020 2020 2020 2074 6167  one,.        tag
+0001e460: 3a20 7374 7220 3d20 4e6f 6e65 2c0a 2020  : str = None,.  
+0001e470: 2020 2020 2020 666f 7263 655f 7265 6672        force_refr
+0001e480: 6573 683a 2062 6f6f 6c20 3d20 4661 6c73  esh: bool = Fals
+0001e490: 652c 0a20 2020 2029 3a0a 2020 2020 2020  e,.    ):.      
+0001e4a0: 2020 2222 220a 2020 2020 2020 2020 5265    """.        Re
+0001e4b0: 7472 6965 7665 2074 6865 2069 7465 6d20  trieve the item 
+0001e4c0: 6361 7461 6c6f 6720 666f 7220 6120 7370  catalog for a sp
+0001e4d0: 6563 6966 6965 6420 6d61 726b 6574 706c  ecified marketpl
+0001e4e0: 6163 6520 736f 7572 6365 2e0a 2020 2020  ace source..    
+0001e4f0: 2020 2020 5468 6520 6c69 7374 206f 6620      The list of 
+0001e500: 6974 656d 7320 6361 6e20 6265 2066 696c  items can be fil
+0001e510: 7465 7265 6420 6163 636f 7264 696e 6720  tered according 
+0001e520: 746f 2076 6172 696f 7573 2066 696c 7465  to various filte
+0001e530: 7273 2c20 7573 696e 6720 6974 656d 2773  rs, using item's
+0001e540: 206d 6574 6164 6174 6120 746f 2066 696c   metadata to fil
+0001e550: 7465 722e 0a0a 2020 2020 2020 2020 3a70  ter...        :p
+0001e560: 6172 616d 2073 6f75 7263 655f 6e61 6d65  aram source_name
+0001e570: 3a20 4e61 6d65 206f 6620 7468 6520 736f  : Name of the so
+0001e580: 7572 6365 2e0a 2020 2020 2020 2020 3a70  urce..        :p
+0001e590: 6172 616d 2063 6861 6e6e 656c 3a20 4669  aram channel: Fi
+0001e5a0: 6c74 6572 2069 7465 6d73 2061 6363 6f72  lter items accor
+0001e5b0: 6469 6e67 2074 6f20 7468 6569 7220 6368  ding to their ch
+0001e5c0: 616e 6e65 6c2e 2046 6f72 2065 7861 6d70  annel. For examp
+0001e5d0: 6c65 2060 6064 6576 656c 6f70 6d65 6e74  le ``development
+0001e5e0: 6060 2e0a 2020 2020 2020 2020 3a70 6172  ``..        :par
+0001e5f0: 616d 2076 6572 7369 6f6e 3a20 4669 6c74  am version: Filt
+0001e600: 6572 2069 7465 6d73 2061 6363 6f72 6469  er items accordi
+0001e610: 6e67 2074 6f20 7468 6569 7220 7665 7273  ng to their vers
+0001e620: 696f 6e2e 0a20 2020 2020 2020 203a 7061  ion..        :pa
+0001e630: 7261 6d20 7461 673a 2046 696c 7465 7220  ram tag: Filter 
+0001e640: 6974 656d 7320 6261 7365 6420 6f6e 2074  items based on t
+0001e650: 6167 2e0a 2020 2020 2020 2020 3a70 6172  ag..        :par
+0001e660: 616d 2066 6f72 6365 5f72 6566 7265 7368  am force_refresh
+0001e670: 3a20 4d61 6b65 2074 6865 2073 6572 7665  : Make the serve
+0001e680: 7220 6665 7463 6820 7468 6520 6361 7461  r fetch the cata
+0001e690: 6c6f 6720 6672 6f6d 2074 6865 2061 6374  log from the act
+0001e6a0: 7561 6c20 6d61 726b 6574 706c 6163 6520  ual marketplace 
+0001e6b0: 736f 7572 6365 2c0a 2020 2020 2020 2020  source,.        
+0001e6c0: 2020 2020 7261 7468 6572 2074 6861 6e20      rather than 
+0001e6d0: 7265 6c79 206f 6e20 6361 6368 6564 2069  rely on cached i
+0001e6e0: 6e66 6f72 6d61 7469 6f6e 2077 6869 6368  nformation which
+0001e6f0: 206d 6179 2065 7869 7374 2066 726f 6d20   may exist from 
+0001e700: 7072 6576 696f 7573 2067 6574 2072 6571  previous get req
+0001e710: 7565 7374 732e 2046 6f72 2065 7861 6d70  uests. For examp
+0001e720: 6c65 2c0a 2020 2020 2020 2020 2020 2020  le,.            
+0001e730: 6966 2074 6865 2073 6f75 7263 6520 7761  if the source wa
+0001e740: 7320 7265 2d62 7569 6c74 2c0a 2020 2020  s re-built,.    
+0001e750: 2020 2020 2020 2020 7468 6973 2077 696c          this wil
+0001e760: 6c20 6d61 6b65 2074 6865 2073 6572 7665  l make the serve
+0001e770: 7220 6765 7420 7468 6520 7570 6461 7465  r get the update
+0001e780: 6420 696e 666f 726d 6174 696f 6e2e 2044  d information. D
+0001e790: 6566 6175 6c74 2069 7320 6060 4661 6c73  efault is ``Fals
+0001e7a0: 6560 602e 0a20 2020 2020 2020 203a 7265  e``..        :re
+0001e7b0: 7475 726e 733a 203a 7079 3a63 6c61 7373  turns: :py:class
+0001e7c0: 3a60 7e6d 6c72 756e 2e61 7069 2e73 6368  :`~mlrun.api.sch
+0001e7d0: 656d 6173 2e6d 6172 6b65 7470 6c61 6365  emas.marketplace
+0001e7e0: 2e4d 6172 6b65 7470 6c61 6365 4361 7461  .MarketplaceCata
+0001e7f0: 6c6f 6760 206f 626a 6563 742c 2077 6869  log` object, whi
+0001e800: 6368 2069 7320 6573 7365 6e74 6961 6c6c  ch is essentiall
+0001e810: 7920 6120 6c69 7374 0a20 2020 2020 2020  y a list.       
+0001e820: 2020 2020 206f 6620 3a70 793a 636c 6173       of :py:clas
+0001e830: 733a 607e 6d6c 7275 6e2e 6170 692e 7363  s:`~mlrun.api.sc
+0001e840: 6865 6d61 732e 6d61 726b 6574 706c 6163  hemas.marketplac
+0001e850: 652e 4d61 726b 6574 706c 6163 6549 7465  e.MarketplaceIte
+0001e860: 6d60 2065 6e74 7269 6573 2e0a 2020 2020  m` entries..    
+0001e870: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0001e880: 7061 7468 203d 2028 6622 6d61 726b 6574  path = (f"market
+0001e890: 706c 6163 652f 736f 7572 6365 732f 7b73  place/sources/{s
+0001e8a0: 6f75 7263 655f 6e61 6d65 7d2f 6974 656d  ource_name}/item
+0001e8b0: 7322 2c29 0a20 2020 2020 2020 2070 6172  s",).        par
+0001e8c0: 616d 7320 3d20 7b0a 2020 2020 2020 2020  ams = {.        
+0001e8d0: 2020 2020 2263 6861 6e6e 656c 223a 2063      "channel": c
+0001e8e0: 6861 6e6e 656c 2c0a 2020 2020 2020 2020  hannel,.        
+0001e8f0: 2020 2020 2276 6572 7369 6f6e 223a 2076      "version": v
+0001e900: 6572 7369 6f6e 2c0a 2020 2020 2020 2020  ersion,.        
+0001e910: 2020 2020 2274 6167 223a 2074 6167 2c0a      "tag": tag,.
+0001e920: 2020 2020 2020 2020 2020 2020 2266 6f72              "for
+0001e930: 6365 2d72 6566 7265 7368 223a 2066 6f72  ce-refresh": for
+0001e940: 6365 5f72 6566 7265 7368 2c0a 2020 2020  ce_refresh,.    
+0001e950: 2020 2020 7d0a 2020 2020 2020 2020 7265      }.        re
+0001e960: 7370 6f6e 7365 203d 2073 656c 662e 6170  sponse = self.ap
+0001e970: 695f 6361 6c6c 286d 6574 686f 643d 2247  i_call(method="G
+0001e980: 4554 222c 2070 6174 683d 7061 7468 2c20  ET", path=path, 
+0001e990: 7061 7261 6d73 3d70 6172 616d 7329 0a20  params=params). 
+0001e9a0: 2020 2020 2020 2072 6574 7572 6e20 7363         return sc
+0001e9b0: 6865 6d61 732e 4d61 726b 6574 706c 6163  hemas.Marketplac
+0001e9c0: 6543 6174 616c 6f67 282a 2a72 6573 706f  eCatalog(**respo
+0001e9d0: 6e73 652e 6a73 6f6e 2829 290a 0a20 2020  nse.json())..   
+0001e9e0: 2064 6566 2067 6574 5f6d 6172 6b65 7470   def get_marketp
+0001e9f0: 6c61 6365 5f69 7465 6d28 0a20 2020 2020  lace_item(.     
+0001ea00: 2020 2073 656c 662c 0a20 2020 2020 2020     self,.       
+0001ea10: 2073 6f75 7263 655f 6e61 6d65 3a20 7374   source_name: st
+0001ea20: 722c 0a20 2020 2020 2020 2069 7465 6d5f  r,.        item_
+0001ea30: 6e61 6d65 3a20 7374 722c 0a20 2020 2020  name: str,.     
+0001ea40: 2020 2063 6861 6e6e 656c 3a20 7374 7220     channel: str 
+0001ea50: 3d20 2264 6576 656c 6f70 6d65 6e74 222c  = "development",
+0001ea60: 0a20 2020 2020 2020 2076 6572 7369 6f6e  .        version
+0001ea70: 3a20 7374 7220 3d20 4e6f 6e65 2c0a 2020  : str = None,.  
+0001ea80: 2020 2020 2020 7461 673a 2073 7472 203d        tag: str =
+0001ea90: 2022 6c61 7465 7374 222c 0a20 2020 2020   "latest",.     
+0001eaa0: 2020 2066 6f72 6365 5f72 6566 7265 7368     force_refresh
+0001eab0: 3a20 626f 6f6c 203d 2046 616c 7365 2c0a  : bool = False,.
+0001eac0: 2020 2020 293a 0a20 2020 2020 2020 2022      ):.        "
+0001ead0: 2222 0a20 2020 2020 2020 2052 6574 7269  "".        Retri
+0001eae0: 6576 6520 6120 7370 6563 6966 6963 206d  eve a specific m
+0001eaf0: 6172 6b65 7470 6c61 6365 2069 7465 6d2e  arketplace item.
+0001eb00: 0a0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+0001eb10: 2073 6f75 7263 655f 6e61 6d65 3a20 4e61   source_name: Na
+0001eb20: 6d65 206f 6620 736f 7572 6365 2e0a 2020  me of source..  
+0001eb30: 2020 2020 2020 3a70 6172 616d 2069 7465        :param ite
+0001eb40: 6d5f 6e61 6d65 3a20 4e61 6d65 206f 6620  m_name: Name of 
+0001eb50: 7468 6520 6974 656d 2074 6f20 7265 7472  the item to retr
+0001eb60: 6965 7665 2c20 6173 2069 7420 6170 7065  ieve, as it appe
+0001eb70: 6172 7320 696e 2074 6865 2063 6174 616c  ars in the catal
+0001eb80: 6f67 2e0a 2020 2020 2020 2020 3a70 6172  og..        :par
+0001eb90: 616d 2063 6861 6e6e 656c 3a20 4765 7420  am channel: Get 
+0001eba0: 7468 6520 6974 656d 2066 726f 6d20 7468  the item from th
+0001ebb0: 6520 7370 6563 6966 6965 6420 6368 616e  e specified chan
+0001ebc0: 6e65 6c2e 2044 6566 6175 6c74 2069 7320  nel. Default is 
+0001ebd0: 6060 6465 7665 6c6f 706d 656e 7460 602e  ``development``.
+0001ebe0: 0a20 2020 2020 2020 203a 7061 7261 6d20  .        :param 
+0001ebf0: 7665 7273 696f 6e3a 2047 6574 2061 2073  version: Get a s
+0001ec00: 7065 6369 6669 6320 7665 7273 696f 6e20  pecific version 
+0001ec10: 6f66 2074 6865 2069 7465 6d2e 2044 6566  of the item. Def
+0001ec20: 6175 6c74 2069 7320 6060 4e6f 6e65 6060  ault is ``None``
+0001ec30: 2e0a 2020 2020 2020 2020 3a70 6172 616d  ..        :param
+0001ec40: 2074 6167 3a20 4765 7420 6120 7370 6563   tag: Get a spec
+0001ec50: 6966 6963 2076 6572 7369 6f6e 206f 6620  ific version of 
+0001ec60: 7468 6520 6974 656d 2069 6465 6e74 6966  the item identif
+0001ec70: 6965 6420 6279 2074 6167 2e20 4465 6661  ied by tag. Defa
+0001ec80: 756c 7420 6973 2060 606c 6174 6573 7460  ult is ``latest`
+0001ec90: 602e 0a20 2020 2020 2020 203a 7061 7261  `..        :para
+0001eca0: 6d20 666f 7263 655f 7265 6672 6573 683a  m force_refresh:
+0001ecb0: 204d 616b 6520 7468 6520 7365 7276 6572   Make the server
+0001ecc0: 2066 6574 6368 2074 6865 2069 6e66 6f72   fetch the infor
+0001ecd0: 6d61 7469 6f6e 2066 726f 6d20 7468 6520  mation from the 
+0001ece0: 6163 7475 616c 206d 6172 6b65 7470 6c61  actual marketpla
+0001ecf0: 6365 0a20 2020 2020 2020 2020 2020 2073  ce.            s
+0001ed00: 6f75 7263 652c 2072 6174 6865 7220 7468  ource, rather th
+0001ed10: 616e 0a20 2020 2020 2020 2020 2020 2072  an.            r
+0001ed20: 656c 7920 6f6e 2063 6163 6865 6420 696e  ely on cached in
+0001ed30: 666f 726d 6174 696f 6e2e 2044 6566 6175  formation. Defau
+0001ed40: 6c74 2069 7320 6060 4661 6c73 6560 602e  lt is ``False``.
+0001ed50: 0a20 2020 2020 2020 203a 7265 7475 726e  .        :return
+0001ed60: 733a 203a 7079 3a63 6c61 7373 3a60 7e6d  s: :py:class:`~m
+0001ed70: 6c72 756e 2e61 7069 2e73 6368 656d 6173  lrun.api.schemas
+0001ed80: 2e6d 6172 6b65 7470 6c61 6365 2e4d 6172  .marketplace.Mar
+0001ed90: 6b65 7470 6c61 6365 4974 656d 602e 0a20  ketplaceItem`.. 
+0001eda0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+0001edb0: 2020 2070 6174 6820 3d20 2866 226d 6172     path = (f"mar
+0001edc0: 6b65 7470 6c61 6365 2f73 6f75 7263 6573  ketplace/sources
+0001edd0: 2f7b 736f 7572 6365 5f6e 616d 657d 2f69  /{source_name}/i
+0001ede0: 7465 6d73 2f7b 6974 656d 5f6e 616d 657d  tems/{item_name}
+0001edf0: 222c 290a 2020 2020 2020 2020 7061 7261  ",).        para
+0001ee00: 6d73 203d 207b 0a20 2020 2020 2020 2020  ms = {.         
+0001ee10: 2020 2022 6368 616e 6e65 6c22 3a20 6368     "channel": ch
+0001ee20: 616e 6e65 6c2c 0a20 2020 2020 2020 2020  annel,.         
+0001ee30: 2020 2022 7665 7273 696f 6e22 3a20 7665     "version": ve
+0001ee40: 7273 696f 6e2c 0a20 2020 2020 2020 2020  rsion,.         
+0001ee50: 2020 2022 7461 6722 3a20 7461 672c 0a20     "tag": tag,. 
+0001ee60: 2020 2020 2020 2020 2020 2022 666f 7263             "forc
+0001ee70: 652d 7265 6672 6573 6822 3a20 666f 7263  e-refresh": forc
+0001ee80: 655f 7265 6672 6573 682c 0a20 2020 2020  e_refresh,.     
+0001ee90: 2020 207d 0a20 2020 2020 2020 2072 6573     }.        res
+0001eea0: 706f 6e73 6520 3d20 7365 6c66 2e61 7069  ponse = self.api
+0001eeb0: 5f63 616c 6c28 6d65 7468 6f64 3d22 4745  _call(method="GE
+0001eec0: 5422 2c20 7061 7468 3d70 6174 682c 2070  T", path=path, p
+0001eed0: 6172 616d 733d 7061 7261 6d73 290a 2020  arams=params).  
+0001eee0: 2020 2020 2020 7265 7475 726e 2073 6368        return sch
+0001eef0: 656d 6173 2e4d 6172 6b65 7470 6c61 6365  emas.Marketplace
+0001ef00: 4974 656d 282a 2a72 6573 706f 6e73 652e  Item(**response.
+0001ef10: 6a73 6f6e 2829 290a 0a20 2020 2064 6566  json())..    def
+0001ef20: 2076 6572 6966 795f 6175 7468 6f72 697a   verify_authoriz
+0001ef30: 6174 696f 6e28 0a20 2020 2020 2020 2073  ation(.        s
+0001ef40: 656c 662c 2061 7574 686f 7269 7a61 7469  elf, authorizati
+0001ef50: 6f6e 5f76 6572 6966 6963 6174 696f 6e5f  on_verification_
+0001ef60: 696e 7075 743a 2073 6368 656d 6173 2e41  input: schemas.A
+0001ef70: 7574 686f 7269 7a61 7469 6f6e 5665 7269  uthorizationVeri
+0001ef80: 6669 6361 7469 6f6e 496e 7075 740a 2020  ficationInput.  
+0001ef90: 2020 293a 0a20 2020 2020 2020 2022 2222    ):.        """
+0001efa0: 5665 7269 6669 6573 2061 7574 686f 7269  Verifies authori
+0001efb0: 7a61 7469 6f6e 2066 6f72 2074 6865 2070  zation for the p
+0001efc0: 726f 7669 6465 6420 6163 7469 6f6e 206f  rovided action o
+0001efd0: 6e20 7468 6520 7072 6f76 6964 6564 2072  n the provided r
+0001efe0: 6573 6f75 7263 652e 0a0a 2020 2020 2020  esource...      
+0001eff0: 2020 3a70 6172 616d 2061 7574 686f 7269    :param authori
+0001f000: 7a61 7469 6f6e 5f76 6572 6966 6963 6174  zation_verificat
+0001f010: 696f 6e5f 696e 7075 743a 2049 6e73 7461  ion_input: Insta
+0001f020: 6e63 6520 6f66 0a20 2020 2020 2020 2020  nce of.         
+0001f030: 2020 203a 7079 3a63 6c61 7373 3a60 7e6d     :py:class:`~m
+0001f040: 6c72 756e 2e61 7069 2e73 6368 656d 6173  lrun.api.schemas
+0001f050: 2e41 7574 686f 7269 7a61 7469 6f6e 5665  .AuthorizationVe
+0001f060: 7269 6669 6361 7469 6f6e 496e 7075 7460  rificationInput`
+0001f070: 2074 6861 7420 696e 636c 7564 6573 2061   that includes a
+0001f080: 6c6c 2074 6865 206e 6565 6465 6420 7061  ll the needed pa
+0001f090: 7261 6d65 7465 7273 2066 6f72 0a20 2020  rameters for.   
+0001f0a0: 2020 2020 2020 2020 2074 6865 2061 7574           the aut
+0001f0b0: 6820 7665 7269 6669 6361 7469 6f6e 0a20  h verification. 
+0001f0c0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+0001f0d0: 2020 2065 7272 6f72 5f6d 6573 7361 6765     error_message
+0001f0e0: 203d 2022 4175 7468 6f72 697a 6174 696f   = "Authorizatio
+0001f0f0: 6e20 6368 6563 6b20 6661 696c 6564 220a  n check failed".
+0001f100: 2020 2020 2020 2020 7365 6c66 2e61 7069          self.api
+0001f110: 5f63 616c 6c28 0a20 2020 2020 2020 2020  _call(.         
+0001f120: 2020 2022 504f 5354 222c 0a20 2020 2020     "POST",.     
+0001f130: 2020 2020 2020 2022 6175 7468 6f72 697a         "authoriz
+0001f140: 6174 696f 6e2f 7665 7269 6669 6361 7469  ation/verificati
+0001f150: 6f6e 7322 2c0a 2020 2020 2020 2020 2020  ons",.          
+0001f160: 2020 6572 726f 725f 6d65 7373 6167 652c    error_message,
+0001f170: 0a20 2020 2020 2020 2020 2020 2062 6f64  .            bod
+0001f180: 793d 6469 6374 5f74 6f5f 6a73 6f6e 2861  y=dict_to_json(a
+0001f190: 7574 686f 7269 7a61 7469 6f6e 5f76 6572  uthorization_ver
+0001f1a0: 6966 6963 6174 696f 6e5f 696e 7075 742e  ification_input.
+0001f1b0: 6469 6374 2829 292c 0a20 2020 2020 2020  dict()),.       
+0001f1c0: 2029 0a0a 2020 2020 6465 6620 7472 6967   )..    def trig
+0001f1d0: 6765 725f 6d69 6772 6174 696f 6e73 2873  ger_migrations(s
+0001f1e0: 656c 6629 202d 3e20 4f70 7469 6f6e 616c  elf) -> Optional
+0001f1f0: 5b73 6368 656d 6173 2e42 6163 6b67 726f  [schemas.Backgro
+0001f200: 756e 6454 6173 6b5d 3a0a 2020 2020 2020  undTask]:.      
+0001f210: 2020 2222 2254 7269 6767 6572 206d 6967    """Trigger mig
+0001f220: 7261 7469 6f6e 7320 2877 696c 6c20 646f  rations (will do
+0001f230: 206e 6f74 6869 6e67 2069 6620 6e6f 206d   nothing if no m
+0001f240: 6967 7261 7469 6f6e 7320 6172 6520 6e65  igrations are ne
+0001f250: 6564 6564 2920 616e 6420 7761 6974 2066  eded) and wait f
+0001f260: 6f72 2074 6865 6d20 746f 2066 696e 6973  or them to finis
+0001f270: 6820 6966 2061 6374 7561 6c6c 790a 2020  h if actually.  
+0001f280: 2020 2020 2020 7472 6967 6765 7265 640a        triggered.
+0001f290: 2020 2020 2020 2020 3a72 6574 7572 6e73          :returns
+0001f2a0: 3a20 3a70 793a 636c 6173 733a 607e 6d6c  : :py:class:`~ml
+0001f2b0: 7275 6e2e 6170 692e 7363 6865 6d61 732e  run.api.schemas.
+0001f2c0: 4261 636b 6772 6f75 6e64 5461 736b 602e  BackgroundTask`.
+0001f2d0: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+0001f2e0: 2020 2020 2072 6573 706f 6e73 6520 3d20       response = 
+0001f2f0: 7365 6c66 2e61 7069 5f63 616c 6c28 0a20  self.api_call(. 
+0001f300: 2020 2020 2020 2020 2020 2022 504f 5354             "POST
+0001f310: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
+0001f320: 6f70 6572 6174 696f 6e73 2f6d 6967 7261  operations/migra
+0001f330: 7469 6f6e 7322 2c0a 2020 2020 2020 2020  tions",.        
+0001f340: 2020 2020 2246 6169 6c65 6420 7472 6967      "Failed trig
+0001f350: 6765 7269 6e67 206d 6967 7261 7469 6f6e  gering migration
+0001f360: 7322 2c0a 2020 2020 2020 2020 290a 2020  s",.        ).  
+0001f370: 2020 2020 2020 6966 2072 6573 706f 6e73        if respons
+0001f380: 652e 7374 6174 7573 5f63 6f64 6520 3d3d  e.status_code ==
+0001f390: 2068 7474 702e 4854 5450 5374 6174 7573   http.HTTPStatus
+0001f3a0: 2e41 4343 4550 5445 443a 0a20 2020 2020  .ACCEPTED:.     
+0001f3b0: 2020 2020 2020 2062 6163 6b67 726f 756e         backgroun
+0001f3c0: 645f 7461 736b 203d 2073 6368 656d 6173  d_task = schemas
+0001f3d0: 2e42 6163 6b67 726f 756e 6454 6173 6b28  .BackgroundTask(
+0001f3e0: 2a2a 7265 7370 6f6e 7365 2e6a 736f 6e28  **response.json(
+0001f3f0: 2929 0a20 2020 2020 2020 2020 2020 2072  )).            r
+0001f400: 6574 7572 6e20 7365 6c66 2e5f 7761 6974  eturn self._wait
+0001f410: 5f66 6f72 5f62 6163 6b67 726f 756e 645f  _for_background_
+0001f420: 7461 736b 5f74 6f5f 7265 6163 685f 7465  task_to_reach_te
+0001f430: 726d 696e 616c 5f73 7461 7465 280a 2020  rminal_state(.  
+0001f440: 2020 2020 2020 2020 2020 2020 2020 6261                ba
+0001f450: 636b 6772 6f75 6e64 5f74 6173 6b2e 6d65  ckground_task.me
+0001f460: 7461 6461 7461 2e6e 616d 650a 2020 2020  tadata.name.    
+0001f470: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+0001f480: 2020 7265 7475 726e 204e 6f6e 650a 0a0a    return None...
+0001f490: 6465 6620 5f61 735f 6a73 6f6e 286f 626a  def _as_json(obj
+0001f4a0: 293a 0a20 2020 2066 6e20 3d20 6765 7461  ):.    fn = geta
+0001f4b0: 7474 7228 6f62 6a2c 2022 746f 5f6a 736f  ttr(obj, "to_jso
+0001f4c0: 6e22 2c20 4e6f 6e65 290a 2020 2020 6966  n", None).    if
+0001f4d0: 2066 6e3a 0a20 2020 2020 2020 2072 6574   fn:.        ret
+0001f4e0: 7572 6e20 666e 2829 0a20 2020 2072 6574  urn fn().    ret
+0001f4f0: 7572 6e20 6469 6374 5f74 6f5f 6a73 6f6e  urn dict_to_json
+0001f500: 286f 626a 290a                           (obj).
```

## mlrun/db/sqldb.py

```diff
@@ -12,28 +12,28 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import datetime
 from typing import List, Optional, Union
 
 import mlrun.api.schemas
+import mlrun.model_monitoring.model_endpoint
 from mlrun.api.db.base import DBError
 from mlrun.api.db.sqldb.db import SQLDB as SQLAPIDB
 from mlrun.api.db.sqldb.session import create_session
 
 # This class is a proxy for the real implementation that sits under mlrun.api.db.sqldb
 # The runtime objects (which manages the resources that do the real logic, like Nuclio functions, Dask jobs, etc...)
 # require a RunDB to manage their state, when a user run them locally this db will either be the
 # local filedb or the remote httpdb (we decided that we don't want to support SQLDB as an optional RunDB).
 # When the user submits something to run (task, function etc...) this runtime managers actually runs inside the api
 # service, in order to prevent the api from calling itself several times for each submission request (since the runDB
 # will be httpdb to that same api service) we have this class which is kind of a proxy between the RunDB interface to
 # the api service's DB interface
 from ..api import schemas
-from ..api.schemas import ModelEndpoint
 from .base import RunDBError, RunDBInterface
 
 
 class SQLDB(RunDBInterface):
     def __init__(
         self,
         dsn,
@@ -57,23 +57,22 @@
             body,
             project,
             uid,
             append,
         )
 
     def get_log(self, uid, project="", offset=0, size=0):
-        import mlrun.api.crud
-
-        return self._transform_db_error(
-            mlrun.api.crud.Logs().get_logs,
-            self.session,
-            project,
-            uid,
-            size,
-            offset,
+        # TODO: this is method which is not being called through the API (only through the SDK), but due to changes in
+        #  the API we changed the get_log method to async so we cannot call it here, and in this PR we won't change the
+        #  SDK to run async, we will use the legacy method for now, and later when we will have a better solution
+        #  we will change it.
+        raise NotImplementedError(
+            "This should be changed to async call, if you are running in the API, use `crud.get_log`"
+            " method directly instead and not through the get_db().get_log() method"
+            "This will be removed in 1.5.0",
         )
 
     def store_run(self, struct, uid, project="", iter=0):
         import mlrun.api.crud
 
         return self._transform_db_error(
             mlrun.api.crud.Runs().store_run,
@@ -296,22 +295,24 @@
         )
 
     def list_functions(self, name=None, project=None, tag=None, labels=None):
         import mlrun.api.crud
 
         return self._transform_db_error(
             mlrun.api.crud.Functions().list_functions,
-            self.session,
-            project,
-            name,
-            tag,
-            labels,
+            db_session=self.session,
+            project=project,
+            name=name,
+            tag=tag,
+            labels=labels,
         )
 
-    def list_artifact_tags(self, project=None):
+    def list_artifact_tags(
+        self, project=None, category: Union[str, schemas.ArtifactCategories] = None
+    ):
         return self._transform_db_error(
             self.db.list_artifact_tags, self.session, project
         )
 
     def tag_objects(
         self,
         project: str,
@@ -768,15 +769,17 @@
     ):
         raise NotImplementedError()
 
     def create_model_endpoint(
         self,
         project: str,
         endpoint_id: str,
-        model_endpoint: ModelEndpoint,
+        model_endpoint: Union[
+            mlrun.model_monitoring.model_endpoint.ModelEndpoint, dict
+        ],
     ):
         raise NotImplementedError()
 
     def delete_model_endpoint(
         self,
         project: str,
         endpoint_id: str,
```

## mlrun/feature_store/api.py

```diff
@@ -34,14 +34,15 @@
     validate_target_list,
     validate_target_paths_for_engine,
 )
 from ..db import RunDBError
 from ..model import DataSource, DataTargetBase
 from ..runtimes import RuntimeKinds
 from ..runtimes.function_reference import FunctionReference
+from ..serving.server import Response
 from ..utils import get_caller_globals, logger, normalize_name, str_to_timestamp
 from .common import (
     RunConfig,
     get_feature_set_by_uri,
     get_feature_vector_by_uri,
     verify_feature_set_exists,
     verify_feature_set_permissions,
@@ -97,14 +98,16 @@
     start_time: Union[str, datetime] = None,
     end_time: Union[str, datetime] = None,
     with_indexes: bool = False,
     update_stats: bool = False,
     engine: str = None,
     engine_args: dict = None,
     query: str = None,
+    join_type: str = "inner",
+    order_by: Union[str, List[str]] = None,
     spark_service: str = None,
 ) -> OfflineVectorResponse:
     """retrieve offline feature vector results
 
     specify a feature vector object/uri and retrieve the desired features, their metadata
     and statistics. returns :py:class:`~mlrun.feature_store.OfflineVectorResponse`,
     results can be returned as a dataframe or written to a target
@@ -145,14 +148,26 @@
         entity_timestamp_column must be passed when using time filtering.
     :param with_indexes:    return vector with index columns and timestamp_key from the feature sets (default False)
     :param update_stats:    update features statistics from the requested feature sets on the vector. Default is False.
     :param engine:          processing engine kind ("local", "dask", or "spark")
     :param engine_args:     kwargs for the processing engine
     :param query:           The query string used to filter rows
     :param spark_service:   Name of the spark service to be used (when using a remote-spark runtime)
+    :param join_type:               {'left', 'right', 'outer', 'inner'}, default 'inner'
+                                    Supported retrieval engines: "dask", "local"
+                                    This parameter is in use when entity_timestamp_column and
+                                    feature_vector.spec.timestamp_field are None, if one of them
+                                    isn't none we're preforming as_of join.
+                                    Possible values :
+                                    * left: use only keys from left frame (SQL: left outer join)
+                                    * right: use only keys from right frame (SQL: right outer join)
+                                    * outer: use union of keys from both frames (SQL: full outer join)
+                                    * inner: use intersection of keys from both frames (SQL: inner join).
+    :param order_by:        Name or list of names to order by. The name or the names in the list can be the feature name
+                            or the alias of the feature you pass in the feature list.
     """
     if isinstance(feature_vector, FeatureVector):
         update_stats = True
 
     feature_vector = _features_to_vector_and_check_permissions(
         feature_vector, update_stats
     )
@@ -173,14 +188,16 @@
             spark_service,
             entity_rows,
             timestamp_column=entity_timestamp_column,
             run_config=run_config,
             drop_columns=drop_columns,
             with_indexes=with_indexes,
             query=query,
+            join_type=join_type,
+            order_by=order_by,
         )
 
     start_time = str_to_timestamp(start_time)
     end_time = str_to_timestamp(end_time)
     if (start_time or end_time) and not entity_timestamp_column:
         raise TypeError(
             "entity_timestamp_column or feature_vector.spec.timestamp_field is required when passing start/end time"
@@ -195,14 +212,16 @@
         target=target,
         drop_columns=drop_columns,
         start_time=start_time,
         end_time=end_time,
         with_indexes=with_indexes,
         update_stats=update_stats,
         query=query,
+        join_type=join_type,
+        order_by=order_by,
     )
 
 
 def get_online_feature_service(
     feature_vector: Union[str, FeatureVector],
     run_config: RunConfig = None,
     fixed_window_type: FixedWindowType = FixedWindowType.LastClosedWindow,
@@ -349,15 +368,15 @@
                           call `.save()` if it's not)
     :param source:        source dataframe or other sources (e.g. parquet source see:
                           :py:class:`~mlrun.datastore.ParquetSource` and other classes in mlrun.datastore with suffix
                           Source)
     :param targets:       optional list of data target objects
     :param namespace:     namespace or module containing graph classes
     :param return_df:     indicate if to return a dataframe with the graph results
-    :param infer_options: schema and stats infer options
+    :param infer_options: schema and stats infer options (:py:class:`~mlrun.feature_store.InferOptions`)
     :param run_config:    function and/or run configuration for remote jobs,
                           see :py:class:`~mlrun.feature_store.RunConfig`
     :param mlrun_context: mlrun context (when running as a job), for internal use !
     :param spark_context: local spark session for spark ingestion, example for creating the spark context:
                           `spark = SparkSession.builder.appName("Spark function").getOrCreate()`
                           For remote spark ingestion, this should contain the remote spark service name
     :param overwrite:     delete the targets' data prior to ingestion
@@ -388,16 +407,18 @@
             source = featureset.spec.source
 
     if not mlrun_context and (not featureset or source is None):
         raise mlrun.errors.MLRunInvalidArgumentError(
             "feature set and source must be specified"
         )
 
+    if featureset is not None:
+        featureset.validate_steps(namespace=namespace)
     # This flow may happen both on client side (user provides run config) and server side (through the ingest API)
-    if run_config:
+    if run_config and not run_config.local:
         if isinstance(source, pd.DataFrame):
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "DataFrame source is illegal in conjunction with run_config"
             )
         # remote job execution
         verify_feature_set_permissions(
             featureset, mlrun.api.schemas.AuthorizationAction.update
@@ -426,14 +447,15 @@
             featureset,
             source,
             targets,
             infer_options,
             overwrite,
         ) = context_to_ingestion_params(mlrun_context)
 
+        featureset.validate_steps(namespace=namespace)
         verify_feature_set_permissions(
             featureset, mlrun.api.schemas.AuthorizationAction.update
         )
         if not source:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "data source was not specified"
             )
@@ -625,17 +647,18 @@
         raise mlrun.errors.MLRunInvalidArgumentError(
             "preview with spark engine is not supported"
         )
 
     options = options if options is not None else InferOptions.default()
     if timestamp_key is not None:
         warnings.warn(
-            "preview's timestamp_key parameter is deprecated. Please pass this parameter to FeatureSet instead",
-            # TODO: Remove this API in 1.4.0
-            PendingDeprecationWarning,
+            "preview's 'timestamp_key' parameter is deprecated in 1.3.0 and will be removed in 1.5.0. "
+            "Pass this parameter to 'FeatureSet' instead.",
+            # TODO: Remove this API in 1.5.0
+            FutureWarning,
         )
         featureset.spec.timestamp_key = timestamp_key
         for step in featureset.graph.steps.values():
             if step.class_name == "storey.AggregateByKey":
                 step.class_args["time_field"] = timestamp_key
 
     if isinstance(source, str):
@@ -643,14 +666,15 @@
         source = mlrun.store_manager.object(url=source).as_df()
 
     verify_feature_set_permissions(
         featureset, mlrun.api.schemas.AuthorizationAction.update
     )
 
     featureset.spec.validate_no_processing_for_passthrough()
+    featureset.validate_steps(namespace=namespace)
 
     namespace = namespace or get_caller_globals()
     if featureset.spec.require_processing():
         _, default_final_step, _ = featureset.graph.check_and_process_graph(
             allow_empty=True
         )
         if not default_final_step:
@@ -823,25 +847,29 @@
         elif isinstance(source, pyspark.sql.DataFrame):
             df = source
         else:
             df = source.to_spark_df(spark, time_field=timestamp_key)
             df = source.filter_df_start_end_time(df, timestamp_key)
         if featureset.spec.graph and featureset.spec.graph.steps:
             df = run_spark_graph(df, featureset, namespace, spark)
+
+        if isinstance(df, Response) and df.status_code != 0:
+            mlrun.errors.raise_for_status_code(df.status_code, df.body.split(": ")[1])
         _infer_from_static_df(df, featureset, options=infer_options)
 
         key_columns = list(featureset.spec.entities.keys())
         targets = targets or featureset.spec.targets
 
         targets_to_ingest = copy.deepcopy(targets)
         featureset.update_targets_for_ingest(targets_to_ingest, overwrite=overwrite)
 
         for target in targets_to_ingest or []:
             if type(target) is DataTargetBase:
                 target = get_target_driver(target, featureset)
+            target.set_resource(featureset)
             if featureset.spec.passthrough and target.is_offline:
                 continue
             if target.path and urlparse(target.path).scheme == "":
                 if mlrun_context:
                     mlrun_context.logger.error(
                         "Paths for spark ingest must contain schema, i.e v3io, s3, az"
                     )
@@ -882,24 +910,23 @@
                         partition not in df_to_write.columns
                         and partition in time_unit_to_op
                     ):
                         op = time_unit_to_op[partition]
                         df_to_write = df_to_write.withColumn(
                             partition, op(timestamp_col)
                         )
-            df_to_write = target.prepare_spark_df(df_to_write)
+            df_to_write = target.prepare_spark_df(df_to_write, key_columns)
             if overwrite:
                 df_to_write.write.mode("overwrite").save(**spark_options)
             else:
                 # appending an empty dataframe may cause an empty file to be created (e.g. when writing to parquet)
                 # we would like to avoid that
                 df_to_write.persist()
                 if df_to_write.count() > 0:
                     df_to_write.write.mode("append").save(**spark_options)
-            target.set_resource(featureset)
             target.update_resource_status("ready")
 
         if isinstance(source, BaseSourceDriver) and source.schedule:
             max_time = df.agg({timestamp_key: "max"}).collect()[0][0]
             if not max_time:
                 # if max_time is None(no data), next scheduled run should be with same start_time
                 max_time = source.start_time
```

## mlrun/feature_store/common.py

```diff
@@ -225,15 +225,16 @@
                             or a :py:class:`~mlrun.runtimes.function_reference.FunctionReference`
                             the function define the code, dependencies, and resources
         :param local:       use True to simulate local job run or mock service
         :param image:       function container image
         :param kind:        function runtime kind (job, serving, spark, ..), required when function points to code
         :param handler:     the function handler to execute (for jobs or nuclio)
         :param parameters:  job parameters
-        :param watch:       in batch jobs will wait for the job completion and print job logs to the console
+        :param watch:       in batch jobs will wait for the job completion and print job logs to the console.
+                            Default (None) is True.
         :param owner:       job owner
         :param credentials: job credentials
         :param code:        function source code (as string)
         :param requirements: python requirements file path or list of packages
         :param extra_spec:  additional dict with function spec fields/values to add to the function
         :param auth_info:   authentication info. *For internal use* when running on server
         """
```

## mlrun/feature_store/feature_set.py

```diff
@@ -36,19 +36,20 @@
 )
 from ..features import Entity, Feature
 from ..model import (
     DataSource,
     DataTarget,
     DataTargetBase,
     ModelObj,
+    ObjectDict,
     ObjectList,
     VersionedObjMetadata,
 )
 from ..runtimes.function_reference import FunctionReference
-from ..serving.states import BaseStep, RootFlowStep, previous_step
+from ..serving.states import BaseStep, RootFlowStep, previous_step, queue_class_names
 from ..serving.utils import StepToDict
 from ..utils import StorePrefix, logger
 from .common import verify_feature_set_permissions
 
 aggregates_step = "Aggregates"
 
 
@@ -108,22 +109,23 @@
         self._features: ObjectList = None
         self._entities: ObjectList = None
         self._targets: ObjectList = None
         self._graph: RootFlowStep = None
         self._source = None
         self._engine = None
         self._function: FunctionReference = None
+        self._relations: ObjectDict = None
 
         self.owner = owner
         self.description = description
         self.entities: List[Union[Entity, str]] = entities or []
+        self.relations: Dict[str, Union[Entity, str]] = relations or {}
         self.features: List[Feature] = features or []
         self.partition_keys = partition_keys or []
         self.timestamp_key = timestamp_key
-        self.relations = relations or {}
         self.source = source
         self.targets = targets or []
         self.graph = graph
         self.label_column = label_column
         self.function = function
         self.analysis = analysis or {}
         self.engine = engine
@@ -138,14 +140,27 @@
     @entities.setter
     def entities(self, entities: List[Union[Entity, str]]):
         if entities:
             # if the entity is a string, convert it to Entity class
             for i, entity in enumerate(entities):
                 if isinstance(entity, str):
                     entities[i] = Entity(entity)
+                elif isinstance(entity, Entity) and entity.name is None:
+                    raise mlrun.errors.MLRunInvalidArgumentError(
+                        "You have to provide an "
+                        "Entity with valid name of string type"
+                    )
+                elif isinstance(entity, dict) and (
+                    "name" not in entity
+                    or ("name" in entity and entity["name"] is None)
+                ):
+                    raise mlrun.errors.MLRunInvalidArgumentError(
+                        "You have to provide an "
+                        "Entity with valid name of string type"
+                    )
         self._entities = ObjectList.from_list(Entity, entities)
 
     @property
     def features(self) -> List[Feature]:
         """feature set features list"""
         return self._features
 
@@ -206,14 +221,26 @@
     @source.setter
     def source(self, source: Union[BaseSourceDriver, dict]):
         if isinstance(source, dict):
             kind = source.get("kind", "")
             source = source_kind_to_driver[kind].from_dict(source)
         self._source = source
 
+    @property
+    def relations(self) -> Dict[str, Entity]:
+        """feature set relations dict"""
+        return self._relations
+
+    @relations.setter
+    def relations(self, relations: Dict[str, Entity]):
+        for col, ent in relations.items():
+            if isinstance(ent, str):
+                relations[col] = Entity(ent)
+        self._relations = ObjectDict.from_dict({"entity": Entity}, relations, "entity")
+
     def require_processing(self):
         return len(self._graph.steps) > 0
 
     def validate_no_processing_for_passthrough(self):
         if self.passthrough and self.require_processing():
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "passthrough feature set can not have graph transformations"
@@ -296,14 +323,15 @@
         self,
         name: str = None,
         description: str = None,
         entities: List[Union[Entity, str]] = None,
         timestamp_key: str = None,
         engine: str = None,
         label_column: str = None,
+        relations: Dict[str, Union[Entity, str]] = None,
         passthrough: bool = None,
     ):
         """Feature set object, defines a set of features and their data pipeline
 
         example::
 
             import mlrun.feature_store as fstore
@@ -312,14 +340,17 @@
 
         :param name:          name of the feature set
         :param description:   text description
         :param entities:      list of entity (index key) names or :py:class:`~mlrun.features.FeatureSet.Entity`
         :param timestamp_key: timestamp column name
         :param engine:        name of the processing engine (storey, pandas, or spark), defaults to storey
         :param label_column:  name of the label column (the one holding the target (y) values)
+        :param relations:     dictionary that indicates all the relations this feature set
+                              have with another feature sets. The format of this dictionary is
+                              {"my_column":Entity, ...}
         :param passthrough:   if true, ingest will skip offline targets, and get_offline_features will read
                               directly from source
         """
         self._spec: FeatureSetSpec = None
         self._metadata = None
         self._status = None
         self._api_client = None
@@ -327,14 +358,15 @@
 
         self.spec = FeatureSetSpec(
             description=description,
             entities=entities,
             timestamp_key=timestamp_key,
             engine=engine,
             label_column=label_column,
+            relations=relations,
             passthrough=passthrough,
         )
 
         if timestamp_key in self.spec.entities.keys():
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "timestamp key can not be entity"
             )
@@ -371,15 +403,15 @@
     @property
     def uri(self):
         """fully qualified feature set uri"""
         return get_store_uri(StorePrefix.FeatureSet, self.fullname)
 
     @property
     def fullname(self) -> str:
-        """full name in the form {project}/{name}[:{tag}]"""
+        """full name in the form ``{project}/{name}[:{tag}]``"""
         fullname = (
             f"{self._metadata.project or mlconf.default_project}/{self._metadata.name}"
         )
         if self._metadata.tag:
             fullname += ":" + self._metadata.tag
         return fullname
 
@@ -424,17 +456,18 @@
         :param default_final_step: the final graph step after which we add the
                                     target writers, used when the graph branches and
                                     the end cant be determined automatically
         :param default_final_state: *Deprecated* - use default_final_step instead
         """
         if default_final_state:
             warnings.warn(
-                "The default_final_state parameter is deprecated. Use default_final_step instead",
-                # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-                PendingDeprecationWarning,
+                "The 'default_final_state' parameter is deprecated in 1.3.0 and will be remove in 1.5.0. "
+                "Use 'default_final_step' instead.",
+                # TODO: remove in 1.5.0
+                FutureWarning,
             )
             default_final_step = default_final_step or default_final_state
 
         if targets is not None and not isinstance(targets, list):
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "targets can only be None or a list of kinds or DataTargetBase derivatives"
             )
@@ -454,14 +487,42 @@
                 target = DataTargetBase(
                     target, name=str(target), partitioned=(target == "parquet")
                 )
             self.spec.targets.update(target)
         if default_final_step:
             self.spec.graph.final_step = default_final_step
 
+    def validate_steps(self, namespace):
+        if not self.spec:
+            return
+        if not self.spec.graph:
+            return
+        for step in self.spec.graph.steps.values():
+            if (
+                step.class_name in queue_class_names
+                or step.class_name is None
+                or "." not in step.class_name
+            ):
+                #  we are not checking none class names or queue class names.
+                continue
+            class_object, class_name = step.get_step_class_object(namespace=namespace)
+            if not hasattr(class_object, "validate_args"):
+                continue
+            class_args = step.get_full_class_args(
+                namespace=namespace, class_object=class_object
+            )
+            if class_name.startswith("storey"):
+                class_object.validate_args(
+                    **(class_args if class_args is not None else {})
+                )
+            else:
+                class_object.validate_args(
+                    self, **(class_args if class_args is not None else {})
+                )
+
     def purge_targets(self, target_names: List[str] = None, silent: bool = False):
         """Delete data of specific targets
         :param target_names: List of names of targets to delete (default: delete all ingested targets)
         :param silent: Fail silently if target doesn't exist in featureset status"""
 
         verify_feature_set_permissions(
             self, mlrun.api.schemas.AuthorizationAction.delete
@@ -595,15 +656,15 @@
         self._spec.features.update(feature, name)
 
     def link_analysis(self, name, uri):
         """add a linked file/artifact (chart, data, ..)"""
         self._spec.analysis[name] = uri
 
     @property
-    def graph(self):
+    def graph(self) -> RootFlowStep:
         """feature set transformation graph/DAG"""
         return self.spec.graph
 
     def _add_aggregation_to_existing(self, new_aggregation):
         name = new_aggregation["name"]
         if name in self._aggregations:
             current_aggr = self._aggregations[name]
@@ -648,15 +709,16 @@
 
             myset.add_aggregation("ask", ["sum", "max"], "1h", "10m", name="asks")
 
         :param column:     name of column/field aggregate. Do not name columns starting with either `_` or `aggr_`.
                            They are reserved for internal use, and the data does not ingest correctly.
                            When using the pandas engine, do not use spaces (` `) or periods (`.`) in the column names;
                            they cause errors in the ingestion.
-        :param operations: aggregation operations, e.g. ['sum', 'std']
+        :param operations: aggregation operations. Supported operations:
+                             count, sum, sqr, max, min, first, last, avg, stdvar, stddev
         :param windows:    time windows, can be a single window, e.g. '1h', '1d',
                             or a list of same unit windows e.g. ['1h', '6h']
                             windows are transformed to fixed windows or
                             sliding windows depending whether period parameter
                             provided.
 
                             - Sliding window is fixed-size overlapping windows
@@ -686,17 +748,18 @@
         """
         if isinstance(operations, str):
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "Invalid parameters provided - operations must be a list."
             )
         if state_name:
             warnings.warn(
-                "The state_name parameter is deprecated. Use step_name instead",
-                # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-                PendingDeprecationWarning,
+                "The 'state_name' parameter is deprecated in 1.3.0 and will be removed in 1.5.0. "
+                "Use 'step_name' instead.",
+                # TODO: remove in 1.5.0
+                FutureWarning,
             )
             step_name = step_name or state_name
 
         name = name or column
 
         if isinstance(windows, str):
             windows = [windows]
@@ -780,18 +843,45 @@
         if self.status.stats:
             return pd.DataFrame.from_dict(self.status.stats, orient="index")
 
     def __getitem__(self, name):
         return self._spec.features[name]
 
     def __setitem__(self, key, item):
-        self._spec.features.update(item, key)
+        if key not in self._spec.entities.keys():
+            self._spec.features.update(item, key)
+        else:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                "A `FeatureSet` cannot have an entity and a feature with the same name. "
+                f"The feature that was given to add '{key}' has the same name of the `FeatureSet`'s entity."
+            )
 
     def plot(self, filename=None, format=None, with_targets=False, **kw):
-        """generate graphviz plot"""
+        """plot/save graph using graphviz
+
+        example::
+
+            import mlrun.feature_store as fstore
+            ...
+            ticks = fstore.FeatureSet("ticks",
+                            entities=["stock"],
+                            timestamp_key="timestamp")
+            ticks.add_aggregation(name='priceN',
+                                column='price',
+                                operations=['avg'],
+                                windows=['1d'],
+                                period='1h')
+            ticks.plot(rankdir="LR", with_targets=True)
+
+        :param filename:     target filepath for the graph image (None for the notebook)
+        :param format:       the output format used for rendering (``'pdf'``, ``'png'``, etc.)
+        :param with_targets: show targets in the graph image
+        :param kw:           kwargs passed to graphviz, e.g. rankdir=”LR” (see https://graphviz.org/doc/info/attrs.html)
+        :return:             graphviz graph object
+        """
         graph = self.spec.graph
         _, default_final_step, _ = graph.check_and_process_graph(allow_empty=True)
         targets = None
         if with_targets:
             validate_target_list(targets=targets)
             validate_target_placement(graph, default_final_step, self.spec.targets)
             targets = [
@@ -891,14 +981,27 @@
 
         self.status = feature_set.status
         if update_spec:
             self.spec = feature_set.spec
 
 
 class SparkAggregateByKey(StepToDict):
+    _supported_operations = [
+        "count",
+        "sum",
+        "sqr",
+        "max",
+        "min",
+        "first",
+        "last",
+        "avg",
+        "stdvar",
+        "stddev",
+    ]
+
     def __init__(
         self,
         key_columns: List[str],
         time_column: str,
         aggregates: List[Dict],
         emit_policy: Union[EmitPolicy, Dict] = None,
     ):
@@ -923,26 +1026,49 @@
             unit = "minute"
         elif unit == "s":
             unit = "second"
         else:
             raise ValueError(f"Invalid duration '{duration}'")
         return f"{num} {unit}"
 
+    @staticmethod
+    def _verify_operation(op):
+        if op not in SparkAggregateByKey._supported_operations:
+            error_string = (
+                f"operation {op} is unsupported. Supported operations: "
+                + ", ".join(SparkAggregateByKey._supported_operations)
+            )
+            raise mlrun.errors.MLRunInvalidArgumentError(error_string)
+
     def _extract_fields_from_aggregate_dict(self, aggregate):
         name = aggregate["name"]
         column = aggregate["column"]
         operations = aggregate["operations"]
+        for op in operations:
+            self._verify_operation(op)
         windows = aggregate["windows"]
         spark_period = (
             self._duration_to_spark_format(aggregate["period"])
             if "period" in aggregate
             else None
         )
         return name, column, operations, windows, spark_period
 
+    @staticmethod
+    def _get_aggr(operation, column):
+        import pyspark.sql.functions as funcs
+
+        if operation == "sqr":
+            return funcs.sum(funcs.expr(f"{column} * {column}"))
+        elif operation == "stdvar":
+            return funcs.variance(column)
+        else:
+            func = getattr(funcs, operation)
+            return func(column)
+
     def do(self, event):
         import pyspark.sql.functions as funcs
         from pyspark.sql import Window
 
         time_column = self.time_column or "time"
         input_df = event
 
@@ -963,17 +1089,17 @@
                     spark_period,
                 ) = self._extract_fields_from_aggregate_dict(aggregate)
 
                 for window in windows:
                     spark_window = self._duration_to_spark_format(window)
                     aggs = last_value_aggs
                     for operation in operations:
-                        func = getattr(funcs, operation)
+                        agg = self._get_aggr(operation, column)
                         agg_name = f"{name if name else column}_{operation}_{window}"
-                        agg = func(column).alias(agg_name)
+                        agg = agg.alias(agg_name)
                         aggs.append(agg)
                     window_column = funcs.window(
                         time_column, spark_window, spark_period
                     )
                     df = input_df.groupBy(
                         *self.key_columns,
                         window_column.end.alias(time_column),
@@ -1022,19 +1148,17 @@
                     )
                     window_rank_cols.append(window_rank_col)
                     drop_columns.extend([window_col, window_rank_col])
 
                     window_counter += 1
 
                     for operation in operations:
-                        func = getattr(funcs, operation)
+                        agg = self._get_aggr(operation, column)
                         agg_name = f"{name if name else column}_{operation}_{window}"
-                        win_df = win_df.withColumn(
-                            agg_name, func(column).over(function_window)
-                        )
+                        win_df = win_df.withColumn(agg_name, agg.over(function_window))
 
                     union_df = (
                         union_df.unionByName(win_df, allowMissingColumns=True)
                         if union_df
                         else win_df
                     )
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## mlrun/feature_store/feature_vector.py

```diff
@@ -8,14 +8,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import collections
+import logging
 from copy import copy
 from enum import Enum
 from typing import List, Union
 
 import numpy as np
 import pandas as pd
 
@@ -315,18 +316,22 @@
             feature_set, name, _ = parse_feature_string(self.spec.label_feature)
             self.status.label_column = name
             label_column_name = name
             label_column_fset = feature_set
 
         def add_feature(name, alias, feature_set_object, feature_set_full_name):
             if alias in processed_features.keys():
-                raise mlrun.errors.MLRunInvalidArgumentError(
+                logging.log(
+                    logging.WARN,
                     f"feature name/alias {alias} already specified,"
-                    " use another alias (feature-set.name [as alias])"
+                    " you need to use another alias (feature-set.name [as alias])"
+                    f" by default it changed to be {alias}_{feature_set_full_name}",
                 )
+                alias = f"{alias}_{feature_set_full_name}"
+
             feature = feature_set_object[name]
             processed_features[alias or name] = (feature_set_object, feature)
             feature_set_fields[feature_set_full_name].append((name, alias))
 
         for feature in features:
             project_name, feature = parse_project_name_from_feature_string(feature)
             feature_set, feature_name, alias = parse_feature_string(feature)
@@ -511,14 +516,16 @@
                         data[column] = None
 
             if self._impute_values and data:
                 for name in data.keys():
                     v = data[name]
                     if v is None or (type(v) == float and (np.isinf(v) or np.isnan(v))):
                         data[name] = self._impute_values.get(name, v)
+            for name in list(self.vector.spec.entity_fields.keys()):
+                data.pop(name, None)
 
             if as_list and data:
                 data = [
                     data.get(key, None)
                     for key in requested_columns
                     if key != self.vector.status.label_column
                 ]
```

## mlrun/feature_store/ingestion.py

```diff
@@ -92,15 +92,15 @@
     data_result = None
     total_rows = 0
     targets = [get_target_driver(target, featureset) for target in targets]
     if featureset.spec.passthrough:
         targets = [target for target in targets if not target.is_offline]
     for chunk in chunks:
         event = MockEvent(body=chunk)
-        if featureset.spec.entities[0] and isinstance(event.body, pd.DataFrame):
+        if len(featureset.spec.entities) and isinstance(event.body, pd.DataFrame):
             # set the entities to be the indexes of the df
             event.body = entities_to_index(featureset, event.body)
 
         data = server.run(event, get_body=True)
         if data is not None:
             for i, target in enumerate(targets):
                 size = target.write_dataframe(
@@ -150,15 +150,22 @@
 
 def run_spark_graph(df, featureset, namespace, spark):
     """run spark (sync) pipeline"""
     cache = ResourceCache()
     graph = featureset.spec.graph.copy()
     if graph.engine != "sync":
         raise mlrun.errors.MLRunInvalidArgumentError("spark must use sync graph")
-
+    for step_dict in graph.steps.values():
+        if step_dict.class_name in [
+            "mlrun.feature_store.steps.FeaturesetValidator",
+            "mlrun.feature_store.steps.SetEventMetadata",
+        ]:
+            raise mlrun.errors.MLRunRuntimeError(
+                f"{step_dict.class_name} is not supported for spark engine."
+            )
     server = create_graph_server(graph=graph, parameters={})
     server.init_states(context=None, namespace=namespace, resource_cache=cache)
     server.init_object(namespace)
     server.context.spark = spark
     event = MockEvent(body=df)
     return server.run(event, get_body=True)
```

## mlrun/feature_store/steps.py

```diff
@@ -268,20 +268,20 @@
 
         :param method:        for future use
         :param default_value: default value if not specified per column
         :param mapping:       a dict of per column default value
         :param kwargs:        optional kwargs (for storey)
         """
         super().__init__(**kwargs)
-        self.mapping = mapping
+        self.mapping = mapping or {}
         self.method = method
         self.default_value = default_value
 
-    def _impute(self, feature: str, value):
-        if value is None:
+    def _impute(self, feature: str, value: Any):
+        if pd.isna(value):
             return self.mapping.get(feature, self.default_value)
         return value
 
     def _do_storey(self, event):
         imputed_values = {
             feature: self._impute(feature, val) for feature, val in event.items()
         }
@@ -453,26 +453,14 @@
         :param parts: list of pandas style date-time parts you want to extract.
         :param timestamp_col: The name of the column containing the timestamps to extract from,
                               by default "timestamp"
         """
         super().__init__(**kwargs)
         self.timestamp_col = timestamp_col if timestamp_col else "timestamp"
         self.parts = parts
-        self.fstore_date_format_to_spark_date_format = {
-            "day_of_year": "DD",
-            "day_of_month": "dd",
-            "dayofyear": "DD",
-            "dayofmonth": "dd",
-            "month": "MM",
-            "year": "yyyy",
-            "quarter": "Q",
-            "hour": "hh",
-            "minute": "mm",
-            "second": "ss",
-        }
 
     def _get_key_name(self, part: str):
         return f"{self.timestamp_col}_{part}"
 
     def _extract_timestamp(self, event):
         # Extract timestamp
         try:
@@ -501,24 +489,26 @@
             # Extract part and add it to event
             event[self._get_key_name(part)] = timestamp.map(
                 lambda x: getattr(pd.Timestamp(x), part)
             )
         return event
 
     def _do_spark(self, event):
-        from pyspark.sql.functions import date_format
+        import pyspark.sql.functions
 
         for part in self.parts:
-            if part in self.fstore_date_format_to_spark_date_format:
+            func = part
+            # spark's naming for these functions is without underscores
+            if func in ("day_of_year", "day_of_month"):
+                func = func.replace("_", "")
+            func = getattr(pyspark.sql.functions, func, None)
+            if func:
                 event = event.withColumn(
                     self._get_key_name(part),
-                    date_format(
-                        self.timestamp_col,
-                        self.fstore_date_format_to_spark_date_format[part],
-                    ),
+                    func(self.timestamp_col).cast("long"),
                 )
             else:
                 raise mlrun.errors.MLRunRuntimeError(
                     f"DateExtractor with spark engine doesn't support {part} param"
                 )
         return event
 
@@ -556,16 +546,17 @@
         :param id_path:   path to the id value
         :param key_path:  path to the key value
         :param time_path: DEPRECATED
         :param random_id: if True will set the event.id to a random value
         """
         if time_path:
             warnings.warn(
-                "SetEventMetadata's time_path parameter is deprecated and has no effect",
-                PendingDeprecationWarning,
+                "SetEventMetadata's 'time_path' parameter is deprecated in 1.3.0 and will be removed in 1.5.0. "
+                "It has no effect.",
+                FutureWarning,
             )
 
         kwargs["full_event"] = True
         super().__init__(**kwargs)
         self.id_path = id_path
         self.key_path = key_path
         self.random_id = random_id
@@ -606,15 +597,15 @@
         example::
 
             feature_set = fstore.FeatureSet("fs-new",
                                         entities=[fstore.Entity("id")],
                                         description="feature set",
                                         engine="pandas",
                                         )
-            # Pre-processing grpah steps
+            # Pre-processing graph steps
             feature_set.graph.to(DropFeatures(features=["age"]))
             df_pandas = fstore.ingest(feature_set, data)
 
         """
         super().__init__(**kwargs)
         self.features = features
 
@@ -629,7 +620,17 @@
         return event
 
     def _do_pandas(self, event):
         return event.drop(columns=self.features)
 
     def _do_spark(self, event):
         return event.drop(*self.features)
+
+    @classmethod
+    def validate_args(cls, feature_set, **kwargs):
+        features = kwargs.get("features", [])
+        entity_names = list(feature_set.spec.entities.keys())
+        dropped_entities = set(features).intersection(entity_names)
+        if dropped_entities:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                f"DropFeatures can only drop features, not entities: {dropped_entities}"
+            )
```

## mlrun/feature_store/retrieval/__init__.py

```diff
@@ -7,14 +7,15 @@
 #   http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import mlrun.errors
 
 from .dask_merger import DaskFeatureMerger
 from .job import run_merge_job  # noqa
 from .local_merger import LocalFeatureMerger
 from .online import init_feature_vector_graph  # noqa
 from .spark_merger import SparkFeatureMerger
 
@@ -24,8 +25,13 @@
     "spark": SparkFeatureMerger,
 }
 
 
 def get_merger(kind):
     if not kind:
         return LocalFeatureMerger
-    return mergers.get(kind)
+    merger = mergers.get(kind)
+    if not merger:
+        raise mlrun.errors.MLRunInvalidArgumentError(
+            f"No merger was found for engine '{kind}'. Supported engines: {', '.join(mergers)}."
+        )
+    return merger
```

## mlrun/feature_store/retrieval/base.py

```diff
@@ -9,57 +9,82 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import abc
+import typing
+from datetime import datetime
 
 import mlrun
 from mlrun.datastore.targets import CSVTarget, ParquetTarget
+from mlrun.feature_store.feature_set import FeatureSet
+from mlrun.feature_store.feature_vector import Feature
 
 from ...utils import logger
+from ..feature_vector import OfflineVectorResponse
 
 
 class BaseMerger(abc.ABC):
     """abstract feature merger class"""
 
+    engine = None
+
     def __init__(self, vector, **engine_args):
+        self._relation = dict()
+        self._join_type = "inner"
         self.vector = vector
 
         self._result_df = None
         self._drop_columns = []
         self._index_columns = []
         self._drop_indexes = True
         self._target = None
+        self._alias = dict()
+        self._origin_alias = dict()
 
     def _append_drop_column(self, key):
         if key and key not in self._drop_columns:
             self._drop_columns.append(key)
 
     def _append_index(self, key):
         if key:
             if key not in self._index_columns:
                 self._index_columns.append(key)
             if self._drop_indexes:
                 self._append_drop_column(key)
 
+    def _update_alias(self, key: str = None, val: str = None, dictionary: dict = None):
+        if dictionary is not None:
+            # adding dictionary to alias
+            self._alias.update(dictionary)
+        elif val in self._alias.values():
+            # changing alias key
+            old_key = [key for key, v in self._alias.items() if v == val][0]
+            self._alias[key] = self._alias.pop(old_key)
+        else:
+            self._alias[key] = val
+
     def start(
         self,
         entity_rows=None,
         entity_timestamp_column=None,
         target=None,
         drop_columns=None,
         start_time=None,
         end_time=None,
         with_indexes=None,
         update_stats=None,
         query=None,
+        join_type="inner",
+        order_by=None,
     ):
         self._target = target
+        self._join_type = join_type
 
         # calculate the index columns and columns we need to drop
         self._drop_columns = drop_columns or self._drop_columns
         if self.vector.spec.with_indexes or with_indexes:
             self._drop_indexes = False
 
         if entity_timestamp_column and self._drop_indexes:
@@ -88,29 +113,39 @@
             entity_rows,
             entity_timestamp_column,
             feature_set_objects=feature_set_objects,
             feature_set_fields=feature_set_fields,
             start_time=start_time,
             end_time=end_time,
             query=query,
+            order_by=order_by,
         )
 
     def _write_to_target(self):
+        self.vector.spec.with_indexes = not self._drop_indexes
         if self._target:
             is_persistent_vector = self.vector.metadata.name is not None
             if not self._target.path and not is_persistent_vector:
                 raise mlrun.errors.MLRunInvalidArgumentError(
                     "target path was not specified"
                 )
             self._target.set_resource(self.vector)
             size = self._target.write_dataframe(self._result_df)
             if is_persistent_vector:
                 target_status = self._target.update_resource_status("ready", size=size)
                 logger.info(f"wrote target: {target_status}")
                 self.vector.save()
+        if self.vector.spec.with_indexes:
+            self.vector.spec.entity_fields = [
+                Feature(name=feature, value_type=self._result_df[feature].dtype)
+                if self._result_df[feature].dtype.name != "object"
+                else Feature(name=feature, value_type="str")
+                for feature in self._index_columns
+            ]
+            self.vector.save()
 
     def _set_indexes(self, df):
         if self._index_columns and not self._drop_indexes:
             if df.index is None or df.index.name is None:
                 index_columns_missing = []
                 for index in self._index_columns:
                     if index not in df.columns:
@@ -118,106 +153,561 @@
                 if not index_columns_missing:
                     df.set_index(self._index_columns, inplace=True)
                 else:
                     logger.warn(
                         f"Can't set index, not all index columns found: {index_columns_missing}. "
                         f"It is possible that column was already indexed."
                     )
+        else:
+            df.reset_index(drop=True, inplace=True)
 
-    @abc.abstractmethod
     def _generate_vector(
         self,
         entity_rows,
         entity_timestamp_column,
         feature_set_objects,
         feature_set_fields,
         start_time=None,
         end_time=None,
         query=None,
+        order_by=None,
     ):
-        raise NotImplementedError("_generate_vector() operation not supported in class")
+        self._create_engine_env()
+
+        feature_sets = []
+        dfs = []
+        keys = (
+            []
+        )  # the struct of key is [[[],[]], ..] So that each record indicates which way the corresponding
+        # featureset is connected to the previous one, and within each record the left keys are indicated in index 0
+        # and the right keys in index 1, this keys will be the keys that will be used in this join
+
+        fs_link_list = self._create_linked_relation_list(
+            feature_set_objects, feature_set_fields
+        )
+
+        for node in fs_link_list:
+            name = node.name
+            feature_set = feature_set_objects[name]
+            feature_sets.append(feature_set)
+            columns = feature_set_fields[name]
+            self._origin_alias.update({name: alias for name, alias in columns})
+            column_names = [name for name, _ in columns]
+
+            for column in node.data["save_cols"]:
+                if column not in column_names:
+                    self._append_drop_column(column)
+                    column_names.append(column)
+
+            df = self._get_engine_df(
+                feature_set,
+                name,
+                column_names,
+                start_time,
+                end_time,
+                entity_timestamp_column,
+            )
+
+            column_names += node.data["save_index"]
+            node.data["save_cols"] += node.data["save_index"]
+            if feature_set.spec.timestamp_key:
+                entity_timestamp_column_list = [feature_set.spec.timestamp_key]
+                column_names += entity_timestamp_column_list
+                node.data["save_cols"] += entity_timestamp_column_list
+                if not entity_timestamp_column:
+                    # if not entity_timestamp_column the firs `FeatureSet` will define it
+                    entity_timestamp_column = feature_set.spec.timestamp_key
+
+            # rename columns to be unique for each feature set and select if needed
+            rename_col_dict = {
+                column: f"{column}_{name}"
+                for column in column_names
+                if column not in node.data["save_cols"]
+            }
+            fs_entities = list(feature_set.spec.entities.keys())
+            df_temp = self._rename_columns_and_select(
+                df, rename_col_dict, columns=list(set(column_names + fs_entities))
+            )
+
+            if df_temp is not None:
+                df = df_temp
+                del df_temp
+
+            dfs.append(df)
+            del df
+
+            keys.append([node.data["left_keys"], node.data["right_keys"]])
+
+            # update alias according to the unique column name
+            new_columns = []
+            if not self._drop_indexes:
+                new_columns.extend([(ind, ind) for ind in fs_entities])
+            for column, alias in columns:
+                if column in rename_col_dict:
+                    new_columns.append((rename_col_dict[column], alias or column))
+                else:
+                    new_columns.append((column, alias))
+            self._update_alias(dictionary={name: alias for name, alias in new_columns})
+
+        # convert pandas entity_rows to spark DF if needed
+        if (
+            entity_rows is not None
+            and not hasattr(entity_rows, "rdd")
+            and self.engine == "spark"
+        ):
+            entity_rows = self.spark.createDataFrame(entity_rows)
+
+        # join the feature data frames
+        self.merge(
+            entity_df=entity_rows,
+            entity_timestamp_column=entity_timestamp_column,
+            featuresets=feature_sets,
+            featureset_dfs=dfs,
+            keys=keys,
+        )
+
+        all_columns = None
+        if not self._drop_indexes and entity_timestamp_column:
+            if entity_timestamp_column not in self._alias.values():
+                self._update_alias(
+                    key=entity_timestamp_column, val=entity_timestamp_column
+                )
+            all_columns = list(self._alias.keys())
+
+        df_temp = self._rename_columns_and_select(
+            self._result_df, self._alias, columns=all_columns
+        )
+        if df_temp is not None:
+            self._result_df = df_temp
+            del df_temp
+
+        df_temp = self._drop_columns_from_result()
+        if df_temp is not None:
+            self._result_df = df_temp
+            del df_temp
+
+        if self.vector.status.label_column:
+            self._result_df = self._result_df.dropna(
+                subset=[self.vector.status.label_column]
+            )
+        # filter joined data frame by the query param
+        if query:
+            self._filter(query)
+
+        if order_by:
+            if isinstance(order_by, str):
+                order_by = [order_by]
+            order_by_active = [
+                order_col
+                if order_col in self._result_df.columns
+                else self._origin_alias.get(order_col, None)
+                for order_col in order_by
+            ]
+            if None in order_by_active:
+                raise mlrun.errors.MLRunInvalidArgumentError(
+                    f"Result dataframe contains {self._result_df.columns} "
+                    f"columns and can't order by {order_by}"
+                )
+            self._order_by(order_by_active)
+
+        self._write_to_target()
+        return OfflineVectorResponse(self)
 
     def _unpersist_df(self, df):
         pass
 
     def merge(
         self,
         entity_df,
         entity_timestamp_column: str,
         featuresets: list,
         featureset_dfs: list,
+        keys: list = None,
     ):
         """join the entities and feature set features into a result dataframe"""
         merged_df = entity_df
         if entity_df is None and featureset_dfs:
             merged_df = featureset_dfs.pop(0)
             featureset = featuresets.pop(0)
+            if keys is not None:
+                keys.pop(0)
+            else:
+                # keys can be multiple keys on each side of the join
+                keys = [[[], []]] * len(featureset_dfs)
             entity_timestamp_column = (
                 entity_timestamp_column or featureset.spec.timestamp_key
             )
+        elif entity_df is not None and featureset_dfs:
+            # when `entity_rows` passed to `get_offline_features`
+            # keys[0] mention the way that `entity_rows`  joins to the first `featureset`
+            # and it can join only by the entities of the first `featureset`
+            keys[0][0] = keys[0][1] = list(featuresets[0].spec.entities.keys())
 
-        for i in range(len(featuresets)):
-            featureset = featuresets[i]
-            featureset_df = featureset_dfs[i]
+        for featureset, featureset_df, lr_key in zip(featuresets, featureset_dfs, keys):
             if featureset.spec.timestamp_key:
                 merge_func = self._asof_join
+                if self._join_type != "inner":
+                    logger.warn(
+                        "Merge all the features with as_of_join and don't "
+                        "take into account the join_type that was given"
+                    )
             else:
                 merge_func = self._join
 
             merged_df = merge_func(
                 merged_df,
                 entity_timestamp_column,
                 featureset,
                 featureset_df,
+                lr_key[0],
+                lr_key[1],
             )
 
             # unpersist as required by the implementation (e.g. spark) and delete references
             # to dataframe to allow for GC to free up the memory (local, dask)
             self._unpersist_df(featureset_df)
-            featureset_dfs[i] = None
             del featureset_df
 
         self._result_df = merged_df
 
     @abc.abstractmethod
     def _asof_join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
         featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
         raise NotImplementedError("_asof_join() operation not implemented in class")
 
     @abc.abstractmethod
     def _join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
         featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
         raise NotImplementedError("_join() operation not implemented in class")
 
     def get_status(self):
         """return the status of the merge operation (in case its asynchrounious)"""
         if self._result_df is None:
             raise RuntimeError("unexpected status, no result df")
         return "completed"
 
     def get_df(self, to_pandas=True):
         """return the result as a dataframe (pandas by default)"""
+        self._set_indexes(self._result_df)
         return self._result_df
 
     def to_parquet(self, target_path, **kw):
         """return results as parquet file"""
         size = ParquetTarget(path=target_path).write_dataframe(self._result_df, **kw)
         return size
 
     def to_csv(self, target_path, **kw):
         """return results as csv file"""
         size = CSVTarget(path=target_path).write_dataframe(self._result_df, **kw)
         return size
 
+    class _Node:
+        def __init__(self, name: str, order: int, data=None):
+            self.name = name
+            self.data = data
+            # order of this feature_set in the original list
+            self.order = order
+            self.next = None
+
+        def __repr__(self):
+            return self.name
+
+        def __eq__(self, other):
+            return self.name == other.name
+
+        def __copy__(self):
+            return BaseMerger._Node(self.name, self.order, self.data.copy())
+
+    class _LinkedList:
+        def __init__(self, head=None):
+            self.head = head
+            self.len = 1 if head is not None else 0
+
+        def __repr__(self):
+            node = self.head
+            nodes = []
+            while node is not None:
+                nodes.append(node.name)
+                node = node.next
+            nodes.append("None")
+            return " -> ".join(nodes)
+
+        def __iter__(self):
+            node = self.head
+            while node is not None:
+                yield node
+                node = node.next
+
+        def __copy__(self):
+            ll = BaseMerger._LinkedList()
+            prev_node = None
+            for node in self:
+                new_node = node.__copy__()
+                if ll.head is None:
+                    ll.head = new_node
+                else:
+                    prev_node.next = new_node
+                prev_node = new_node
+            ll.len = self.len
+            return ll
+
+        def add_first(self, node):
+            node.next = self.head
+            self.head = node
+            self.len += 1
+
+        def add_last(self, node):
+            if self.head is None:
+                self.head = node
+                return
+            for current_node in self:
+                pass
+            current_node.next = node
+            while node:
+                self.len += 1
+                node = node.next
+
+        def add_after(self, target_node, new_node):
+            new_node.next = target_node.next
+            target_node.next = new_node
+            self.len += 1
+
+        def find_node(self, target_node_name: str):
+            if self.head is None:
+                return None
+
+            for node in self:
+                if node.name == target_node_name:
+                    return node
+
+        def concat(self, other):
+            other_iter = iter(other)
+            other_head = next(other_iter)
+            node = self.find_node(other_head.name)
+            if node is None:
+                return
+            for col in other_head.data["save_cols"]:
+                if col not in node.data["save_cols"]:
+                    node.data["save_cols"].append(col)
+            for other_node in other_iter:
+                if self.find_node(other_node.name) is None:
+                    while node is not None and other_node.order > node.order:
+                        node = node.next
+                    if node:
+                        self.add_after(node, other_node)
+                    else:
+                        self.add_last(other_node)
+                    node = other_node
+
+    @staticmethod
+    def _create_linked_relation_list(feature_set_objects, feature_set_fields):
+        feature_set_names = list(feature_set_fields.keys())
+        if len(feature_set_names) == 1:
+            return BaseMerger._LinkedList(
+                head=BaseMerger._Node(
+                    name=feature_set_names[0],
+                    order=0,
+                    data={
+                        "left_keys": [],
+                        "right_keys": [],
+                        "save_cols": [],
+                        "save_index": [],
+                    },
+                )
+            )
+        relation_linked_lists = []
+        feature_set_entity_list_dict = {
+            name: feature_set_objects[name].spec.entities for name in feature_set_names
+        }
+        entity_relation_val_list = {
+            name: list(feature_set_objects[name].spec.relations.values())
+            for name in feature_set_names
+        }
+        entity_relation_key_list = {
+            name: list(feature_set_objects[name].spec.relations.keys())
+            for name in feature_set_names
+        }
+
+        def _create_relation(name: str, order):
+            relations = BaseMerger._LinkedList()
+            main_node = BaseMerger._Node(
+                name,
+                data={
+                    "left_keys": [],
+                    "right_keys": [],
+                    "save_cols": [],
+                    "save_index": [],
+                },
+                order=order,
+            )
+            relations.add_first(main_node)
+            return relations
+
+        def _build_relation(
+            fs_name_in: str, name_in_order, linked_list_relation, head_order
+        ):
+            name_head = linked_list_relation.head.name
+            feature_set_in_entity_list = feature_set_entity_list_dict[fs_name_in]
+            feature_set_in_entity_list_names = list(feature_set_in_entity_list.keys())
+            entity_relation_list = entity_relation_val_list[name_head]
+            col_relation_list = entity_relation_key_list[name_head]
+            curr_col_relation_list = list(
+                map(
+                    lambda ent: (
+                        col_relation_list[entity_relation_list.index(ent)]
+                        if ent in entity_relation_list
+                        else False
+                    ),
+                    feature_set_in_entity_list,
+                )
+            )
+
+            if all(
+                curr_col_relation_list
+            ):  # checking if feature_set have relation with feature_set_in
+                # add to the link list feature set according to the defined relation
+                linked_list_relation.add_last(
+                    BaseMerger._Node(
+                        fs_name_in,
+                        data={
+                            "left_keys": curr_col_relation_list,
+                            "right_keys": feature_set_in_entity_list_names,
+                            "save_cols": [],
+                            "save_index": [],
+                        },
+                        order=name_in_order,
+                    )
+                )
+                linked_list_relation.head.data["save_cols"].extend(
+                    curr_col_relation_list
+                )
+            elif name_in_order > head_order and sorted(
+                feature_set_in_entity_list_names
+            ) == sorted(feature_set_entity_list_dict[name_head].keys()):
+                # add to the link list feature set according to indexes match
+                keys = feature_set_in_entity_list_names
+                linked_list_relation.add_last(
+                    BaseMerger._Node(
+                        fs_name_in,
+                        data={
+                            "left_keys": keys,
+                            "right_keys": keys,
+                            "save_cols": [],
+                            "save_index": keys,
+                        },
+                        order=name_in_order,
+                    )
+                )
+                linked_list_relation.head.data["save_index"] = keys
+            return linked_list_relation
+
+        for i, name in enumerate(feature_set_names):
+            linked_relation = _create_relation(name, i)
+            for j, name_in in enumerate(feature_set_names):
+                if name != name_in:
+                    linked_relation = _build_relation(name_in, j, linked_relation, i)
+            relation_linked_lists.append(linked_relation)
+
+        # concat all the link lists to one, for the merging process
+        for i in range(len(relation_linked_lists)):
+            return_relation = relation_linked_lists[i].__copy__()
+            for relation_list in relation_linked_lists:
+                return_relation.concat(relation_list)
+            if return_relation.len == len(feature_set_objects):
+                return return_relation
+
+        raise mlrun.errors.MLRunRuntimeError("Failed to merge")
+
     @classmethod
     def get_default_image(cls, kind):
         return mlrun.mlconf.feature_store.default_job_image
+
+    def _reset_index(self, _result_df):
+        raise NotImplementedError
+
+    @abc.abstractmethod
+    def _create_engine_env(self):
+        """
+        initialize engine env if needed
+        """
+        raise NotImplementedError
+
+    @abc.abstractmethod
+    def _get_engine_df(
+        self,
+        feature_set: FeatureSet,
+        feature_set_name: typing.List[str],
+        column_names: typing.List[str] = None,
+        start_time: typing.Union[str, datetime] = None,
+        end_time: typing.Union[str, datetime] = None,
+        entity_timestamp_column: str = None,
+    ):
+        """
+        Return the feature_set data frame according to the args
+
+        :param feature_set:             current feature_set to extract from the data frame
+        :param feature_set_name:        the name of the current feature_set
+        :param column_names:            list of columns to select (if not all)
+        :param start_time:              filter by start time
+        :param end_time:                filter by end time
+        :param entity_timestamp_column: specify the time column name in the file
+
+        :return: Data frame of the current engine
+        """
+        raise NotImplementedError
+
+    @abc.abstractmethod
+    def _rename_columns_and_select(
+        self,
+        df,
+        rename_col_dict: typing.Dict[str, str],
+        columns: typing.List[str] = None,
+    ):
+        """
+        rename the columns of the df according to rename_col_dict, and select only `columns` if it is not none
+
+        :param df:              the data frame to change
+        :param rename_col_dict: the renaming dictionary - {<current_column_name>: <new_column_name>, ...}
+        :param columns:         list of columns to select (if not all)
+
+        :return: the data frame after the transformation or None if the transformation were preformed inplace
+        """
+        raise NotImplementedError
+
+    @abc.abstractmethod
+    def _drop_columns_from_result(self):
+        """
+        drop `self._drop_columns` from `self._result_df`
+        """
+        raise NotImplementedError
+
+    @abc.abstractmethod
+    def _filter(self, query: str):
+        """
+        filter `self._result_df` by `query`
+
+        :param query: The query string used to filter rows
+        """
+        raise NotImplementedError
+
+    @abc.abstractmethod
+    def _order_by(self, order_by_active: typing.List[str]):
+        """
+        Order by `order_by_active` along all axis.
+
+        :param order_by_active: list of names to sort by.
+        """
+        raise NotImplementedError
```

## mlrun/feature_store/retrieval/dask_merger.py

```diff
@@ -8,143 +8,140 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
+import re
+
 import dask.dataframe as dd
-import pandas as pd
 from dask.dataframe.multi import merge, merge_asof
 from dask.distributed import Client
 
 import mlrun
 
-from ..feature_vector import OfflineVectorResponse
 from .base import BaseMerger
 
 
 class DaskFeatureMerger(BaseMerger):
+    engine = "dask"
+
     def __init__(self, vector, **engine_args):
         super().__init__(vector, **engine_args)
         self.client = engine_args.get("dask_client")
         self._dask_cluster_uri = engine_args.get("dask_cluster_uri")
 
-    def _generate_vector(
-        self,
-        entity_rows,
-        entity_timestamp_column,
-        feature_set_objects,
-        feature_set_fields,
-        start_time=None,
-        end_time=None,
-        query=None,
-    ):
-        # init the dask client if needed
-        if not self.client:
-            if self._dask_cluster_uri:
-                function = mlrun.import_function(self._dask_cluster_uri)
-                self.client = function.client
-            else:
-                self.client = Client()
-
-        # load dataframes
-        feature_sets = []
-        dfs = []
-        for name, columns in feature_set_fields.items():
-            feature_set = feature_set_objects[name]
-            feature_sets.append(feature_set)
-            column_names = [name for name, alias in columns]
-            df = feature_set.to_dataframe(
-                columns=column_names,
-                df_module=dd,
-                start_time=start_time,
-                end_time=end_time,
-                time_column=entity_timestamp_column,
-                index=False,
-            )
-            # rename columns with aliases
-            df = df.rename(columns={name: alias for name, alias in columns if alias})
-
-            df = df.persist()
-            dfs.append(df)
-            del df
-
-        self.merge(entity_rows, entity_timestamp_column, feature_sets, dfs)
-
-        # filter joined data frame by the query param
-        if query:
-            self._result_df = self._result_df.query(query)
-
-        self._result_df = self._result_df.drop(
-            columns=self._drop_columns, errors="ignore"
-        )
-
-        if self.vector.status.label_column:
-            self._result_df = self._result_df.dropna(
-                subset=[self.vector.status.label_column]
-            )
-
-        if self._drop_indexes:
-            self._result_df = self._result_df.reset_index(drop=True)
-        self._write_to_target()
-
-        # check if need to set indices
-        self._set_indexes(self._result_df)
-        return OfflineVectorResponse(self)
-
     def _reset_index(self, df):
         to_drop = df.index.name is None
-        return df.reset_index(drop=to_drop)
+        df = df.reset_index(drop=to_drop)
+        return df
 
     def _asof_join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
-        featureset_df: pd.DataFrame,
+        featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
-        indexes = list(featureset.spec.entities.keys())
-
-        entity_df = self._reset_index(entity_df)
-        entity_df = (
-            entity_df
-            if entity_timestamp_column not in entity_df
-            else entity_df.set_index(entity_timestamp_column, drop=True)
-        )
-        featureset_df = self._reset_index(featureset_df)
-        featureset_df = (
-            featureset_df
-            if entity_timestamp_column not in featureset_df
-            else featureset_df.set_index(entity_timestamp_column, drop=True)
-        )
 
         merged_df = merge_asof(
             entity_df,
             featureset_df,
-            left_index=True,
-            right_index=True,
-            by=indexes,
+            left_on=entity_timestamp_column,
+            right_on=entity_timestamp_column,
+            left_by=left_keys or None,
+            right_by=right_keys or None,
+            suffixes=("", f"_{featureset.metadata.name}_"),
         )
+        for col in merged_df.columns:
+            if re.findall(f"_{featureset.metadata.name}_$", col):
+                self._append_drop_column(col)
 
         return merged_df
 
     def _join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
-        featureset_df: pd.DataFrame,
+        featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
-        indexes = list(featureset.spec.entities.keys())
-        merged_df = merge(entity_df, featureset_df, on=indexes)
+
+        fs_name = featureset.metadata.name
+        merged_df = merge(
+            entity_df,
+            featureset_df,
+            how=self._join_type,
+            left_on=left_keys,
+            right_on=right_keys,
+            suffixes=("", f"_{fs_name}_"),
+        )
+        for col in merged_df.columns:
+            if re.findall(f"_{fs_name}_$", col):
+                self._append_drop_column(col)
         return merged_df
 
     def get_status(self):
         if self._result_df is None:
             raise RuntimeError("unexpected status, no result df")
         return "completed"
 
     def get_df(self, to_pandas=True):
         if to_pandas and hasattr(self._result_df, "dask"):
-            return self._result_df.compute()
-        return self._result_df
+            df = self._result_df.compute()
+        else:
+            df = self._result_df
+        self._set_indexes(df)
+        return df
+
+    def _create_engine_env(self):
+        if "index" not in self._index_columns:
+            self._append_drop_column("index")
+
+        # init the dask client if needed
+        if not self.client:
+            if self._dask_cluster_uri:
+                function = mlrun.import_function(self._dask_cluster_uri)
+                self.client = function.client
+            else:
+                self.client = Client()
+
+    def _get_engine_df(
+        self,
+        feature_set,
+        feature_set_name,
+        column_names=None,
+        start_time=None,
+        end_time=None,
+        entity_timestamp_column=None,
+    ):
+        df = feature_set.to_dataframe(
+            columns=column_names,
+            df_module=dd,
+            start_time=start_time,
+            end_time=end_time,
+            time_column=entity_timestamp_column,
+            index=False,
+        )
+
+        return self._reset_index(df).persist()
+
+    def _rename_columns_and_select(self, df, rename_col_dict, columns=None):
+        return df.rename(
+            columns=rename_col_dict,
+        )
+
+    def _drop_columns_from_result(self):
+        self._result_df = self._result_df.drop(
+            columns=self._drop_columns, errors="ignore"
+        )
+
+    def _filter(self, query):
+        self._result_df = self._result_df.query(query)
+
+    def _order_by(self, order_by_active):
+        self._result_df.sort_values(by=order_by_active)
```

## mlrun/feature_store/retrieval/job.py

```diff
@@ -11,14 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import uuid
 
 import mlrun
+from mlrun.config import config as mlconf
 from mlrun.model import DataTargetBase, new_task
 from mlrun.runtimes.function_reference import FunctionReference
 from mlrun.utils import logger
 
 from ...runtimes import RuntimeKinds
 from ..common import RunConfig
 from .base import BaseMerger
@@ -33,49 +34,81 @@
     spark_service: str = None,
     entity_rows=None,
     timestamp_column=None,
     run_config=None,
     drop_columns=None,
     with_indexes=None,
     query=None,
+    join_type="inner",
+    order_by=None,
 ):
     name = vector.metadata.name
     if not target or not hasattr(target, "to_dict"):
         raise mlrun.errors.MLRunInvalidArgumentError("target object must be specified")
-    name = f"{name}_merger"
+    name = f"{name}-merger"
     run_config = run_config or RunConfig()
     kind = run_config.kind or ("spark" if engine == "spark" else "job")
+    run_config.kind = kind
+    default_code = _default_merger_handler.replace("{{{engine}}}", merger.__name__)
     if not run_config.function:
         function_ref = vector.spec.function.copy()
         if function_ref.is_empty():
             function_ref = FunctionReference(name=name, kind=kind)
         if not function_ref.url:
-            function_ref.code = _default_merger_handler.replace(
-                "{{{engine}}}", merger.__name__
-            )
+            function_ref.code = default_code
         run_config.function = function_ref
 
     function = run_config.to_function(kind, merger.get_default_image(kind))
+
+    # Avoid overriding a handler that was provided by the user
+    # The user shouldn't have to provide a handler, but we leave this option open just in case
+    if not run_config.handler:
+        function.with_code(body=default_code)
+
+    function.metadata.project = vector.metadata.project
+    function.metadata.name = function.metadata.name or name
+
     if run_config.kind == RuntimeKinds.remotespark:
         if not spark_service:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "spark_service must be set when running with a remote spark runtime"
             )
         function.with_spark_service(spark_service=spark_service)
-    function.metadata.project = vector.metadata.project
-    function.metadata.name = function.metadata.name or name
+    elif run_config.kind == RuntimeKinds.spark:
+
+        if mlconf.is_running_on_iguazio():
+            function.with_igz_spark()
+
+        def set_default_resources(resources, setter_function):
+            requests = resources.get("requests")
+            set_memory = requests is None or "memory" not in requests
+            set_cpu = requests is None or "cpu" not in requests
+            if set_memory or set_cpu:
+                mem = "1G" if set_memory else None
+                cpu = "1" if set_cpu else None
+                setter_function(mem=mem, cpu=cpu, patch=True)
+
+        set_default_resources(
+            function.spec.driver_resources, function.with_driver_requests
+        )
+        set_default_resources(
+            function.spec.executor_resources, function.with_executor_requests
+        )
+
     task = new_task(
         name=name,
         params={
             "vector_uri": vector.uri,
             "target": target.to_dict(),
             "timestamp_column": timestamp_column,
             "drop_columns": drop_columns,
             "with_indexes": with_indexes,
             "query": query,
+            "join_type": join_type,
+            "order_by": order_by,
             "engine_args": engine_args,
         },
         inputs={"entity_rows": entity_rows},
     )
     task.spec.secret_sources = run_config.secret_sources
     task.set_label("job-type", "feature-merge").set_label("feature-vector", vector.uri)
     task.metadata.uid = uuid.uuid4().hex
@@ -112,38 +145,49 @@
     def to_dataframe(self, columns=None, df_module=None, **kwargs):
         """return result as a dataframe object (generated from the dataitem).
 
         :param columns:   optional, list of columns to select
         :param df_module: optional, py module used to create the DataFrame (e.g. pd, dd, cudf, ..)
         :param kwargs:    extended DataItem.as_df() args
         """
-        return mlrun.get_dataitem(self.target_uri).as_df(
-            columns=columns, df_module=df_module, **kwargs
+
+        file_format = kwargs.get("format")
+        if not file_format:
+            file_format = self.run.status.results["target"]["kind"]
+        df = mlrun.get_dataitem(self.target_uri).as_df(
+            columns=columns, df_module=df_module, format=file_format, **kwargs
         )
+        if self.vector.spec.with_indexes:
+            df.set_index(
+                list(self.vector.spec.entity_fields.keys()), inplace=True, drop=True
+            )
+        return df
 
     @property
     def target_uri(self):
         """return path of the results file"""
         self._is_ready()
         return self.run.output("target")["path"]
 
 
 _default_merger_handler = """
 import mlrun
 import mlrun.feature_store.retrieval
 from mlrun.datastore.targets import get_target_driver
 def merge_handler(context, vector_uri, target, entity_rows=None, 
-                  timestamp_column=None, drop_columns=None, with_indexes=None, query=None, engine_args=None):
+                  timestamp_column=None, drop_columns=None, with_indexes=None, query=None, join_type='inner', 
+                  engine_args=None, order_by=None):
     vector = context.get_store_resource(vector_uri)
     store_target = get_target_driver(target, vector)
     entity_timestamp_column = timestamp_column or vector.spec.timestamp_field
     if entity_rows:
         entity_rows = entity_rows.as_df()
 
     context.logger.info(f"starting vector merge task to {vector.uri}")
     merger = mlrun.feature_store.retrieval.{{{engine}}}(vector, **(engine_args or {}))
     merger.start(entity_rows, entity_timestamp_column, store_target, drop_columns, with_indexes=with_indexes, 
-                 query=query)
+                 query=query, join_type=join_type, order_by=order_by)
+
     target = vector.status.targets[store_target.name].to_dict()
     context.log_result('feature_vector', vector.uri)
     context.log_result('target', target)
 """  # noqa
```

## mlrun/feature_store/retrieval/local_merger.py

```diff
@@ -8,103 +8,42 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import re
+
 import pandas as pd
 
-from ..feature_vector import OfflineVectorResponse
 from .base import BaseMerger
 
 
 class LocalFeatureMerger(BaseMerger):
+    engine = "local"
+
     def __init__(self, vector, **engine_args):
         super().__init__(vector, **engine_args)
 
-    def _generate_vector(
-        self,
-        entity_rows,
-        entity_timestamp_column,
-        feature_set_objects,
-        feature_set_fields,
-        start_time=None,
-        end_time=None,
-        query=None,
-    ):
-
-        feature_sets = []
-        dfs = []
-        for name, columns in feature_set_fields.items():
-            feature_set = feature_set_objects[name]
-            feature_sets.append(feature_set)
-            column_names = [name for name, alias in columns]
-            # handling case where there are multiple feature sets and user creates vector where entity_timestamp_
-            # column is from a specific feature set (can't be entity timestamp)
-            if (
-                entity_timestamp_column in column_names
-                or feature_set.spec.timestamp_key == entity_timestamp_column
-            ):
-                df = feature_set.to_dataframe(
-                    columns=column_names,
-                    start_time=start_time,
-                    end_time=end_time,
-                    time_column=entity_timestamp_column,
-                )
-            else:
-                df = feature_set.to_dataframe(
-                    columns=column_names,
-                    time_column=entity_timestamp_column,
-                )
-            # rename columns with aliases
-            df.rename(
-                columns={name: alias for name, alias in columns if alias}, inplace=True
-            )
-            dfs.append(df)
-            del df
-
-        self.merge(entity_rows, entity_timestamp_column, feature_sets, dfs)
-
-        self._result_df.drop(columns=self._drop_columns, inplace=True, errors="ignore")
-
-        if self.vector.status.label_column:
-            self._result_df.dropna(
-                subset=[self.vector.status.label_column],
-                inplace=True,
-            )
-        # filter joined data frame by the query param
-        if query:
-            self._result_df.query(query, inplace=True)
-
-        if self._drop_indexes:
-            self._result_df.reset_index(drop=True, inplace=True)
-
-        # check if need to set indices
-        self._set_indexes(self._result_df)
-
-        self._write_to_target()
-
-        return OfflineVectorResponse(self)
-
     def _asof_join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
-        featureset_df: pd.DataFrame,
+        featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
-        indexes = list(featureset.spec.entities.keys())
+
+        indexes = None
+        if not right_keys:
+            indexes = list(featureset.spec.entities.keys())
         index_col_not_in_entity = "index" not in entity_df.columns
         index_col_not_in_featureset = "index" not in featureset_df.columns
-        # Sort left and right keys
-        if type(entity_df.index) != pd.RangeIndex:
-            entity_df.reset_index(inplace=True)
-        if type(featureset_df.index) != pd.RangeIndex:
-            featureset_df.reset_index(inplace=True)
         entity_df[entity_timestamp_column] = pd.to_datetime(
             entity_df[entity_timestamp_column]
         )
         featureset_df[featureset.spec.timestamp_key] = pd.to_datetime(
             featureset_df[featureset.spec.timestamp_key]
         )
         entity_df.sort_values(by=entity_timestamp_column, inplace=True)
@@ -112,31 +51,98 @@
 
         merged_df = pd.merge_asof(
             entity_df,
             featureset_df,
             left_on=entity_timestamp_column,
             right_on=featureset.spec.timestamp_key,
             by=indexes,
+            left_by=left_keys or None,
+            right_by=right_keys or None,
+            suffixes=("", f"_{featureset.metadata.name}_"),
         )
+        for col in merged_df.columns:
+            if re.findall(f"_{featureset.metadata.name}_$", col):
+                self._append_drop_column(col)
 
         # Undo indexing tricks for asof merge
         # to return the correct indexes and not
         # overload `index` columns
         if (
-            "index" not in indexes
+            indexes
+            and "index" not in indexes
             and index_col_not_in_entity
             and index_col_not_in_featureset
             and "index" in merged_df.columns
         ):
             merged_df.drop(columns="index", inplace=True)
         return merged_df
 
     def _join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
-        featureset_df: pd.DataFrame,
+        featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
-        indexes = list(featureset.spec.entities.keys())
-        merged_df = pd.merge(entity_df, featureset_df, on=indexes)
+        fs_name = featureset.metadata.name
+        merged_df = pd.merge(
+            entity_df,
+            featureset_df,
+            how=self._join_type,
+            left_on=left_keys,
+            right_on=right_keys,
+            suffixes=("", f"_{fs_name}_"),
+        )
+        for col in merged_df.columns:
+            if re.findall(f"_{fs_name}_$", col):
+                self._append_drop_column(col)
         return merged_df
+
+    def _create_engine_env(self):
+        pass
+
+    def _get_engine_df(
+        self,
+        feature_set,
+        feature_set_name,
+        column_names=None,
+        start_time=None,
+        end_time=None,
+        entity_timestamp_column=None,
+    ):
+        # handling case where there are multiple feature sets and user creates vector where entity_timestamp_
+        # column is from a specific feature set (can't be entity timestamp)
+        if (
+            entity_timestamp_column in column_names
+            or feature_set.spec.timestamp_key == entity_timestamp_column
+        ):
+            df = feature_set.to_dataframe(
+                columns=column_names,
+                start_time=start_time,
+                end_time=end_time,
+                time_column=entity_timestamp_column,
+            )
+        else:
+            df = feature_set.to_dataframe(
+                columns=column_names,
+                time_column=entity_timestamp_column,
+            )
+        if df.index.names[0]:
+            df.reset_index(inplace=True)
+        return df
+
+    def _rename_columns_and_select(self, df, rename_col_dict, columns=None):
+        df.rename(
+            columns=rename_col_dict,
+            inplace=True,
+        )
+
+    def _drop_columns_from_result(self):
+        self._result_df.drop(columns=self._drop_columns, inplace=True, errors="ignore")
+
+    def _filter(self, query):
+        self._result_df.query(query, inplace=True)
+
+    def _order_by(self, order_by_active):
+        self._result_df.sort_values(by=order_by_active, ignore_index=True, inplace=True)
```

## mlrun/feature_store/retrieval/spark_merger.py

```diff
@@ -8,145 +8,46 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
+
 import mlrun
 from mlrun.datastore.targets import get_offline_target
 
 from ...runtimes import RemoteSparkRuntime
 from ...runtimes.sparkjob.abstract import AbstractSparkRuntime
-from ..feature_vector import OfflineVectorResponse
 from .base import BaseMerger
 
 
 class SparkFeatureMerger(BaseMerger):
+    engine = "spark"
+
     def __init__(self, vector, **engine_args):
         super().__init__(vector, **engine_args)
         self.spark = engine_args.get("spark", None)
         self.named_view = engine_args.get("named_view", False)
         self._pandas_df = None
 
     def to_spark_df(self, session, path):
         return session.read.load(path)
 
-    def _generate_vector(
-        self,
-        entity_rows,
-        entity_timestamp_column,
-        feature_set_objects,
-        feature_set_fields,
-        start_time=None,
-        end_time=None,
-        query=None,
-    ):
-        from pyspark.sql import SparkSession
-        from pyspark.sql.functions import col
-
-        if self.spark is None:
-            # create spark context
-            self.spark = SparkSession.builder.appName(
-                f"vector-merger-{self.vector.metadata.name}"
-            ).getOrCreate()
-
-        feature_sets = []
-        dfs = []
-
-        for name, columns in feature_set_fields.items():
-            feature_set = feature_set_objects[name]
-            feature_sets.append(feature_set)
-            column_names = [name for name, alias in columns]
-
-            if feature_set.spec.passthrough:
-                if not feature_set.spec.source:
-                    raise mlrun.errors.MLRunNotFoundError(
-                        f"passthrough feature set {name} with no source"
-                    )
-                source_kind = feature_set.spec.source.kind
-                source_path = feature_set.spec.source.path
-            else:
-                target = get_offline_target(feature_set)
-                if not target:
-                    raise mlrun.errors.MLRunInvalidArgumentError(
-                        f"feature set {name} does not have offline targets"
-                    )
-                source_kind = target.kind
-                source_path = target.get_target_path()
-
-            # handling case where there are multiple feature sets and user creates vector where
-            # entity_timestamp_column is from a specific feature set (can't be entity timestamp)
-            source_driver = mlrun.datastore.sources.source_kind_to_driver[source_kind]
-            if (
-                entity_timestamp_column in column_names
-                or feature_set.spec.timestamp_key == entity_timestamp_column
-            ):
-                source = source_driver(
-                    name=self.vector.metadata.name,
-                    path=source_path,
-                    time_field=entity_timestamp_column,
-                    start_time=start_time,
-                    end_time=end_time,
-                )
-            else:
-                source = source_driver(
-                    name=self.vector.metadata.name,
-                    path=source_path,
-                    time_field=entity_timestamp_column,
-                )
-
-            # add the index/key to selected columns
-            timestamp_key = feature_set.spec.timestamp_key
-
-            df = source.to_spark_df(
-                self.spark, named_view=self.named_view, time_field=timestamp_key
-            )
-
-            if timestamp_key and timestamp_key not in column_names:
-                columns.append((timestamp_key, None))
-            for entity in feature_set.spec.entities.keys():
-                if entity not in column_names:
-                    columns.append((entity, None))
-
-            # select requested columns and rename with alias where needed
-            df = df.select([col(name).alias(alias or name) for name, alias in columns])
-            dfs.append(df)
-            del df
-
-        # convert pandas entity_rows to spark DF if needed
-        if entity_rows is not None and not hasattr(entity_rows, "rdd"):
-            entity_rows = self.spark.createDataFrame(entity_rows)
-
-        # join the feature data frames
-        self.merge(entity_rows, entity_timestamp_column, feature_sets, dfs)
-
-        # filter joined data frame by the query param
-        if query:
-            self._result_df = self._result_df.filter(query)
-
-        self._result_df = self._result_df.drop(*self._drop_columns)
-
-        if self.vector.status.label_column:
-            self._result_df = self._result_df.dropna(
-                subset=[self.vector.status.label_column]
-            )
-
-        self._write_to_target()
-        return OfflineVectorResponse(self)
-
     def _unpersist_df(self, df):
         df.unpersist()
 
     def _asof_join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
         featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
 
         """Perform an as of join between entity and featureset.
         Join conditions:
         Args:
             entity_df (DataFrame): Spark dataframe representing the entities, to be joined with
                 the feature tables.
@@ -161,63 +62,71 @@
                 be prefixed with featureset_df name.
         """
 
         from pyspark.sql import Window
         from pyspark.sql.functions import col, monotonically_increasing_id, row_number
 
         entity_with_id = entity_df.withColumn("_row_nr", monotonically_increasing_id())
-        indexes = list(featureset.spec.entities.keys())
-
+        rename_right_keys = {}
+        for key in right_keys + [entity_timestamp_column]:
+            if key in entity_df.columns:
+                rename_right_keys[key] = f"ft__{key}"
         # get columns for projection
         projection = [
-            col(col_name).alias(
-                f"ft__{col_name}"
-                if col_name in indexes + [entity_timestamp_column]
-                else col_name
-            )
+            col(col_name).alias(rename_right_keys.get(col_name, col_name))
             for col_name in featureset_df.columns
         ]
 
         aliased_featureset_df = featureset_df.select(projection)
 
         # set join conditions
         join_cond = (
             entity_with_id[entity_timestamp_column]
-            >= aliased_featureset_df[f"ft__{entity_timestamp_column}"]
+            >= aliased_featureset_df[
+                rename_right_keys.get(entity_timestamp_column, entity_timestamp_column)
+            ]
         )
 
         # join based on entities
-        for key in indexes:
+        for key_l, key_r in zip(left_keys, right_keys):
             join_cond = join_cond & (
-                entity_with_id[key] == aliased_featureset_df[f"ft__{key}"]
+                entity_with_id[key_l]
+                == aliased_featureset_df[rename_right_keys.get(key_r, key_r)]
             )
 
         conditional_join = entity_with_id.join(
             aliased_featureset_df, join_cond, "leftOuter"
         )
-        for key in indexes + [entity_timestamp_column]:
-            conditional_join = conditional_join.drop(
-                aliased_featureset_df[f"ft__{key}"]
-            )
 
-        window = Window.partitionBy("_row_nr", *indexes).orderBy(
-            col(entity_timestamp_column).desc(),
+        window = Window.partitionBy("_row_nr").orderBy(
+            col(f"ft__{entity_timestamp_column}").desc(),
         )
         filter_most_recent_feature_timestamp = conditional_join.withColumn(
             "_rank", row_number().over(window)
         ).filter(col("_rank") == 1)
 
-        return filter_most_recent_feature_timestamp.drop("_row_nr", "_rank")
+        for key in right_keys + [entity_timestamp_column]:
+            if key in entity_df.columns + [entity_timestamp_column]:
+                filter_most_recent_feature_timestamp = (
+                    filter_most_recent_feature_timestamp.drop(
+                        aliased_featureset_df[f"ft__{key}"]
+                    )
+                )
+        return filter_most_recent_feature_timestamp.drop("_row_nr", "_rank").orderBy(
+            col(entity_timestamp_column)
+        )
 
     def _join(
         self,
         entity_df,
         entity_timestamp_column: str,
         featureset,
         featureset_df,
+        left_keys: list,
+        right_keys: list,
     ):
 
         """
         spark dataframes join
 
         Args:
         entity_df (DataFrame): Spark dataframe representing the entities, to be joined with
@@ -230,16 +139,27 @@
 
         Returns:
             DataFrame: Join result, which contains all the original columns from entity_df, as well
                 as all the features specified in featureset, where the feature columns will
                 be prefixed with featureset_df name.
 
         """
-        indexes = list(featureset.spec.entities.keys())
-        merged_df = entity_df.join(featureset_df, on=indexes)
+        if left_keys != right_keys:
+            join_cond = [
+                entity_df[key_l] == featureset_df[key_r]
+                for key_l, key_r in zip(left_keys, right_keys)
+            ]
+        else:
+            join_cond = left_keys
+
+        merged_df = entity_df.join(
+            featureset_df,
+            join_cond,
+            how=self._join_type,
+        )
         return merged_df
 
     def get_df(self, to_pandas=True):
         if to_pandas:
             if self._pandas_df is None:
                 self._pandas_df = self._result_df.toPandas()
                 self._set_indexes(self._pandas_df)
@@ -253,7 +173,99 @@
             return AbstractSparkRuntime._get_default_deployed_mlrun_image_name(
                 with_gpu=False
             )
         elif kind == RemoteSparkRuntime.kind:
             return RemoteSparkRuntime.default_image
         else:
             raise mlrun.errors.MLRunInvalidArgumentError(f"Unsupported kind '{kind}'")
+
+    def _create_engine_env(self):
+        from pyspark.sql import SparkSession
+
+        if self.spark is None:
+            # create spark context
+            self.spark = SparkSession.builder.appName(
+                f"vector-merger-{self.vector.metadata.name}"
+            ).getOrCreate()
+
+    def _get_engine_df(
+        self,
+        feature_set,
+        feature_set_name,
+        column_names=None,
+        start_time=None,
+        end_time=None,
+        entity_timestamp_column=None,
+    ):
+        if feature_set.spec.passthrough:
+            if not feature_set.spec.source:
+                raise mlrun.errors.MLRunNotFoundError(
+                    f"passthrough feature set {feature_set_name} with no source"
+                )
+            source_kind = feature_set.spec.source.kind
+            source_path = feature_set.spec.source.path
+        else:
+            target = get_offline_target(feature_set)
+            if not target:
+                raise mlrun.errors.MLRunInvalidArgumentError(
+                    f"feature set {feature_set_name} does not have offline targets"
+                )
+            source_kind = target.kind
+            source_path = target.get_target_path()
+
+        # handling case where there are multiple feature sets and user creates vector where
+        # entity_timestamp_column is from a specific feature set (can't be entity timestamp)
+        source_driver = mlrun.datastore.sources.source_kind_to_driver[source_kind]
+        if (
+            entity_timestamp_column in column_names
+            or feature_set.spec.timestamp_key == entity_timestamp_column
+        ):
+            source = source_driver(
+                name=self.vector.metadata.name,
+                path=source_path,
+                time_field=entity_timestamp_column,
+                start_time=start_time,
+                end_time=end_time,
+            )
+        else:
+            source = source_driver(
+                name=self.vector.metadata.name,
+                path=source_path,
+                time_field=entity_timestamp_column,
+            )
+
+        if not entity_timestamp_column:
+            entity_timestamp_column = feature_set.spec.timestamp_key
+        # add the index/key to selected columns
+        timestamp_key = feature_set.spec.timestamp_key
+
+        return source.to_spark_df(
+            self.spark, named_view=self.named_view, time_field=timestamp_key
+        )
+
+    def _rename_columns_and_select(
+        self,
+        df,
+        rename_col_dict,
+        columns=None,
+    ):
+        from pyspark.sql.functions import col
+
+        return df.select(
+            [
+                col(name).alias(rename_col_dict.get(name, name))
+                for name in columns or rename_col_dict.keys()
+            ]
+        )
+
+    def _drop_columns_from_result(self):
+        self._result_df = self._result_df.drop(*self._drop_columns)
+
+    def _filter(self, query):
+        self._result_df = self._result_df.filter(query)
+
+    def _order_by(self, order_by_active):
+        from pyspark.sql.functions import col
+
+        self._result_df = self._result_df.orderBy(
+            *[col(col_name).asc_nulls_last() for col_name in order_by_active]
+        )
```

## mlrun/frameworks/parallel_coordinates.py

```diff
@@ -10,27 +10,23 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import datetime
 import os
-import warnings
 from typing import List, Union
 
 import numpy as np
 import pandas as pd
 from IPython.core.display import HTML, display
 from pandas.api.types import is_numeric_dtype, is_string_dtype
 
 import mlrun
-from mlrun.utils import flatten
-
-warnings.simplefilter(action="ignore", category=FutureWarning)
-
+from mlrun.utils import filter_warnings, flatten
 
 max_table_rows = 50
 
 
 def _gen_dropdown_buttons(output_cols) -> list:
     """Uses each output col name to generate an equivalent dropdown button for plotting."""
 
@@ -102,14 +98,15 @@
         if name.startswith("param."):
             params.append(name)
         if name.startswith("output."):
             outputs.append(name)
     return params, outputs
 
 
+@filter_warnings("ignore", FutureWarning)
 def gen_pcp_plot(
     source_df: pd.DataFrame,
     index_col: str,
     hide_identical: bool = True,
     exclude: list = None,
     colorscale: str = None,
 ):
@@ -235,14 +232,15 @@
 
     runs_df = flatten(runs_df, "parameters", "param.")
     runs_df = flatten(runs_df, "results", "output.")
     runs_df["iter"] = range(1, 1 + len(runs_df))
     return runs_df
 
 
+@filter_warnings("ignore", FutureWarning)
 def compare_run_objects(
     runs_list: Union[mlrun.model.RunObject, List[mlrun.model.RunObject]],
     hide_identical: bool = True,
     exclude: list = None,
     show: bool = None,
     extend_iterations=True,
     filename=None,
@@ -284,14 +282,15 @@
         hide_identical=hide_identical,
         exclude=exclude,
         colorscale=colorscale,
     )
     return _show_and_export_html(plot_as_html, show, filename, runs_list=runs_list)
 
 
+@filter_warnings("ignore", FutureWarning)
 def compare_db_runs(
     project_name=None,
     run_name=None,
     labels=None,
     iter=False,
     start_time_from: datetime = None,
     hide_identical: bool = True,
```

## mlrun/frameworks/_ml_common/pkl_model_server.py

```diff
@@ -9,14 +9,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import numpy as np
+import pandas as pd
 from cloudpickle import load
 
 from mlrun.serving.v2_serving import V2ModelServer
 
 
 class PickleModelServer(V2ModelServer):
     """
@@ -27,21 +28,31 @@
     def load(self):
         """
         Load and initialize the model and/or other elements.
         """
         model_file, extra_data = self.get_model(".pkl")
         self.model = load(open(model_file, "rb"))
 
-    def predict(self, body: dict) -> list:
+    def predict(self, request: dict) -> list:
         """
         Infer the inputs through the model using MLRun's PyTorch interface and return its output. The inferred data will
         be read from the "inputs" key of the request.
 
         :param request: The request of the model. The input to the model will be read from the "inputs" key.
+                        The input value can be either a dictionary with the feature names
+                        (only one can be sent so only the first one will take into consideration)
+                        or a list with feature values.
+                        For example, a batch size of 2 for data of two features 'x' and 'y' can be given:
 
+                        * As a dictionary: `{"inputs": [{"x": [1, 2], "y": [3, 5.5]}]}`
+                        * As a list: `{"inputs": [[1, 2], [3, 5.5]]}`
         :return: The model's prediction on the given input.
         """
-        x = np.asarray(body["inputs"])
+        inputs = request["inputs"]
+        if inputs and isinstance(inputs[0], dict):
+            x = pd.DataFrame(inputs[0])
+        else:
+            x = np.asarray(inputs)
 
         y_pred: np.ndarray = self.model.predict(x)
 
         return y_pred.tolist()
```

## mlrun/frameworks/onnx/model_handler.py

```diff
@@ -95,16 +95,17 @@
 
     def load(self, **kwargs):
         """
         Load the specified model in this handler.
         """
         super(ONNXModelHandler, self).load()
 
-        # Check that the model is well formed:
-        onnx.checker.check_model(self._model_file)
+        # Check that the model is well-formed:
+        # TODO: Currently not working well with HuggingFace models so we skip it
+        # onnx.checker.check_model(self._model_file)
 
         # Load the ONNX model:
         self._model = onnx.load(self._model_file)
 
     def optimize(self, optimizations: List[str] = None, fixed_point: bool = False):
         """
         Use ONNX optimizer to optimize the ONNX model. The optimizations supported can be seen by calling
```

## mlrun/frameworks/sklearn/__init__.py

```diff
@@ -195,17 +195,17 @@
         y_test=y_test,
         model_handler=handler,
     )
 
     return handler
 
 
-# TODO: Remove once 1.0.0 is no longer supported
 def __getattr__(name):
     if name == "SklearnModelServer":
         warnings.warn(
-            "PendingDeprecationWarning: 'SklearnModelServer' was renamed to 'SKLearnModelServer'. "
-            "Please use the new name. The old name will be removed in mlrun 1.2.0.",
-            PendingDeprecationWarning,
+            "'SklearnModelServer' was renamed to 'SKLearnModelServer'. "
+            "'SklearnModelServer' is deprecated in 1.3.0 and will be removed in 1.5.0.",
+            # TODO: remove in 1.5.0
+            FutureWarning,
         )
         return SKLearnModelServer
     raise ImportError(f"cannot import name '{name}' from '{__name__}' ({__file__})")
```

## mlrun/mlutils/data.py

```diff
@@ -11,19 +11,27 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from typing import Union
 
 import pandas as pd
+from deprecated import deprecated
 from sklearn.model_selection import train_test_split
 
 from ..datastore import DataItem
 
+# TODO: remove mlutils in 1.5.0
 
+
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def get_sample(
     src: Union[DataItem, pd.core.frame.DataFrame], sample: int, label: str, reader=None
 ):
     """generate data sample to be split (candidate for mlrun)
 
     Return features matrix and header (x), and labels (y)
     :param src:    data artifact
@@ -57,14 +65,19 @@
     Just a stupid wrapper so that nice error will be raised when users give wrong label
     """
     if label not in raw:
         raise ValueError(f"Specified label could not be found: {label}")
     return raw.pop(label)
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def get_splits(
     raw,
     labels,
     n_ways: int = 3,
     test_size: float = 0.15,
     valid_size: float = 0.30,
     label_names: list = ["labels"],
@@ -97,14 +110,19 @@
             x, y, train_size=1 - valid_size, random_state=random_state
         )
         return (xtr, ytr), (xva, yva), (xte, yte)
     else:
         raise Exception("n_ways must be in the range [2,3]")
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def save_test_set(
     context,
     data: dict,
     header: list,
     label: str = "labels",
     file_ext: str = "parquet",
     index: bool = False,
```

## mlrun/mlutils/models.py

```diff
@@ -12,18 +12,27 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import json
 from importlib import import_module
 from inspect import _empty, signature
 
+from deprecated import deprecated
+
 # for backwards compatibility - can be removed when we separate the hub branches for 0.6.x ad 0.5.x
 from .plots import eval_class_model, eval_model_v2  # noqa: F401
 
+# TODO: remove mlutils in 1.5.0
+
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def get_class_fit(module_pkg_class: str):
     """generate a model config
     :param module_pkg_class:  str description of model, e.g.
         `sklearn.ensemble.RandomForestClassifier`
     """
     splits = module_pkg_class.split(".")
     model_ = getattr(import_module(".".join(splits[:-1])), splits[-1])
@@ -38,14 +47,19 @@
         "META": {
             "pkg_version": import_module(splits[0]).__version__,
             "class": module_pkg_class,
         },
     }
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def gen_sklearn_model(model_pkg, skparams):
     """generate an sklearn model configuration
 
     input can be either a "package.module.class" or
     a json file
     """
     if model_pkg.endswith("json"):
```

## mlrun/mlutils/plots.py

```diff
@@ -15,35 +15,48 @@
 from itertools import cycle
 from typing import List
 
 import matplotlib.pyplot as plt
 import numpy as np
 import pandas as pd
 import seaborn as sns
+from deprecated import deprecated
 from scikitplot.metrics import plot_calibration_curve
 from scipy import interp
 from sklearn import metrics
 from sklearn.calibration import calibration_curve
 from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix
 from sklearn.preprocessing import LabelBinarizer
 
 from ..artifacts import PlotArtifact
 
+# TODO: remove mlutils in 1.5.0
 
+
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def gcf_clear(plt):
     """Utility to clear matplotlib figure
     Run this inside every plot method before calling any matplotlib
     methods
     :param plot:    matloblib figure object
     """
     plt.cla()
     plt.clf()
     plt.close()
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def feature_importances(model, header):
     """Display estimated feature importances
     Only works for models with attribute 'feature_importances_`
     :param model:       fitted model
     :param header:      feature labels
     """
     if not hasattr(model, "feature_importances_"):
@@ -69,14 +82,19 @@
         PlotArtifact(
             "feature-importances", body=plt.gcf(), title="Feature Importances"
         ),
         feature_imp,
     )
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def plot_importance(
     context, model, key: str = "feature-importances", plots_dest: str = "plots"
 ):
     """Display estimated feature importances
     Only works for models with attribute 'feature_importances_`
 
     **legacy version please deprecate in functions and demos**
@@ -106,14 +124,19 @@
     context.log_artifact(PlotArtifact(key, body=plt.gcf()), local_path=fname)
 
     # feature importances are also saved as a csv table (generally small):
     fname = key + "-tbl.csv"
     return context.log_dataset(key + "-tbl", df=feature_imp, local_path=fname)
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def learning_curves(model):
     """model class dependent
 
     WIP
 
     get training history plots for xgboost, lightgbm
 
@@ -159,14 +182,19 @@
         plots.append(PlotArtifact("learning curve - taoot", body=plt.gcf()))
 
     # elif some other model history api...
 
     return plots
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def confusion_matrix(model, xtest, ytest, cmap="Blues"):
     cmd = metrics.plot_confusion_matrix(
         model,
         xtest,
         ytest,
         normalize="all",
         values_format=".2g",
@@ -177,14 +205,19 @@
     return PlotArtifact(
         "confusion-matrix-normalized",
         body=cmd.figure_,
         title="Confusion Matrix - Normalized Plot",
     )
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def precision_recall_multi(ytest_b, yprob, labels, scoring="micro"):
     """"""
     n_classes = len(labels)
 
     precision = dict()
     recall = dict()
     avg_prec = dict()
@@ -235,14 +268,19 @@
     return PlotArtifact(
         "precision-recall-multiclass",
         body=plt.gcf(),
         title="Multiclass Precision Recall",
     )
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def roc_multi(ytest_b, yprob, labels):
     """"""
     n_classes = len(labels)
 
     # Compute ROC curve and ROC area for each class
     fpr = dict()
     tpr = dict()
@@ -308,14 +346,19 @@
     plt.ylabel("True Positive Rate")
     plt.title("receiver operating characteristic - multiclass")
     plt.legend(loc=(0, -0.68), prop=dict(size=10))
 
     return PlotArtifact("roc-multiclass", body=plt.gcf(), title="Multiclass ROC Curve")
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def roc_bin(ytest, yprob, clear: bool = False):
     """"""
     # ROC plot
     if clear:
         gcf_clear(plt)
     fpr, tpr, _ = metrics.roc_curve(ytest, yprob)
     plt.figure()
@@ -325,28 +368,38 @@
     plt.ylabel("true positive rate")
     plt.title("roc curve")
     plt.legend(loc="best")
 
     return PlotArtifact("roc-binary", body=plt.gcf(), title="Binary ROC Curve")
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def precision_recall_bin(model, xtest, ytest, yprob, clear=False):
     """"""
     if clear:
         gcf_clear(plt)
     disp = metrics.plot_precision_recall_curve(model, xtest, ytest)
     disp.ax_.set_title(
         f"precision recall: AP={metrics.average_precision_score(ytest, yprob):0.2f}"
     )
 
     return PlotArtifact(
         "precision-recall-binary", body=disp.figure_, title="Binary Precision Recall"
     )
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def plot_roc(
     context,
     y_labels,
     y_probs,
     key="roc",
     plots_dir: str = "plots",
     fmt="png",
@@ -402,14 +455,19 @@
         fpr, tpr, _ = metrics.roc_curve(y_labels, y_probs[:, 1], pos_label=1)
         plt.plot(fpr, tpr, label="positive class")
 
     fname = f"{plots_dir}/{key}.html"
     return context.log_artifact(PlotArtifact(key, body=plt.gcf()), local_path=fname)
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def eval_class_model(
     xtest, ytest, model, labels: str = "labels", pred_params: dict = {}
 ):
     """generate predictions and validation stats
 
     pred_params are non-default, scikit-learn api prediction-function parameters.
     For example, a tree-type of model may have a tree depth limit for its prediction
@@ -619,14 +677,19 @@
         # precision-recall
 
         # ROC plot
 
     return model_metrics
 
 
+@deprecated(
+    version="1.3.0",
+    reason="'mlrun.mlutils' will be removed in 1.5.0, use 'mlrun.framework' instead",
+    category=FutureWarning,
+)
 def eval_model_v2(
     context,
     xtest,
     ytest,
     model,
     pcurve_bins: int = 10,
     pcurve_names: List[str] = ["my classifier"],
```

## mlrun/model_monitoring/constants.py

```diff
@@ -10,28 +10,31 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 class EventFieldType:
     FUNCTION_URI = "function_uri"
+    FUNCTION = "function"
+    MODEL_URI = "model_uri"
     MODEL = "model"
     VERSION = "version"
     VERSIONED_MODEL = "versioned_model"
     MODEL_CLASS = "model_class"
     TIMESTAMP = "timestamp"
     ENDPOINT_ID = "endpoint_id"
+    UID = "uid"
+    ENDPOINT_TYPE = "endpoint_type"
     REQUEST_ID = "request_id"
     RECORD_TYPE = "record_type"
     FEATURES = "features"
     FEATURE_NAMES = "feature_names"
     NAMED_FEATURES = "named_features"
     LABELS = "labels"
     LATENCY = "latency"
-    UNPACKED_LABELS = "unpacked_labels"
     LABEL_COLUMNS = "label_columns"
     LABEL_NAMES = "label_names"
     PREDICTION = "prediction"
     PREDICTIONS = "predictions"
     NAMED_PREDICTIONS = "named_predictions"
     ERROR_COUNT = "error_count"
     ENTITIES = "entities"
@@ -43,25 +46,58 @@
     BATCH_INTERVALS_DICT = "batch_intervals_dict"
     DEFAULT_BATCH_INTERVALS = "default_batch_intervals"
     DEFAULT_BATCH_IMAGE = "default_batch_image"
     STREAM_IMAGE = "stream_image"
     MINUTES = "minutes"
     HOURS = "hours"
     DAYS = "days"
+    MODEL_ENDPOINTS = "model_endpoints"
+    STATE = "state"
+    PROJECT = "project"
+    STREAM_PATH = "stream_path"
+    ACTIVE = "active"
+    MONITORING_MODE = "monitoring_mode"
+    FEATURE_STATS = "feature_stats"
+    CURRENT_STATS = "current_stats"
+    CHILDREN = "children"
+    CHILDREN_UIDS = "children_uids"
+    DRIFT_MEASURES = "drift_measures"
+    DRIFT_STATUS = "drift_status"
+    MONITOR_CONFIGURATION = "monitor_configuration"
+    FEATURE_SET_URI = "monitoring_feature_set_uri"
+    ALGORITHM = "algorithm"
+    ACCURACY = "accuracy"
 
 
 class EventLiveStats:
     LATENCY_AVG_5M = "latency_avg_5m"
     LATENCY_AVG_1H = "latency_avg_1h"
     PREDICTIONS_PER_SECOND = "predictions_per_second"
     PREDICTIONS_COUNT_5M = "predictions_count_5m"
     PREDICTIONS_COUNT_1H = "predictions_count_1h"
 
 
 class EventKeyMetrics:
     BASE_METRICS = "base_metrics"
     CUSTOM_METRICS = "custom_metrics"
     ENDPOINT_FEATURES = "endpoint_features"
+    GENERIC = "generic"
+    REAL_TIME = "real_time"
 
 
-class StoreTarget:
+class TimeSeriesTarget:
     TSDB = "tsdb"
+
+
+class ModelEndpointTarget:
+    V3IO_NOSQL = "v3io-nosql"
+    SQL = "sql"
+
+
+class ProjectSecretKeys:
+    ENDPOINT_STORE_CONNECTION = "MODEL_MONITORING_ENDPOINT_STORE_CONNECTION"
+    ACCESS_KEY = "MODEL_MONITORING_ACCESS_KEY"
+
+
+class ModelMonitoringStoreKinds:
+    ENDPOINTS = "endpoints"
+    EVENTS = "events"
```

## mlrun/model_monitoring/helpers.py

```diff
@@ -63,15 +63,15 @@
 
     # Create a new serving function for the streaming process
     function = mlrun.code_to_function(
         name="model-monitoring-stream",
         project=project,
         filename=str(_STREAM_PROCESSING_FUNCTION_PATH),
         kind="serving",
-        image=tracking_policy[model_monitoring_constants.EventFieldType.STREAM_IMAGE],
+        image=tracking_policy.stream_image,
     )
 
     # Create monitoring serving graph
     stream_processor.apply_monitoring_serving_graph(function)
 
     # Set the project to the serving function
     function.metadata.project = project
@@ -82,19 +82,19 @@
     )
     function.add_v3io_stream_trigger(
         stream_path=stream_path, name="monitoring_stream_trigger"
     )
 
     # Set model monitoring access key for managing permissions
     function.set_env_from_secret(
-        "MODEL_MONITORING_ACCESS_KEY",
+        model_monitoring_constants.ProjectSecretKeys.ACCESS_KEY,
         mlrun.api.utils.singletons.k8s.get_k8s().get_project_secret_name(project),
         mlrun.api.crud.secrets.Secrets().generate_client_project_secret_key(
             mlrun.api.crud.secrets.SecretsClientType.model_monitoring,
-            "MODEL_MONITORING_ACCESS_KEY",
+            model_monitoring_constants.ProjectSecretKeys.ACCESS_KEY,
         ),
     )
 
     run_config = fstore.RunConfig(function=function, local=False)
     function.spec.parameters = run_config.parameters
 
     func = http_source.add_nuclio_trigger(function)
@@ -126,31 +126,29 @@
 
     # Create job function runtime for the model monitoring batch
     function: mlrun.runtimes.KubejobRuntime = mlrun.code_to_function(
         name="model-monitoring-batch",
         project=project,
         filename=str(_MONIOTINRG_BATCH_FUNCTION_PATH),
         kind="job",
-        image=tracking_policy[
-            model_monitoring_constants.EventFieldType.DEFAULT_BATCH_IMAGE
-        ],
+        image=tracking_policy.default_batch_image,
         handler="handler",
     )
     function.set_db_connection(mlrun.api.api.utils.get_run_db_instance(db_session))
 
     # Set the project to the job function
     function.metadata.project = project
 
     # Set model monitoring access key for managing permissions
     function.set_env_from_secret(
-        "MODEL_MONITORING_ACCESS_KEY",
+        model_monitoring_constants.ProjectSecretKeys.ACCESS_KEY,
         mlrun.api.utils.singletons.k8s.get_k8s().get_project_secret_name(project),
         mlrun.api.crud.secrets.Secrets().generate_client_project_secret_key(
             mlrun.api.crud.secrets.SecretsClientType.model_monitoring,
-            "MODEL_MONITORING_ACCESS_KEY",
+            model_monitoring_constants.ProjectSecretKeys.ACCESS_KEY,
         ),
     )
 
     function.apply(mlrun.mount_v3io())
 
     # Needs to be a member of the project and have access to project data path
     function.metadata.credentials.access_key = model_monitoring_access_key
```

## mlrun/model_monitoring/model_monitoring_batch.py

```diff
@@ -27,19 +27,20 @@
 import v3io.dataplane
 import v3io_frames
 
 import mlrun
 import mlrun.api.schemas
 import mlrun.data_types.infer
 import mlrun.feature_store as fstore
+import mlrun.model_monitoring
+import mlrun.model_monitoring.stores
 import mlrun.run
 import mlrun.utils.helpers
 import mlrun.utils.model_monitoring
 import mlrun.utils.v3io_clients
-from mlrun.model_monitoring.constants import EventFieldType
 from mlrun.utils import logger
 
 
 class DriftStatus(Enum):
     """
     Enum for the drift status values.
     """
@@ -457,14 +458,15 @@
     :param sample_set_statistics: The sample set (stored end point's dataset to reference) statistics. The bins of the
                                   histograms of each feature will be used to recalculate the histograms of the inputs.
     :param inputs:                The inputs to calculate their statistics and later on - the drift with respect to the
                                   sample set.
 
     :returns: The calculated statistics of the inputs data.
     """
+
     # Use `DFDataInfer` to calculate the statistics over the inputs:
     inputs_statistics = mlrun.data_types.infer.DFDataInfer.get_stats(
         df=inputs,
         options=mlrun.data_types.infer.InferOptions.Histogram,
     )
 
     # Recalculate the histograms over the bins that are set in the sample-set of the end point:
@@ -563,15 +565,18 @@
             mlrun.mlconf.model_endpoint_monitoring.drift_thresholds.default.possible_drift
         )
         self.default_drift_detected_threshold = (
             mlrun.mlconf.model_endpoint_monitoring.drift_thresholds.default.drift_detected
         )
 
         # Get a runtime database
-        self.db = mlrun.get_run_db()
+        # self.db = mlrun.get_run_db()
+        self.db = mlrun.model_monitoring.stores.get_model_endpoint_store(
+            project=project
+        )
 
         # Get the frames clients based on the v3io configuration
         # it will be used later for writing the results into the tsdb
         self.v3io = mlrun.utils.v3io_clients.get_v3io_client(
             access_key=self.v3io_access_key
         )
         self.frames = mlrun.utils.v3io_clients.get_frames_client(
@@ -580,15 +585,17 @@
             token=self.v3io_access_key,
         )
 
         # If an error occurs, it will be raised using the following argument
         self.exception = None
 
         # Get the batch interval range
-        self.batch_dict = context.parameters[EventFieldType.BATCH_INTERVALS_DICT]
+        self.batch_dict = context.parameters[
+            mlrun.model_monitoring.EventFieldType.BATCH_INTERVALS_DICT
+        ]
 
         # TODO: This will be removed in 1.2.0 once the job params can be parsed with different types
         # Convert batch dict string into a dictionary
         if isinstance(self.batch_dict, str):
             self._parse_batch_dict_str()
 
     def post_init(self):
@@ -610,239 +617,252 @@
 
     def run(self):
         """
         Main method for manage the drift analysis and write the results into tsdb and KV table.
         """
         # Get model endpoints (each deployed project has at least 1 serving model):
         try:
-            endpoints = self.db.list_model_endpoints(self.project)
+            endpoints = self.db.list_model_endpoints()
         except Exception as e:
             logger.error("Failed to list endpoints", exc=e)
             return
 
-        active_endpoints = set()
-        for endpoint in endpoints.endpoints:
+        for endpoint in endpoints:
             if (
-                endpoint.spec.active
-                and endpoint.spec.monitoring_mode
-                == mlrun.api.schemas.ModelMonitoringMode.enabled.value
+                endpoint[mlrun.model_monitoring.EventFieldType.ACTIVE]
+                and endpoint[mlrun.model_monitoring.EventFieldType.MONITORING_MODE]
+                == mlrun.model_monitoring.ModelMonitoringMode.enabled.value
             ):
-                active_endpoints.add(endpoint.metadata.uid)
-
-        # perform drift analysis for each model endpoint
-        for endpoint_id in active_endpoints:
-            try:
-
-                # Get model endpoint object:
-                endpoint = self.db.get_model_endpoint(
-                    project=self.project, endpoint_id=endpoint_id
-                )
-
                 # Skip router endpoint:
                 if (
-                    endpoint.status.endpoint_type
-                    == mlrun.utils.model_monitoring.EndpointType.ROUTER
+                    int(endpoint[mlrun.model_monitoring.EventFieldType.ENDPOINT_TYPE])
+                    == mlrun.model_monitoring.EndpointType.ROUTER
                 ):
-                    # endpoint.status.feature_stats is None
-                    logger.info(f"{endpoint_id} is router skipping")
+                    # Router endpoint has no feature stats
+                    logger.info(
+                        f"{endpoint[mlrun.model_monitoring.EventFieldType.UID]} is router skipping"
+                    )
                     continue
+                self.update_drift_metrics(endpoint=endpoint)
 
-                # convert feature set into dataframe and get the latest dataset
-                (
-                    _,
-                    serving_function_name,
-                    _,
-                    _,
-                ) = mlrun.utils.helpers.parse_versioned_object_uri(
-                    endpoint.spec.function_uri
-                )
+    def update_drift_metrics(self, endpoint: dict):
+        try:
+            # Convert feature set into dataframe and get the latest dataset
+            (
+                _,
+                serving_function_name,
+                _,
+                _,
+            ) = mlrun.utils.helpers.parse_versioned_object_uri(
+                endpoint[mlrun.model_monitoring.EventFieldType.FUNCTION_URI]
+            )
 
-                model_name = endpoint.spec.model.replace(":", "-")
+            model_name = endpoint[mlrun.model_monitoring.EventFieldType.MODEL].replace(
+                ":", "-"
+            )
 
-                m_fs = fstore.get_feature_set(
-                    f"store://feature-sets/{self.project}/monitoring-{serving_function_name}-{model_name}"
-                )
+            m_fs = fstore.get_feature_set(
+                f"store://feature-sets/{self.project}/monitoring-{serving_function_name}-{model_name}"
+            )
 
-                # Getting batch interval start time and end time
-                start_time, end_time = self.get_interval_range()
+            # Getting batch interval start time and end time
+            start_time, end_time = self.get_interval_range()
 
-                try:
-                    df = m_fs.to_dataframe(
-                        start_time=start_time,
-                        end_time=end_time,
-                        time_column="timestamp",
-                    )
+            try:
+                df = m_fs.to_dataframe(
+                    start_time=start_time,
+                    end_time=end_time,
+                    time_column="timestamp",
+                )
 
-                    if len(df) == 0:
-                        logger.warn(
-                            "Not enough model events since the beginning of the batch interval",
-                            parquet_target=m_fs.status.targets[0].path,
-                            endpoint=endpoint_id,
-                            min_rqeuired_events=mlrun.mlconf.model_endpoint_monitoring.parquet_batching_max_events,
-                            start_time=str(
-                                datetime.datetime.now() - datetime.timedelta(hours=1)
-                            ),
-                            end_time=str(datetime.datetime.now()),
-                        )
-                        continue
-
-                # TODO: The below warn will be removed once the state of the Feature Store target is updated
-                #       as expected. In that case, the existence of the file will be checked before trying to get
-                #       the offline data from the feature set.
-                # Continue if not enough events provided since the deployment of the model endpoint
-                except FileNotFoundError:
+                if len(df) == 0:
                     logger.warn(
-                        "Parquet not found, probably due to not enough model events",
+                        "Not enough model events since the beginning of the batch interval",
                         parquet_target=m_fs.status.targets[0].path,
-                        endpoint=endpoint_id,
+                        endpoint=endpoint[mlrun.model_monitoring.EventFieldType.UID],
                         min_rqeuired_events=mlrun.mlconf.model_endpoint_monitoring.parquet_batching_max_events,
+                        start_time=str(
+                            datetime.datetime.now() - datetime.timedelta(hours=1)
+                        ),
+                        end_time=str(datetime.datetime.now()),
                     )
-                    continue
+                    return
 
-                # Get feature names from monitoring feature set
-                feature_names = [
-                    feature_name["name"]
-                    for feature_name in m_fs.spec.features.to_dict()
-                ]
-
-                # Create DataFrame based on the input features
-                stats_columns = [
-                    "timestamp",
-                    *feature_names,
-                ]
-
-                # Add label names if provided
-                if endpoint.spec.label_names:
-                    stats_columns.extend(endpoint.spec.label_names)
-
-                named_features_df = df[stats_columns].copy()
-
-                # Infer feature set stats and schema
-                fstore.api._infer_from_static_df(
-                    named_features_df,
-                    m_fs,
-                    options=mlrun.data_types.infer.InferOptions.all_stats(),
-                )
+            # TODO: The below warn will be removed once the state of the Feature Store target is updated
+            #       as expected. In that case, the existence of the file will be checked before trying to get
+            #       the offline data from the feature set.
+            # Continue if not enough events provided since the deployment of the model endpoint
+            except FileNotFoundError:
+                logger.warn(
+                    "Parquet not found, probably due to not enough model events",
+                    parquet_target=m_fs.status.targets[0].path,
+                    endpoint=endpoint[mlrun.model_monitoring.EventFieldType.UID],
+                    min_rqeuired_events=mlrun.mlconf.model_endpoint_monitoring.parquet_batching_max_events,
+                )
+                return
+
+            # Get feature names from monitoring feature set
+            feature_names = [
+                feature_name["name"] for feature_name in m_fs.spec.features.to_dict()
+            ]
+            # Create DataFrame based on the input features
+            stats_columns = [
+                "timestamp",
+                *feature_names,
+            ]
+            # Add label names if provided
+            if endpoint[mlrun.model_monitoring.EventFieldType.LABEL_NAMES]:
+                labels = endpoint[mlrun.model_monitoring.EventFieldType.LABEL_NAMES]
+                if isinstance(labels, str):
+                    labels = json.loads(labels)
+                stats_columns.extend(labels)
+
+            named_features_df = df[stats_columns].copy()
+
+            # Infer feature set stats and schema
+            fstore.api._infer_from_static_df(
+                named_features_df,
+                m_fs,
+                options=mlrun.data_types.infer.InferOptions.all_stats(),
+            )
 
-                # Save feature set to apply changes
-                m_fs.save()
+            # Save feature set to apply changes
+            m_fs.save()
 
-                # Get the timestamp of the latest request:
-                timestamp = df["timestamp"].iloc[-1]
+            # Get the timestamp of the latest request:
+            timestamp = df["timestamp"].iloc[-1]
 
-                # Get the current stats:
-                current_stats = calculate_inputs_statistics(
-                    sample_set_statistics=endpoint.status.feature_stats,
-                    inputs=named_features_df,
-                )
+            # Get the feature stats from the model endpoint for reference data
+            feature_stats = json.loads(
+                endpoint[mlrun.model_monitoring.EventFieldType.FEATURE_STATS]
+            )
 
-                # Compute the drift based on the histogram of the current stats and the histogram of the original
-                # feature stats that can be found in the model endpoint object:
-                drift_result = self.virtual_drift.compute_drift_from_histograms(
-                    feature_stats=endpoint.status.feature_stats,
-                    current_stats=current_stats,
-                )
-                logger.info("Drift result", drift_result=drift_result)
+            # Get the current stats:
+            current_stats = calculate_inputs_statistics(
+                sample_set_statistics=feature_stats,
+                inputs=named_features_df,
+            )
 
-                # Get drift thresholds from the model configuration:
-                monitor_configuration = endpoint.spec.monitor_configuration or {}
-                possible_drift = monitor_configuration.get(
-                    "possible_drift", self.default_possible_drift_threshold
-                )
-                drift_detected = monitor_configuration.get(
-                    "drift_detected", self.default_drift_detected_threshold
-                )
+            # Compute the drift based on the histogram of the current stats and the histogram of the original
+            # feature stats that can be found in the model endpoint object:
+            drift_result = self.virtual_drift.compute_drift_from_histograms(
+                feature_stats=feature_stats,
+                current_stats=current_stats,
+            )
+            logger.info("Drift result", drift_result=drift_result)
 
-                # Check for possible drift based on the results of the statistical metrics defined above:
-                drift_status, drift_measure = self.virtual_drift.check_for_drift(
-                    metrics_results_dictionary=drift_result,
-                    possible_drift_threshold=possible_drift,
-                    drift_detected_threshold=drift_detected,
-                )
-                logger.info(
-                    "Drift status",
-                    endpoint_id=endpoint_id,
-                    drift_status=drift_status.value,
-                    drift_measure=drift_measure,
+            # Get drift thresholds from the model configuration:
+            monitor_configuration = (
+                json.loads(
+                    endpoint[
+                        mlrun.model_monitoring.EventFieldType.MONITOR_CONFIGURATION
+                    ]
                 )
+                or {}
+            )
+            possible_drift = monitor_configuration.get(
+                "possible_drift", self.default_possible_drift_threshold
+            )
+            drift_detected = monitor_configuration.get(
+                "drift_detected", self.default_drift_detected_threshold
+            )
 
-                # If drift was detected, add the results to the input stream
-                if (
-                    drift_status == DriftStatus.POSSIBLE_DRIFT
-                    or drift_status == DriftStatus.DRIFT_DETECTED
-                ):
-                    self.v3io.stream.put_records(
-                        container=self.stream_container,
-                        stream_path=self.stream_path,
-                        records=[
-                            {
-                                "data": json.dumps(
-                                    {
-                                        "endpoint_id": endpoint_id,
-                                        "drift_status": drift_status.value,
-                                        "drift_measure": drift_measure,
-                                        "drift_per_feature": {**drift_result},
-                                    }
-                                )
-                            }
-                        ],
-                    )
+            # Check for possible drift based on the results of the statistical metrics defined above:
+            drift_status, drift_measure = self.virtual_drift.check_for_drift(
+                metrics_results_dictionary=drift_result,
+                possible_drift_threshold=possible_drift,
+                drift_detected_threshold=drift_detected,
+            )
+            logger.info(
+                "Drift status",
+                endpoint_id=endpoint[mlrun.model_monitoring.EventFieldType.UID],
+                drift_status=drift_status.value,
+                drift_measure=drift_measure,
+            )
 
-                attributes = {
-                    "current_stats": json.dumps(current_stats),
-                    "drift_measures": json.dumps(drift_result),
-                    "drift_status": drift_status.value,
-                }
-
-                self.db.patch_model_endpoint(
-                    project=self.project,
-                    endpoint_id=endpoint_id,
-                    attributes=attributes,
-                )
+            # If drift was detected, add the results to the input stream
+            if (
+                drift_status == DriftStatus.POSSIBLE_DRIFT
+                or drift_status == DriftStatus.DRIFT_DETECTED
+            ):
+                self.v3io.stream.put_records(
+                    container=self.stream_container,
+                    stream_path=self.stream_path,
+                    records=[
+                        {
+                            "data": json.dumps(
+                                {
+                                    "endpoint_id": endpoint[
+                                        mlrun.model_monitoring.EventFieldType.UID
+                                    ],
+                                    "drift_status": drift_status.value,
+                                    "drift_measure": drift_measure,
+                                    "drift_per_feature": {**drift_result},
+                                }
+                            )
+                        }
+                    ],
+                )
+
+            attributes = {
+                "current_stats": json.dumps(current_stats),
+                "drift_measures": json.dumps(drift_result),
+                "drift_status": drift_status.value,
+            }
 
-                # Update the results in tsdb:
-                tsdb_drift_measures = {
-                    "endpoint_id": endpoint_id,
-                    "timestamp": pd.to_datetime(
-                        timestamp,
-                        format=EventFieldType.TIME_FORMAT,
-                    ),
-                    "record_type": "drift_measures",
-                    "tvd_mean": drift_result["tvd_mean"],
-                    "kld_mean": drift_result["kld_mean"],
-                    "hellinger_mean": drift_result["hellinger_mean"],
-                }
-
-                try:
-                    self.frames.write(
-                        backend="tsdb",
-                        table=self.tsdb_path,
-                        dfs=pd.DataFrame.from_dict([tsdb_drift_measures]),
-                        index_cols=["timestamp", "endpoint_id", "record_type"],
-                    )
-                except v3io_frames.errors.Error as err:
-                    logger.warn(
-                        "Could not write drift measures to TSDB",
-                        err=err,
-                        tsdb_path=self.tsdb_path,
-                        endpoint=endpoint_id,
-                    )
+            self.db.update_model_endpoint(
+                endpoint_id=endpoint[mlrun.model_monitoring.EventFieldType.UID],
+                attributes=attributes,
+            )
 
-                logger.info("Done updating drift measures", endpoint_id=endpoint_id)
+            # Update the results in tsdb:
+            tsdb_drift_measures = {
+                "endpoint_id": endpoint[mlrun.model_monitoring.EventFieldType.UID],
+                "timestamp": pd.to_datetime(
+                    timestamp,
+                    format=mlrun.model_monitoring.EventFieldType.TIME_FORMAT,
+                ),
+                "record_type": "drift_measures",
+                "tvd_mean": drift_result["tvd_mean"],
+                "kld_mean": drift_result["kld_mean"],
+                "hellinger_mean": drift_result["hellinger_mean"],
+            }
+
+            try:
+                self.frames.write(
+                    backend="tsdb",
+                    table=self.tsdb_path,
+                    dfs=pd.DataFrame.from_dict([tsdb_drift_measures]),
+                    index_cols=["timestamp", "endpoint_id", "record_type"],
+                )
+            except v3io_frames.errors.Error as err:
+                logger.warn(
+                    "Could not write drift measures to TSDB",
+                    err=err,
+                    tsdb_path=self.tsdb_path,
+                    endpoint=endpoint[mlrun.model_monitoring.EventFieldType.UID],
+                )
+
+            logger.info(
+                "Done updating drift measures",
+                endpoint_id=endpoint[mlrun.model_monitoring.EventFieldType.UID],
+            )
 
-            except Exception as e:
-                logger.error(f"Exception for endpoint {endpoint_id}")
-                self.exception = e
+        except Exception as e:
+            logger.error(
+                f"Exception for endpoint {endpoint[mlrun.model_monitoring.EventFieldType.UID]}"
+            )
+            self.exception = e
 
     def get_interval_range(self) -> Tuple[datetime.datetime, datetime.datetime]:
         """Getting batch interval time range"""
         minutes, hours, days = (
-            self.batch_dict[EventFieldType.MINUTES],
-            self.batch_dict[EventFieldType.HOURS],
-            self.batch_dict[EventFieldType.DAYS],
+            self.batch_dict[mlrun.model_monitoring.EventFieldType.MINUTES],
+            self.batch_dict[mlrun.model_monitoring.EventFieldType.HOURS],
+            self.batch_dict[mlrun.model_monitoring.EventFieldType.DAYS],
         )
         start_time = datetime.datetime.now() - datetime.timedelta(
             minutes=minutes, hours=hours, days=days
         )
         end_time = datetime.datetime.now()
         return start_time, end_time
 
@@ -859,14 +879,16 @@
             self.batch_dict[pair_list[0]] = float(pair_list[1])
 
 
 def handler(context: mlrun.run.MLClientCtx):
     batch_processor = BatchProcessor(
         context=context,
         project=context.project,
-        model_monitoring_access_key=os.environ.get("MODEL_MONITORING_ACCESS_KEY"),
+        model_monitoring_access_key=os.environ.get(
+            mlrun.model_monitoring.ProjectSecretKeys.ACCESS_KEY
+        ),
         v3io_access_key=os.environ.get("V3IO_ACCESS_KEY"),
     )
     batch_processor.post_init()
     batch_processor.run()
     if batch_processor.exception:
         raise batch_processor.exception
```

## mlrun/model_monitoring/stream_processing_fs.py

```diff
@@ -15,31 +15,31 @@
 import collections
 import datetime
 import json
 import os
 import typing
 
 import pandas as pd
-
-# Constants
 import storey
-import v3io
-import v3io.dataplane
 
+import mlrun
 import mlrun.config
 import mlrun.datastore.targets
 import mlrun.feature_store.steps
 import mlrun.utils
 import mlrun.utils.model_monitoring
 import mlrun.utils.v3io_clients
-from mlrun.model_monitoring.constants import (
+from mlrun.model_monitoring import (
     EventFieldType,
     EventKeyMetrics,
     EventLiveStats,
+    ModelEndpointTarget,
+    ProjectSecretKeys,
 )
+from mlrun.model_monitoring.stores import get_model_endpoint_store
 from mlrun.utils import logger
 
 
 # Stream processing code
 class EventStreamProcessor:
     def __init__(
         self,
@@ -71,20 +71,23 @@
 
         self.v3io_framesd = v3io_framesd or mlrun.mlconf.v3io_framesd
         self.v3io_api = v3io_api or mlrun.mlconf.v3io_api
 
         self.v3io_access_key = v3io_access_key or os.environ.get("V3IO_ACCESS_KEY")
         self.model_monitoring_access_key = (
             model_monitoring_access_key
-            or os.environ.get("MODEL_MONITORING_ACCESS_KEY")
+            or os.environ.get(ProjectSecretKeys.ACCESS_KEY)
             or self.v3io_access_key
         )
         self.storage_options = dict(
             v3io_access_key=self.model_monitoring_access_key, v3io_api=self.v3io_api
         )
+        self.model_endpoint_store_target = (
+            mlrun.mlconf.model_endpoint_monitoring.store_type
+        )
 
         template = mlrun.mlconf.model_endpoint_monitoring.store_prefixes.default
 
         kv_path = template.format(project=project, kind="endpoints")
         (
             _,
             self.kv_container,
@@ -123,20 +126,22 @@
 
     def apply_monitoring_serving_graph(self, fn):
         """
         Apply monitoring serving graph to a given serving function. The following serving graph includes about 20 steps
         of different operations that are executed on the events from the model server. Each event has
         metadata (function_uri, timestamp, class, etc.) but also inputs and predictions from the model server.
         Throughout the serving graph, the results are written to 3 different databases:
-        1. KV (steps 7-9): Stores metadata and stats about the average latency and the amount of predictions over time
-           per endpoint. for example the amount of predictions of endpoint x in the last 5 min. This data is used by
-           the monitoring dashboards in grafana. Please note that the KV table, which can be found under
-           v3io:///users/pipelines/project-name/model-endpoints/endpoints/ also contains data on the model endpoint
-            from other processes, such as current_stats that is being calculated by the monitoring batch job
-            process.
+        1. KV/SQL (steps 7-9): Stores metadata and stats about the average latency and the amount of predictions over
+           time per endpoint. for example the amount of predictions of endpoint x in the last 5 min. This data is used
+           by the monitoring dashboards in grafana. The model endpoints table also contains data on the model endpoint
+           from other processes, such as current_stats that is being calculated by the monitoring batch job
+           process. If the target is from type KV, then the model endpoints table can be found under
+           v3io:///users/pipelines/project-name/model-endpoints/endpoints/. If the target is SQL, then the table
+           is stored within the database that was defined in the provided connection string and can be found
+           under mlrun.mlconf.model_endpoint_monitoring.endpoint_store_connection.
         2. TSDB (steps 12-18): Stores live data of different key metric dictionaries in tsdb target. Results can be
            found under v3io:///users/pipelines/project-name/model-endpoints/events/. At the moment, this part supports
            3 different key metric dictionaries: base_metrics (average latency and predictions over time),
            endpoint_features (Prediction and feature names and values), and custom_metrics (user-defined metrics).
            This data is also being used by the monitoring dashboards in grafana.
         3. Parquet (steps 19-20): This Parquet file includes the required data for the model monitoring batch job
            that run every hour by default. The parquet target can be found under
@@ -147,17 +152,14 @@
 
         graph = fn.set_topology("flow")
 
         # Step 1 - Process endpoint event: splitting into sub-events and validate event data
         def apply_process_endpoint_event():
             graph.add_step(
                 "ProcessEndpointEvent",
-                kv_container=self.kv_container,
-                kv_path=self.kv_path,
-                v3io_access_key=self.v3io_access_key,
                 full_event=True,
                 project=self.project,
             )
 
         apply_process_endpoint_event()
 
         # Steps 2,3 - Applying Storey operations of filtering and flatten
@@ -178,18 +180,16 @@
         apply_storey_filter_and_flatmap()
 
         # Step 4 - Validating feature names and map each feature to its value
         def apply_map_feature_names():
             graph.add_step(
                 "MapFeatureNames",
                 name="MapFeatureNames",
-                kv_container=self.kv_container,
-                kv_path=self.kv_path,
-                access_key=self.v3io_access_key,
                 infer_columns_from_data=True,
+                project=self.project,
                 after="flatten_events",
             )
 
         apply_map_feature_names()
 
         # Step 5 - Calculate number of predictions and average latency
         def apply_storey_aggregations():
@@ -240,49 +240,53 @@
                 window_size=self.sample_window,
                 key=EventFieldType.ENDPOINT_ID,
                 v3io_access_key=self.v3io_access_key,
             )
 
         apply_storey_sample_window()
 
-        # Steps 7-9 - KV branch
-        # Step 7 - Filter relevant keys from the event before writing the data into KV
-        def apply_process_before_kv():
-            graph.add_step("ProcessBeforeKV", name="ProcessBeforeKV", after="sample")
+        # Steps 7-9 - KV/SQL branch
+        # Step 7 - Filter relevant keys from the event before writing the data into the database table
+        def apply_process_before_endpoint_update():
+            graph.add_step(
+                "ProcessBeforeEndpointUpdate",
+                name="ProcessBeforeEndpointUpdate",
+                after="sample",
+            )
 
-        apply_process_before_kv()
+        apply_process_before_endpoint_update()
 
-        # Step 8 - Write the filtered event to KV table. At this point, the serving graph updates the stats
+        # Step 8 - Write the filtered event to KV/SQL table. At this point, the serving graph updates the stats
         # about average latency and the amount of predictions over time
-        def apply_write_to_kv():
+        def apply_update_endpoint():
             graph.add_step(
-                "WriteToKV",
-                name="WriteToKV",
-                after="ProcessBeforeKV",
-                container=self.kv_container,
-                table=self.kv_path,
-                v3io_access_key=self.v3io_access_key,
+                "UpdateEndpoint",
+                name="UpdateEndpoint",
+                after="ProcessBeforeEndpointUpdate",
+                project=self.project,
+                model_endpoint_store_target=self.model_endpoint_store_target,
             )
 
-        apply_write_to_kv()
+        apply_update_endpoint()
 
-        # Step 9 - Apply infer_schema on the KB table for generating schema file
+        # Step 9 (only for KV target) - Apply infer_schema on the model endpoints table for generating schema file
         # which will be used by Grafana monitoring dashboards
         def apply_infer_schema():
             graph.add_step(
                 "InferSchema",
                 name="InferSchema",
-                after="WriteToKV",
+                after="UpdateEndpoint",
                 v3io_access_key=self.v3io_access_key,
                 v3io_framesd=self.v3io_framesd,
                 container=self.kv_container,
                 table=self.kv_path,
             )
 
-        apply_infer_schema()
+        if self.model_endpoint_store_target == ModelEndpointTarget.V3IO_NOSQL:
+            apply_infer_schema()
 
         # Steps 11-18 - TSDB branch
         # Step 11 - Before writing data to TSDB, create dictionary of 2-3 dictionaries that contains
         # stats and details about the events
         def apply_process_before_tsdb():
             graph.add_step(
                 "ProcessBeforeTSDB", name="ProcessBeforeTSDB", after="sample"
@@ -380,58 +384,65 @@
                 time_partitioning_granularity="hour",
                 partition_cols=["$key", "$year", "$month", "$day", "$hour"],
             )
 
         apply_parquet_target()
 
 
-class ProcessBeforeKV(mlrun.feature_store.steps.MapClass):
+class ProcessBeforeEndpointUpdate(mlrun.feature_store.steps.MapClass):
     def __init__(self, **kwargs):
         """
-        Filter relevant keys from the event before writing the data to KV table (in WriteToKV step). Note that in KV
-        we only keep metadata (function_uri, model_class, etc.) and stats about the average latency and the number
-        of predictions (per 5min and 1hour).
+        Filter relevant keys from the event before writing the data to database table (in EndpointUpdate step).
+        Note that in the endpoint table we only keep metadata (function_uri, model_class, etc.) and stats about the
+        average latency and the number of predictions (per 5min and 1hour).
 
-        :returns: A filtered event as a dictionary which will be written to KV table in the next step.
+        :returns: A filtered event as a dictionary which will be written to the endpoint table in the next step.
         """
         super().__init__(**kwargs)
 
     def do(self, event):
+
         # Compute prediction per second
         event[EventLiveStats.PREDICTIONS_PER_SECOND] = (
             float(event[EventLiveStats.PREDICTIONS_COUNT_5M]) / 300
         )
         # Filter relevant keys
         e = {
             k: event[k]
             for k in [
                 EventFieldType.FUNCTION_URI,
                 EventFieldType.MODEL,
                 EventFieldType.MODEL_CLASS,
-                EventFieldType.TIMESTAMP,
                 EventFieldType.ENDPOINT_ID,
                 EventFieldType.LABELS,
-                EventFieldType.UNPACKED_LABELS,
+                EventFieldType.FIRST_REQUEST,
+                EventFieldType.LAST_REQUEST,
+                EventFieldType.ERROR_COUNT,
+            ]
+        }
+
+        # Add generic metrics statistics
+        generic_metrics = {
+            k: event[k]
+            for k in [
                 EventLiveStats.LATENCY_AVG_5M,
                 EventLiveStats.LATENCY_AVG_1H,
                 EventLiveStats.PREDICTIONS_PER_SECOND,
                 EventLiveStats.PREDICTIONS_COUNT_5M,
                 EventLiveStats.PREDICTIONS_COUNT_1H,
-                EventFieldType.FIRST_REQUEST,
-                EventFieldType.LAST_REQUEST,
-                EventFieldType.ERROR_COUNT,
             ]
         }
-        # Unpack labels dictionary
-        e = {
-            **e,
-            **e.pop(EventFieldType.UNPACKED_LABELS, {}),
-        }
-        # Write labels to kv as json string to be presentable later
+
+        e[EventFieldType.METRICS] = json.dumps(
+            {EventKeyMetrics.GENERIC: generic_metrics}
+        )
+
+        # Write labels as json string as required by the DB format
         e[EventFieldType.LABELS] = json.dumps(e[EventFieldType.LABELS])
+
         return e
 
 
 class ProcessBeforeTSDB(mlrun.feature_store.steps.MapClass):
     def __init__(self, **kwargs):
         """
         Process the data before writing to TSDB. This step creates a dictionary that includes 3 different dictionaries
@@ -443,14 +454,15 @@
 
         :returns: Dictionary of 2-3 dictionaries that contains stats and details about the events.
 
         """
         super().__init__(**kwargs)
 
     def do(self, event):
+
         # Compute prediction per second
         event[EventLiveStats.PREDICTIONS_PER_SECOND] = (
             float(event[EventLiveStats.PREDICTIONS_COUNT_5M]) / 300
         )
         base_fields = [
             EventFieldType.TIMESTAMP,
             EventFieldType.ENDPOINT_ID,
@@ -512,18 +524,18 @@
 
         :returns: Event dictionary with filtered data for the Parquet target.
 
         """
         super().__init__(**kwargs)
 
     def do(self, event):
+
         logger.info("ProcessBeforeParquet1", event=event)
         # Remove the following keys from the event
         for key in [
-            EventFieldType.UNPACKED_LABELS,
             EventFieldType.FEATURES,
             EventFieldType.NAMED_FEATURES,
         ]:
             event.pop(key, None)
 
         # Split entities dictionary to separate dictionaries within the event
         value = event.get("entities")
@@ -541,40 +553,31 @@
         logger.info("ProcessBeforeParquet2", event=event)
         return event
 
 
 class ProcessEndpointEvent(mlrun.feature_store.steps.MapClass):
     def __init__(
         self,
-        kv_container: str,
-        kv_path: str,
-        v3io_access_key: str,
+        project: str,
         **kwargs,
     ):
         """
         Process event or batch of events as part of the first step of the monitoring serving graph. It includes
-        Adding important details to the event such as endpoint_id, handling errors coming from the stream, Validation
+        Adding important details to the event such as endpoint_id, handling errors coming from the stream, validation
         of event data such as inputs and outputs, and splitting model event into sub-events.
 
-        :param kv_container:    Name of the container that will be used to retrieve the endpoint id. For model
-                                endpoints it is usually 'users'.
-        :param kv_path:         KV table path that will be used to retrieve the endpoint id. For model endpoints
-                                it is usually pipelines/project-name/model-endpoints/endpoints/
-        :param v3io_access_key: Access key with permission to read from a KV table.
-        :param project:         Project name.
-
+        :param project: Project name.
 
         :returns: A Storey event object which is the basic unit of data in Storey. Note that the next steps of
                   the monitoring serving graph are based on Storey operations.
 
         """
         super().__init__(**kwargs)
-        self.kv_container: str = kv_container
-        self.kv_path: str = kv_path
-        self.v3io_access_key: str = v3io_access_key
+
+        self.project: str = project
 
         # First and last requests timestamps (value) of each endpoint (key)
         self.first_request: typing.Dict[str, str] = dict()
         self.last_request: typing.Dict[str, str] = dict()
 
         # Number of errors (value) per endpoint (key)
         self.error_count: typing.Dict[str, int] = collections.defaultdict(int)
@@ -594,15 +597,15 @@
         model = event.get(EventFieldType.MODEL)
         if not is_not_none(model, [EventFieldType.MODEL]):
             return None
 
         version = event.get(EventFieldType.VERSION)
         versioned_model = f"{model}:{version}" if version else f"{model}:latest"
 
-        endpoint_id = mlrun.utils.model_monitoring.create_model_endpoint_id(
+        endpoint_id = mlrun.model_monitoring.create_model_endpoint_uid(
             function_uri=function_uri,
             versioned_model=versioned_model,
         )
 
         endpoint_id = str(endpoint_id)
 
         event[EventFieldType.VERSIONED_MODEL] = versioned_model
@@ -631,15 +634,23 @@
             is_not_none,
             timestamp,
             ["when"],
         ):
             return None
 
         if endpoint_id not in self.first_request:
+            # Set time for the first request of the current endpoint
             self.first_request[endpoint_id] = timestamp
+
+        # Validate that the request time of the current event is later than the previous request time
+        self._validate_last_request_timestamp(
+            endpoint_id=endpoint_id, timestamp=timestamp
+        )
+
+        # Set time for the last reqeust of the current endpoint
         self.last_request[endpoint_id] = timestamp
 
         if not self.is_valid(
             endpoint_id,
             is_not_none,
             request_id,
             ["request", "id"],
@@ -663,19 +674,14 @@
             endpoint_id,
             is_not_none,
             predictions,
             ["resp", "outputs"],
         ):
             return None
 
-        # Get labels from event (if exist)
-        unpacked_labels = {
-            f"_{k}": v for k, v in event.get(EventFieldType.LABELS, {}).items()
-        }
-
         # Adjust timestamp format
         timestamp = datetime.datetime.strptime(timestamp[:-6], "%Y-%m-%d %H:%M:%S.%f")
 
         # Separate each model invocation into sub events that will be stored as dictionary
         # in list of events. This list will be used as the body for the storey event.
         events = []
         for i, (feature, prediction) in enumerate(zip(features, predictions)):
@@ -706,53 +712,80 @@
                     EventFieldType.LAST_REQUEST: self.last_request[endpoint_id],
                     EventFieldType.ERROR_COUNT: self.error_count[endpoint_id],
                     EventFieldType.LABELS: event.get(EventFieldType.LABELS, {}),
                     EventFieldType.METRICS: event.get(EventFieldType.METRICS, {}),
                     EventFieldType.ENTITIES: event.get("request", {}).get(
                         EventFieldType.ENTITIES, {}
                     ),
-                    EventFieldType.UNPACKED_LABELS: unpacked_labels,
                 }
             )
 
         # Create a storey event object with list of events, based on endpoint_id which will be used
         # in the upcoming steps
         storey_event = storey.Event(body=events, key=endpoint_id)
         return storey_event
 
+    def _validate_last_request_timestamp(self, endpoint_id: str, timestamp: str):
+        """Validate that the request time of the current event is later than the previous request time that has
+        already been processed.
+
+        :param endpoint_id: The unique id of the model endpoint.
+        :param timestamp:   Event request time as a string.
+
+        :raise MLRunPreconditionFailedError: If the request time of the current is later than the previous request time.
+        """
+
+        if (
+            endpoint_id in self.last_request
+            and self.last_request[endpoint_id] > timestamp
+        ):
+
+            logger.error(
+                f"current event request time {timestamp} is earlier than the last request time "
+                f"{self.last_request[endpoint_id]} - write to TSDB will be rejected"
+            )
+
+    @staticmethod
     def is_list_of_numerics(
-        self,
         field: typing.List[typing.Union[int, float, dict, list]],
         dict_path: typing.List[str],
     ):
         if all(isinstance(x, int) or isinstance(x, float) for x in field):
             return True
         logger.error(
             f"List does not consist of only numeric values: {field} [Event -> {','.join(dict_path)}]"
         )
         return False
 
     def resume_state(self, endpoint_id):
         # Make sure process is resumable, if process fails for any reason, be able to pick things up close to where we
         # left them
         if endpoint_id not in self.endpoints:
+
             logger.info("Trying to resume state", endpoint_id=endpoint_id)
+
             endpoint_record = get_endpoint_record(
-                kv_container=self.kv_container,
-                kv_path=self.kv_path,
+                project=self.project,
                 endpoint_id=endpoint_id,
-                access_key=self.v3io_access_key,
             )
 
-            # If model endpoint found, validate first_request and error_count values
+            # If model endpoint found, get first_request, last_request and error_count values
             if endpoint_record:
                 first_request = endpoint_record.get(EventFieldType.FIRST_REQUEST)
+
                 if first_request:
                     self.first_request[endpoint_id] = first_request
+
+                last_request = endpoint_record.get(EventFieldType.LAST_REQUEST)
+                if last_request:
+
+                    self.last_request[endpoint_id] = last_request
+
                 error_count = endpoint_record.get(EventFieldType.ERROR_COUNT)
+
                 if error_count:
                     self.error_count[endpoint_id] = error_count
 
             # add endpoint to endpoints set
             self.endpoints.add(endpoint_id)
 
     def is_valid(
@@ -813,43 +846,36 @@
                 unpacked[key] = new_event[key]
         return unpacked if unpacked else None
 
 
 class MapFeatureNames(mlrun.feature_store.steps.MapClass):
     def __init__(
         self,
-        kv_container: str,
-        kv_path: str,
-        access_key: str,
+        project: str,
         infer_columns_from_data: bool = False,
         **kwargs,
     ):
         """
         Validating feature names and label columns and map each feature to its value. In the end of this step,
         the event should have key-value pairs of (feature name: feature value).
 
-        :param kv_container:            Name of the container that will be used to retrieve the endpoint id. For model
-                                        endpoints it is usually 'users'.
-        :param kv_path:                 KV table path that will be used to retrieve the endpoint id. For model endpoints
-                                        it is usually pipelines/project-name/model-endpoints/endpoints/
-        :param v3io_access_key:         Access key with permission to read from a KV table.
+        :param project:                 Project name.
         :param infer_columns_from_data: If true and features or labels names were not found, then try to
                                         retrieve them from data that was stored in the previous events of
                                         the current process. This data can be found under self.feature_names and
                                         self.label_columns.
 
 
         :returns: A single event as a dictionary that includes metadata (endpoint_id, model_class, etc.) and also
                   feature names and values (as well as the prediction results).
         """
         super().__init__(**kwargs)
-        self.kv_container = kv_container
-        self.kv_path = kv_path
-        self.access_key = access_key
+
         self._infer_columns_from_data = infer_columns_from_data
+        self.project = project
 
         # Dictionaries that will be used in case features names
         # and labels columns were not found in the current event
         self.feature_names = {}
         self.label_columns = {}
 
     def _infer_feature_names_from_data(self, event):
@@ -870,18 +896,16 @@
 
     def do(self, event: typing.Dict):
         endpoint_id = event[EventFieldType.ENDPOINT_ID]
 
         # Get feature names and label columns
         if endpoint_id not in self.feature_names:
             endpoint_record = get_endpoint_record(
-                kv_container=self.kv_container,
-                kv_path=self.kv_path,
+                project=self.project,
                 endpoint_id=endpoint_id,
-                access_key=self.access_key,
             )
             feature_names = endpoint_record.get(EventFieldType.FEATURE_NAMES)
             feature_names = json.loads(feature_names) if feature_names else None
 
             label_columns = endpoint_record.get(EventFieldType.LABEL_NAMES)
             label_columns = json.loads(label_columns) if label_columns else None
 
@@ -896,46 +920,39 @@
                     endpoint_id=endpoint_id,
                 )
                 feature_names = [
                     f"f{i}" for i, _ in enumerate(event[EventFieldType.FEATURES])
                 ]
 
                 # Update the endpoint record with the generated features
-                mlrun.utils.v3io_clients.get_v3io_client().kv.update(
-                    container=self.kv_container,
-                    table_path=self.kv_path,
-                    access_key=self.access_key,
-                    key=event[EventFieldType.ENDPOINT_ID],
+                update_endpoint_record(
+                    project=self.project,
+                    endpoint_id=endpoint_id,
                     attributes={
                         EventFieldType.FEATURE_NAMES: json.dumps(feature_names)
                     },
-                    raise_for_status=v3io.dataplane.RaiseForStatus.always,
                 )
 
             # Similar process with label columns
             if not label_columns and self._infer_columns_from_data:
                 label_columns = self._infer_label_columns_from_data(event)
 
             if not label_columns:
                 logger.warn(
                     "label column names are not initialized, they will be automatically generated",
                     endpoint_id=endpoint_id,
                 )
                 label_columns = [
                     f"p{i}" for i, _ in enumerate(event[EventFieldType.PREDICTION])
                 ]
-                mlrun.utils.v3io_clients.get_v3io_client().kv.update(
-                    container=self.kv_container,
-                    table_path=self.kv_path,
-                    access_key=self.access_key,
-                    key=event[EventFieldType.ENDPOINT_ID],
-                    attributes={
-                        EventFieldType.LABEL_COLUMNS: json.dumps(label_columns)
-                    },
-                    raise_for_status=v3io.dataplane.RaiseForStatus.always,
+
+                update_endpoint_record(
+                    project=self.project,
+                    endpoint_id=endpoint_id,
+                    attributes={EventFieldType.LABEL_NAMES: json.dumps(label_columns)},
                 )
 
             self.label_columns[endpoint_id] = label_columns
             self.feature_names[endpoint_id] = feature_names
 
             logger.info(
                 "Label columns", endpoint_id=endpoint_id, label_columns=label_columns
@@ -989,41 +1006,32 @@
         """
         event[mapping_dictionary] = {}
         for name, value in zip(named_iters, values_iters):
             event[name] = value
             event[mapping_dictionary][name] = value
 
 
-class WriteToKV(mlrun.feature_store.steps.MapClass):
-    def __init__(self, container: str, table: str, v3io_access_key: str, **kwargs):
+class UpdateEndpoint(mlrun.feature_store.steps.MapClass):
+    def __init__(self, project: str, model_endpoint_store_target: str, **kwargs):
         """
-        Writes the event to KV table. Note that the event at this point includes metadata and stats about the
-        average latency and the amount of predictions over time. This data will be used in the monitoring dashboards
+        Update the model endpoint record in the DB. Note that the event at this point includes metadata and stats about
+        the average latency and the amount of predictions over time. This data will be used in the monitoring dashboards
         such as "Model Monitoring - Performance" which can be found in Grafana.
 
-        :param kv_container:            Name of the container that will be used to retrieve the endpoint id. For model
-                                        endpoints it is usually 'users'.
-        :param table:                   KV table path that will be used to retrieve the endpoint id. For model endpoints
-                                        it is usually pipelines/project-name/model-endpoints/endpoints/.
-        :param v3io_access_key:         Access key with permission to read from a KV table.
-
         :returns: Event as a dictionary (without any changes) for the next step (InferSchema).
         """
         super().__init__(**kwargs)
-        self.container = container
-        self.table = table
-        self.v3io_access_key = v3io_access_key
+        self.project = project
+        self.model_endpoint_store_target = model_endpoint_store_target
 
     def do(self, event: typing.Dict):
-        mlrun.utils.v3io_clients.get_v3io_client().kv.update(
-            container=self.container,
-            table_path=self.table,
-            key=event[EventFieldType.ENDPOINT_ID],
+        update_endpoint_record(
+            project=self.project,
+            endpoint_id=event.pop(EventFieldType.ENDPOINT_ID),
             attributes=event,
-            access_key=self.v3io_access_key,
         )
         return event
 
 
 class InferSchema(mlrun.feature_store.steps.MapClass):
     def __init__(
         self,
@@ -1049,43 +1057,40 @@
         self.container = container
         self.v3io_access_key = v3io_access_key
         self.v3io_framesd = v3io_framesd
         self.table = table
         self.keys = set()
 
     def do(self, event: typing.Dict):
+
         key_set = set(event.keys())
         if not key_set.issubset(self.keys):
             self.keys.update(key_set)
             # Apply infer_schema on the kv table for generating the schema file
             mlrun.utils.v3io_clients.get_frames_client(
                 token=self.v3io_access_key,
                 container=self.container,
                 address=self.v3io_framesd,
             ).execute(backend="kv", table=self.table, command="infer_schema")
+
         return event
 
 
-def get_endpoint_record(
-    kv_container: str, kv_path: str, endpoint_id: str, access_key: str
-) -> typing.Optional[dict]:
-    logger.info(
-        "Grabbing endpoint data",
-        container=kv_container,
-        table_path=kv_path,
-        key=endpoint_id,
+def update_endpoint_record(
+    project: str,
+    endpoint_id: str,
+    attributes: dict,
+):
+    model_endpoint_store = get_model_endpoint_store(
+        project=project,
     )
-    try:
-        endpoint_record = (
-            mlrun.utils.v3io_clients.get_v3io_client()
-            .kv.get(
-                container=kv_container,
-                table_path=kv_path,
-                key=endpoint_id,
-                access_key=access_key,
-                raise_for_status=v3io.dataplane.RaiseForStatus.always,
-            )
-            .output.item
-        )
-        return endpoint_record
-    except Exception:
-        return None
+
+    model_endpoint_store.update_model_endpoint(
+        endpoint_id=endpoint_id, attributes=attributes
+    )
+
+
+def get_endpoint_record(project: str, endpoint_id: str):
+    model_endpoint_store = get_model_endpoint_store(
+        project=project,
+    )
+    return model_endpoint_store.get_model_endpoint(endpoint_id=endpoint_id)
```

## mlrun/platforms/iguazio.py

```diff
@@ -11,190 +11,165 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import json
 import os
 import urllib
-import warnings
 from collections import namedtuple
 from datetime import datetime
 from http import HTTPStatus
 from urllib.parse import urlparse
 
 import kfp.dsl
 import requests
 import semver
 import urllib3
 import v3io
+from deprecated import deprecated
 
 import mlrun.errors
 from mlrun.config import config as mlconf
 from mlrun.errors import err_to_str
 from mlrun.utils import dict_to_json
 
 _cached_control_session = None
 
 VolumeMount = namedtuple("Mount", ["path", "sub_path"])
 
 
+# TODO: Remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'mount_v3io_extended' will be removed in 1.5.0, use 'mount_v3io' instead",
+    category=FutureWarning,
+)
 def mount_v3io_extended(
     name="v3io", remote="", mounts=None, access_key="", user="", secret=None
 ):
     """Modifier function to apply to a Container Op to volume mount a v3io path
-
     :param name:            the volume name
     :param remote:          the v3io path to use for the volume. ~/ prefix will be replaced with /users/<username>/
-    :param mounts:          list of mount & volume sub paths (type Mount). empty mounts & remote mount /v3io & /User
+    :param mounts:          list of mount & volume sub paths (type VolumeMount).
+                            empty mounts & remote will default to mount /v3io & /User.
     :param access_key:      the access key used to auth against v3io. if not given V3IO_ACCESS_KEY env var will be used
     :param user:            the username used to auth against v3io. if not given V3IO_USERNAME env var will be used
     :param secret:          k8s secret name which would be used to get the username and access key to auth against v3io.
     """
-    if remote and not mounts:
-        raise mlrun.errors.MLRunInvalidArgumentError(
-            "mounts must be specified when remote is given"
-        )
-
-    # Empty remote & mounts defaults are mounts of /v3io and /User
-    if not remote and not mounts:
-        user = _resolve_mount_user(user)
-        if not user:
-            raise mlrun.errors.MLRunInvalidArgumentError(
-                "user name/env must be specified when using empty remote and mounts"
-            )
-        mounts = [
-            VolumeMount(path="/v3io", sub_path=""),
-            VolumeMount(path="/User", sub_path="users/" + user),
-        ]
-
-    if not isinstance(mounts, list) and any(
-        [not isinstance(x, VolumeMount) for x in mounts]
-    ):
-        raise TypeError("mounts should be a list of Mount")
-
-    def _mount_v3io_extended(container_op: kfp.dsl.ContainerOp):
-        from kubernetes import client as k8s_client
-
-        vol = v3io_to_vol(name, remote, access_key, user, secret=secret)
-        container_op.add_volume(vol)
-        for mount in mounts:
-            container_op.container.add_volume_mount(
-                k8s_client.V1VolumeMount(
-                    mount_path=mount.path, sub_path=mount.sub_path, name=name
-                )
-            )
-
-        if not secret:
-            container_op = v3io_cred(access_key=access_key, user=user)(container_op)
-        return container_op
-
-    return _mount_v3io_extended
-
-
-def _resolve_mount_user(user=None):
-    return user or os.environ.get("V3IO_USERNAME")
+    return mount_v3io(
+        name=name,
+        remote=remote,
+        volume_mounts=mounts,
+        access_key=access_key,
+        user=user,
+        secret=secret,
+    )
 
 
 def mount_v3io(
     name="v3io",
     remote="",
-    mount_path="",
     access_key="",
     user="",
     secret=None,
     volume_mounts=None,
 ):
     """Modifier function to apply to a Container Op to volume mount a v3io path
 
     :param name:            the volume name
     :param remote:          the v3io path to use for the volume. ~/ prefix will be replaced with /users/<username>/
-    :param mount_path:      the volume mount path (deprecated, exists for backwards compatibility, prefer to
-                            use mounts instead)
     :param access_key:      the access key used to auth against v3io. if not given V3IO_ACCESS_KEY env var will be used
     :param user:            the username used to auth against v3io. if not given V3IO_USERNAME env var will be used
     :param secret:          k8s secret name which would be used to get the username and access key to auth against v3io.
     :param volume_mounts:   list of VolumeMount. empty volume mounts & remote will default to mount /v3io & /User.
     """
-    if mount_path and volume_mounts:
-        raise mlrun.errors.MLRunInvalidArgumentError(
-            "mount_path and mounts can not be given together"
-        )
+    volume_mounts, user = _enrich_and_validate_v3io_mounts(
+        remote=remote,
+        volume_mounts=volume_mounts,
+        user=user,
+    )
 
-    if mount_path:
-        warnings.warn(
-            "mount_path is pending deprecation, use mounts instead"
-            "This will be deprecated in 0.8.0, and will be removed in 0.10.0",
-            # TODO: In 0.8.0 do changes in examples & demos In 0.10.0 remove
-            PendingDeprecationWarning,
-        )
+    def _attach_volume_mounts_and_creds(container_op: kfp.dsl.ContainerOp):
+        from kubernetes import client as k8s_client
 
-    # For backwards compatibility with version<0.6.0 when multi mount wasn't an option (there was no mounts)
-    if not volume_mounts:
-        if mount_path:
-            if remote:
-                # If both remote and mount_path given, no default behavior is expected, we can't assume anything
-                # therefore we don't add the v3io volume mount and default to legacy behavior
-                return mount_v3io_legacy(
-                    name, remote, mount_path, access_key, user, secret
-                )
-            else:
-                # If mount path but no remote, it means the user "counted" on the default remote
-                # Back then remote default was ~/ which is /users/<username>, but since we now use multi mount, we're
-                # using subpath instead
-                user = _resolve_mount_user(user)
-                if not user:
-                    raise mlrun.errors.MLRunInvalidArgumentError(
-                        "user name/env must be specified when using empty remote and mount_path"
-                    )
-                volume_mounts = [
-                    VolumeMount(path="/v3io", sub_path=""),
-                    VolumeMount(path=mount_path, sub_path="users/" + user),
-                ]
-        else:
-            if remote:
-                # If remote but no mount path, it means the user "counted" on the default mount path
-                # Back then mount_path default was /User, but since the remote was given we can't assume anything
-                # therefore we don't add the v3io volume mount and default to legacy behavior
-                return mount_v3io_legacy(
-                    name, remote, access_key=access_key, user=user, secret=secret
+        vol = v3io_to_vol(name, remote, access_key, user, secret=secret)
+        container_op.add_volume(vol)
+        for volume_mount in volume_mounts:
+            container_op.container.add_volume_mount(
+                k8s_client.V1VolumeMount(
+                    mount_path=volume_mount.path,
+                    sub_path=volume_mount.sub_path,
+                    name=name,
                 )
-            # not remote and not mounts (and not mount_path) handled by the extended handler
+            )
 
-    return mount_v3io_extended(
-        name=name,
-        remote=remote,
-        mounts=volume_mounts,
-        access_key=access_key,
-        user=user,
-        secret=secret,
-    )
+        if not secret:
+            container_op = v3io_cred(access_key=access_key, user=user)(container_op)
+        return container_op
 
+    return _attach_volume_mounts_and_creds
 
+
+# TODO: Remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'mount_v3io_legacy' will be removed in 1.5.0, use 'mount_v3io' instead",
+    category=FutureWarning,
+)
 def mount_v3io_legacy(
     name="v3io", remote="~/", mount_path="/User", access_key="", user="", secret=None
 ):
     """Modifier function to apply to a Container Op to volume mount a v3io path
     :param name:            the volume name
     :param remote:          the v3io path to use for the volume. ~/ prefix will be replaced with /users/<username>/
     :param mount_path:      the volume mount path
     :param access_key:      the access key used to auth against v3io. if not given V3IO_ACCESS_KEY env var will be used
     :param user:            the username used to auth against v3io. if not given V3IO_USERNAME env var will be used
     :param secret:          k8s secret name which would be used to get the username and access key to auth against v3io.
     """
-
-    return mount_v3io_extended(
+    return mount_v3io(
         name=name,
         remote=remote,
-        mounts=[VolumeMount(path=mount_path, sub_path="")],
+        volume_mounts=[VolumeMount(path=mount_path, sub_path="")],
         access_key=access_key,
         user=user,
         secret=secret,
     )
 
 
+def _enrich_and_validate_v3io_mounts(remote="", volume_mounts=None, user=""):
+    if remote and not volume_mounts:
+        raise mlrun.errors.MLRunInvalidArgumentError(
+            "volume_mounts must be specified when remote is given"
+        )
+
+    # Empty remote & volume_mounts defaults are volume mounts of /v3io and /User
+    if not remote and not volume_mounts:
+        user = _resolve_mount_user(user)
+        if not user:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                "user name/env must be specified when using empty remote and volume_mounts"
+            )
+        volume_mounts = [
+            VolumeMount(path="/v3io", sub_path=""),
+            VolumeMount(path="/User", sub_path="users/" + user),
+        ]
+
+    if not isinstance(volume_mounts, list) and any(
+        [not isinstance(x, VolumeMount) for x in volume_mounts]
+    ):
+        raise TypeError("mounts should be a list of Mount")
+
+    return volume_mounts, user
+
+
+def _resolve_mount_user(user=None):
+    return user or os.environ.get("V3IO_USERNAME")
+
+
 def mount_spark_conf():
     def _mount_spark(container_op: kfp.dsl.ContainerOp):
         from kubernetes import client as k8s_client
 
         container_op.container.add_volume_mount(
             k8s_client.V1VolumeMount(
                 name="spark-master-config", mount_path="/etc/config/spark"
```

## mlrun/projects/operations.py

```diff
@@ -8,15 +8,15 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from typing import List, Union
+from typing import Dict, List, Optional, Union
 
 import kfp
 
 import mlrun
 from mlrun.utils import hub_prefix
 
 from .pipelines import enrich_function_object, pipeline_context
@@ -68,14 +68,15 @@
     local: bool = None,
     verbose: bool = None,
     selector: str = None,
     project_object=None,
     auto_build: bool = None,
     schedule: Union[str, mlrun.api.schemas.ScheduleCronTrigger] = None,
     artifact_path: str = None,
+    returns: Optional[List[Union[str, Dict[str, str]]]] = None,
 ) -> Union[mlrun.model.RunObject, kfp.dsl.ContainerOp]:
     """Run a local or remote task as part of a local/kubeflow pipeline
 
     run_function() allow you to execute a function locally, on a remote cluster, or as part of an automated workflow
     function can be specified as an object or by name (str), when the function is specified by name it is looked up
     in the current project eliminating the need to redefine/edit functions.
 
@@ -120,15 +121,17 @@
     :param handler:         name of the function handler
     :param name:            execution name
     :param params:          input parameters (dict)
     :param hyperparams:     hyper parameters
     :param selector:        selection criteria for hyper params e.g. "max.accuracy"
     :param hyper_param_options:  hyper param options (selector, early stop, strategy, ..)
                             see: :py:class:`~mlrun.model.HyperParamOptions`
-    :param inputs:          input objects (dict of key: path)
+    :param inputs:          Input objects to pass to the handler. Type hints can be given so the input will be parsed
+                            during runtime from `mlrun.DataItem` to the given type hint. The type hint can be given
+                            in the key field of the dictionary after a colon, e.g: "<key> : <type_hint>".
     :param outputs:         list of outputs which can pass in the workflow
     :param workdir:         default input artifacts path
     :param labels:          labels to tag the job/run with ({key:val, ..})
     :param base_task:       task object to use as base
     :param watch:           watch/follow run log, True by default
     :param local:           run the function locally vs on the runtime/cluster
     :param verbose:         add verbose prints/logs
@@ -136,23 +139,35 @@
     :param auto_build:      when set to True and the function require build it will be built on the first
                             function run, use only if you dont plan on changing the build config between runs
     :param schedule:        ScheduleCronTrigger class instance or a standard crontab expression string
                             (which will be converted to the class using its `from_crontab` constructor),
                             see this link for help:
                             https://apscheduler.readthedocs.io/en/3.x/modules/triggers/cron.html#module-apscheduler.triggers.cron
     :param artifact_path:   path to store artifacts, when running in a workflow this will be set automatically
+    :param returns:         List of log hints - configurations for how to log the returning values from the handler's
+                            run (as artifacts or results). The list's length must be equal to the amount of returning
+                            objects. A log hint may be given as:
+
+                            * A string of the key to use to log the returning value as result or as an artifact. To
+                              specify The artifact type, it is possible to pass a string in the following structure:
+                              "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no
+                              artifact type is specified, the object's default artifact type will be used.
+                            * A dictionary of configurations to use when logging. Further info per object type and
+                              artifact type can be given there. The artifact key must appear in the dictionary as
+                              "key": "the_key".
     :return: MLRun RunObject or KubeFlow containerOp
     """
     engine, function = _get_engine_and_function(function, project_object)
     task = mlrun.new_task(
         handler=handler,
         params=params,
         hyper_params=hyperparams,
         hyper_param_options=hyper_param_options,
         inputs=inputs,
+        returns=returns,
         base=base_task,
         selector=selector,
     )
     task.spec.verbose = task.spec.verbose or verbose
 
     if engine == "kfp":
         return function.as_step(
@@ -172,19 +187,19 @@
         run_result = function.run(
             name=name,
             runspec=task,
             workdir=workdir,
             verbose=verbose,
             watch=watch,
             local=local,
+            artifact_path=artifact_path
             # workflow artifact_path has precedence over the project artifact_path equivalent to
             # passing artifact_path to function.run() has precedence over the project.artifact_path and the default one
-            artifact_path=pipeline_context.workflow_artifact_path
-            or (project.artifact_path if project else None)
-            or artifact_path,
+            or pipeline_context.workflow_artifact_path
+            or (project.artifact_path if project else None),
             auto_build=auto_build,
             schedule=schedule,
         )
         if run_result:
             run_result._notified = False
             pipeline_context.runs_map[run_result.uid()] = run_result
             run_result.after = (
@@ -212,15 +227,15 @@
 def build_function(
     function: Union[str, mlrun.runtimes.BaseRuntime],
     with_mlrun: bool = None,
     skip_deployed: bool = False,
     image=None,
     base_image=None,
     commands: list = None,
-    secret_name="",
+    secret_name=None,
     requirements: Union[str, List[str]] = None,
     mlrun_version_specifier=None,
     builder_env: dict = None,
     project_object=None,
     overwrite_build_params: bool = False,
 ) -> Union[BuildStatus, kfp.dsl.ContainerOp]:
     """deploy ML function, build container with its dependencies
@@ -308,15 +323,15 @@
     builder_env: dict = None,
     project_object=None,
     mock: bool = None,
 ) -> Union[DeployStatus, kfp.dsl.ContainerOp]:
     """deploy real-time (nuclio based) functions
 
     :param function:   name of the function (in the project) or function object
-    :param dashboard:  url of the remote Nuclio dashboard (when not local)
+    :param dashboard:  DEPRECATED. Keep empty to allow auto-detection by MLRun API.
     :param models:     list of model items
     :param env:        dict of extra environment variables
     :param tag:        extra version tag
     :param verbose:    add verbose prints/logs
     :param builder_env: env vars dict for source archive config/credentials e.g. builder_env={"GIT_TOKEN": token}
     :param mock:       deploy mock server vs a real Nuclio function (for local simulations)
     :param project_object:  override the project object to use, will default to the project set in the runtime context.
```

## mlrun/projects/pipelines.py

```diff
@@ -16,27 +16,33 @@
 import importlib.util as imputil
 import os
 import tempfile
 import time
 import traceback
 import typing
 import uuid
+import warnings
 
 import kfp.compiler
 from kfp import dsl
 from kfp.compiler import compiler
 
 import mlrun
 import mlrun.api.schemas
 import mlrun.utils.notifications
 from mlrun.errors import err_to_str
-from mlrun.utils import get_ui_url, logger, new_pipe_meta, parse_versioned_object_uri
+from mlrun.utils import (
+    get_ui_url,
+    logger,
+    new_pipe_metadata,
+    parse_versioned_object_uri,
+)
 
 from ..config import config
-from ..run import run_pipeline, wait_for_pipeline_completion
+from ..run import _run_pipeline, wait_for_pipeline_completion
 from ..runtimes.pod import AutoMountType
 
 
 def get_workflow_engine(engine_kind, local=False):
     if pipeline_context.is_run_local(local):
         if engine_kind == "kfp":
             logger.warning(
@@ -66,31 +72,40 @@
         self,
         engine=None,
         code=None,
         path=None,
         args=None,
         name=None,
         handler=None,
+        # TODO: deprecated, remove in 1.5.0
         ttl=None,
         args_schema: dict = None,
         schedule: typing.Union[str, mlrun.api.schemas.ScheduleCronTrigger] = None,
-        override: bool = None,
+        cleanup_ttl: int = None,
     ):
+        if ttl:
+            warnings.warn(
+                "'ttl' is deprecated, use 'cleanup_ttl' instead. "
+                "This will be removed in 1.5.0",
+                # TODO: Remove this in 1.5.0
+                FutureWarning,
+            )
+
         self.engine = engine
         self.code = code
         self.path = path
         self.args = args
         self.name = name
         self.handler = handler
-        self.ttl = ttl
+        self.ttl = cleanup_ttl or ttl
+        self.cleanup_ttl = cleanup_ttl or ttl
         self.args_schema = args_schema
         self.run_local = False
         self._tmp_path = None
         self.schedule = schedule
-        self.override = override
 
     def get_source_file(self, context=""):
         if not self.code and not self.path:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "workflow must have code or path properties"
             )
         if self.code:
@@ -366,14 +381,20 @@
     project, function, decorator=None, copy_function=True
 ) -> mlrun.runtimes.BaseRuntime:
     if hasattr(function, "_enriched"):
         return function
     f = function.copy() if copy_function else function
     f.metadata.project = project.metadata.name
     setattr(f, "_enriched", True)
+
+    # set project default image if defined and function does not have an image specified
+    if project.spec.default_image and not f.spec.image:
+        f._enriched_image = True
+        f.spec.image = project.spec.default_image
+
     src = f.spec.build.source
     if src and src in [".", "./"]:
         if not project.spec.source and not project.spec.mountdir:
             logger.warning(
                 "project.spec.source should be specified when function is using code from project context"
             )
 
@@ -524,15 +545,18 @@
             project,
             workflow_file,
             functions,
             secrets=project._secrets,
         )
         artifact_path = artifact_path or project.spec.artifact_path
 
-        conf = new_pipe_meta(artifact_path, ttl=workflow_spec.ttl)
+        conf = new_pipe_metadata(
+            artifact_path=artifact_path,
+            cleanup_ttl=workflow_spec.cleanup_ttl or workflow_spec.ttl,
+        )
         compiler.Compiler().compile(pipeline, target, pipeline_conf=conf)
         workflow_spec.clear_tmp()
         pipeline_context.clear()
 
     @classmethod
     def run(
         cls,
@@ -549,22 +573,22 @@
         workflow_handler = _PipelineRunner._get_handler(
             workflow_handler, workflow_spec, project, secrets
         )
         if source:
             project.set_source(source=source)
 
         namespace = namespace or config.namespace
-        id = run_pipeline(
+        id = _run_pipeline(
             workflow_handler,
             project=project.metadata.name,
             arguments=workflow_spec.args,
             experiment=name or workflow_spec.name,
             namespace=namespace,
             artifact_path=artifact_path,
-            ttl=workflow_spec.ttl,
+            cleanup_ttl=workflow_spec.cleanup_ttl or workflow_spec.ttl,
         )
         project.notifiers.push_pipeline_start_message(
             project.metadata.name,
             project.get_param("commit_id", None),
             id,
             True,
         )
@@ -760,15 +784,15 @@
                     "save": save,
                     "workflow_name": workflow_name or workflow_spec.name,
                     "workflow_path": workflow_spec.path,
                     "workflow_arguments": workflow_spec.args,
                     "artifact_path": artifact_path,
                     "workflow_handler": workflow_handler or workflow_spec.handler,
                     "namespace": namespace,
-                    "ttl": workflow_spec.ttl,
+                    "ttl": workflow_spec.cleanup_ttl or workflow_spec.ttl,
                     "engine": workflow_spec.engine,
                     "local": workflow_spec.run_local,
                     "schedule": workflow_spec.schedule,
                 },
                 handler="mlrun.projects.load_and_run",
             ),
             metadata=mlrun.model.RunMetadata(name=workflow_name),
@@ -814,38 +838,14 @@
             workflow_name=workflow_name,
             workflow_spec=workflow_spec,
             artifact_path=artifact_path,
             workflow_handler=workflow_handler,
             namespace=namespace,
         )
 
-        if workflow_spec.schedule:
-            is_scheduled = True
-            schedule_name = runspec.spec.parameters.get("workflow_name")
-            run_db = mlrun.get_run_db()
-
-            try:
-                run_db.get_schedule(project.name, schedule_name)
-            except mlrun.errors.MLRunNotFoundError:
-                is_scheduled = False
-
-            if workflow_spec.override:
-                if is_scheduled:
-                    logger.info(f"Deleting schedule {schedule_name}")
-                    run_db.delete_schedule(project.name, schedule_name)
-                else:
-                    logger.info(
-                        f"No schedule by name '{schedule_name}' was found, nothing to override."
-                    )
-            elif is_scheduled:
-                raise mlrun.errors.MLRunConflictError(
-                    f"There is already a schedule for workflow {schedule_name}."
-                    " If you want to override this schedule use 'override=True' (SDK) or '--override-workflow' (CLI)"
-                )
-
         # The returned engine for this runner is the engine of the workflow.
         # In this way wait_for_completion/get_run_status would be executed by the correct pipeline runner.
         inner_engine = get_workflow_engine(workflow_spec.engine)
 
         msg = "executing workflow"
         if workflow_spec.schedule:
             msg += " scheduling"
@@ -906,14 +906,21 @@
     spec.loader.exec_module(mod)
 
     setattr(mod, "funcs", functions)  # should be replaced with "functions" in future
     setattr(mod, "functions", functions)
     setattr(mod, "this_project", project)
 
     if hasattr(mod, "init_functions"):
+
+        # TODO: remove in 1.5.0
+        warnings.warn(
+            "'init_functions' is deprecated in 1.3.0 and will be removed in 1.5.0. "
+            "Place function initialization in the pipeline code.",
+            FutureWarning,
+        )
         getattr(mod, "init_functions")(functions, project, secrets)
 
     # verify all functions are in this project (init_functions may add new functions)
     for f in functions.values():
         f.metadata.project = project.metadata.name
 
     if not handler and hasattr(mod, "kfpipeline"):
@@ -952,18 +959,20 @@
     workflow_path: str = None,
     workflow_arguments: typing.Dict[str, typing.Any] = None,
     artifact_path: str = None,
     workflow_handler: typing.Union[str, typing.Callable] = None,
     namespace: str = None,
     sync: bool = False,
     dirty: bool = False,
+    # TODO: deprecated, remove in 1.5.0
     ttl: int = None,
     engine: str = None,
     local: bool = None,
     schedule: typing.Union[str, mlrun.api.schemas.ScheduleCronTrigger] = None,
+    cleanup_ttl: int = None,
 ):
     """
     Auxiliary function that the RemoteRunner run once or run every schedule.
     This function loads a project from a given remote source and then runs the workflow.
 
     :param context:             mlrun context.
     :param url:                 remote url that represents the project's source.
@@ -978,20 +987,31 @@
     :param workflow_arguments:  kubeflow pipelines arguments (parameters)
     :param artifact_path:       target path/url for workflow artifacts, the string
                                 '{{workflow.uid}}' will be replaced by workflow id
     :param workflow_handler:    workflow function handler (for running workflow function directly)
     :param namespace:           kubernetes namespace if other than default
     :param sync:                force functions sync before run
     :param dirty:               allow running the workflow when the git repo is dirty
-    :param ttl:                 pipeline ttl in secs (after that the pods will be removed)
+    :param ttl:                 pipeline cleanup ttl in secs (time to wait after workflow completion, at which point the
+                                workflow and all its resources are deleted) (deprecated, use cleanup_ttl instead)
     :param engine:              workflow engine running the workflow.
                                 supported values are 'kfp' (default) or 'local'
     :param local:               run local pipeline with local functions (set local=True in function.run())
     :param schedule:            ScheduleCronTrigger class instance or a standard crontab expression string
+    :param cleanup_ttl:         pipeline cleanup ttl in secs (time to wait after workflow completion, at which point the
+                                workflow and all its resources are deleted)
     """
+    if ttl:
+        warnings.warn(
+            "'ttl' is deprecated, use 'cleanup_ttl' instead. "
+            "This will be removed in 1.5.0",
+            # TODO: Remove this in 1.5.0
+            FutureWarning,
+        )
+
     try:
         project = mlrun.load_project(
             context=f"./{project_name}",
             url=url,
             name=project_name,
             init_git=init_git,
             subpath=subpath,
@@ -1031,14 +1051,14 @@
         arguments=workflow_arguments,
         artifact_path=artifact_path,
         workflow_handler=workflow_handler,
         namespace=namespace,
         sync=sync,
         watch=False,  # Required for fetching the workflow_id
         dirty=dirty,
-        ttl=ttl,
+        cleanup_ttl=cleanup_ttl or ttl,
         engine=engine,
         local=local,
     )
     context.log_result(key="workflow_id", value=run.run_id)
 
     context.log_result(key="engine", value=run._engine.engine, commit=True)
```

## mlrun/projects/project.py

```diff
@@ -19,25 +19,28 @@
 import shutil
 import tempfile
 import typing
 import uuid
 import warnings
 import zipfile
 from os import environ, makedirs, path, remove
+from typing import Dict, List, Optional, Union
 
 import dotenv
+import git
+import git.exc
 import inflection
 import kfp
 import nuclio
 import yaml
-from git import Repo
 
 import mlrun.api.schemas
 import mlrun.db
 import mlrun.errors
+import mlrun.model_monitoring.constants as model_monitoring_constants
 import mlrun.utils.regex
 from mlrun.runtimes import RuntimeKinds
 
 from ..artifacts import Artifact, ArtifactProducer, DatasetArtifact, ModelArtifact
 from ..artifacts.manager import ArtifactManager, dict_to_artifact, extend_artifact_path
 from ..datastore import store_manager
 from ..features import Feature
@@ -50,15 +53,15 @@
     is_legacy_artifact,
     is_relative_path,
     is_yaml_path,
     logger,
     update_in,
 )
 from ..utils.clones import clone_git, clone_tgz, clone_zip, get_repo_url
-from ..utils.model_monitoring import set_project_model_monitoring_credentials
+from ..utils.helpers import ensure_git_branch, resolve_git_reference_from_source
 from ..utils.notifications import CustomNotificationPusher, NotificationTypes
 from .operations import (
     BuildStatus,
     DeployStatus,
     build_function,
     deploy_function,
     run_function,
@@ -82,19 +85,19 @@
     repo = None
     context_path = pathlib.Path(context)
     if not context_path.exists():
         context_path.mkdir(parents=True)
     elif not context_path.is_dir():
         raise ValueError(f"context {context} is not a dir path")
     try:
-        repo = Repo(context)
+        repo = git.Repo(context)
         url = get_repo_url(repo)
     except Exception:
         if init_git:
-            repo = Repo.init(context)
+            repo = git.Repo.init(context)
     return repo, url
 
 
 def new_project(
     name,
     context: str = "./",
     init_git: bool = False,
@@ -159,14 +162,16 @@
             project = _load_project_dir(context, name)
         elif from_template.endswith(".zip"):
             clone_zip(from_template, context, secrets)
             project = _load_project_dir(context, name)
         else:
             raise ValueError("template must be a path to .yaml or .zip file")
         project.metadata.name = name
+        # Remove original owner name for avoiding possible conflicts
+        project.spec.owner = None
     else:
         project = MlrunProject(name=name)
     project.spec.context = context
     project.spec.subpath = subpath or project.spec.subpath
 
     repo, url = init_repo(context, remote, init_git or remote)
     project.spec.repo = repo
@@ -222,29 +227,29 @@
 
         # Load the project and run the 'main' workflow.
         # When using git as the url source the context directory must be an empty or
         # non-existent folder as the git repo will be cloned there
         project = load_project("./demo_proj", "git://github.com/mlrun/project-demo.git")
         project.run("main", arguments={'data': data_url})
 
-    :param context:      project local directory path (default value = "./")
-    :param url:          name (in DB) or git or tar.gz or .zip sources archive path e.g.:
-                         git://github.com/mlrun/demo-xgb-project.git
-                         http://mysite/archived-project.zip
-                         <project-name>
-                         The git project should include the project yaml file.
-                         If the project yaml file is in a sub-directory, must specify the sub-directory.
-    :param name:         project name
-    :param secrets:      key:secret dict or SecretsStore used to download sources
-    :param init_git:     if True, will git init the context dir
-    :param subpath:      project subpath (within the archive)
-    :param clone:        if True, always clone (delete any existing content)
-    :param user_project: add the current user name to the project name (for db:// prefixes)
-    :param save:         whether to save the created project and artifact in the DB
-    :param sync_functions: sync the project's functions into the project object (will be saved to the DB if save=True)
+    :param context:         project local directory path (default value = "./")
+    :param url:             name (in DB) or git or tar.gz or .zip sources archive path e.g.:
+                            git://github.com/mlrun/demo-xgb-project.git
+                            http://mysite/archived-project.zip
+                            <project-name>
+                            The git project should include the project yaml file.
+                            If the project yaml file is in a sub-directory, must specify the sub-directory.
+    :param name:            project name
+    :param secrets:         key:secret dict or SecretsStore used to download sources
+    :param init_git:        if True, will git init the context dir
+    :param subpath:         project subpath (within the archive)
+    :param clone:           if True, always clone (delete any existing content)
+    :param user_project:    add the current user name to the project name (for db:// prefixes)
+    :param save:            whether to save the created project and artifact in the DB
+    :param sync_functions:  sync the project's functions into the project object (will be saved to the DB if save=True)
 
     :returns: project object
     """
     if not context:
         raise ValueError("valid context (local dir path) must be provided")
 
     secrets = secrets or {}
@@ -256,14 +261,16 @@
     if url:
         url = str(url)  # to support path objects
         if is_yaml_path(url):
             project = _load_project_file(url, name, secrets)
             project.spec.context = context
         elif url.startswith("git://"):
             url, repo = clone_git(url, context, secrets, clone)
+            # Validate that git source includes branch and refs
+            url = ensure_git_branch(url=url, repo=repo)
         elif url.endswith(".tar.gz"):
             clone_tgz(url, context, secrets, clone)
         elif url.endswith(".zip"):
             clone_zip(url, context, secrets, clone)
         else:
             project = _load_project_from_db(url, secrets, user_project)
             project.spec.context = context
@@ -273,19 +280,23 @@
             from_db = True
 
     if not repo:
         repo, url = init_repo(context, url, init_git)
 
     if not project:
         project = _load_project_dir(context, name, subpath)
+
     if not project.metadata.name:
         raise ValueError("project name must be specified")
-    if not from_db or (url and url.startswith("git://")):
+    if not from_db:
         project.spec.source = url or project.spec.source
         project.spec.origin_url = url or project.spec.origin_url
+        # Remove original owner name for avoiding possible conflicts when loading project from remote
+        project.spec.owner = None
+
     project.spec.repo = repo
     if repo:
         try:
             # handle cases where active_branch is not set (e.g. in Gitlab CI)
             project.spec.branch = repo.active_branch.name
         except Exception:
             pass
@@ -458,48 +469,18 @@
     except FileNotFoundError as exc:
         raise FileNotFoundError(f"cant find project file at {url}") from exc
     struct = yaml.load(obj, Loader=yaml.FullLoader)
     return _project_instance_from_struct(struct, name)
 
 
 def _project_instance_from_struct(struct, name):
-    # Name is in the root level only in the legacy project structure
-    if "name" in struct:
-        legacy_project = MlrunProjectLegacy.from_dict(struct)
-        project = MlrunProject(
-            legacy_project.name,
-            legacy_project.description,
-            legacy_project.params,
-            [],
-            legacy_project.workflows,
-            legacy_project.artifacts,
-            legacy_project.artifact_path,
-            legacy_project.conda,
-        )
-        # other attributes that not passed on initialization
-        project._initialized = legacy_project._initialized
-        project._secrets = legacy_project._secrets
-        project._artifact_manager = legacy_project._artifact_mngr
-
-        project.spec.source = legacy_project.source
-        project.spec.context = legacy_project.context
-        project.spec.mountdir = legacy_project.mountdir
-        project.spec.subpath = legacy_project.subpath
-        project.spec.origin_url = legacy_project.origin_url
-        project.spec.branch = legacy_project.branch
-        project.spec.tag = legacy_project.tag
-        project.spec._function_definitions = legacy_project._function_defs
-        project.spec._function_objects = legacy_project._function_objects
-        project.spec.functions = legacy_project.functions
-    else:
-        struct.setdefault("metadata", {})["name"] = name or struct.get(
-            "metadata", {}
-        ).get("name", "")
-        project = MlrunProject.from_dict(struct)
-    return project
+    struct.setdefault("metadata", {})["name"] = name or struct.get("metadata", {}).get(
+        "name", ""
+    )
+    return MlrunProject.from_dict(struct)
 
 
 class ProjectMetadata(ModelObj):
     def __init__(self, name=None, created=None, labels=None, annotations=None):
         self.name = name
         self.created = created
         self.labels = labels or {}
@@ -545,14 +526,15 @@
         goals=None,
         load_source_on_run=None,
         default_requirements: typing.Union[str, typing.List[str]] = None,
         desired_state=mlrun.api.schemas.ProjectState.online.value,
         owner=None,
         disable_auto_mount=None,
         workdir=None,
+        default_image=None,
     ):
         self.repo = None
 
         self.description = description
         self.context = ""
         self._mountdir = None
         self._source = None
@@ -562,28 +544,29 @@
         self.origin_url = origin_url
         self.goals = goals
         self.desired_state = desired_state
         self.owner = owner
         self.branch = None
         self.tag = ""
         self.params = params or {}
-        self.conda = conda or {}
+        self.conda = conda or ""
         self.artifact_path = artifact_path
         self._artifacts = {}
         self.artifacts = artifacts or []
         self.default_requirements = default_requirements
         self.workdir = workdir
 
         self._workflows = {}
         self.workflows = workflows or []
 
         self._function_objects = {}
         self._function_definitions = {}
         self.functions = functions or []
         self.disable_auto_mount = disable_auto_mount
+        self.default_image = default_image
 
     @property
     def source(self) -> str:
         """source url or git repo"""
         if not self._source:
             if self.repo:
                 url = get_repo_url(self.repo)
@@ -759,14 +742,25 @@
                 return True
         return False
 
     def get_code_path(self):
         """Get the path to the code root/workdir"""
         return path.join(self.context, self.workdir or self.subpath or "")
 
+    def _replace_default_image_in_enriched_functions(self, previous_image, new_image):
+        """
+        Set a new project-default-image in functions that were already enriched.
+        """
+        if previous_image == new_image:
+            return
+        for key in self._function_objects:
+            function = self._function_objects[key]
+            if function._enriched_image:
+                function.spec.image = new_image
+
 
 class ProjectStatus(ModelObj):
     def __init__(self, state=None):
         self.state = state
 
 
 class MlrunProject(ModelObj):
@@ -854,67 +848,49 @@
 
     @name.setter
     def name(self, name):
         self.metadata.name = name
 
     @property
     def artifact_path(self) -> str:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.artifact_path instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.artifact_path
 
     @artifact_path.setter
     def artifact_path(self, artifact_path):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.artifact_path instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.artifact_path = artifact_path
 
     @property
     def source(self) -> str:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.source instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.source
 
     @source.setter
     def source(self, source):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.source instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.source = source
 
     def set_source(self, source, pull_at_runtime=False, workdir=None):
         """set the project source code path(can be git/tar/zip archive)
 
         :param source:     valid path to git, zip, or tar file, (or None for current) e.g.
                            git://github.com/mlrun/something.git
                            http://some/url/file.zip
         :param pull_at_runtime: load the archive into the container at job runtime vs on build/deploy
         :param workdir:    the relative workdir path (under the context dir)
         """
         self.spec.load_source_on_run = pull_at_runtime
         self.spec.source = source or self.spec.source
+
+        if self.spec.source.startswith("git://"):
+
+            source, reference, branch = resolve_git_reference_from_source(source)
+            if not branch and not reference:
+                logger.warn(
+                    "Please add git branch or refs to the source e.g.: "
+                    "'git://<url>/org/repo.git#<branch-name or refs/heads/..>'"
+                )
+
         self.spec.workdir = workdir or self.spec.workdir
         # reset function objects (to recalculate build attributes)
         self.sync_functions()
 
     def get_artifact_uri(
         self, key: str, category: str = "artifact", tag: str = None
     ) -> str:
@@ -937,142 +913,76 @@
         """get store resource object by uri"""
         return mlrun.datastore.get_store_resource(
             uri, secrets=self._secrets, project=self.metadata.name
         )
 
     @property
     def context(self) -> str:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.context instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.context
 
     @context.setter
     def context(self, context):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.context instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.context = context
 
     @property
     def mountdir(self) -> str:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.mountdir instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.mountdir
 
     @mountdir.setter
     def mountdir(self, mountdir):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.mountdir instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.mountdir = mountdir
 
     @property
     def params(self) -> str:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.params instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.params
 
     @params.setter
     def params(self, params):
         warnings.warn(
-            "This is a property of the spec, use project.spec.params instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
+            "This is a property of the spec, use project.spec.params instead. "
+            "This is deprecated in 1.3.0, and will be removed in 1.5.0",
+            # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
+            FutureWarning,
         )
         self.spec.params = params
 
     @property
     def description(self) -> str:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.description instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.description
 
     @description.setter
     def description(self, description):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.description instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.description = description
 
     @property
-    def functions(self) -> list:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.functions instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        return self.spec.functions
+    def default_image(self) -> str:
+        return self.spec.default_image
 
-    @functions.setter
-    def functions(self, functions):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.functions instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        self.spec.functions = functions
+    def set_default_image(self, default_image: str):
+        """
+        Set the default image to be used for running runtimes (functions) in this project. This image will be used
+        if an image was not provided for a runtime. In case the default image is replaced, functions already
+        registered with the project that used the previous default image will have their image replaced on
+        next execution.
+
+        :param default_image: Default image to use
+        """
+        current_default_image = self.spec.default_image
+        if current_default_image:
+            self.spec._replace_default_image_in_enriched_functions(
+                current_default_image, default_image
+            )
+        self.spec.default_image = default_image
 
     @property
     def workflows(self) -> list:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.workflows instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         return self.spec.workflows
 
     @workflows.setter
     def workflows(self, workflows):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.workflows instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
         self.spec.workflows = workflows
 
     def set_workflow(
         self,
         name,
         workflow_path: str,
         embed=False,
@@ -1120,36 +1030,14 @@
             workflow["args_schema"] = args_schema
         workflow["engine"] = engine
         workflow["schedule"] = schedule
         if ttl:
             workflow["ttl"] = ttl
         self.spec.set_workflow(name, workflow)
 
-    @property
-    def artifacts(self) -> list:
-        """This is a property of the spec, look there for documentation
-        leaving here for backwards compatibility with users code that used MlrunProjectLegacy"""
-        warnings.warn(
-            "This is a property of the spec, use project.spec.artifacts instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        return self.spec.artifacts
-
-    @artifacts.setter
-    def artifacts(self, artifacts):
-        warnings.warn(
-            "This is a property of the spec, use project.spec.artifacts instead"
-            "This will be deprecated in 0.7.0, and will be removed in 0.9.0",
-            # TODO: In 0.7.0 do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        self.spec.artifacts = artifacts
-
     def set_artifact(
         self,
         key,
         artifact: typing.Union[str, dict, Artifact] = None,
         target_path: str = None,
         tag: str = None,
     ):
@@ -1169,15 +1057,21 @@
         :param key:  artifact key/name
         :param artifact:  mlrun Artifact object/dict (or its subclasses) or path to artifact
                           file to import (yaml/json/zip), relative paths are relative to the context path
         :param target_path: absolute target path url (point to the artifact content location)
         :param tag:    artifact tag
         """
         if artifact and isinstance(artifact, str):
-            artifact = {"import_from": artifact, "key": key}
+            artifact_path, _ = self.get_item_absolute_path(
+                artifact, check_path_in_context=True
+            )
+            artifact = {
+                "import_from": artifact_path,
+                "key": key,
+            }
             if tag:
                 artifact["tag"] = tag
         else:
             if not artifact:
                 artifact = Artifact()
             artifact.spec.target_path = target_path or artifact.spec.target_path
             if artifact.spec.target_path and "://" not in artifact.spec.target_path:
@@ -1234,25 +1128,38 @@
         try:
             if self.spec.repo:
                 return self.spec.repo.head.commit.hexsha
         except Exception:
             pass
         return None
 
-    def get_item_absolute_path(self, url: str) -> typing.Tuple[str, bool]:
-        in_context = False
+    def get_item_absolute_path(
+        self,
+        url: str,
+        check_path_in_context: bool = False,
+    ) -> typing.Tuple[str, bool]:
+        """
+        Get the absolute path of the artifact or function file
+        :param url:                   remote url, absolute path or relative path
+        :param check_path_in_context: if True, will check if the path exists when in the context
+                                      (temporary parameter to allow for backwards compatibility)
+        :returns:                     absolute path / url, whether the path is in the project context
+        """
         # If the URL is for a remote location, we do not want to change it
-        if url and "://" not in url:
-            # We don't want to change the url if the project has no cntext or if it is already absolute
-            if self.spec.context and not url.startswith("/"):
-                in_context = True
-                url = path.normpath(path.join(self.spec.get_code_path(), url))
-                return url, in_context
-            if not path.isfile(url):
-                raise OSError(f"{url} not found")
+        if not url or "://" in url:
+            return url, False
+
+        # We don't want to change the url if the project has no context or if it is already absolute
+        in_context = self.spec.context and not url.startswith("/")
+        if in_context:
+            url = path.normpath(path.join(self.spec.get_code_path(), url))
+
+        if (not in_context or check_path_in_context) and not path.isfile(url):
+            raise mlrun.errors.MLRunNotFoundError(f"{url} not found")
+
         return url, in_context
 
     def log_artifact(
         self,
         item,
         body=None,
         tag="",
@@ -1589,23 +1496,31 @@
             proj.set_function(func_object)
             proj.set_function('./src/mycode.py', 'ingest',
                               image='myrepo/ing:latest', with_repo=True)
             proj.set_function('http://.../mynb.ipynb', 'train')
             proj.set_function('./func.yaml')
             proj.set_function('hub://get_toy_data', 'getdata')
 
+            # set function requirements
+
+            # by providing a list of packages
+            proj.set_function('my.py', requirements=["requests", "pandas"])
+
+            # by providing a path to a pip requirements file
+            proj.set_function('my.py', requirements="requirements.txt")
+
         :param func:      function object or spec/code url, None refers to current Notebook
         :param name:      name of the function (under the project)
         :param kind:      runtime kind e.g. job, nuclio, spark, dask, mpijob
                           default: job
         :param image:     docker image to be used, can also be specified in
                           the function object/yaml
         :param handler:   default function handler to invoke (can only be set with .py/.ipynb files)
         :param with_repo: add (clone) the current repo to the build source
-        :tag:             function version tag (none for 'latest', can only be set with .py/.ipynb files)
+        :param tag:       function version tag (none for 'latest', can only be set with .py/.ipynb files)
         :param requirements:    list of python packages or pip requirements file path
 
         :returns: project object
         """
         if func is None and not _has_module(handler, kind):
             # if function path is not provided and it is not a module (no ".")
             # use the current notebook as default
@@ -1617,14 +1532,15 @@
 
             kernel = get_ipython()
             func = nuclio.utils.notebook_file_name(kernel)
             if func.startswith(path.abspath(self.spec.context)):
                 func = path.relpath(func, self.spec.context)
 
         func = func or ""
+        name = mlrun.utils.normalize_name(name) if name else name
         if isinstance(func, str):
             # in hub or db functions name defaults to the function name
             if not name and not (func.startswith("db://") or func.startswith("hub://")):
                 raise ValueError("function name must be specified")
             function_dict = {
                 "url": func,
                 "name": name,
@@ -1661,28 +1577,14 @@
     def remove_function(self, name):
         """remove a function from a project
 
         :param name:    name of the function (under the project)
         """
         self.spec.remove_function(name)
 
-    def func(self, key, sync=False) -> mlrun.runtimes.BaseRuntime:
-        """get function object by name
-
-        :param sync:  will reload/reinit the function
-
-        :returns: function object
-        """
-        warnings.warn(
-            "This will be deprecated in future releases, use  get_function() instead",
-            # TODO: do changes in examples & demos In 0.9.0 remove
-            PendingDeprecationWarning,
-        )
-        return self.get_function(key, sync)
-
     def get_function(
         self,
         key,
         sync=False,
         enrich=False,
         ignore_cache=False,
         copy_function=True,
@@ -1702,15 +1604,18 @@
         elif key in self.spec._function_definitions and not ignore_cache:
             self.sync_functions([key])
             function = self.spec._function_objects[key]
         else:
             function = get_db_function(self, key)
             self.spec._function_objects[key] = function
         if enrich:
-            return enrich_function_object(self, function, copy_function=copy_function)
+            function = enrich_function_object(
+                self, function, copy_function=copy_function
+            )
+            self.spec._function_objects[key] = function
         return function
 
     def get_function_objects(self) -> typing.Dict[str, mlrun.runtimes.BaseRuntime]:
         """ "get a virtual dict with all the project functions ready for use in a pipeline"""
         self.sync_functions()
         return FunctionsDict(self)
 
@@ -1775,15 +1680,29 @@
         add.append("project.yaml")
         repo.index.add(add)
         if update:
             repo.git.add(update=True)
         if repo.is_dirty():
             if not message:
                 raise ValueError("please specify the commit message")
-            repo.git.commit(m=message)
+            try:
+                repo.git.commit(m=message)
+            except git.exc.GitCommandError as exc:
+                if "Please tell me who you are" in str(exc):
+                    warning_message = (
+                        "Git is not configured, please run the following commands and run git push from the terminal "
+                        "once to store your credentials:\n"
+                        '\tgit config --global user.email "<my@email.com>"\n'
+                        '\tgit config --global user.name "<name>"\n'
+                        "\tgit config --global credential.helper store\n"
+                    )
+                    raise mlrun.errors.MLRunPreconditionFailedError(
+                        warning_message
+                    ) from exc
+                raise exc
 
         if not branch:
             raise ValueError("please specify the remote branch")
         repo.git.push(remote or "origin", branch)
 
     def sync_functions(self, names: list = None, always=True, save=False):
         """reload function objects from specs and files"""
@@ -1900,42 +1819,14 @@
             if key != "MLRUN_DBPATH" and not key.startswith("V3IO_")
         }
         provider = provider or mlrun.api.schemas.SecretProviderName.kubernetes
         mlrun.db.get_run_db().create_project_secrets(
             self.metadata.name, provider=provider, secrets=env_vars
         )
 
-    def create_vault_secrets(self, secrets):
-        warnings.warn(
-            "This method is obsolete, use project.set_secrets() instead"
-            "This will be deprecated and removed in 1.0.0",
-            # TODO: In 1.0 remove
-            PendingDeprecationWarning,
-        )
-        run_db = mlrun.db.get_run_db(secrets=self._secrets)
-        run_db.create_project_secrets(
-            self.metadata.name, mlrun.api.schemas.SecretProviderName.vault, secrets
-        )
-
-    def get_vault_secrets(self, secrets=None, local=False):
-        if local:
-            logger.warning(
-                "get_vault_secrets executed locally. This is not recommended and may become deprecated soon"
-            )
-            return self._secrets.vault.get_secrets(secrets, project=self.metadata.name)
-
-        run_db = mlrun.db.get_run_db(secrets=self._secrets)
-        project_secrets = run_db.list_project_secrets(
-            self.metadata.name,
-            self._secrets.vault.token,
-            mlrun.api.schemas.SecretProviderName.vault,
-            secrets,
-        )
-        return project_secrets.secrets
-
     def get_param(self, key: str, default=None):
         """get project param by key"""
         if self.spec.params:
             return self.spec.params.get(key, default)
         return default
 
     def _enrich_artifact_path_with_workflow_uid(self):
@@ -1964,22 +1855,23 @@
         arguments: typing.Dict[str, typing.Any] = None,
         artifact_path: str = None,
         workflow_handler: typing.Union[str, typing.Callable] = None,
         namespace: str = None,
         sync: bool = False,
         watch: bool = False,
         dirty: bool = False,
+        # TODO: deprecated, remove in 1.5.0
         ttl: int = None,
         engine: str = None,
         local: bool = None,
         schedule: typing.Union[str, mlrun.api.schemas.ScheduleCronTrigger, bool] = None,
         timeout: int = None,
         overwrite: bool = False,
-        override: bool = False,
         source: str = None,
+        cleanup_ttl: int = None,
     ) -> _PipelineRunStatus:
         """run a workflow using kubeflow pipelines
 
         :param name:      name of the workflow
         :param workflow_path:
                           url to a workflow file, if not a project workflow
         :param arguments:
@@ -1989,32 +1881,52 @@
                           '{{workflow.uid}}' will be replaced by workflow id
         :param workflow_handler:
                           workflow function handler (for running workflow function directly)
         :param namespace: kubernetes namespace if other than default
         :param sync:      force functions sync before run
         :param watch:     wait for pipeline completion
         :param dirty:     allow running the workflow when the git repo is dirty
-        :param ttl:       pipeline ttl in secs (after that the pods will be removed)
+        :param ttl:       pipeline cleanup ttl in secs (time to wait after workflow completion, at which point the
+                          workflow and all its resources are deleted) (deprecated, use cleanup_ttl instead)
         :param engine:    workflow engine running the workflow.
                           supported values are 'kfp' (default), 'local' or 'remote'.
                           for setting engine for remote running use 'remote:local' or 'remote:kfp'.
         :param local:     run local pipeline with local functions (set local=True in function.run())
         :param schedule:  ScheduleCronTrigger class instance or a standard crontab expression string
                           (which will be converted to the class using its `from_crontab` constructor),
                           see this link for help:
                           https://apscheduler.readthedocs.io/en/3.x/modules/triggers/cron.html#module-apscheduler.triggers.cron
                           for using the pre-defined workflow's schedule, set `schedule=True`
         :param timeout:   timeout in seconds to wait for pipeline completion (watch will be activated)
-        :param overwrite: replacing the schedule of the same workflow (under the same name) if exists with the new one
-        :param override:  replacing the schedule of the same workflow (under the same name) if exists with the new one
+        :param overwrite: (deprecated) replacing the schedule of the same workflow (under the same name) if exists
+                          with the new one.
         :param source:    remote source to use instead of the actual `project.spec.source` (used when engine is remote).
                           for other engines the source is to validate that the code is up-to-date
+        :param cleanup_ttl:
+                          pipeline cleanup ttl in secs (time to wait after workflow completion, at which point the
+                          workflow and all its resources are deleted)
         :returns: run id
         """
 
+        if ttl:
+            warnings.warn(
+                "'ttl' is deprecated, use 'cleanup_ttl' instead. "
+                "This will be removed in 1.5.0",
+                # TODO: Remove this in 1.5.0
+                FutureWarning,
+            )
+
+        if overwrite:
+            warnings.warn(
+                "'overwrite' is deprecated, running a schedule is now an upsert operation. "
+                "This will be removed in 1.5.0",
+                # TODO: Remove this in 1.5.0
+                FutureWarning,
+            )
+
         arguments = arguments or {}
         need_repo = self.spec._need_repo()
         if self.spec.repo and self.spec.repo.is_dirty():
             msg = "you seem to have uncommitted git changes, use .push()"
             if dirty or not need_repo:
                 logger.warning("WARNING!, " + msg)
             else:
@@ -2036,35 +1948,27 @@
                 raise ValueError("workflow name or path must be specified")
 
         if workflow_path or (workflow_handler and callable(workflow_handler)):
             workflow_spec = WorkflowSpec(path=workflow_path, args=arguments)
         else:
             workflow_spec = self.spec._workflows[name].copy()
             workflow_spec.merge_args(arguments)
-            workflow_spec.ttl = ttl or workflow_spec.ttl
+            workflow_spec.cleanup_ttl = (
+                cleanup_ttl or ttl or workflow_spec.cleanup_ttl or workflow_spec.ttl
+            )
         workflow_spec.run_local = local
 
         name = f"{self.metadata.name}-{name}" if name else self.metadata.name
         artifact_path = artifact_path or self._enrich_artifact_path_with_workflow_uid()
 
-        if schedule:
-            if override or overwrite:
-                if overwrite:
-                    logger.warn(
-                        "Please use override (SDK) or --override-workflow (CLI) "
-                        "instead of overwrite (SDK) or --overwrite-schedule (CLI)"
-                        "This will be removed in 1.6.0",
-                        # TODO: Remove in 1.6.0
-                    )
-                workflow_spec.override = True
-            # Schedule = True -> use workflow_spec.schedule
-            if not isinstance(schedule, bool):
-                workflow_spec.schedule = schedule
-        else:
+        if not schedule:
             workflow_spec.schedule = None
+        elif not isinstance(schedule, bool):
+            # Schedule = True -> use workflow_spec.schedule
+            workflow_spec.schedule = schedule
 
         inner_engine = None
         if engine and engine.startswith("remote"):
             if ":" in engine:
                 engine, inner_engine = engine.split(":")
         elif workflow_spec.schedule:
             inner_engine = engine
@@ -2120,17 +2024,17 @@
         self,
         run,
         timeout=None,
         expected_statuses=None,
         notifiers: CustomNotificationPusher = None,
     ):
         warnings.warn(
-            "This will be deprecated in 1.4.0, and will be removed in 1.6.0. "
+            "This is deprecated in 1.3.0, and will be removed in 1.5.0. "
             "Use `timeout` parameter in `project.run()` method instead",
-            PendingDeprecationWarning,
+            FutureWarning,
         )
         return run._engine.get_run_status(
             project=self,
             run=run,
             timeout=timeout,
             expected_statuses=expected_statuses,
             notifiers=notifiers,
@@ -2198,23 +2102,38 @@
                 write_path = pathlib.Path(file_path)
                 zipf.write(write_path, arcname=write_path.relative_to(project_dir))
             zipf.close()
             if tmp_path:
                 mlrun.get_dataitem(filepath).upload(tmp_path)
                 remove(tmp_path)
 
-    def set_model_monitoring_credentials(self, access_key: str):
+    def set_model_monitoring_credentials(
+        self, access_key: str = None, endpoint_store_connection: str = None
+    ):
         """Set the credentials that will be used by the project's model monitoring
         infrastructure functions.
-        The supplied credentials must have data access
 
-        :param access_key: Model Monitoring access key for managing user permissions.
+        :param access_key:                Model Monitoring access key for managing user permissions
+        :param endpoint_store_connection: Endpoint store connection string
         """
-        set_project_model_monitoring_credentials(
-            access_key=access_key, project=self.metadata.name
+
+        secrets_dict = {}
+        if access_key:
+            secrets_dict[
+                model_monitoring_constants.ProjectSecretKeys.ACCESS_KEY
+            ] = access_key
+
+        if endpoint_store_connection:
+            secrets_dict[
+                model_monitoring_constants.ProjectSecretKeys.ENDPOINT_STORE_CONNECTION
+            ] = endpoint_store_connection
+
+        self.set_secrets(
+            secrets=secrets_dict,
+            provider=mlrun.api.schemas.SecretProviderName.kubernetes,
         )
 
     def run_function(
         self,
         function: typing.Union[str, mlrun.runtimes.BaseRuntime],
         handler: str = None,
         name: str = "",
@@ -2229,14 +2148,15 @@
         watch: bool = True,
         local: bool = None,
         verbose: bool = None,
         selector: str = None,
         auto_build: bool = None,
         schedule: typing.Union[str, mlrun.api.schemas.ScheduleCronTrigger] = None,
         artifact_path: str = None,
+        returns: Optional[List[Union[str, Dict[str, str]]]] = None,
     ) -> typing.Union[mlrun.model.RunObject, kfp.dsl.ContainerOp]:
         """Run a local or remote task as part of a local/kubeflow pipeline
 
         example (use with project)::
 
             # create a project with two functions (local and from marketplace)
             project = mlrun.new_project(project_name, "./proj")
@@ -2252,29 +2172,42 @@
         :param handler:         name of the function handler
         :param name:            execution name
         :param params:          input parameters (dict)
         :param hyperparams:     hyper parameters
         :param selector:        selection criteria for hyper params e.g. "max.accuracy"
         :param hyper_param_options:  hyper param options (selector, early stop, strategy, ..)
                                 see: :py:class:`~mlrun.model.HyperParamOptions`
-        :param inputs:          input objects (dict of key: path)
+        :param inputs:          Input objects to pass to the handler. Type hints can be given so the input will be
+                                parsed during runtime from `mlrun.DataItem` to the given type hint. The type hint can be
+                                given in the key field of the dictionary after a colon, e.g: "<key> : <type_hint>".
         :param outputs:         list of outputs which can pass in the workflow
         :param workdir:         default input artifacts path
         :param labels:          labels to tag the job/run with ({key:val, ..})
         :param base_task:       task object to use as base
         :param watch:           watch/follow run log, True by default
         :param local:           run the function locally vs on the runtime/cluster
         :param verbose:         add verbose prints/logs
         :param auto_build:      when set to True and the function require build it will be built on the first
                                 function run, use only if you dont plan on changing the build config between runs
         :param schedule:        ScheduleCronTrigger class instance or a standard crontab expression string
                                 (which will be converted to the class using its `from_crontab` constructor),
                                 see this link for help:
                                 https://apscheduler.readthedocs.io/en/3.x/modules/triggers/cron.html#module-apscheduler.triggers.cron
         :param artifact_path:   path to store artifacts, when running in a workflow this will be set automatically
+        :param returns:         List of log hints - configurations for how to log the returning values from the
+                                handler's run (as artifacts or results). The list's length must be equal to the amount
+                                of returning objects. A log hint may be given as:
+
+                                * A string of the key to use to log the returning value as result or as an artifact. To
+                                  specify The artifact type, it is possible to pass a string in the following structure:
+                                  "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no
+                                  artifact type is specified, the object's default artifact type will be used.
+                                * A dictionary of configurations to use when logging. Further info per object type and
+                                  artifact type can be given there. The artifact key must appear in the dictionary as
+                                  "key": "the_key".
 
         :return: MLRun RunObject or KubeFlow containerOp
         """
         return run_function(
             function,
             handler=handler,
             name=name,
@@ -2290,25 +2223,26 @@
             local=local,
             verbose=verbose,
             selector=selector,
             project_object=self,
             auto_build=auto_build,
             schedule=schedule,
             artifact_path=artifact_path,
+            returns=returns,
         )
 
     def build_function(
         self,
         function: typing.Union[str, mlrun.runtimes.BaseRuntime],
         with_mlrun: bool = None,
         skip_deployed: bool = False,
         image=None,
         base_image=None,
         commands: list = None,
-        secret_name="",
+        secret_name=None,
         requirements: typing.Union[str, typing.List[str]] = None,
         mlrun_version_specifier=None,
         builder_env: dict = None,
         overwrite_build_params: bool = False,
     ) -> typing.Union[BuildStatus, kfp.dsl.ContainerOp]:
         """deploy ML function, build container with its dependencies
 
@@ -2351,15 +2285,15 @@
         verbose: bool = None,
         builder_env: dict = None,
         mock: bool = None,
     ) -> typing.Union[DeployStatus, kfp.dsl.ContainerOp]:
         """deploy real-time (nuclio based) functions
 
         :param function:    name of the function (in the project) or function object
-        :param dashboard:   url of the remote Nuclio dashboard (when not local)
+        :param dashboard:   DEPRECATED. Keep empty to allow auto-detection by MLRun API.
         :param models:      list of model items
         :param env:         dict of extra environment variables
         :param tag:         extra version tag
         :param verbose:     add verbose prints/logs
         :param builder_env: env vars dict for source archive config/credentials e.g. `builder_env={"GIT_TOKEN": token}`
         :param mock:        deploy mock server vs a real Nuclio function (for local simulations)
         """
@@ -2387,15 +2321,15 @@
         artifact = db.read_artifact(key, tag, iter=iter, project=self.metadata.name)
         return dict_to_artifact(artifact)
 
     def list_artifacts(
         self,
         name=None,
         tag=None,
-        labels=None,
+        labels: Optional[Union[Dict[str, str], List[str]]] = None,
         since=None,
         until=None,
         iter: int = None,
         best_iteration: bool = False,
         kind: str = None,
         category: typing.Union[str, mlrun.api.schemas.ArtifactCategories] = None,
     ) -> mlrun.lists.ArtifactList:
@@ -2410,15 +2344,16 @@
             latest_artifacts = project.list_artifacts('', tag='latest')
             # check different artifact versions for a specific artifact, return as objects list
             result_versions = project.list_artifacts('results', tag='*').to_objects()
 
         :param name: Name of artifacts to retrieve. Name is used as a like query, and is not case-sensitive. This means
             that querying for ``name`` may return artifacts named ``my_Name_1`` or ``surname``.
         :param tag: Return artifacts assigned this tag.
-        :param labels: Return artifacts that have these labels.
+        :param labels: Return artifacts that have these labels. Labels can either be a dictionary {"label": "value"} or
+            a list of "label=value" (match label key and value) or "label" (match just label key) strings.
         :param since: Not in use in :py:class:`HTTPRunDB`.
         :param until: Not in use in :py:class:`HTTPRunDB`.
         :param iter: Return artifacts from a specific iteration (where ``iter=0`` means the root iteration). If
             ``None`` (default) return artifacts from all iterations.
         :param best_iteration: Returns the artifact which belongs to the best iteration of a given run, in the case of
             artifacts generated from a hyper-param run. If only a single iteration exists, will return the artifact
             from that iteration. If using ``best_iter``, the ``iter`` parameter must not be used.
@@ -2439,31 +2374,33 @@
             category=category,
         )
 
     def list_models(
         self,
         name=None,
         tag=None,
-        labels=None,
+        labels: Optional[Union[Dict[str, str], List[str]]] = None,
         since=None,
         until=None,
         iter: int = None,
         best_iteration: bool = False,
     ):
         """List models in project, filtered by various parameters.
 
         Examples::
 
             # Get latest version of all models in project
             latest_models = project.list_models('', tag='latest')
 
+
         :param name: Name of artifacts to retrieve. Name is used as a like query, and is not case-sensitive. This means
             that querying for ``name`` may return artifacts named ``my_Name_1`` or ``surname``.
         :param tag: Return artifacts assigned this tag.
-        :param labels: Return artifacts that have these labels.
+        :param labels: Return artifacts that have these labels. Labels can either be a dictionary {"label": "value"} or
+            a list of "label=value" (match label key and value) or "label" (match just label key) strings.
         :param since: Not in use in :py:class:`HTTPRunDB`.
         :param until: Not in use in :py:class:`HTTPRunDB`.
         :param iter: Return artifacts from a specific iteration (where ``iter=0`` means the root iteration). If
             ``None`` (default) return artifacts from all iterations.
         :param best_iteration: Returns the artifact which belongs to the best iteration of a given run, in the case of
             artifacts generated from a hyper-param run. If only a single iteration exists, will return the artifact
             from that iteration. If using ``best_iter``, the ``iter`` parameter must not be used.
@@ -2565,273 +2502,14 @@
 
 
 def _set_as_current_default_project(project: MlrunProject):
     mlrun.mlconf.default_project = project.metadata.name
     pipeline_context.set(project)
 
 
-class MlrunProjectLegacy(ModelObj):
-    kind = "project"
-
-    def __init__(
-        self,
-        name=None,
-        description=None,
-        params=None,
-        functions=None,
-        workflows=None,
-        artifacts=None,
-        artifact_path=None,
-        conda=None,
-    ):
-
-        self._initialized = False
-        self.name = name
-        self.description = description
-        self.tag = ""
-        self.origin_url = ""
-        self._source = ""
-        self.context = None
-        self.subpath = ""
-        self.branch = None
-        self.repo = None
-        self._secrets = SecretsStore()
-        self.params = params or {}
-        self.conda = conda or {}
-        self._mountdir = None
-        self._artifact_mngr = None
-        self.artifact_path = artifact_path
-
-        self.workflows = workflows or []
-        self.artifacts = artifacts or []
-
-        self._function_objects = {}
-        self._function_defs = {}
-        self.functions = functions or []
-
-    @property
-    def source(self) -> str:
-        """source url or git repo"""
-        if not self._source:
-            if self.repo:
-                url = get_repo_url(self.repo)
-                if url:
-                    self._source = url
-
-        return self._source
-
-    @source.setter
-    def source(self, src):
-        self._source = src
-
-    def _source_repo(self):
-        src = self.source
-        if src:
-            return src.split("#")[0]
-        return ""
-
-    def _get_hexsha(self):
-        try:
-            if self.repo:
-                return self.repo.head.commit.hexsha
-        except Exception:
-            pass
-        return None
-
-    @property
-    def mountdir(self) -> str:
-        """specify to mount the context dir inside the function container
-        use '.' to use the same path as in the client e.g. Jupyter"""
-
-        if self._mountdir and self._mountdir in [".", "./"]:
-            return path.abspath(self.context)
-        return self._mountdir
-
-    @mountdir.setter
-    def mountdir(self, mountdir):
-        self._mountdir = mountdir
-
-    @property
-    def functions(self) -> list:
-        """list of function object/specs used in this project"""
-        funcs = []
-        for name, f in self._function_defs.items():
-            if hasattr(f, "to_dict"):
-                spec = f.to_dict(strip=True)
-                if f.spec.build.source and f.spec.build.source.startswith(
-                    self._source_repo()
-                ):
-                    update_in(spec, "spec.build.source", "./")
-                funcs.append({"name": name, "spec": spec})
-            else:
-                funcs.append(f)
-        return funcs
-
-    @functions.setter
-    def functions(self, funcs):
-        if not isinstance(funcs, list):
-            raise ValueError("functions must be a list")
-
-        func_defs = {}
-        for f in funcs:
-            if not isinstance(f, dict) and not hasattr(f, "to_dict"):
-                raise ValueError("functions must be an objects or dict")
-            if isinstance(f, dict):
-                name = f.get("name", "")
-                if not name:
-                    raise ValueError("function name must be specified in dict")
-            else:
-                name = f.metadata.name
-            func_defs[name] = f
-
-        self._function_defs = func_defs
-
-    @property
-    def workflows(self) -> list:
-        """list of workflows specs used in this project"""
-        return [w for w in self._workflows.values()]
-
-    @workflows.setter
-    def workflows(self, workflows):
-        if not isinstance(workflows, list):
-            raise ValueError("workflows must be a list")
-
-        wfdict = {}
-        for w in workflows:
-            if not isinstance(w, dict):
-                raise ValueError("workflow must be a dict")
-            name = w.get("name", "")
-            # todo: support steps dsl as code alternative
-            if not name:
-                raise ValueError('workflow "name" must be specified')
-            if "path" not in w and "code" not in w:
-                raise ValueError('workflow source "path" or "code" must be specified')
-            wfdict[name] = w
-
-        self._workflows = wfdict
-
-    @property
-    def artifacts(self) -> list:
-        """list of artifacts used in this project"""
-        return [a for a in self._artifacts.values()]
-
-    @artifacts.setter
-    def artifacts(self, artifacts):
-        if not isinstance(artifacts, list):
-            raise ValueError("artifacts must be a list")
-
-        afdict = {}
-        for a in artifacts:
-            if not isinstance(a, dict) and not hasattr(a, "to_dict"):
-                raise ValueError("artifacts must be a dict or class")
-            if isinstance(a, dict):
-                key = a.get("key", "")
-                if not key:
-                    raise ValueError('artifacts "key" must be specified')
-            else:
-                key = a.key
-                a = a.to_dict()
-
-            afdict[key] = a
-
-        self._artifacts = afdict
-
-    # needed for tests
-    def set_workflow(self, name, workflow_path: str, embed=False, **args):
-        """add or update a workflow, specify a name and the code path"""
-        if not workflow_path:
-            raise ValueError("valid workflow_path must be specified")
-        if embed:
-            if self.context and not workflow_path.startswith("/"):
-                workflow_path = path.join(self.context, workflow_path)
-            with open(workflow_path, "r") as fp:
-                txt = fp.read()
-            workflow = {"name": name, "code": txt}
-        else:
-            workflow = {"name": name, "path": workflow_path}
-        if args:
-            workflow["args"] = args
-        self._workflows[name] = workflow
-
-    # needed for tests
-    def set_function(
-        self,
-        func: typing.Union[str, mlrun.runtimes.BaseRuntime],
-        name: str = "",
-        kind: str = "",
-        image: str = None,
-        with_repo: bool = None,
-    ):
-        """update or add a function object to the project
-
-        function can be provided as an object (func) or a .py/.ipynb/.yaml url
-
-        supported url prefixes::
-
-            object (s3://, v3io://, ..)
-            MLRun DB e.g. db://project/func:ver
-            functions hub/market: e.g. hub://auto_trainer:master
-
-        examples::
-
-            proj.set_function(func_object)
-            proj.set_function('./src/mycode.py', 'ingest',
-                              image='myrepo/ing:latest', with_repo=True)
-            proj.set_function('http://.../mynb.ipynb', 'train')
-            proj.set_function('./func.yaml')
-            proj.set_function('hub://get_toy_data', 'getdata')
-
-        :param func:      function object or spec/code url
-        :param name:      name of the function (under the project)
-        :param kind:      runtime kind e.g. job, nuclio, spark, dask, mpijob
-                          default: job
-        :param image:     docker image to be used, can also be specified in
-                          the function object/yaml
-        :param with_repo: add (clone) the current repo to the build source
-
-        :returns: project object
-        """
-        if isinstance(func, str):
-            if not name:
-                raise ValueError("function name must be specified")
-            fdict = {
-                "url": func,
-                "name": name,
-                "kind": kind,
-                "image": image,
-                "with_repo": with_repo,
-            }
-            func = {k: v for k, v in fdict.items() if v}
-            name, f = _init_function_from_dict_legacy(func, self)
-        elif hasattr(func, "to_dict"):
-            name, f = _init_function_from_obj_legacy(func, self, name=name)
-            if image:
-                f.spec.image = image
-            if with_repo:
-                f.spec.build.source = "./"
-
-            if not name:
-                raise ValueError("function name must be specified")
-        else:
-            raise ValueError("func must be a function url or object")
-
-        self._function_defs[name] = func
-        self._function_objects[name] = f
-        return f
-
-    # needed for tests
-    def save(self, filepath=None):
-        """save the project object into a file (default to project.yaml)"""
-        filepath = filepath or path.join(
-            self.context, self.subpath or "", "project.yaml"
-        )
-        with open(filepath, "w") as fp:
-            fp.write(self.to_yaml())
-
-
 def _init_function_from_dict(f, project, name=None):
     name = name or f.get("name", "")
     url = f.get("url", "")
     kind = f.get("kind", "")
     image = f.get("image", None)
     handler = f.get("handler", None)
     with_repo = f.get("with_repo", False)
@@ -2863,15 +2541,15 @@
             func.spec.image = image
     elif url.endswith(".ipynb"):
         # not defaulting kind to job here cause kind might come from magic annotations in the notebook
         func = code_to_function(
             name, filename=url, image=image, kind=kind, handler=handler, tag=tag
         )
     elif url.endswith(".py"):
-        if not image and kind != "local":
+        if not image and not project.default_image and kind != "local":
             raise ValueError(
                 "image must be provided with py code files which do not "
                 "run on 'local' engine kind"
             )
         if in_context and with_repo:
             func = new_function(
                 name,
@@ -2914,80 +2592,14 @@
     if project.metadata.name:
         func.metadata.project = project.metadata.name
     if project.spec.tag:
         func.metadata.tag = project.spec.tag
     return name or func.metadata.name, func
 
 
-def _init_function_from_dict_legacy(f, project):
-    name = f.get("name", "")
-    url = f.get("url", "")
-    kind = f.get("kind", "")
-    image = f.get("image", None)
-    with_repo = f.get("with_repo", False)
-
-    if with_repo and not project.source:
-        raise ValueError("project source must be specified when cloning context")
-
-    in_context = False
-    if not url and "spec" not in f:
-        raise ValueError("function missing a url or a spec")
-    # We are not using the project method to obtain an absolute path here,
-    # because legacy projects are built differently, and we cannot rely on them to have a spec
-    if url and "://" not in url:
-        if project.context and not url.startswith("/"):
-            url = path.join(project.context, url)
-            in_context = True
-        if not path.isfile(url):
-            raise OSError(f"{url} not found")
-
-    if "spec" in f:
-        func = new_function(name, runtime=f["spec"])
-    elif is_yaml_path(url) or url.startswith("db://") or url.startswith("hub://"):
-        func = import_function(url)
-        if image:
-            func.spec.image = image
-    elif url.endswith(".ipynb"):
-        func = code_to_function(name, filename=url, image=image, kind=kind)
-    elif url.endswith(".py"):
-        if not image:
-            raise ValueError(
-                "image must be provided with py code files, "
-                "use function object for more control/settings"
-            )
-        if in_context and with_repo:
-            func = new_function(name, command=url, image=image, kind=kind or "job")
-        else:
-            func = code_to_function(name, filename=url, image=image, kind=kind or "job")
-    else:
-        raise ValueError(f"unsupported function url {url} or no spec")
-
-    if with_repo:
-        func.spec.build.source = "./"
-
-    return _init_function_from_obj_legacy(func, project, name)
-
-
-def _init_function_from_obj_legacy(func, project, name=None):
-    build = func.spec.build
-    if project.origin_url:
-        origin = project.origin_url
-        try:
-            if project.repo:
-                origin += "#" + project.repo.head.commit.hexsha
-        except Exception:
-            pass
-        build.code_origin = origin
-    if project.name:
-        func.metadata.project = project.name
-    if project.tag:
-        func.metadata.tag = project.tag
-    return name or func.metadata.name, func
-
-
 def _has_module(handler, kind):
     if not handler:
         return False
     return (kind in RuntimeKinds.nuclio_runtimes() and ":" in handler) or "." in handler
 
 
 def _is_imported_artifact(artifact):
```

## mlrun/runtimes/__init__.py

```diff
@@ -22,20 +22,21 @@
     "RemoteRuntime",
     "ServingRuntime",
     "DaskCluster",
     "RemoteSparkRuntime",
 ]
 
 
+from mlrun.runtimes.package.context_handler import ArtifactType, ContextHandler
 from mlrun.runtimes.utils import (
     resolve_mpijob_crd_version,
     resolve_spark_operator_version,
 )
 
-from .base import BaseRuntime, BaseRuntimeHandler, RunError  # noqa
+from .base import BaseRuntime, BaseRuntimeHandler, RunError, RuntimeClassMode  # noqa
 from .constants import MPIJobCRDVersions
 from .daskjob import DaskCluster, DaskRuntimeHandler, get_dask_resource  # noqa
 from .function import RemoteRuntime
 from .kubejob import KubejobRuntime, KubeRuntimeHandler  # noqa
 from .local import HandlerRuntime, LocalRuntime  # noqa
 from .mpijob import (  # noqa
     MpiRuntimeV1,
@@ -148,20 +149,76 @@
     def local_runtimes():
         return [
             RuntimeKinds.local,
             RuntimeKinds.handler,
         ]
 
     @staticmethod
+    def is_log_collectable_runtime(kind: str):
+        """
+        whether log collector can collect logs for that runtime
+        :param kind: kind name
+        :return: whether log collector can collect logs for that runtime
+        """
+        # if local run, the log collector doesn't support it as it is only supports k8s resources
+        # when runtime is local the client is responsible for logging the stdout of the run by using `log_std`
+        if RuntimeKinds.is_local_runtime(kind):
+            return False
+
+        if kind not in [
+            # dask implementation is different than other runtimes, because few runs can be run against the same runtime
+            # resource, so collecting logs on that runtime resource won't be correct, the way we collect logs for dask
+            # is by using `log_std` on client side after we execute the code against the cluster, as submitting the
+            # run with the dask client will return the run stdout. for more information head to `DaskCluster._run`
+            RuntimeKinds.dask
+        ]:
+            return True
+
+        return False
+
+    @staticmethod
     def is_local_runtime(kind):
         # "" or None counted as local
         if not kind or kind in RuntimeKinds.local_runtimes():
             return True
         return False
 
+    @staticmethod
+    def is_watchable(kind):
+        """
+        Returns True if the runtime kind is watchable, False otherwise.
+        Runtimes that are not watchable are blocking, meaning that the run() method will not return until the runtime
+        is completed.
+        """
+        # "" or None counted as local
+        if not kind:
+            return False
+        return kind not in [
+            RuntimeKinds.local,
+            RuntimeKinds.handler,
+            RuntimeKinds.dask,
+        ]
+
+    @staticmethod
+    def requires_absolute_artifacts_path(kind):
+        """
+        Returns True if the runtime kind requires absolute artifacts' path (e.i. is local), False otherwise.
+        """
+        if RuntimeKinds.is_local_runtime(kind):
+            return False
+
+        if kind not in [
+            # logging artifacts is done externally to the dask cluster by a client that can either run locally (in which
+            # case the path can be relative) or remotely (in which case the path must be absolute and will be passed
+            # to another run)
+            RuntimeKinds.dask
+        ]:
+            return True
+        return False
+
 
 runtime_resources_map = {RuntimeKinds.dask: get_dask_resource()}
 
 runtime_handler_instances_cache = {}
 
 
 def get_runtime_handler(kind: str) -> BaseRuntimeHandler:
```

## mlrun/runtimes/base.py

```diff
@@ -7,18 +7,19 @@
 #   http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
+import enum
 import getpass
 import http
-import os
+import os.path
+import shlex
 import traceback
 import typing
 import uuid
 from abc import ABC, abstractmethod
 from ast import literal_eval
 from base64 import b64encode
 from copy import deepcopy
@@ -62,14 +63,15 @@
     dict_to_yaml,
     enrich_image_url,
     get_in,
     get_parsed_docker_registry,
     get_ui_url,
     is_ipython,
     logger,
+    normalize_name,
     now_date,
     update_in,
 )
 from .constants import PodPhases, RunStates
 from .funcdoc import update_function_entry_points
 from .generators import get_generator
 from .utils import RunError, calc_hash, results_to_iter
@@ -84,17 +86,33 @@
     "entry_points",
     "description",
     "workdir",
     "default_handler",
     "pythonpath",
     "disable_auto_mount",
     "allow_empty_resources",
+    "clone_target_dir",
 ]
 
 
+class RuntimeClassMode(enum.Enum):
+    """
+    Runtime class mode
+    Currently there are two modes:
+    1. run - the runtime class is used to run a function
+    2. build - the runtime class is used to build a function
+
+    The runtime class mode is used to determine what should be the name of the runtime class, each runtime might have a
+    different name for each mode and some might not have both modes.
+    """
+
+    run = "run"
+    build = "build"
+
+
 class FunctionStatus(ModelObj):
     def __init__(self, state=None, build_pod=None):
         self.state = state
         self.build_pod = build_pod
 
 
 class FunctionSpec(ModelObj):
@@ -109,14 +127,15 @@
         build=None,
         entry_points=None,
         description=None,
         workdir=None,
         default_handler=None,
         pythonpath=None,
         disable_auto_mount=False,
+        clone_target_dir=None,
     ):
 
         self.command = command or ""
         self.image = image or ""
         self.mode = mode
         self.args = args or []
         self.rundb = None
@@ -127,14 +146,17 @@
         self._build = None
         self.build = build
         self.default_handler = default_handler
         # TODO: type verification (FunctionEntrypoint dict)
         self.entry_points = entry_points or {}
         self.disable_auto_mount = disable_auto_mount
         self.allow_empty_resources = None
+        # the build.source is cloned/extracted to the specified clone_target_dir
+        # if a relative path is specified, it will be enriched with a temp dir path
+        self.clone_target_dir = clone_target_dir or ""
 
     @property
     def build(self) -> ImageBuilder:
         return self._build
 
     @build.setter
     def build(self, build):
@@ -164,19 +186,20 @@
         self._k8s = None
         self._is_built = False
         self.is_child = False
         self._status = None
         self.status = None
         self._is_api_server = False
         self.verbose = False
+        self._enriched_image = False
 
-    def set_db_connection(self, conn, is_api=False):
+    def set_db_connection(self, conn):
         if not self._db_conn:
             self._db_conn = conn
-        self._is_api_server = is_api
+        self._is_api_server = mlrun.config.is_running_as_api()
 
     @property
     def metadata(self) -> BaseMetadata:
         return self._metadata
 
     @metadata.setter
     def metadata(self, metadata):
@@ -226,15 +249,15 @@
             and self._get_db().kind == "http"
         ):
             return True
         return False
 
     def _enrich_on_client_side(self):
         self.try_auto_mount_based_on_config()
-        self.fill_credentials()
+        self._fill_credentials()
 
     def _enrich_on_server_side(self):
         pass
 
     def _enrich_on_server_and_client_sides(self):
         """
         enrich function also in client side and also on server side
@@ -263,34 +286,47 @@
         self.spec.rundb = self.spec.rundb or get_or_set_dburl()
 
     def _get_db(self):
         self._ensure_run_db()
         if not self._db_conn:
             if self.spec.rundb:
                 self._db_conn = get_run_db(self.spec.rundb, secrets=self._secrets)
+                self._is_api_server = mlrun.config.is_running_as_api()
         return self._db_conn
 
     # This function is different than the auto_mount function, as it mounts to runtimes based on the configuration.
     # That's why it's named differently.
     def try_auto_mount_based_on_config(self):
         pass
 
     def validate_and_enrich_service_account(
         self, allowed_service_account, default_service_account
     ):
         pass
 
-    def fill_credentials(self):
-        auth_session_env_var = (
-            mlrun.runtimes.constants.FunctionEnvironmentVariables.auth_session
-        )
-        if auth_session_env_var in os.environ or "V3IO_ACCESS_KEY" in os.environ:
-            self.metadata.credentials.access_key = os.environ.get(
-                auth_session_env_var
-            ) or os.environ.get("V3IO_ACCESS_KEY")
+    def _fill_credentials(self):
+        """
+        If access key is not mask (starts with secret prefix) then fill $generate so that the API will handle filling
+         of the credentials.
+        We rely on the HTTPDB to send the access key session through the request header and that the API will mask
+         the access key, that way we won't even store any plain access key in the function.
+        """
+        if self.metadata.credentials.access_key and (
+            # if contains secret reference or $generate then no need to overwrite the access key
+            self.metadata.credentials.access_key.startswith(
+                mlrun.model.Credentials.secret_reference_prefix
+            )
+            or self.metadata.credentials.access_key.startswith(
+                mlrun.model.Credentials.generate_access_key
+            )
+        ):
+            return
+        self.metadata.credentials.access_key = (
+            mlrun.model.Credentials.generate_access_key
+        )
 
     def run(
         self,
         runspec: RunObject = None,
         handler=None,
         name: str = "",
         project: str = "",
@@ -305,23 +341,27 @@
         hyper_param_options: HyperParamOptions = None,
         verbose=None,
         scrape_metrics: bool = None,
         local=False,
         local_code_path=None,
         auto_build=None,
         param_file_secrets: Dict[str, str] = None,
+        returns: Optional[List[Union[str, Dict[str, str]]]] = None,
     ) -> RunObject:
-        """Run a local or remote task.
+        """
+        Run a local or remote task.
 
         :param runspec:        run template object or dict (see RunTemplate)
         :param handler:        pointer or name of a function handler
         :param name:           execution name
         :param project:        project name
         :param params:         input parameters (dict)
-        :param inputs:         input objects (dict of key: path)
+        :param inputs:         Input objects to pass to the handler. Type hints can be given so the input will be parsed
+                               during runtime from `mlrun.DataItem` to the given type hint. The type hint can be given
+                               in the key field of the dictionary after a colon, e.g: "<key> : <type_hint>".
         :param out_path:       default artifact output path
         :param artifact_path:  default artifact output path (will replace out_path)
         :param workdir:        default input artifacts path
         :param watch:          watch/follow run log
         :param schedule:       ScheduleCronTrigger class instance or a standard crontab expression string
                                (which will be converted to the class using its `from_crontab` constructor),
                                see this link for help:
@@ -335,66 +375,73 @@
         :param scrape_metrics: whether to add the `mlrun/scrape-metrics` label to this run's resources
         :param local:      run the function locally vs on the runtime/cluster
         :param local_code_path: path of the code for local runs & debug
         :param auto_build: when set to True and the function require build it will be built on the first
                            function run, use only if you dont plan on changing the build config between runs
         :param param_file_secrets: dictionary of secrets to be used only for accessing the hyper-param parameter file.
                             These secrets are only used locally and will not be stored anywhere
+        :param returns: List of log hints - configurations for how to log the returning values from the handler's run
+                        (as artifacts or results). The list's length must be equal to the amount of returning objects. A
+                        log hint may be given as:
+
+                        * A string of the key to use to log the returning value as result or as an artifact. To specify
+                          The artifact type, it is possible to pass a string in the following structure:
+                          "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no
+                          artifact type is specified, the object's default artifact type will be used.
+                        * A dictionary of configurations to use when logging. Further info per object type and artifact
+                          type can be given there. The artifact key must appear in the dictionary as "key": "the_key".
+
         :return: run context object (RunObject) with run metadata, results and status
         """
         mlrun.utils.helpers.verify_dict_items_type("Inputs", inputs, [str], [str])
 
         if self.spec.mode and self.spec.mode not in run_modes:
             raise ValueError(f'run mode can only be {",".join(run_modes)}')
 
         self._enrich_function()
 
         run = self._create_run_object(runspec)
 
         if local:
+
+            # do not allow local function to be scheduled
+            if schedule is not None:
+                raise mlrun.errors.MLRunInvalidArgumentError(
+                    "local and schedule cannot be used together"
+                )
             return self._run_local(
                 run,
-                schedule,
                 local_code_path,
                 project,
                 name,
                 workdir,
                 handler,
                 params,
                 inputs,
+                returns,
                 artifact_path,
             )
 
         run = self._enrich_run(
             run,
             handler,
             project,
             name,
             params,
             inputs,
+            returns,
             hyperparams,
             hyper_param_options,
             verbose,
             scrape_metrics,
             out_path,
             artifact_path,
             workdir,
         )
-
-        if is_local(run.spec.output_path):
-            logger.warning(
-                "artifact path is not defined or is local,"
-                " artifacts will not be visible in the UI"
-            )
-            if self.kind not in ["", "local", "handler", "dask"]:
-                raise ValueError(
-                    "absolute artifact_path must be specified"
-                    " when running remote tasks"
-                )
-
+        self._validate_output_path(run)
         db = self._get_db()
 
         if not self.is_deployed():
             if self.spec.build.auto_build or auto_build:
                 logger.info(
                     "Function is not deployed and auto_build flag is set, starting deploy..."
                 )
@@ -407,14 +454,21 @@
         if self.verbose:
             logger.info(f"runspec:\n{run.to_yaml()}")
 
         if "V3IO_USERNAME" in environ and "v3io_user" not in run.metadata.labels:
             run.metadata.labels["v3io_user"] = environ.get("V3IO_USERNAME")
 
         if not self.is_child:
+            db_str = "self" if self._is_api_server else self.spec.rundb
+            logger.info(
+                "Storing function",
+                name=run.metadata.name,
+                uid=run.metadata.uid,
+                db=db_str,
+            )
             self._store_function(run, run.metadata, db)
 
         # execute the job remotely (to a k8s cluster via the API service)
         if self._use_remote_api():
             return self._submit_job(run, schedule, db, watch)
 
         elif self._is_remote and not self._is_api_server and not self.kfp:
@@ -423,31 +477,31 @@
             )
 
         execution = MLClientCtx.from_dict(
             run.to_dict(),
             db,
             autocommit=False,
             is_api=self._is_api_server,
-            update_db=False,
+            store_run=False,
         )
 
         self._verify_run_params(run.spec.parameters)
 
         # create task generator (for child runs) from spec
         task_generator = get_generator(
             run.spec, execution, param_file_secrets=param_file_secrets
         )
         if task_generator:
             # verify valid task parameters
             tasks = task_generator.generate(run)
             for task in tasks:
                 self._verify_run_params(task.spec.parameters)
 
-        # post verifications, update execution in db and run pre run hooks
-        execution.commit(completed=False)
+        # post verifications, store execution in db and run pre run hooks
+        execution.store_run()
         self._pre_run(run, execution)  # hook for runtime specific prep
 
         last_err = None
         # If the runtime is nested, it means the hyper-run will run within a single instance of the run.
         # So while in the API, we consider the hyper-run as a single run, and then in the runtime itself when the
         # runtime is now a local runtime and therefore `self._is_nested == False`, we run each task as a separate run by
         # using the task generator
@@ -455,22 +509,28 @@
             # multiple runs (based on hyper params or params file)
             runner = self._run_many
             if hasattr(self, "_parallel_run_many") and task_generator.use_parallel():
                 runner = self._parallel_run_many
             results = runner(task_generator, execution, run)
             results_to_iter(results, run, execution)
             result = execution.to_dict()
+            result = self._update_run_state(result, task=run)
 
         else:
             # single run
             try:
                 resp = self._run(run, execution)
-                if watch and self.kind not in ["", "handler", "local"]:
-                    state = run.logs(True, self._get_db())
-                    if state != "succeeded":
+                if (
+                    watch
+                    and mlrun.runtimes.RuntimeKinds.is_watchable(self.kind)
+                    # API shouldn't watch logs, its the client job to query the run logs
+                    and not mlrun.config.is_running_as_api()
+                ):
+                    state, _ = run.logs(True, self._get_db())
+                    if state not in ["succeeded", "completed"]:
                         logger.warning(f"run ended with state {state}")
                 result = self._update_run_state(resp, task=run)
             except RunError as err:
                 last_err = err
                 result = self._update_run_state(task=run, err=err)
 
         self._post_run(result, execution)  # hook for runtime specific cleanup
@@ -516,15 +576,17 @@
                 "To track results use the CLI", info_cmd=info_cmd, logs_cmd=logs_cmd
             )
             ui_url = get_ui_url(project, uid)
             if ui_url:
                 logger.info("Or click for UI", ui_url=ui_url)
         if result:
             run = RunObject.from_dict(result)
-            logger.info(f"run executed, status={run.status.state}")
+            logger.info(
+                f"run executed, status={run.status.state}", name=run.metadata.name
+            )
             if run.status.state == "error":
                 if self._is_remote and not self.is_child:
                     logger.error(f"runtime error: {run.status.error}")
                 raise RunError(run.status.error)
             return run
 
         return None
@@ -555,28 +617,24 @@
         if self.metadata.namespace or config.namespace:
             runtime_env["MLRUN_NAMESPACE"] = self.metadata.namespace or config.namespace
         return runtime_env
 
     def _run_local(
         self,
         runspec,
-        schedule,
         local_code_path,
         project,
         name,
         workdir,
         handler,
         params,
         inputs,
+        returns,
         artifact_path,
     ):
-        if schedule is not None:
-            raise mlrun.errors.MLRunInvalidArgumentError(
-                "local and schedule cannot be used together"
-            )
         # allow local run simulation with a flip of a flag
         command = self
         if local_code_path:
             project = project or self.metadata.project
             name = name or self.metadata.name
             command = local_code_path
         return mlrun.run_local(
@@ -588,17 +646,21 @@
             project=project,
             handler=handler,
             params=params,
             inputs=inputs,
             artifact_path=artifact_path,
             mode=self.spec.mode,
             allow_empty_resources=self.spec.allow_empty_resources,
+            returns=returns,
         )
 
     def _create_run_object(self, runspec):
+        # TODO: Once implemented the `Runtime` handlers configurations (doc strings, params type hints and returning
+        #       log hints, possible parameter values, etc), the configured type hints and log hints should be set into
+        #       the `RunObject` from the `Runtime`.
         if runspec:
             runspec = deepcopy(runspec)
             if isinstance(runspec, str):
                 runspec = literal_eval(runspec)
             if not isinstance(runspec, (dict, RunTemplate, RunObject)):
                 raise ValueError(
                     "task/runspec is not a valid task object," f" type={type(runspec)}"
@@ -614,14 +676,15 @@
         self,
         runspec,
         handler,
         project_name,
         name,
         params,
         inputs,
+        returns,
         hyperparams,
         hyper_param_options,
         verbose,
         scrape_metrics,
         out_path,
         artifact_path,
         workdir,
@@ -636,26 +699,36 @@
         if runspec.spec.handler_name:
             short_name = runspec.spec.handler_name
             for separator in ["#", "::", "."]:
                 # drop paths, module or class name from short name
                 if separator in short_name:
                     short_name = short_name.split(separator)[-1]
             def_name += "-" + short_name
-        runspec.metadata.name = name or runspec.metadata.name or def_name
+
+        runspec.metadata.name = normalize_name(
+            name=name or runspec.metadata.name or def_name,
+            # if name or runspec.metadata.name are set then it means that is user defined name and we want to warn the
+            # user that the passed name needs to be set without underscore, if its not user defined but rather enriched
+            # from the handler(function) name then we replace the underscore without warning the user.
+            # most of the time handlers will have `_` in the handler name (python convention is to separate function
+            # words with `_`), therefore we don't want to be noisy when normalizing the run name
+            verbose=bool(name or runspec.metadata.name),
+        )
         verify_field_regex(
             "run.metadata.name", runspec.metadata.name, mlrun.utils.regex.run_name
         )
         runspec.metadata.project = (
             project_name
             or runspec.metadata.project
             or self.metadata.project
             or config.default_project
         )
         runspec.spec.parameters = params or runspec.spec.parameters
         runspec.spec.inputs = inputs or runspec.spec.inputs
+        runspec.spec.returns = returns or runspec.spec.returns
         runspec.spec.hyperparams = hyperparams or runspec.spec.hyperparams
         runspec.spec.hyper_param_options = (
             hyper_param_options or runspec.spec.hyper_param_options
         )
         runspec.spec.verbose = verbose or runspec.spec.verbose
         if scrape_metrics is None:
             if runspec.spec.scrape_metrics is None:
@@ -714,35 +787,36 @@
                 "{{run.uid}}", meta.uid
             )
             runspec.spec.output_path = mlrun.utils.helpers.fill_artifact_path_template(
                 runspec.spec.output_path, runspec.metadata.project
             )
         return runspec
 
-    def _submit_job(self, runspec, schedule, db, watch):
+    def _submit_job(self, run: RunObject, schedule, db, watch):
         if self._secrets:
-            runspec.spec.secret_sources = self._secrets.to_serial()
+            run.spec.secret_sources = self._secrets.to_serial()
         try:
-            resp = db.submit_job(runspec, schedule=schedule)
+            resp = db.submit_job(run, schedule=schedule)
             if schedule:
-                logger.info(f"task scheduled, {resp}")
+                action = resp.pop("action", "created")
+                logger.info(f"task schedule {action}", **resp)
                 return
 
         except (requests.HTTPError, Exception) as err:
             logger.error(f"got remote run err, {err_to_str(err)}")
 
             if isinstance(err, requests.HTTPError):
                 self._handle_submit_job_http_error(err)
 
             result = None
             # if we got a schedule no reason to do post_run stuff (it purposed to update the run status with error,
             # but there's no run in case of schedule)
             if not schedule:
-                result = self._update_run_state(task=runspec, err=err_to_str(err))
-            return self._wrap_run_result(result, runspec, schedule=schedule, err=err)
+                result = self._update_run_state(task=run, err=err_to_str(err))
+            return self._wrap_run_result(result, run, schedule=schedule, err=err)
 
         if resp:
             txt = get_in(resp, "status.status_text")
             if txt:
                 logger.info(txt)
         # watch is None only in scenario where we run from pipeline step, in this case we don't want to watch the run
         # logs too frequently but rather just pull the state of the run from the DB and pull the logs every x seconds
@@ -757,41 +831,39 @@
             state_interval = int(
                 config.httpdb.logs.pipelines.pull_state.pull_state_interval
             )
             logs_interval = int(
                 config.httpdb.logs.pipelines.pull_state.pull_logs_interval
             )
 
-            runspec.wait_for_completion(
+            run.wait_for_completion(
                 show_logs=True,
                 sleep=state_interval,
                 logs_interval=logs_interval,
                 raise_on_failure=False,
             )
-            resp = self._get_db_run(runspec)
+            resp = self._get_db_run(run)
 
         elif watch or self.kfp:
-            runspec.logs(True, self._get_db())
-            resp = self._get_db_run(runspec)
+            run.logs(True, self._get_db())
+            resp = self._get_db_run(run)
 
-        return self._wrap_run_result(resp, runspec, schedule=schedule)
+        return self._wrap_run_result(resp, run, schedule=schedule)
 
     @staticmethod
     def _handle_submit_job_http_error(error: requests.HTTPError):
         # if we receive a 400 status code, this means the request was invalid and the run wasn't created in the DB.
         # so we don't need to update the run state and we can just raise the error.
         # more status code handling can be added here if needed
         if error.response.status_code == http.HTTPStatus.BAD_REQUEST.value:
             raise mlrun.errors.MLRunBadRequestError(
                 f"Bad request to mlrun api: {error.response.text}"
             )
 
     def _store_function(self, runspec, meta, db):
-        db_str = "self" if self._is_api_server else self.spec.rundb
-        logger.info(f"starting run {meta.name} uid={meta.uid} DB={db_str}")
         meta.labels["kind"] = self.kind
         if "owner" not in meta.labels:
             meta.labels["owner"] = environ.get("V3IO_USERNAME") or getpass.getuser()
         if runspec.spec.output_path:
             runspec.spec.output_path = runspec.spec.output_path.replace(
                 "{{run.user}}", meta.labels["owner"]
             )
@@ -937,44 +1009,60 @@
             return None
 
         if not isinstance(resp, dict):
             raise ValueError(f"post_run called with type {type(resp)}")
 
         updates = None
         last_state = get_in(resp, "status.state", "")
+        kind = get_in(resp, "metadata.labels.kind", "")
         if last_state == "error" or err:
-            updates = {"status.last_update": now_date().isoformat()}
-            updates["status.state"] = "error"
+            updates = {
+                "status.last_update": now_date().isoformat(),
+                "status.state": "error",
+            }
             update_in(resp, "status.state", "error")
             if err:
                 update_in(resp, "status.error", err_to_str(err))
             err = get_in(resp, "status.error")
             if err:
                 updates["status.error"] = err_to_str(err)
-        elif not was_none and last_state != "completed":
-            updates = {"status.last_update": now_date().isoformat()}
-            updates["status.state"] = "completed"
-            update_in(resp, "status.state", "completed")
 
+        elif not was_none and last_state != "completed":
+            try:
+                runtime_handler = mlrun.runtimes.get_runtime_handler(kind)
+                updates = runtime_handler._get_run_completion_updates(resp)
+            except KeyError:
+                updates = BaseRuntimeHandler._get_run_completion_updates(resp)
+
+        uid = get_in(resp, "metadata.uid")
+        logger.debug(
+            "Run updates",
+            name=get_in(resp, "metadata.name"),
+            uid=uid,
+            kind=kind,
+            last_state=last_state,
+            updates=updates,
+        )
         if self._get_db() and updates:
             project = get_in(resp, "metadata.project")
-            uid = get_in(resp, "metadata.uid")
             iter = get_in(resp, "metadata.iteration", 0)
             self._get_db().update_run(updates, uid, project, iter=iter)
 
         return resp
 
     def _force_handler(self, handler):
         if not handler:
             raise RunError(f"handler must be provided for {self.kind} runtime")
 
-    def full_image_path(self, image=None, client_version: str = None):
+    def full_image_path(
+        self, image=None, client_version: str = None, client_python_version: str = None
+    ):
         image = image or self.spec.image or ""
 
-        image = enrich_image_url(image, client_version)
+        image = enrich_image_url(image, client_version, client_python_version)
         if not image.startswith("."):
             return image
         registry, repository = get_parsed_docker_registry()
         if registry:
             if repository and repository not in image:
                 return f"{registry}/{repository}/{image[1:]}"
             return f"{registry}/{image[1:]}"
@@ -998,36 +1086,53 @@
         workdir: str = "",
         artifact_path: str = "",
         image: str = "",
         labels: dict = None,
         use_db=True,
         verbose=None,
         scrape_metrics=False,
+        returns: Optional[List[Union[str, Dict[str, str]]]] = None,
+        auto_build: bool = False,
     ):
         """Run a local or remote task.
 
         :param runspec:         run template object or dict (see RunTemplate)
         :param handler:         name of the function handler
         :param name:            execution name
         :param project:         project name
         :param params:          input parameters (dict)
         :param hyperparams:     hyper parameters
         :param selector:        selection criteria for hyper params
         :param hyper_param_options:  hyper param options (selector, early stop, strategy, ..)
                             see: :py:class:`~mlrun.model.HyperParamOptions`
-        :param inputs:          input objects (dict of key: path)
+        :param inputs:          Input objects to pass to the handler. Type hints can be given so the input will be
+                                parsed during runtime from `mlrun.DataItem` to the given type hint. The type hint can be
+                                given in the key field of the dictionary after a colon, e.g: "<key> : <type_hint>".
         :param outputs:         list of outputs which can pass in the workflow
         :param artifact_path:   default artifact output path (replace out_path)
         :param workdir:         default input artifacts path
         :param image:           container image to use
         :param labels:          labels to tag the job/run with ({key:val, ..})
         :param use_db:          save function spec in the db (vs the workflow file)
         :param verbose:         add verbose prints/logs
         :param scrape_metrics:  whether to add the `mlrun/scrape-metrics` label to this run's resources
-
+        :param returns:         List of configurations for how to log the returning values from the handler's run
+                                (as artifacts or results). The list's length must be equal to the amount of returning
+                                objects. A configuration may be given as:
+
+                                * A string of the key to use to log the returning value as result or as an artifact.
+                                  To specify The artifact type, it is possible to pass a string in the following
+                                  structure:
+                                  "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no
+                                  artifact type is specified, the object's default artifact type will be used.
+                                * A dictionary of configurations to use when logging. Further info per object type and
+                                  artifact type can be given there. The artifact key must appear in the dictionary as
+                                  "key": "the_key".
+        :param auto_build:      when set to True and the function require build it will be built on the first
+                                function run, use only if you dont plan on changing the build config between runs
         :return: KubeFlow containerOp
         """
 
         # if self.spec.image and not image:
         #     image = self.full_image_path()
 
         if use_db:
@@ -1051,21 +1156,23 @@
             runobj=runspec,
             handler=handler,
             params=params,
             hyperparams=hyperparams,
             selector=selector,
             hyper_param_options=hyper_param_options,
             inputs=inputs,
+            returns=returns,
             outputs=outputs,
             job_image=image,
             labels=labels,
             out_path=artifact_path,
             in_path=workdir,
             verbose=verbose,
             scrape_metrics=scrape_metrics,
+            auto_build=auto_build,
         )
 
     def with_code(self, from_file="", body=None, with_doc=True):
         """Update the function code
         This function eliminates the need to build container images every time we edit the code
 
         :param from_file:   blank for current notebook, or path to .py/.ipynb file
@@ -1109,19 +1216,17 @@
         """add package requirements from file or list to build spec.
 
         :param requirements:  python requirements file path or list of packages
         :param overwrite:     overwrite existing requirements
         :param verify_base_image:  verify that the base image is configured
         :return: function object
         """
-        if isinstance(requirements, str):
-            with open(requirements, "r") as fp:
-                requirements = fp.read().splitlines()
+        encoded_requirements = self._encode_requirements(requirements)
         commands = self.spec.build.commands or [] if not overwrite else []
-        new_command = "python -m pip install " + " ".join(requirements)
+        new_command = f"python -m pip install {encoded_requirements}"
         # make sure we dont append the same line twice
         if new_command not in commands:
             commands.append(new_command)
         self.spec.build.commands = commands
         if verify_base_image:
             self.verify_base_image()
         return self
@@ -1287,42 +1392,112 @@
                         if "type" in p:
                             line += f"({p['type']})"
                         line += "  - " + p.get("doc", "")
                         if "default" in p:
                             line += f", default={p['default']}"
                         print("    " + line)
 
+    def _encode_requirements(self, requirements_to_encode):
+
+        # if a string, read the file then encode
+        if isinstance(requirements_to_encode, str):
+            with open(requirements_to_encode, "r") as fp:
+                requirements_to_encode = fp.read().splitlines()
+
+        requirements = []
+        for requirement in requirements_to_encode:
+            requirement = requirement.strip()
+
+            # ignore empty lines
+            # ignore comments
+            if not requirement or requirement.startswith("#"):
+                continue
+
+            # ignore inline comments as well
+            inline_comment = requirement.split(" #")
+            if len(inline_comment) > 1:
+                requirement = inline_comment[0].strip()
+
+            # -r / --requirement are flags and should not be escaped
+            # we allow such flags (could be passed within the requirements.txt file) and do not
+            # try to open the file and include its content since it might be a remote file
+            # given on the base image.
+            for req_flag in ["-r", "--requirement"]:
+                if requirement.startswith(req_flag):
+                    requirement = requirement[len(req_flag) :].strip()
+                    requirements.append(req_flag)
+                    break
+
+            # wrap in single quote to ensure that the requirement is treated as a single string
+            # quote the requirement to avoid issues with special characters, double quotes, etc.
+            requirements.append(shlex.quote(requirement))
+
+        return " ".join(requirements)
+
+    def _validate_output_path(self, run):
+        if is_local(run.spec.output_path):
+            message = ""
+            if not os.path.isabs(run.spec.output_path):
+                message = (
+                    "artifact/output path is not defined or is local and relative,"
+                    " artifacts will not be visible in the UI"
+                )
+                if mlrun.runtimes.RuntimeKinds.requires_absolute_artifacts_path(
+                    self.kind
+                ):
+                    raise mlrun.errors.MLRunPreconditionFailedError(
+                        "artifact path (`artifact_path`) must be absolute for remote tasks"
+                    )
+            elif hasattr(self.spec, "volume_mounts") and not self.spec.volume_mounts:
+                message = (
+                    "artifact output path is local while no volume mount is specified. "
+                    "artifacts would not be visible via UI."
+                )
+            if message:
+                logger.warning(message, output_path=run.spec.output_path)
+
 
 def is_local(url):
     if not url:
         return True
-    return "://" not in url and not url.startswith("/")
+    return "://" not in url
 
 
 class BaseRuntimeHandler(ABC):
     # setting here to allow tests to override
     kind = "base"
+    class_modes: typing.Dict[RuntimeClassMode, str] = {}
     wait_for_deletion_interval = 10
 
     @staticmethod
     @abstractmethod
     def _get_object_label_selector(object_id: str) -> str:
         """
-        Should return the label selector should be used to get only resources of a specific object (with id object_id)
+        Should return the label selector to get only resources of a specific object (with id object_id)
         """
         pass
 
-    @staticmethod
-    @abstractmethod
-    def _get_possible_mlrun_class_label_values() -> List[str]:
+    def _should_collect_logs(self) -> bool:
+        """
+        There are some runtimes which we don't collect logs for using the log collector
+        :return: whether should collect log for it
+        """
+        return True
+
+    def _get_possible_mlrun_class_label_values(
+        self, class_mode: typing.Union[RuntimeClassMode, str] = None
+    ) -> List[str]:
         """
         Should return the possible values of the mlrun/class label for runtime resources that are of this runtime
         handler kind
         """
-        pass
+        if not class_mode:
+            return list(self.class_modes.values())
+        class_mode = self.class_modes.get(class_mode, None)
+        return [class_mode] if class_mode else []
 
     def list_resources(
         self,
         project: str,
         object_id: typing.Optional[str] = None,
         label_selector: str = None,
         group_by: Optional[mlrun.api.schemas.ListRuntimeResourcesGroupByField] = None,
@@ -1334,17 +1509,15 @@
         # We currently don't support removing runtime resources in non k8s env
         if not mlrun.k8s_utils.get_k8s_helper(
             silent=True
         ).is_running_inside_kubernetes_cluster():
             return {}
         k8s_helper = get_k8s_helper()
         namespace = k8s_helper.resolve_namespace()
-        label_selector = self._resolve_label_selector(
-            project, object_id, label_selector
-        )
+        label_selector = self.resolve_label_selector(project, object_id, label_selector)
         pods = self._list_pods(namespace, label_selector)
         pod_resources = self._build_pod_resources(pods)
         crd_objects = self._list_crd_objects(namespace, label_selector)
         crd_resources = self._build_crd_resources(crd_objects)
         response = self._build_list_resources_response(
             pod_resources, crd_resources, group_by
         )
@@ -1384,17 +1557,15 @@
         # We currently don't support removing runtime resources in non k8s env
         if not mlrun.k8s_utils.get_k8s_helper(
             silent=True
         ).is_running_inside_kubernetes_cluster():
             return
         k8s_helper = get_k8s_helper()
         namespace = k8s_helper.resolve_namespace()
-        label_selector = self._resolve_label_selector(
-            "*", label_selector=label_selector
-        )
+        label_selector = self.resolve_label_selector("*", label_selector=label_selector)
         crd_group, crd_version, crd_plural = self._get_crd_info()
         if crd_group and crd_version and crd_plural:
             deleted_resources = self._delete_crd_resources(
                 db,
                 db_session,
                 namespace,
                 label_selector,
@@ -1406,15 +1577,15 @@
                 db,
                 db_session,
                 namespace,
                 label_selector,
                 force,
                 grace_period,
             )
-        self._delete_resources(
+        self._delete_extra_resources(
             db,
             db_session,
             namespace,
             deleted_resources,
             label_selector,
             force,
             grace_period,
@@ -1575,14 +1746,17 @@
                     debounce_period=debounce_period,
                 )
             else:
                 logger.info(
                     "Updating run state", run_uid=run_uid, run_state=RunStates.error
                 )
                 run.setdefault("status", {})["state"] = RunStates.error
+                run.setdefault("status", {})[
+                    "reason"
+                ] = "A runtime resource related to this run could not be found"
                 run.setdefault("status", {})["last_update"] = now.isoformat()
                 db.store_run(db_session, run, run_uid, project)
 
     def _add_object_label_selector_if_needed(
         self,
         object_id: typing.Optional[str] = None,
         label_selector: typing.Optional[str] = None,
@@ -1591,14 +1765,23 @@
             object_label_selector = self._get_object_label_selector(object_id)
             if label_selector:
                 label_selector = ",".join([object_label_selector, label_selector])
             else:
                 label_selector = object_label_selector
         return label_selector
 
+    @staticmethod
+    def _get_main_runtime_resource_label_selector() -> str:
+        """
+        There are some runtimes which might have multiple k8s resources attached to a one runtime, in this case
+        we don't want to pull logs from all but rather only for the "driver"/"launcher" etc
+        :return: the label selector
+        """
+        return ""
+
     def _enrich_list_resources_response(
         self,
         response: Union[
             mlrun.api.schemas.RuntimeResources,
             mlrun.api.schemas.GroupedByJobRuntimeResourcesOutput,
             mlrun.api.schemas.GroupedByProjectRuntimeResourcesOutput,
         ],
@@ -1622,32 +1805,32 @@
             mlrun.api.schemas.GroupedByJobRuntimeResourcesOutput,
             mlrun.api.schemas.GroupedByProjectRuntimeResourcesOutput,
         ],
         runtime_resources_list: List[mlrun.api.schemas.RuntimeResources],
         group_by: Optional[mlrun.api.schemas.ListRuntimeResourcesGroupByField] = None,
     ):
         """
-        Override this to add runtime resources other then pods or CRDs (which are handled by the base class) to the
+        Override this to add runtime resources other than pods or CRDs (which are handled by the base class) to the
         output
         """
         return response
 
-    def _delete_resources(
+    def _delete_extra_resources(
         self,
         db: DBInterface,
         db_session: Session,
         namespace: str,
         deleted_resources: List[Dict],
         label_selector: str = None,
         force: bool = False,
         grace_period: int = None,
     ):
         """
-        Override this to handle deletion of resources other then pods or CRDs (which are handled by the base class)
-        Note that this is happening before the deletion of the CRDs or the pods
+        Override this to handle deletion of resources other than pods or CRDs (which are handled by the base class)
+        Note that this is happening after the deletion of the CRDs or the pods
         Note to add this at the beginning:
         if grace_period is None:
             grace_period = config.runtime_resources_deletion_grace_period
         """
         pass
 
     def _resolve_crd_object_status_info(
@@ -1700,26 +1883,41 @@
                         not last_container_completion_time
                         or last_container_completion_time < container_completion_time
                     ):
                         last_container_completion_time = container_completion_time
 
         return in_terminal_state, last_container_completion_time, run_state
 
-    def _get_default_label_selector(self) -> str:
+    def _get_default_label_selector(
+        self, class_mode: typing.Union[RuntimeClassMode, str] = None
+    ) -> str:
         """
         Override this to add a default label selector
         """
-        class_values = self._get_possible_mlrun_class_label_values()
+        class_values = self._get_possible_mlrun_class_label_values(class_mode)
         if not class_values:
             return ""
         if len(class_values) == 1:
             return f"mlrun/class={class_values[0]}"
         return f"mlrun/class in ({', '.join(class_values)})"
 
     @staticmethod
+    def _get_run_completion_updates(run: dict) -> dict:
+        """
+        Get the required updates for the run object when it's completed and update the run object state
+        Override this if the run completion is not resolved by a single execution
+        """
+        updates = {
+            "status.last_update": now_date().isoformat(),
+            "status.state": "completed",
+        }
+        update_in(run, "status.state", "completed")
+        return updates
+
+    @staticmethod
     def _get_crd_info() -> Tuple[str, str, str]:
         """
         Override this if the runtime has CRD resources. this should return the CRD info:
         crd group, crd version, crd plural
         """
         return "", "", ""
 
@@ -1763,36 +1961,59 @@
                 # ignore error if crd is not defined
                 if exc.status != 404:
                     raise
             else:
                 crd_objects = crd_objects["items"]
         return crd_objects
 
-    def _resolve_label_selector(
+    def resolve_label_selector(
         self,
         project: str,
         object_id: typing.Optional[str] = None,
         label_selector: typing.Optional[str] = None,
+        class_mode: typing.Union[RuntimeClassMode, str] = None,
+        with_main_runtime_resource_label_selector: bool = False,
     ) -> str:
-        default_label_selector = self._get_default_label_selector()
+        default_label_selector = self._get_default_label_selector(class_mode=class_mode)
 
         if label_selector:
             label_selector = ",".join([default_label_selector, label_selector])
         else:
             label_selector = default_label_selector
 
         if project and project != "*":
             label_selector = ",".join([label_selector, f"mlrun/project={project}"])
 
         label_selector = self._add_object_label_selector_if_needed(
             object_id, label_selector
         )
 
+        if with_main_runtime_resource_label_selector:
+            main_runtime_resource_label_selector = (
+                self._get_main_runtime_resource_label_selector()
+            )
+            if main_runtime_resource_label_selector:
+                label_selector = ",".join(
+                    [label_selector, main_runtime_resource_label_selector]
+                )
+
         return label_selector
 
+    @staticmethod
+    def resolve_object_id(
+        run: dict,
+    ) -> typing.Optional[str]:
+        """
+        Get the object id from the run object
+        Override this if the object id is not the run uid
+        :param run: run object
+        :return: object id
+        """
+        return run.get("metadata", {}).get("uid", None)
+
     def _wait_for_pods_deletion(
         self,
         namespace: str,
         deleted_pods: List[Dict],
         label_selector: str = None,
     ):
         k8s_helper = get_k8s_helper()
@@ -1947,14 +2168,15 @@
 
                 get_k8s_helper().delete_pod(pod.metadata.name, namespace)
                 deleted_pods.append(pod_dict)
             except Exception as exc:
                 logger.warning(
                     f"Cleanup failed processing pod {pod.metadata.name}: {repr(exc)}. Continuing"
                 )
+        # TODO: don't wait for pods to be deleted, client should poll the deletion status
         self._wait_for_pods_deletion(namespace, deleted_pods, label_selector)
         return deleted_pods
 
     def _delete_crd_resources(
         self,
         db: DBInterface,
         db_session: Session,
@@ -2330,17 +2552,19 @@
     @staticmethod
     def _ensure_run_logs_collected(
         db: DBInterface, db_session: Session, project: str, uid: str
     ):
         # import here to avoid circular imports
         import mlrun.api.crud as crud
 
-        log_file_exists = crud.Logs().log_file_exists(project, uid)
+        log_file_exists, _ = crud.Logs().log_file_exists_for_run_uid(project, uid)
         if not log_file_exists:
-            _, logs_from_k8s = crud.Logs().get_logs(
+            # this stays for now for backwards compatibility in case we would not use the log collector but rather
+            # the legacy method to pull logs
+            logs_from_k8s = crud.Logs()._get_logs_legacy_method(
                 db_session, project, uid, source=LogSources.K8S
             )
             if logs_from_k8s:
                 logger.info("Storing run logs", project=project, uid=uid)
                 crud.Logs().store_log(logs_from_k8s, project, uid, append=False)
 
     @staticmethod
```

## mlrun/runtimes/daskjob.py

```diff
@@ -11,18 +11,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import datetime
 import inspect
 import socket
 import time
-import warnings
+import typing
 from os import environ
 from typing import Dict, List, Optional, Union
 
+from deprecated import deprecated
 from kubernetes.client.rest import ApiException
 from sqlalchemy.orm import Session
 
 import mlrun.api.schemas
 import mlrun.errors
 import mlrun.utils
 import mlrun.utils.regex
@@ -32,15 +33,15 @@
 
 from ..config import config
 from ..execution import MLClientCtx
 from ..k8s_utils import get_k8s_helper
 from ..model import RunObject
 from ..render import ipython_display
 from ..utils import logger, normalize_name, update_in
-from .base import FunctionStatus
+from .base import FunctionStatus, RuntimeClassMode
 from .kubejob import KubejobRuntime
 from .local import exec_from_params, load_module
 from .pod import KubeResourceSpec, kube_resource_spec_to_pod_spec
 from .utils import RunError, get_func_selector, get_resource_labels, log_std
 
 
 def get_dask_resource():
@@ -101,14 +102,15 @@
         priority_class_name=None,
         disable_auto_mount=False,
         pythonpath=None,
         workdir=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        clone_target_dir=None,
     ):
 
         super().__init__(
             command=command,
             args=args,
             image=image,
             mode=mode,
@@ -130,14 +132,15 @@
             priority_class_name=priority_class_name,
             disable_auto_mount=disable_auto_mount,
             pythonpath=pythonpath,
             workdir=workdir,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            clone_target_dir=clone_target_dir,
         )
         self.args = args
 
         self.extra_pip = extra_pip
         self.remote = True if remote is None else remote  # make remote the default
 
         self.service_type = service_type
@@ -148,15 +151,15 @@
         # supported format according to https://github.com/dask/dask/blob/master/dask/utils.py#L1402
         self.scheduler_timeout = scheduler_timeout or "60 minutes"
         self.nthreads = nthreads or 1
         self._scheduler_resources = self.enrich_resources_with_default_pod_resources(
             "scheduler_resources", scheduler_resources
         )
         self._worker_resources = self.enrich_resources_with_default_pod_resources(
-            "worker_resources", scheduler_resources
+            "worker_resources", worker_resources
         )
 
     @property
     def scheduler_resources(self) -> dict:
         return self._scheduler_resources
 
     @scheduler_resources.setter
@@ -224,15 +227,15 @@
     def is_deployed(self):
         if not self.spec.remote:
             return True
         return super().is_deployed()
 
     @property
     def initialized(self):
-        return True if self._cluster else False
+        return bool(self._cluster)
 
     def _load_db_status(self):
         meta = self.metadata
         if self._is_remote_api():
             db = self._get_db()
             db_func = None
             try:
@@ -247,15 +250,15 @@
                 return "scheduler_address" in db_func["status"]
 
         return False
 
     def _start(self, watch=True):
         if self._is_remote_api():
             self.try_auto_mount_based_on_config()
-            self.fill_credentials()
+            self._fill_credentials()
             db = self._get_db()
             if not self.is_deployed():
                 raise RunError(
                     "function image is not built/ready, use .deploy()"
                     " method first, or set base dask image (daskdev/dask:latest)"
                 )
 
@@ -303,20 +306,20 @@
             client.shutdown()
             client.close()
         except ValueError:
             pass
 
     def get_status(self):
         meta = self.metadata
-        s = get_func_selector(meta.project, meta.name, meta.tag)
+        selector = get_func_selector(meta.project, meta.name, meta.tag)
         if self._is_remote_api():
             db = self._get_db()
-            return db.remote_status(meta.project, meta.name, self.kind, s)
+            return db.remote_status(meta.project, meta.name, self.kind, selector)
 
-        status = get_obj_status(s)
+        status = get_obj_status(selector)
         print(status)
         return status
 
     def cluster(self):
         return self._cluster
 
     def _remote_addresses(self):
@@ -379,62 +382,61 @@
     def deploy(
         self,
         watch=True,
         with_mlrun=None,
         skip_deployed=False,
         is_kfp=False,
         mlrun_version_specifier=None,
+        builder_env: dict = None,
         show_on_failure: bool = False,
     ):
         """deploy function, build container with dependencies
 
-        :param watch:      wait for the deploy to complete (and print build logs)
-        :param with_mlrun: add the current mlrun package to the container build
-        :param skip_deployed: skip the build if we already have an image for the function
-        :param mlrun_version_specifier:  which mlrun package version to include (if not current)
-        :param builder_env:   Kaniko builder pod env vars dict (for config/credentials)
-                              e.g. builder_env={"GIT_TOKEN": token}
-        :param show_on_failure:  show logs only in case of build failure
+        :param watch:                   wait for the deploy to complete (and print build logs)
+        :param with_mlrun:              add the current mlrun package to the container build
+        :param skip_deployed:           skip the build if we already have an image for the function
+        :param is_kfp:                  deploy as part of a kfp pipeline
+        :param mlrun_version_specifier: which mlrun package version to include (if not current)
+        :param builder_env:             Kaniko builder pod env vars dict (for config/credentials)
+                                        e.g. builder_env={"GIT_TOKEN": token}
+        :param show_on_failure:         show logs only in case of build failure
 
         :return True if the function is ready (deployed)
         """
         return super().deploy(
             watch,
             with_mlrun,
             skip_deployed,
             is_kfp=is_kfp,
             mlrun_version_specifier=mlrun_version_specifier,
+            builder_env=builder_env,
             show_on_failure=show_on_failure,
         )
 
+    # TODO: Remove in 1.5.0
+    @deprecated(
+        version="1.3.0",
+        reason="'Dask gpus' will be removed in 1.5.0, use 'with_scheduler_limits' / 'with_worker_limits' instead",
+        category=FutureWarning,
+    )
     def gpus(self, gpus, gpu_type="nvidia.com/gpu"):
-        warnings.warn(
-            "Dask's gpus will be deprecated in 0.8.0, and will be removed in 0.10.0, use "
-            "with_scheduler_limits/with_worker_limits instead",
-            # TODO: In 0.8.0 deprecate and replace gpus to with_worker/scheduler_limits in examples & demos (or maybe
-            #  just change behavior ?)
-            PendingDeprecationWarning,
-        )
-        # the scheduler/worker specific functions was introduced after the general one, to keep backwards compatibility
-        # this function just sets the gpus for both of them
         update_in(self.spec.scheduler_resources, ["limits", gpu_type], gpus)
         update_in(self.spec.worker_resources, ["limits", gpu_type], gpus)
 
-    def with_limits(self, mem=None, cpu=None, gpus=None, gpu_type="nvidia.com/gpu"):
-        warnings.warn(
-            "Dask's with_limits will be deprecated in 0.8.0, and will be removed in 0.10.0, use "
-            "with_scheduler_limits/with_worker_limits instead",
-            # TODO: In 0.8.0 deprecate and replace with_limits to with_worker/scheduler_limits in examples & demos (or
-            #  maybe just change behavior ?)
-            PendingDeprecationWarning,
-        )
-        # the scheduler/worker specific function was introduced after the general one, to keep backwards compatibility
-        # this function just sets the limits for both of them
-        self.with_scheduler_limits(mem, cpu, gpus, gpu_type)
-        self.with_worker_limits(mem, cpu, gpus, gpu_type)
+    def with_limits(
+        self,
+        mem=None,
+        cpu=None,
+        gpus=None,
+        gpu_type="nvidia.com/gpu",
+        patch: bool = False,
+    ):
+        raise NotImplementedError(
+            "Use with_scheduler_limits/with_worker_limits to set resource limits",
+        )
 
     def with_scheduler_limits(
         self,
         mem: str = None,
         cpu: str = None,
         gpus: int = None,
         gpu_type: str = "nvidia.com/gpu",
@@ -461,18 +463,16 @@
         by default it overrides the whole limits section, if you wish to patch specific resources use `patch=True`.
         """
         self.spec._verify_and_set_limits(
             "worker_resources", mem, cpu, gpus, gpu_type, patch=patch
         )
 
     def with_requests(self, mem=None, cpu=None, patch: bool = False):
-        # TODO: In 1.4.0 change to NotImplementedError
-        raise DeprecationWarning(
-            "Dask's with_requests is deprecated and will be removed in 1.4.0, use "
-            "with_scheduler_requests/with_worker_requests instead",
+        raise NotImplementedError(
+            "Use with_scheduler_requests/with_worker_requests to set resource requests",
         )
 
     def with_scheduler_requests(
         self, mem: str = None, cpu: str = None, patch: bool = False
     ):
         """
         set scheduler pod resources requests
@@ -513,19 +513,24 @@
         client = self.client
         setattr(context, "dask_client", client)
         sout, serr = exec_from_params(handler, runobj, context)
         log_std(self._db_conn, runobj, sout, serr, skip=self.is_child, show=False)
         return context.to_dict()
 
 
-def deploy_function(function: DaskCluster, secrets=None, client_version: str = None):
+def deploy_function(
+    function: DaskCluster,
+    secrets=None,
+    client_version: str = None,
+    client_python_version: str = None,
+):
     _validate_dask_related_libraries_installed()
 
     scheduler_pod, worker_pod, function, namespace = enrich_dask_cluster(
-        function, secrets, client_version
+        function, secrets, client_version, client_python_version
     )
     return initialize_dask_cluster(scheduler_pod, worker_pod, function, namespace)
 
 
 def initialize_dask_cluster(scheduler_pod, worker_pod, function, namespace):
     import dask
     import dask_kubernetes
@@ -570,43 +575,52 @@
         cluster.scale(spec.replicas)
     else:
         cluster.adapt(minimum=spec.min_replicas, maximum=spec.max_replicas)
 
     return cluster
 
 
-def enrich_dask_cluster(function, secrets, client_version):
+def enrich_dask_cluster(
+    function, secrets, client_version: str = None, client_python_version: str = None
+):
     from dask.distributed import Client, default_client  # noqa: F401
     from dask_kubernetes import KubeCluster, make_pod_spec  # noqa: F401
     from kubernetes import client
 
     # Is it possible that the function will not have a project at this point?
     if function.metadata.project:
         function._add_secrets_to_spec_before_running(project=function.metadata.project)
 
     spec = function.spec
     meta = function.metadata
     spec.remote = True
 
     image = (
-        function.full_image_path(client_version=client_version) or "daskdev/dask:latest"
+        function.full_image_path(
+            client_version=client_version, client_python_version=client_python_version
+        )
+        # TODO: we might never enter here, since running a function requires defining an image
+        or "daskdev/dask:latest"
     )
     env = spec.env
     namespace = meta.namespace or config.namespace
     if spec.extra_pip:
         env.append(spec.extra_pip)
 
     pod_labels = get_resource_labels(function, scrape_metrics=config.scrape_metrics)
-    # TODO: 'dask-worker' has deprecation notice, user 'dask worker' instead
+    # TODO: 'dask-worker' is deprecated, new dask CLI was introduced in 2022.10.0.
+    #  Upgrade when we drop python 3.7 support and use 'dask worker' instead
     worker_args = ["dask-worker", "--nthreads", str(spec.nthreads)]
-    memory_limit = spec.resources.get("limits", {}).get("memory")
+    memory_limit = spec.worker_resources.get("limits", {}).get("memory")
     if memory_limit:
         worker_args.extend(["--memory-limit", str(memory_limit)])
     if spec.args:
         worker_args.extend(spec.args)
+    # TODO: 'dask-scheduler' is deprecated, new dask CLI was introduced in 2022.10.0.
+    #  Upgrade when we drop python 3.7 support and use 'dask scheduler' instead
     scheduler_args = ["dask-scheduler"]
 
     container_kwargs = {
         "name": "base",
         "image": image,
         "env": env,
         "image_pull_policy": spec.image_pull_policy,
@@ -651,53 +665,73 @@
             "missing dask or dask_kubernetes, please run "
             '"pip install dask distributed dask_kubernetes", %s',
             exc,
         )
         raise exc
 
 
-def get_obj_status(selector=[], namespace=None):
+def get_obj_status(selector=None, namespace=None):
+    if selector is None:
+        selector = []
+
     k8s = get_k8s_helper()
     namespace = namespace or config.namespace
     selector = ",".join(["dask.org/component=scheduler"] + selector)
     pods = k8s.list_pods(namespace, selector=selector)
     status = ""
     for pod in pods:
         status = pod.status.phase.lower()
-        print(pod)
         if status == "running":
             cluster = pod.metadata.labels.get("dask.org/cluster-name")
             logger.info(
                 f"found running dask function {pod.metadata.name}, cluster={cluster}"
             )
             return status
         logger.info(
             f"found dask function {pod.metadata.name} in non ready state ({status})"
         )
     return status
 
 
 class DaskRuntimeHandler(BaseRuntimeHandler):
     kind = "dask"
+    class_modes = {RuntimeClassMode.run: "dask"}
 
     # Dask runtime resources are per function (and not per run).
     # It means that monitoring runtime resources state doesn't say anything about the run state.
     # Therefore dask run monitoring is done completely by the SDK, so overriding the monitoring method with no logic
     def monitor_runs(
         self, db: DBInterface, db_session: Session, leader_session: Optional[str] = None
     ):
         return
 
     @staticmethod
     def _get_object_label_selector(object_id: str) -> str:
         return f"mlrun/function={object_id}"
 
     @staticmethod
-    def _get_possible_mlrun_class_label_values() -> List[str]:
-        return ["dask"]
+    def resolve_object_id(
+        run: dict,
+    ) -> typing.Optional[str]:
+        """
+        Resolves the object ID from the run object.
+        In dask runtime, the object ID is the function name.
+        :param run: run object
+        :return: function name
+        """
+
+        function = run.get("spec", {}).get("function", None)
+        if function:
+
+            # a dask run's function field is in the format <project-name>/<function-name>@<run-uid>
+            # we only want the function name
+            project_and_function = function.split("@")[0]
+            return project_and_function.split("/")[-1]
+
+        return None
 
     def _enrich_list_resources_response(
         self,
         response: Union[
             mlrun.api.schemas.RuntimeResources,
             mlrun.api.schemas.GroupedByJobRuntimeResourcesOutput,
             mlrun.api.schemas.GroupedByProjectRuntimeResourcesOutput,
@@ -783,15 +817,15 @@
                 self._add_resource_to_grouped_by_project_resources_response(
                     response, "service_resources", service_resource
                 )
         else:
             response.service_resources = service_resources
         return response
 
-    def _delete_resources(
+    def _delete_extra_resources(
         self,
         db: DBInterface,
         db_session: Session,
         namespace: str,
         deleted_resources: List[Dict],
         label_selector: str = None,
         force: bool = False,
```

## mlrun/runtimes/function.py

```diff
@@ -11,64 +11,74 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import asyncio
 import json
 import typing
+import warnings
 from base64 import b64encode
 from datetime import datetime
 from time import sleep
 from urllib.parse import urlparse
 
 import nuclio
+import nuclio.utils
 import requests
 import semver
 from aiohttp.client import ClientSession
 from kubernetes import client
 from nuclio.deploy import find_dashboard_url, get_deploy_status
 from nuclio.triggers import V3IOStreamTrigger
 
 import mlrun.errors
+import mlrun.utils
 from mlrun.datastore import parse_s3_bucket_and_key
 from mlrun.db import RunDBError
-from mlrun.utils import get_git_username_password_from_token
 
 from ..api.schemas import AuthInfo
 from ..config import config as mlconf
+from ..config import is_running_as_api
 from ..errors import err_to_str
 from ..k8s_utils import get_k8s_helper
 from ..kfpops import deploy_op
 from ..lists import RunList
 from ..model import RunObject
-from ..platforms.iguazio import mount_v3io, parse_path, split_path, v3io_cred
+from ..platforms.iguazio import (
+    VolumeMount,
+    mount_v3io,
+    parse_path,
+    split_path,
+    v3io_cred,
+)
 from ..utils import as_number, enrich_image_url, get_in, logger, update_in
 from .base import FunctionStatus, RunError
 from .constants import NuclioIngressAddTemplatedIngressModes
 from .pod import KubeResource, KubeResourceSpec
 from .utils import get_item_name, log_std
 
-default_max_replicas = 4
-
 
 def validate_nuclio_version_compatibility(*min_versions):
     """
     :param min_versions: Valid minimum version(s) required, assuming no 2 versions has equal major and minor.
     """
     parsed_min_versions = [
         semver.VersionInfo.parse(min_version) for min_version in min_versions
     ]
     try:
         parsed_current_version = semver.VersionInfo.parse(mlconf.nuclio_version)
     except ValueError:
-        logger.warning(
-            "Unable to parse nuclio version, assuming compatibility",
-            nuclio_version=mlconf.nuclio_version,
-            min_versions=min_versions,
-        )
+
+        # only log when version is set but invalid
+        if mlconf.nuclio_version:
+            logger.warning(
+                "Unable to parse nuclio version, assuming compatibility",
+                nuclio_version=mlconf.nuclio_version,
+                min_versions=min_versions,
+            )
         return True
 
     parsed_min_versions.sort(reverse=True)
     for parsed_min_version in parsed_min_versions:
         if (
             parsed_current_version.major == parsed_min_version.major
             and parsed_current_version.minor == parsed_min_version.minor
@@ -127,14 +137,16 @@
         "no_cache",
         "source",
         "function_kind",
         "readiness_timeout",
         "function_handler",
         "nuclio_runtime",
         "base_image_pull",
+        "service_type",
+        "add_templated_ingress_host_mode",
     ]
 
     def __init__(
         self,
         command=None,
         args=None,
         image=None,
@@ -165,14 +177,17 @@
         priority_class_name=None,
         pythonpath=None,
         workdir=None,
         image_pull_secret=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        service_type=None,
+        add_templated_ingress_host_mode=None,
+        clone_target_dir=None,
     ):
 
         super().__init__(
             command=command,
             args=args,
             image=image,
             mode=mode,
@@ -194,33 +209,34 @@
             priority_class_name=priority_class_name,
             pythonpath=pythonpath,
             workdir=workdir,
             image_pull_secret=image_pull_secret,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            clone_target_dir=clone_target_dir,
         )
 
         self.base_spec = base_spec or {}
         self.function_kind = function_kind
         self.source = source or ""
         self.config = config or {}
         self.function_handler = None
         self.nuclio_runtime = None
         self.no_cache = no_cache
         self.readiness_timeout = readiness_timeout
+        self.service_type = service_type
+        self.add_templated_ingress_host_mode = add_templated_ingress_host_mode
 
-        # TODO: we would prefer to default to 0, but invoking a scaled to zero function requires to either add the
-        #  x-nuclio-target header or to create the function with http trigger and invoke the function through it - so
-        #  we need to do one of the two
         self.min_replicas = min_replicas or 1
-        self.max_replicas = max_replicas or default_max_replicas
+        self.max_replicas = max_replicas or 4
+
         # When True it will set Nuclio spec.noBaseImagesPull to False (negative logic)
         # indicate that the base image should be pulled from the container registry (not cached)
-        self.base_image_pull: bool = None
+        self.base_image_pull = False
 
     def generate_nuclio_volumes(self):
         nuclio_volumes = []
         volume_with_volume_mounts_names = set()
         for volume_mount in self._volume_mounts.values():
             volume_name = get_item_name(volume_mount, "name")
             if volume_name not in self._volumes:
@@ -371,56 +387,64 @@
     def with_v3io(self, local="", remote=""):
         """Add v3io volume to the function
 
         :param local: local path (mount path inside the function container)
         :param remote: v3io path
         """
         if local and remote:
-            self.apply(mount_v3io(remote=remote, mount_path=local))
+            self.apply(
+                mount_v3io(
+                    remote=remote, volume_mounts=[VolumeMount(path=local, sub_path="")]
+                )
+            )
         else:
             self.apply(v3io_cred())
         return self
 
     def with_http(
         self,
-        workers=8,
-        port=0,
-        host=None,
-        paths=None,
-        canary=None,
-        secret=None,
-        worker_timeout: int = None,
-        gateway_timeout: int = None,
-        trigger_name=None,
-        annotations=None,
-        extra_attributes=None,
+        workers: typing.Optional[int] = 8,
+        port: typing.Optional[int] = None,
+        host: typing.Optional[str] = None,
+        paths: typing.Optional[typing.List[str]] = None,
+        canary: typing.Optional[float] = None,
+        secret: typing.Optional[str] = None,
+        worker_timeout: typing.Optional[int] = None,
+        gateway_timeout: typing.Optional[int] = None,
+        trigger_name: typing.Optional[str] = None,
+        annotations: typing.Optional[typing.Mapping[str, str]] = None,
+        extra_attributes: typing.Optional[typing.Mapping[str, str]] = None,
     ):
         """update/add nuclio HTTP trigger settings
 
         Note: gateway timeout is the maximum request time before an error is returned, while the worker timeout
         if the max time a request will wait for until it will start processing, gateway_timeout must be greater than
         the worker_timeout.
 
-        :param workers:    number of worker processes (default=8)
-        :param port:       TCP port
-        :param host:       hostname
-        :param paths:      list of sub paths
-        :param canary:     k8s ingress canary (% traffic value between 0 to 100)
+        :param workers:    number of worker processes (default=8). set 0 to use Nuclio's default workers count
+        :param port:       TCP port to listen on. by default, nuclio will choose a random port as long as
+                           the function service is NodePort. if the function service is ClusterIP, the port
+                           is ignored.
+        :param host:       Ingress hostname
+        :param paths:      list of Ingress sub paths
+        :param canary:     k8s ingress canary (% traffic value between 0 and 100)
         :param secret:     k8s secret name for SSL certificate
         :param worker_timeout:  worker wait timeout in sec (how long a message should wait in the worker queue
                                 before an error is returned)
         :param gateway_timeout: nginx ingress timeout in sec (request timeout, when will the gateway return an error)
         :param trigger_name:    alternative nuclio trigger name
         :param annotations:     key/value dict of ingress annotations
         :param extra_attributes: key/value dict of extra nuclio trigger attributes
         :return: function object (self)
         """
         annotations = annotations or {}
         if worker_timeout:
             gateway_timeout = gateway_timeout or (worker_timeout + 60)
+        if workers is None:
+            workers = 0
         if gateway_timeout:
             if worker_timeout and worker_timeout >= gateway_timeout:
                 raise ValueError(
                     "gateway timeout must be greater than the worker timeout"
                 )
             annotations[
                 "nginx.ingress.kubernetes.io/proxy-connect-timeout"
@@ -429,15 +453,15 @@
                 "nginx.ingress.kubernetes.io/proxy-read-timeout"
             ] = f"{gateway_timeout}"
             annotations[
                 "nginx.ingress.kubernetes.io/proxy-send-timeout"
             ] = f"{gateway_timeout}"
 
         trigger = nuclio.HttpTrigger(
-            workers,
+            workers=workers,
             port=port,
             host=host,
             paths=paths,
             canary=canary,
             secret=secret,
             annotations=annotations,
             extra_attributes=extra_attributes,
@@ -508,30 +532,30 @@
         self.spec.min_replicas = shards
         self.spec.max_replicas = shards
 
     def add_secrets_config_to_spec(self):
         # For nuclio functions, we just add the project secrets as env variables. Since there's no MLRun code
         # to decode the secrets and special env variable names in the function, we just use the same env variable as
         # the key name (encode_key_names=False)
-        self._add_project_k8s_secrets_to_spec(
+        self._add_k8s_secrets_to_spec(
             None, project=self.metadata.project, encode_key_names=False
         )
 
     def deploy(
         self,
         dashboard="",
         project="",
         tag="",
         verbose=False,
         auth_info: AuthInfo = None,
         builder_env: dict = None,
     ):
         """Deploy the nuclio function to the cluster
 
-        :param dashboard:  address of the nuclio dashboard service (keep blank for current cluster)
+        :param dashboard:  DEPRECATED. Keep empty to allow auto-detection by MLRun API
         :param project:    project name
         :param tag:        function tag
         :param verbose:    set True for verbose logging
         :param auth_info:  service AuthInfo
         :param builder_env: env vars dict for source archive config/credentials e.g. builder_env={"GIT_TOKEN": token}
         """
         # todo: verify that the function name is normalized
@@ -544,15 +568,15 @@
         if tag:
             self.metadata.tag = tag
 
         save_record = False
         if not dashboard:
             # Attempt auto-mounting, before sending to remote build
             self.try_auto_mount_based_on_config()
-            self.fill_credentials()
+            self._fill_credentials()
             db = self._get_db()
             logger.info("Starting remote function deploy")
             data = db.remote_builder(self, False, builder_env=builder_env)
             self.status = data["data"].get("status")
             self._update_credentials_from_remote_build(data["data"])
 
             # when a function is deployed, we wait for it to be ready by default
@@ -570,15 +594,22 @@
                 self.spec.command = f"http://{self.status.internal_invocation_urls[0]}"
                 save_record = True
             elif self.status.address:
                 self.spec.command = f"http://{self.status.address}"
                 save_record = True
 
         else:
-            # todo: should be deprecated (only work via MLRun service)
+
+            warnings.warn(
+                "'dashboard' is deprecated in 1.3.0, and will be removed in 1.5.0, "
+                "Keep 'dashboard' value empty to allow auto-detection by MLRun API.",
+                # TODO: Remove in 1.5.0
+                FutureWarning,
+            )
+
             self.save(versioned=False)
             self._ensure_run_db()
             internal_invocation_urls, external_invocation_urls = deploy_nuclio_function(
                 self,
                 dashboard=dashboard,
                 watch=True,
                 auth_info=auth_info,
@@ -610,15 +641,17 @@
         return self.spec.command
 
     def _wait_for_function_deployment(self, db, verbose=False):
         text = ""
         state = ""
         last_log_timestamp = 1
         while state not in ["ready", "error", "unhealthy"]:
-            sleep(1)
+            sleep(
+                int(mlrun.mlconf.httpdb.logs.nuclio.pull_deploy_status_default_interval)
+            )
             try:
                 text, last_log_timestamp = db.get_builder_status(
                     self, last_log_timestamp=last_log_timestamp, verbose=verbose
                 )
             except RunDBError:
                 raise ValueError("function or deploy process not found")
             state = self.status.state
@@ -665,14 +698,30 @@
         super().with_preemption_mode(mode=mode)
 
     @min_nuclio_versions("1.6.18")
     def with_priority_class(self, name: typing.Optional[str] = None):
         """k8s priority class"""
         super().with_priority_class(name)
 
+    def with_service_type(
+        self, service_type: str, add_templated_ingress_host_mode: str = None
+    ):
+        """
+        Enables to control the service type of the pod and the addition of templated ingress host
+
+        :param service_type:                      service type (ClusterIP, NodePort), defaults to
+                                                  mlrun.mlconf.httpdb.nuclio.service_type
+        :param add_templated_ingress_host_mode:   add templated ingress host mode (never, always, onClusterIP),
+                                                  see mlrun.mlconf.httpdb.nuclio.add_templated_ingress_host_mode
+                                                  for the default and more information
+
+        """
+        self.spec.service_type = service_type
+        self.spec.add_templated_ingress_host_mode = add_templated_ingress_host_mode
+
     def _get_state(
         self,
         dashboard="",
         last_log_timestamp=0,
         verbose=False,
         raise_on_exception=True,
         resolve_address=True,
@@ -767,15 +816,24 @@
         project="",
         models=None,
         env=None,
         tag=None,
         verbose=None,
         use_function_from_db=None,
     ):
-        """return as a Kubeflow pipeline step (ContainerOp), recommended to use mlrun.deploy_function() instead"""
+        """return as a Kubeflow pipeline step (ContainerOp), recommended to use mlrun.deploy_function() instead
+
+        :param dashboard:      DEPRECATED. Keep empty to allow auto-detection by MLRun API.
+        :param project:        project name, defaults to function project
+        :param models:         model name and paths
+        :param env:            dict of environment variables
+        :param tag:            version tag
+        :param verbose:        verbose output
+        :param use_function_from_db:  use the function from the DB instead of the local function object
+        """
         models = {} if models is None else models
         function_name = self.metadata.name or "function"
         name = f"deploy_{function_name}"
         project = project or self.metadata.project
         if models and isinstance(models, dict):
             models = [{"key": k, "model_path": v} for k, v in models.items()]
 
@@ -1011,33 +1069,33 @@
         if stop:
             for task in runs:
                 task.cancel()
         return results
 
     def _resolve_invocation_url(self, path, force_external_address):
 
-        if path.startswith("/"):
-            path = path[1:]
+        if not path.startswith("/") and path != "":
+            path = f"/{path}"
 
         # internal / external invocation urls is a nuclio >= 1.6.x feature
         # try to infer the invocation url from the internal and if not exists, use external.
         # $$$$ we do not want to use the external invocation url (e.g.: ingress, nodePort, etc.)
         if (
             not force_external_address
             and self.status.internal_invocation_urls
             and get_k8s_helper(
                 silent=True, log=False
             ).is_running_inside_kubernetes_cluster()
         ):
-            return f"http://{self.status.internal_invocation_urls[0]}/{path}"
+            return f"http://{self.status.internal_invocation_urls[0]}{path}"
 
         if self.status.external_invocation_urls:
-            return f"http://{self.status.external_invocation_urls[0]}/{path}"
+            return f"http://{self.status.external_invocation_urls[0]}{path}"
         else:
-            return f"http://{self.status.address}/{path}"
+            return f"http://{self.status.address}{path}"
 
     def _update_credentials_from_remote_build(self, remote_data):
         self.metadata.credentials = remote_data.get("metadata", {}).get(
             "credentials", {}
         )
 
         credentials_env_var_names = ["V3IO_ACCESS_KEY", "MLRUN_AUTH_SESSION"]
@@ -1075,14 +1133,36 @@
         # todo: create mock_server for Nuclio
         if enable:
             raise NotImplementedError(
                 "Mock (simulation) is currently not supported for Nuclio, Turn off the mock (mock=False) "
                 "and make sure Nuclio is installed for real deployment to Nuclio"
             )
 
+    def get_url(
+        self,
+        force_external_address: bool = False,
+        auth_info: AuthInfo = None,
+    ):
+        """
+        This method returns function's url.
+
+        :param force_external_address:   use the external ingress URL
+        :param auth_info:                service AuthInfo
+
+        :return: returns function's url
+        """
+        if not self.status.address:
+            state, _, _ = self._get_state(auth_info=auth_info)
+            if state != "ready" or not self.status.address:
+                raise ValueError(
+                    "no function address or not ready, first run .deploy()"
+                )
+
+        return self._resolve_invocation_url("", force_external_address)
+
 
 def parse_logs(logs):
     logs = json.loads(logs)
     lines = ""
     for line in logs:
         extra = []
         for key, value in line.items():
@@ -1126,39 +1206,85 @@
 def deploy_nuclio_function(
     function: RemoteRuntime,
     dashboard="",
     watch=False,
     auth_info: AuthInfo = None,
     client_version: str = None,
     builder_env: dict = None,
+    client_python_version: str = None,
 ):
+    """Deploys a nuclio function.
+
+    :param function:              nuclio function object
+    :param dashboard:             DEPRECATED. Keep empty to allow auto-detection by MLRun API.
+    :param watch:                 wait for function to be ready
+    :param auth_info:             service AuthInfo
+    :param client_version:        mlrun client version
+    :param builder_env:           mlrun builder environment (for config/credentials)
+    :param client_python_version: mlrun client python version
+    """
     dashboard = dashboard or mlconf.nuclio_dashboard_url
     function_name, project_name, function_config = compile_function_config(
-        function, client_version, builder_env or {}, auth_info=auth_info
+        function,
+        client_version=client_version,
+        client_python_version=client_python_version,
+        builder_env=builder_env or {},
+        auth_info=auth_info,
     )
 
     # if mode allows it, enrich function http trigger with an ingress
     enrich_function_with_ingress(
         function_config,
-        mlconf.httpdb.nuclio.add_templated_ingress_host_mode,
-        mlconf.httpdb.nuclio.default_service_type,
+        function.spec.add_templated_ingress_host_mode
+        or mlconf.httpdb.nuclio.add_templated_ingress_host_mode,
+        function.spec.service_type or mlconf.httpdb.nuclio.default_service_type,
     )
 
-    return nuclio.deploy.deploy_config(
-        function_config,
-        dashboard_url=dashboard,
-        name=function_name,
-        project=project_name,
-        tag=function.metadata.tag,
-        verbose=function.verbose,
-        create_new=True,
-        watch=watch,
-        return_address_mode=nuclio.deploy.ReturnAddressModes.all,
-        auth_info=auth_info.to_nuclio_auth_info() if auth_info else None,
-    )
+    try:
+        return nuclio.deploy.deploy_config(
+            function_config,
+            dashboard_url=dashboard,
+            name=function_name,
+            project=project_name,
+            tag=function.metadata.tag,
+            verbose=function.verbose,
+            create_new=True,
+            watch=watch,
+            return_address_mode=nuclio.deploy.ReturnAddressModes.all,
+            auth_info=auth_info.to_nuclio_auth_info() if auth_info else None,
+        )
+    except nuclio.utils.DeployError as exc:
+        if exc.err:
+            err_message = (
+                f"Failed to deploy nuclio function {project_name}/{function_name}"
+            )
+
+            try:
+
+                # the error might not be jsonable, so we'll try to parse it
+                # and extract the error message
+                json_err = exc.err.response.json()
+                if "error" in json_err:
+                    err_message += f" {json_err['error']}"
+                if "errorStackTrace" in json_err:
+                    logger.warning(
+                        "Failed to deploy nuclio function",
+                        nuclio_stacktrace=json_err["errorStackTrace"],
+                    )
+            except Exception as parse_exc:
+                logger.warning(
+                    "Failed to parse nuclio deploy error",
+                    parse_exc=err_to_str(parse_exc),
+                )
+
+            mlrun.errors.raise_for_status(
+                exc.err.response,
+                err_message,
+            )
+        raise
 
 
 def resolve_function_ingresses(function_spec):
     http_trigger = resolve_function_http_trigger(function_spec)
     if not http_trigger:
         return []
 
@@ -1173,53 +1299,90 @@
 def resolve_function_http_trigger(function_spec):
     for trigger_name, trigger_config in function_spec.get("triggers", {}).items():
         if trigger_config.get("kind") != "http":
             continue
         return trigger_config
 
 
+def _resolve_function_image_pull_secret(function):
+    """
+    the corresponding attribute for 'build.secret' in nuclio is imagePullSecrets, attached link for reference
+    https://github.com/nuclio/nuclio/blob/e4af2a000dc52ee17337e75181ecb2652b9bf4e5/pkg/processor/build/builder.go#L1073
+    if only one of the secrets is set, use it.
+    if both are set, use the non default one and give precedence to image_pull_secret
+    """
+    # enrich only on server side
+    if not is_running_as_api():
+        return function.spec.image_pull_secret or function.spec.build.secret
+
+    if function.spec.image_pull_secret is None:
+        function.spec.image_pull_secret = (
+            mlrun.mlconf.function.spec.image_pull_secret.default
+        )
+    elif (
+        function.spec.image_pull_secret
+        != mlrun.mlconf.function.spec.image_pull_secret.default
+    ):
+        return function.spec.image_pull_secret
+
+    if function.spec.build.secret is None:
+        function.spec.build.secret = mlrun.mlconf.httpdb.builder.docker_registry_secret
+    elif (
+        function.spec.build.secret != mlrun.mlconf.httpdb.builder.docker_registry_secret
+    ):
+        return function.spec.build.secret
+
+    return function.spec.image_pull_secret or function.spec.build.secret
+
+
 def compile_function_config(
     function: RemoteRuntime,
     client_version: str = None,
+    client_python_version: str = None,
     builder_env=None,
     auth_info=None,
 ):
     labels = function.metadata.labels or {}
     labels.update({"mlrun/class": function.kind})
     for key, value in labels.items():
-        function.set_config(f"metadata.labels.{key}", value)
+        # Adding escaping to the key to prevent it from being split by dots if it contains any
+        function.set_config(f"metadata.labels.\\{key}\\", value)
 
     # Add secret configurations to function's pod spec, if secret sources were added.
     # Needs to be here, since it adds env params, which are handled in the next lines.
     # This only needs to run if we're running within k8s context. If running in Docker, for example, skip.
     if get_k8s_helper(silent=True).is_running_inside_kubernetes_cluster():
         function.add_secrets_config_to_spec()
 
     env_dict, external_source_env_dict = function._get_nuclio_config_spec_env()
+
     nuclio_runtime = (
-        function.spec.nuclio_runtime or mlrun.config.config.default_nuclio_runtime
+        function.spec.nuclio_runtime
+        or _resolve_nuclio_runtime_python_image(
+            mlrun_client_version=client_version, python_version=client_python_version
+        )
     )
+
     if is_nuclio_version_in_range("0.0.0", "1.6.0") and nuclio_runtime in [
         "python:3.7",
         "python:3.8",
     ]:
         nuclio_runtime_set_from_spec = nuclio_runtime == function.spec.nuclio_runtime
         if nuclio_runtime_set_from_spec:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 f"Nuclio version does not support the configured runtime: {nuclio_runtime}"
             )
         else:
-            # our default is python:3.7, simply set it to python:3.6 to keep supporting envs with old Nuclio
+            # our default is python:3.9, simply set it to python:3.6 to keep supporting envs with old Nuclio
             nuclio_runtime = "python:3.6"
 
-    # In nuclio 1.6.0<=v<1.8.0 python 3.7 and 3.8 runtime default behavior was to not decode event strings
+    # In nuclio 1.6.0<=v<1.8.0, python runtimes default behavior was to not decode event strings
     # Our code is counting on the strings to be decoded, so add the needed env var for those versions
     if (
-        nuclio_runtime in ["python:3.7", "python:3.8", "python"]
-        and is_nuclio_version_in_range("1.6.0", "1.8.0")
+        is_nuclio_version_in_range("1.6.0", "1.8.0")
         and "NUCLIO_PYTHON_DECODE_EVENT_STRINGS" not in env_dict
     ):
         env_dict["NUCLIO_PYTHON_DECODE_EVENT_STRINGS"] = "true"
 
     nuclio_spec = nuclio.ConfigSpec(
         env=env_dict,
         external_source_env=external_source_env_dict,
@@ -1235,32 +1398,34 @@
             nuclio_spec, function, builder_env, project, auth_info=auth_info
         )
 
     nuclio_spec.set_config("spec.runtime", nuclio_runtime)
 
     # In Nuclio >= 1.6.x default serviceType has changed to "ClusterIP".
     nuclio_spec.set_config(
-        "spec.serviceType", mlconf.httpdb.nuclio.default_service_type
+        "spec.serviceType",
+        function.spec.service_type or mlconf.httpdb.nuclio.default_service_type,
     )
     if function.spec.readiness_timeout:
         nuclio_spec.set_config(
             "spec.readinessTimeoutSeconds", function.spec.readiness_timeout
         )
     if function.spec.resources:
         nuclio_spec.set_config("spec.resources", function.spec.resources)
     if function.spec.no_cache:
         nuclio_spec.set_config("spec.build.noCache", True)
     if function.spec.build.functionSourceCode:
         nuclio_spec.set_config(
             "spec.build.functionSourceCode", function.spec.build.functionSourceCode
         )
-    # the corresponding attribute for build.secret in nuclio is imagePullSecrets, attached link for reference
-    # https://github.com/nuclio/nuclio/blob/e4af2a000dc52ee17337e75181ecb2652b9bf4e5/pkg/processor/build/builder.go#L1073
-    if function.spec.build.secret:
-        nuclio_spec.set_config("spec.imagePullSecrets", function.spec.build.secret)
+
+    image_pull_secret = _resolve_function_image_pull_secret(function)
+    if image_pull_secret:
+        nuclio_spec.set_config("spec.imagePullSecrets", image_pull_secret)
+
     if function.spec.base_image_pull:
         nuclio_spec.set_config("spec.build.noBaseImagesPull", False)
     # don't send node selections if nuclio is not compatible
     if validate_nuclio_version_compatibility("1.5.20", "1.6.10"):
         if function.spec.node_selector:
             nuclio_spec.set_config("spec.nodeSelector", function.spec.node_selector)
         if function.spec.node_name:
@@ -1340,26 +1505,27 @@
             # we create the base spec with essential attributes
             config = nuclio.config.new_config()
             update_in(config, "spec.handler", handler or "main:handler")
 
         config = nuclio.config.extend_config(
             config, nuclio_spec, tag, function.spec.build.code_origin
         )
+
         update_in(config, "metadata.name", function.metadata.name)
         update_in(config, "spec.volumes", function.spec.generate_nuclio_volumes())
         base_image = (
             get_in(config, "spec.build.baseImage")
             or function.spec.image
             or function.spec.build.base_image
         )
         if base_image:
             update_in(
                 config,
                 "spec.build.baseImage",
-                enrich_image_url(base_image, client_version),
+                enrich_image_url(base_image, client_version, client_python_version),
             )
 
         logger.info("deploy started")
         name = get_fullname(function.metadata.name, project, tag)
         function.status.nuclio_name = name
         update_in(config, "metadata.name", name)
 
@@ -1400,15 +1566,15 @@
 
         update_in(config, "spec.volumes", function.spec.generate_nuclio_volumes())
         base_image = function.spec.image or function.spec.build.base_image
         if base_image:
             update_in(
                 config,
                 "spec.build.baseImage",
-                enrich_image_url(base_image, client_version),
+                enrich_image_url(base_image, client_version, client_python_version),
             )
 
         name = get_fullname(name, project, tag)
         function.status.nuclio_name = name
 
         update_in(config, "metadata.name", name)
 
@@ -1467,29 +1633,62 @@
     tag,
     dashboard="",
     last_log_timestamp=0,
     verbose=False,
     resolve_address=True,
     auth_info: AuthInfo = None,
 ):
+    """
+    Get nuclio function deploy status
+
+    :param name:                function name
+    :param project:             project name
+    :param tag:                 function tag
+    :param dashboard:           DEPRECATED. Keep empty to allow auto-detection by MLRun API.
+    :param last_log_timestamp:  last log timestamp
+    :param verbose:             print logs
+    :param resolve_address:     whether to resolve function address
+    :param auth_info:           authentication information
+    """
     api_address = find_dashboard_url(dashboard or mlconf.nuclio_dashboard_url)
     name = get_fullname(name, project, tag)
+    get_err_message = f"Failed to get function {name} deploy status"
 
-    state, address, last_log_timestamp, outputs, function_status = get_deploy_status(
-        api_address,
-        name,
-        last_log_timestamp,
-        verbose,
-        resolve_address,
-        return_function_status=True,
-        auth_info=auth_info.to_nuclio_auth_info() if auth_info else None,
-    )
-
-    text = "\n".join(outputs) if outputs else ""
-    return state, address, name, last_log_timestamp, text, function_status
+    try:
+        (
+            state,
+            address,
+            last_log_timestamp,
+            outputs,
+            function_status,
+        ) = get_deploy_status(
+            api_address,
+            name,
+            last_log_timestamp,
+            verbose,
+            resolve_address,
+            return_function_status=True,
+            auth_info=auth_info.to_nuclio_auth_info() if auth_info else None,
+        )
+    except requests.exceptions.ConnectionError as exc:
+        mlrun.errors.raise_for_status(
+            exc.response,
+            get_err_message,
+        )
+
+    except nuclio.utils.DeployError as exc:
+        if exc.err:
+            mlrun.errors.raise_for_status(
+                exc.err.response,
+                get_err_message,
+            )
+        raise exc
+    else:
+        text = "\n".join(outputs) if outputs else ""
+        return state, address, name, last_log_timestamp, text, function_status
 
 
 def _compile_nuclio_archive_config(
     nuclio_spec,
     function: RemoteRuntime,
     builder_env,
     project=None,
@@ -1554,15 +1753,17 @@
     # git
     if code_entry_type == "git":
 
         # change git:// to https:// as nuclio expects it to be
         if source.startswith("git://"):
             source = source.replace("git://", "https://")
 
-        source, reference, branch = _resolve_git_reference_from_source(source)
+        source, reference, branch = mlrun.utils.resolve_git_reference_from_source(
+            source
+        )
         if not branch and not reference:
             raise mlrun.errors.MLRunInvalidArgumentError(
                 "git branch or refs must be specified in the source e.g.: "
                 "'git://<url>/org/repo.git#<branch-name or refs/heads/..>'"
             )
         if reference:
             code_entry_attributes["reference"] = reference
@@ -1570,41 +1771,26 @@
             code_entry_attributes["branch"] = branch
 
         password = get_secret("GIT_PASSWORD")
         username = get_secret("GIT_USERNAME")
 
         token = get_secret("GIT_TOKEN")
         if token:
-            username, password = get_git_username_password_from_token(token)
+            username, password = mlrun.utils.get_git_username_password_from_token(token)
 
         code_entry_attributes["username"] = username
         code_entry_attributes["password"] = password
 
     # populate spec with relevant fields
     nuclio_spec.set_config("spec.handler", handler)
     nuclio_spec.set_config("spec.build.path", source)
     nuclio_spec.set_config("spec.build.codeEntryType", code_entry_type)
     nuclio_spec.set_config("spec.build.codeEntryAttributes", code_entry_attributes)
 
 
-def _resolve_git_reference_from_source(source):
-    # kaniko allow multiple "#" e.g. #refs/..#commit
-    split_source = source.split("#", 1)
-
-    # no reference was passed
-    if len(split_source) < 2:
-        return source, "", ""
-
-    reference = split_source[1]
-    if reference.startswith("refs/"):
-        return split_source[0], reference, ""
-
-    return split_source[0], "", reference
-
-
 def _resolve_work_dir_and_handler(handler):
     """
     Resolves a nuclio function working dir and handler inside an archive/git repo
     :param handler: a path describing working dir and handler of a nuclio function
     :return: (working_dir, handler) tuple, as nuclio expects to get it
 
     Example: ("a/b/c#main:Handler") -> ("a/b/c", "main:Handler")
@@ -1622,7 +1808,40 @@
         return "", "main:handler"
 
     split_handler = handler.split("#")
     if len(split_handler) == 1:
         return "", extend_handler(handler)
 
     return split_handler[0], extend_handler(split_handler[1])
+
+
+def _resolve_nuclio_runtime_python_image(
+    mlrun_client_version: str = None, python_version: str = None
+):
+    # if no python version or mlrun version is passed it means we use mlrun client older than 1.3.0 therefore need
+    # to use the previoud default runtime which is python 3.7
+    if not python_version or not mlrun_client_version:
+        return "python:3.7"
+
+    # If the mlrun version is 0.0.0-<unstable>, it is a dev version,
+    # so we can't check if it is higher than 1.3.0, but if the python version was passed,
+    # it means it is 1.3.0-rc or higher, so use the image according to the python version
+    if mlrun_client_version.startswith("0.0.0-") or "unstable" in mlrun_client_version:
+        if python_version.startswith("3.7"):
+            return "python:3.7"
+
+        return mlrun.mlconf.default_nuclio_runtime
+
+    # if mlrun version is older than 1.3.0 we need to use the previous default runtime which is python 3.7
+    if semver.VersionInfo.parse(mlrun_client_version) < semver.VersionInfo.parse(
+        "1.3.0-X"
+    ):
+        return "python:3.7"
+
+    # if mlrun version is 1.3.0 or newer and python version is 3.7 we need to use python 3.7 image
+    if semver.VersionInfo.parse(mlrun_client_version) >= semver.VersionInfo.parse(
+        "1.3.0-X"
+    ) and python_version.startswith("3.7"):
+        return "python:3.7"
+
+    # if none of the above conditions are met we use the default runtime which is python 3.9
+    return mlrun.mlconf.default_nuclio_runtime
```

## mlrun/runtimes/kubejob.py

```diff
@@ -10,30 +10,29 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import os
 import time
-import typing
 
 from kubernetes import client
 from kubernetes.client.rest import ApiException
 
 import mlrun.api.schemas
 import mlrun.errors
 from mlrun.runtimes.base import BaseRuntimeHandler
 
 from ..builder import build_runtime
 from ..db import RunDBError
 from ..errors import err_to_str
 from ..kfpops import build_op
 from ..model import RunObject
 from ..utils import get_in, logger
-from .base import RunError
+from .base import RunError, RuntimeClassMode
 from .pod import KubeResource, kube_resource_spec_to_pod_spec
 from .utils import AsyncLogWriter
 
 
 class KubejobRuntime(KubeResource):
     kind = "job"
     _is_nested = True
@@ -55,43 +54,47 @@
         if self.spec.image:
             return True
         if self.status.state and self.status.state == "ready":
             return True
         return False
 
     def with_source_archive(
-        self, source, workdir=None, handler=None, pull_at_runtime=True
+        self, source, workdir=None, handler=None, pull_at_runtime=True, target_dir=None
     ):
         """load the code from git/tar/zip archive at runtime or build
 
-        :param source:     valid path to git, zip, or tar file, e.g.
-                           git://github.com/mlrun/something.git
-                           http://some/url/file.zip
-        :param handler: default function handler
-        :param workdir: working dir relative to the archive root or absolute (e.g. './subdir')
+        :param source:          valid path to git, zip, or tar file, e.g.
+                                git://github.com/mlrun/something.git
+                                http://some/url/file.zip
+        :param handler:         default function handler
+        :param workdir:         working dir relative to the archive root (e.g. './subdir') or absolute to the image root
         :param pull_at_runtime: load the archive into the container at job runtime vs on build/deploy
+        :param target_dir:      target dir on runtime pod or repo clone / archive extraction
         """
         if source.endswith(".zip") and not pull_at_runtime:
             logger.warn(
                 "zip files are not natively extracted by docker, use tar.gz for faster loading during build"
             )
 
         self.spec.build.source = source
         if handler:
             self.spec.default_handler = handler
         if workdir:
             self.spec.workdir = workdir
+        if target_dir:
+            self.spec.clone_target_dir = target_dir
+
         self.spec.build.load_source_on_run = pull_at_runtime
         if (
             self.spec.build.base_image
             and not self.spec.build.commands
             and pull_at_runtime
             and not self.spec.image
         ):
-            # if we load source from repo and dont need a full build use the base_image as the image
+            # if we load source from repo and don't need a full build use the base_image as the image
             self.spec.image = self.spec.build.base_image
         elif not pull_at_runtime:
             # clear the image so build will not be skipped
             self.spec.build.base_image = self.spec.build.base_image or self.spec.image
             self.spec.image = ""
 
     def build_config(
@@ -142,15 +145,15 @@
             self.with_requirements(
                 requirements, overwrite=False, verify_base_image=False
             )
         if commands:
             self.with_commands(commands, overwrite=False, verify_base_image=False)
         if extra:
             self.spec.build.extra = extra
-        if secret:
+        if secret is not None:
             self.spec.build.secret = secret
         if source:
             self.spec.build.source = source
         if load_source_on_run:
             self.spec.build.load_source_on_run = load_source_on_run
         if with_mlrun is not None:
             self.spec.build.with_mlrun = with_mlrun
@@ -168,21 +171,22 @@
         is_kfp=False,
         mlrun_version_specifier=None,
         builder_env: dict = None,
         show_on_failure: bool = False,
     ) -> bool:
         """deploy function, build container with dependencies
 
-        :param watch:      wait for the deploy to complete (and print build logs)
-        :param with_mlrun: add the current mlrun package to the container build
-        :param skip_deployed: skip the build if we already have an image for the function
-        :param mlrun_version_specifier:  which mlrun package version to include (if not current)
-        :param builder_env:   Kaniko builder pod env vars dict (for config/credentials)
-                              e.g. builder_env={"GIT_TOKEN": token}
-        :param show_on_failure:  show logs only in case of build failure
+        :param watch:                   wait for the deploy to complete (and print build logs)
+        :param with_mlrun:              add the current mlrun package to the container build
+        :param skip_deployed:           skip the build if we already have an image for the function
+        :param is_kfp:                  deploy as part of a kfp pipeline
+        :param mlrun_version_specifier: which mlrun package version to include (if not current)
+        :param builder_env:             Kaniko builder pod env vars dict (for config/credentials)
+                                        e.g. builder_env={"GIT_TOKEN": token}
+        :param show_on_failure:         show logs only in case of build failure
 
         :return True if the function is ready (deployed)
         """
 
         build = self.spec.build
 
         if with_mlrun is None:
@@ -219,14 +223,16 @@
                 builder_env=builder_env,
             )
             self.status = data["data"].get("status", None)
             self.spec.image = get_in(data, "data.spec.image")
             self.spec.build.base_image = self.spec.build.base_image or get_in(
                 data, "data.spec.build.base_image"
             )
+            # get the clone target dir in case it was enriched due to loading source
+            self.spec.clone_target_dir = get_in(data, "data.spec.clone_target_dir")
             ready = data.get("ready", False)
             if not ready:
                 logger.info(
                     f"Started building image: {data.get('data', {}).get('spec', {}).get('build', {}).get('image')}"
                 )
             if watch and not ready:
                 state = self._build_watch(watch, show_on_failure=show_on_failure)
@@ -340,26 +346,22 @@
 
         if runobj.metadata.iteration:
             self.store_run(runobj)
         k8s = self._get_k8s()
         new_meta = self._get_meta(runobj)
 
         self._add_secrets_to_spec_before_running(runobj)
-        workdir = self.spec.workdir
-        if workdir:
-            if self.spec.build.source and self.spec.build.load_source_on_run:
-                # workdir will be set AFTER the clone
-                workdir = None
-            elif not workdir.startswith("/"):
-                # relative path mapped to real path in the job pod
-                workdir = os.path.join("/mlrun", workdir)
+        workdir = self._resolve_workdir()
 
         pod_spec = func_to_pod(
             self.full_image_path(
-                client_version=runobj.metadata.labels.get("mlrun/client_version")
+                client_version=runobj.metadata.labels.get("mlrun/client_version"),
+                client_python_version=runobj.metadata.labels.get(
+                    "mlrun/client_python_version"
+                ),
             ),
             self,
             extra_env,
             command,
             args,
             workdir,
         )
@@ -378,14 +380,39 @@
         else:
             txt = f"Job is running in the background, pod: {pod_name}"
             logger.info(txt)
             runobj.status.status_text = txt
 
         return None
 
+    def _resolve_workdir(self):
+        """
+        The workdir is relative to the source root, if the source is not loaded on run then the workdir
+        is relative to the clone target dir (where the source was copied to).
+        Otherwise, if the source is loaded on run, the workdir is resolved on the run as well.
+        If the workdir is absolute, keep it as is.
+        """
+        workdir = self.spec.workdir
+        if self.spec.build.source and self.spec.build.load_source_on_run:
+            # workdir will be set AFTER the clone which is done in the pre-run of local runtime
+            return None
+
+        if workdir and os.path.isabs(workdir):
+            return workdir
+
+        if self.spec.clone_target_dir:
+            workdir = workdir or ""
+            if workdir.startswith("./"):
+                # TODO: use 'removeprefix' when we drop python 3.7 support
+                # workdir.removeprefix("./")
+                workdir = workdir[2:]
+            return os.path.join(self.spec.clone_target_dir, workdir)
+
+        return workdir
+
 
 def func_to_pod(image, runtime, extra_env, command, args, workdir):
     container = client.V1Container(
         name="base",
         image=image,
         env=extra_env + runtime.spec.env,
         command=[command],
@@ -404,14 +431,15 @@
         ]
 
     return pod_spec
 
 
 class KubeRuntimeHandler(BaseRuntimeHandler):
     kind = "job"
+    class_modes = {RuntimeClassMode.run: "job", RuntimeClassMode.build: "build"}
 
     @staticmethod
     def _expect_pods_without_uid() -> bool:
         """
         builder pods are handled as part of this runtime handler - they are not coupled to run object, therefore they
         don't have the uid in their labels
         """
@@ -420,11 +448,7 @@
     @staticmethod
     def _are_resources_coupled_to_run_object() -> bool:
         return True
 
     @staticmethod
     def _get_object_label_selector(object_id: str) -> str:
         return f"mlrun/uid={object_id}"
-
-    @staticmethod
-    def _get_possible_mlrun_class_label_values() -> typing.List[str]:
-        return ["build", "job"]
```

## mlrun/runtimes/local.py

```diff
@@ -10,19 +10,21 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import importlib.util as imputil
 import inspect
+import io
 import json
 import os
 import socket
 import sys
 import tempfile
+import threading
 import traceback
 from contextlib import redirect_stdout
 from copy import copy
 from io import StringIO
 from os import environ, remove
 from pathlib import Path
 from subprocess import PIPE, Popen
@@ -35,15 +37,15 @@
 from mlrun.lists import RunList
 
 from ..errors import err_to_str
 from ..execution import MLClientCtx
 from ..model import RunObject
 from ..utils import get_handler_extended, get_in, logger, set_paths
 from ..utils.clones import extract_source
-from .base import BaseRuntime, FunctionSpec, spec_fields
+from .base import BaseRuntime
 from .kubejob import KubejobRuntime
 from .remotesparkjob import RemoteSparkRuntime
 from .utils import RunError, global_context, log_std
 
 
 class ParallelRunner:
     def _get_handler(self, handler, context):
@@ -166,72 +168,34 @@
         )
         global_context.set(context)
         sout, serr = exec_from_params(handler, runobj, context, self.spec.workdir)
         log_std(self._db_conn, runobj, sout, serr, show=False)
         return context.to_dict()
 
 
-class LocalFunctionSpec(FunctionSpec):
-    _dict_fields = spec_fields + ["clone_target_dir"]
-
-    def __init__(
-        self,
-        command=None,
-        args=None,
-        mode=None,
-        default_handler=None,
-        pythonpath=None,
-        entry_points=None,
-        description=None,
-        workdir=None,
-        build=None,
-        clone_target_dir=None,
-    ):
-        super().__init__(
-            command=command,
-            args=args,
-            mode=mode,
-            build=build,
-            entry_points=entry_points,
-            description=description,
-            workdir=workdir,
-            default_handler=default_handler,
-            pythonpath=pythonpath,
-        )
-        self.clone_target_dir = clone_target_dir
-
-
 class LocalRuntime(BaseRuntime, ParallelRunner):
     kind = "local"
     _is_remote = False
 
-    @property
-    def spec(self) -> LocalFunctionSpec:
-        return self._spec
-
-    @spec.setter
-    def spec(self, spec):
-        self._spec = self._verify_dict(spec, "spec", LocalFunctionSpec)
-
     def to_job(self, image=""):
         struct = self.to_dict()
         obj = KubejobRuntime.from_dict(struct)
         if image:
             obj.spec.image = image
         return obj
 
     def with_source_archive(self, source, workdir=None, handler=None, target_dir=None):
         """load the code from git/tar/zip archive at runtime or build
 
-        :param source:     valid path to git, zip, or tar file, e.g.
-                           git://github.com/mlrun/something.git
-                           http://some/url/file.zip
-        :param handler: default function handler
-        :param workdir: working dir relative to the archive root or absolute (e.g. './subdir')
-        :param target_dir: local target dir for repo clone (by default its <current-dir>/code)
+        :param source:      valid path to git, zip, or tar file, e.g.
+                            git://github.com/mlrun/something.git
+                            http://some/url/file.zip
+        :param handler:     default function handler
+        :param workdir:     working dir relative to the archive root (e.g. './subdir') or absolute
+        :param target_dir:  local target dir for repo clone (by default its <current-dir>/code)
         """
         self.spec.build.source = source
         self.spec.build.load_source_on_run = True
         if handler:
             self.spec.default_handler = handler
         if workdir:
             self.spec.workdir = workdir
@@ -392,29 +356,46 @@
 
     return get_handler_extended(handler, context, class_args, namespaces=module)
 
 
 def run_exec(cmd, args, env=None, cwd=None):
     if args:
         cmd += args
-    out = ""
     if env and "SYSTEMROOT" in os.environ:
         env["SYSTEMROOT"] = os.environ["SYSTEMROOT"]
     print("running:", cmd)
-    process = Popen(cmd, stdout=PIPE, stderr=PIPE, env=os.environ, cwd=cwd)
-    while True:
-        nextline = process.stdout.readline()
-        if not nextline and process.poll() is not None:
-            break
-        print(nextline.decode("utf-8"), end="")
-        sys.stdout.flush()
-        out += nextline.decode("utf-8")
-    code = process.poll()
+    process = Popen(
+        cmd, stdout=PIPE, stderr=PIPE, env=os.environ, cwd=cwd, universal_newlines=True
+    )
+
+    def read_stderr(stderr):
+        while True:
+            nextline = process.stderr.readline()
+            if not nextline:
+                break
+            stderr.write(nextline)
+
+    # ML-3710. We must read stderr in a separate thread to drain the stderr pipe so that the spawned process won't
+    # hang if it tries to write more to stderr than the buffer size (default of approx 8kb).
+    with io.StringIO() as stderr:
+        stderr_consumer_thread = threading.Thread(target=read_stderr, args=[stderr])
+        stderr_consumer_thread.start()
+
+        with io.StringIO() as stdout:
+            while True:
+                nextline = process.stdout.readline()
+                if not nextline:
+                    break
+                print(nextline, end="")
+                sys.stdout.flush()
+                stdout.write(nextline)
+            out = stdout.getvalue()
 
-    err = process.stderr.read().decode("utf-8") if code != 0 else ""
+        stderr_consumer_thread.join()
+        err = stderr.getvalue()
     return out, err
 
 
 class _DupStdout(object):
     def __init__(self):
         self.terminal = sys.stdout
         self.buf = StringIO()
@@ -427,40 +408,60 @@
         self.terminal.flush()
 
 
 def exec_from_params(handler, runobj: RunObject, context: MLClientCtx, cwd=None):
     old_level = logger.level
     if runobj.spec.verbose:
         logger.set_logger_level("DEBUG")
+
+    # Prepare the inputs type hints (user may pass type hints as part of the inputs keys):
+    runobj.spec.extract_type_hints_from_inputs()
+    # Read the keyword arguments to pass to the function (combining params and inputs from the run spec):
     kwargs = get_func_arg(handler, runobj, context)
 
     stdout = _DupStdout()
     err = ""
     val = None
     old_dir = os.getcwd()
     with redirect_stdout(stdout):
         context.set_logger_stream(stdout)
         try:
             if cwd:
                 os.chdir(cwd)
-            val = handler(**kwargs)
+            # Apply the MLRun handler decorator for parsing inputs using type hints and logging outputs using log hints
+            # (Expected behavior: inputs are being parsed when they have type hints in code or given by user.
+            # outputs are logged only if log hints are provided by the user):
+            val = mlrun.handler(
+                inputs=(
+                    runobj.spec.inputs_type_hints
+                    if runobj.spec.inputs_type_hints
+                    else True  # True will use type hints if provided in user's code.
+                ),
+                outputs=(
+                    runobj.spec.returns
+                    if runobj.spec.returns
+                    else None  # None will turn off outputs logging.
+                ),
+            )(handler)(**kwargs)
             context.set_state("completed", commit=False)
         except Exception as exc:
             err = err_to_str(exc)
             logger.error(f"execution error, {traceback.format_exc()}")
             context.set_state(error=err, commit=False)
             logger.set_logger_level(old_level)
 
     stdout.flush()
     if cwd:
         os.chdir(old_dir)
     context.set_logger_stream(sys.stdout)
     if val:
         context.log_result("return", val)
-    context.commit()
+
+    # completion will be ignored if error is set
+    context.commit(completed=True)
     logger.set_logger_level(old_level)
     return stdout.buf.getvalue(), err
 
 
 def get_func_arg(handler, runobj: RunObject, context: MLClientCtx, is_nuclio=False):
     params = runobj.spec.parameters or {}
     inputs = runobj.spec.inputs or {}
```

## mlrun/runtimes/pod.py

```diff
@@ -16,14 +16,15 @@
 import typing
 import uuid
 from enum import Enum
 
 import dotenv
 import kfp.dsl
 import kubernetes.client as k8s_client
+from deprecated import deprecated
 
 import mlrun.errors
 import mlrun.utils.regex
 
 from ..api.schemas import (
     NodeSelectorOperator,
     PreemptionModes,
@@ -45,14 +46,15 @@
     get_item_name,
     get_resource_labels,
     set_named_item,
     verify_limits,
     verify_requests,
 )
 
+# TODO: add env attribute to the sanitized types
 sanitized_types = {
     "affinity": {
         "attribute_type_name": "V1Affinity",
         "attribute_type": k8s_client.V1Affinity,
         "sub_attribute_type": None,
         "contains_many": False,
         "not_sanitized_class": dict,
@@ -129,32 +131,35 @@
         node_selector=None,
         affinity=None,
         disable_auto_mount=False,
         priority_class_name=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        clone_target_dir=None,
     ):
         super().__init__(
             command=command,
             args=args,
             image=image,
             mode=mode,
             build=build,
             entry_points=entry_points,
             description=description,
             workdir=workdir,
             default_handler=default_handler,
             pythonpath=pythonpath,
             disable_auto_mount=disable_auto_mount,
+            clone_target_dir=clone_target_dir,
         )
         self._volumes = {}
         self._volume_mounts = {}
         self.volumes = volumes or []
         self.volume_mounts = volume_mounts or []
+        # TODO: add env attribute to the sanitized types
         self.env = env or []
         self._resources = self.enrich_resources_with_default_pod_resources(
             "resources", resources
         )
 
         self.replicas = replicas
         self.image_pull_policy = image_pull_policy
@@ -274,17 +279,14 @@
             and self.service_account not in allowed_service_accounts
         ):
             raise mlrun.errors.MLRunInvalidArgumentError(
                 f"Function service account {self.service_account} is not in allowed "
                 + f"service accounts {allowed_service_accounts}"
             )
 
-    def _get_affinity_as_k8s_class_instance(self):
-        pass
-
     def _set_volume_mount(
         self, volume_mount, volume_mounts_field_name="_volume_mounts"
     ):
         # using the mountPath as the key cause it must be unique (k8s limitation)
         # volume_mount may be an V1VolumeMount instance (object access, snake case) or sanitized dict (dict
         # access, camel case)
         getattr(self, volume_mounts_field_name)[
@@ -904,15 +906,15 @@
                         ev["value"] = ""
             # Reset this, since mounts and env variables were cleared.
             spec["disable_auto_mount"] = False
         return struct
 
     def apply(self, modify):
         """
-        Apply a modifier to the runtime which is used to change the runtime's k8s object's spec.
+        Apply a modifier to the runtime which is used to change the runtimes k8s object's spec.
         Modifiers can be either KFP modifiers or MLRun modifiers (which are compatible with KFP). All modifiers accept
         a `kfp.dsl.ContainerOp` object, apply some changes on its spec and return it so modifiers can be chained
         one after the other.
 
         :param modify: a modifier runnable object
         :return: the runtime (self) after the modifications
         """
@@ -947,18 +949,21 @@
         return self
 
     def get_env(self, name, default=None):
         """Get the pod environment variable for the given name, if not found return the default
         If it's a scalar value, will return it, if the value is from source, return the k8s struct (V1EnvVarSource)"""
         for env_var in self.spec.env:
             if get_item_name(env_var) == name:
-                value = get_item_name(env_var, "value")
-                if value is not None:
-                    return value
-                return get_item_name(env_var, "value_from")
+                # valueFrom is a workaround for now, for some reason the envs aren't getting sanitized
+                # TODO: add env to sanitized attributes and then remove the valueFrom as the sanitized env will have
+                #   value_from key and not valueFrom
+                for value_key in ["value", "value_from", "valueFrom"]:
+                    value = get_item_name(env_var, value_key)
+                    if value is not None:
+                        return value
         return default
 
     def is_env_exists(self, name):
         """Check whether there is an environment variable define for the given key"""
         for env_var in self.spec.env:
             if get_item_name(env_var) == name:
                 return True
@@ -992,14 +997,20 @@
                     "env file lines must be in the form key=value"
                 )
 
         for name, value in env_vars.items():
             self.set_env(name, value)
         return self
 
+    # TODO: Remove in 1.5.0
+    @deprecated(
+        version="1.3.0",
+        reason="'Job gpus' will be removed in 1.5.0, use 'with_limits' instead",
+        category=FutureWarning,
+    )
     def gpus(self, gpus, gpu_type="nvidia.com/gpu"):
         update_in(self.spec.resources, ["limits", gpu_type], gpus)
 
     def set_image_pull_configuration(
         self, image_pull_policy: str = None, image_pull_secret_name: str = None
     ):
         """
@@ -1169,19 +1180,19 @@
         if self._secrets:
             if self._secrets.has_vault_source():
                 self._add_vault_params_to_spec(runobj=runobj, project=project)
             if self._secrets.has_azure_vault_source():
                 self._add_azure_vault_params_to_spec(
                     self._secrets.get_azure_vault_k8s_secret()
                 )
-            self._add_project_k8s_secrets_to_spec(
+            self._add_k8s_secrets_to_spec(
                 self._secrets.get_k8s_secrets(), runobj=runobj, project=project
             )
         else:
-            self._add_project_k8s_secrets_to_spec(None, runobj=runobj, project=project)
+            self._add_k8s_secrets_to_spec(None, runobj=runobj, project=project)
 
     def _add_azure_vault_params_to_spec(self, k8s_secret_name=None):
         secret_name = (
             k8s_secret_name or mlconf.secret_stores.azure_vault.default_secret_name
         )
         if not secret_name:
             logger.warning(
@@ -1197,17 +1208,36 @@
                 "name": "azure-vault-secret",
                 "secret": {"defaultMode": 420, "secretName": secret_name},
             }
         ]
         volume_mounts = [{"name": "azure-vault-secret", "mountPath": secret_path}]
         self.spec.update_vols_and_mounts(volumes, volume_mounts)
 
-    def _add_project_k8s_secrets_to_spec(
-        self, secrets, runobj=None, project=None, encode_key_names=True
+    def _add_k8s_secrets_to_spec(
+        self,
+        secrets,
+        runobj=None,
+        project=None,
+        encode_key_names=True,
     ):
+        # Check if we need to add the keys of a global secret. Global secrets are intentionally added before
+        # project secrets, to allow project secret keys to override them
+        global_secret_name = (
+            mlconf.secret_stores.kubernetes.global_function_env_secret_name
+        )
+        if mlrun.config.is_running_as_api() and global_secret_name:
+            global_secrets = self._get_k8s().get_secret_data(global_secret_name)
+            for key, value in global_secrets.items():
+                env_var_name = (
+                    SecretsStore.k8s_env_variable_name_for_secret(key)
+                    if encode_key_names
+                    else key
+                )
+                self.set_env_from_secret(env_var_name, global_secret_name, key)
+
         # the secrets param may be an empty dictionary (asking for all secrets of that project) -
         # it's a different case than None (not asking for project secrets at all).
         if (
             secrets is None
             and not mlconf.secret_stores.kubernetes.auto_add_project_secrets
         ):
             return
```

## mlrun/runtimes/remotesparkjob.py

```diff
@@ -8,24 +8,24 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import re
-import typing
 from subprocess import run
 
 import kubernetes.client
 
 import mlrun.errors
 from mlrun.config import config
 
 from ..model import RunObject
-from ..platforms.iguazio import mount_v3io_extended, mount_v3iod
+from ..platforms.iguazio import mount_v3io, mount_v3iod
+from .base import RuntimeClassMode
 from .kubejob import KubejobRuntime, KubeRuntimeHandler
 from .pod import KubeResourceSpec
 
 
 class RemoteSparkSpec(KubeResourceSpec):
     _dict_fields = KubeResourceSpec._dict_fields + ["provider"]
 
@@ -54,14 +54,15 @@
         affinity=None,
         priority_class_name=None,
         disable_auto_mount=False,
         pythonpath=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        clone_target_dir=None,
     ):
         super().__init__(
             command=command,
             args=args,
             image=image,
             mode=mode,
             volumes=volumes,
@@ -82,14 +83,15 @@
             affinity=affinity,
             priority_class_name=priority_class_name,
             disable_auto_mount=disable_auto_mount,
             pythonpath=pythonpath,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            clone_target_dir=clone_target_dir,
         )
         self.provider = provider
 
 
 class RemoteSparkProviders(object):
     iguazio = "iguazio"
 
@@ -135,15 +137,15 @@
     def with_spark_service(self, spark_service, provider=RemoteSparkProviders.iguazio):
         """Attach spark service to function"""
         self.spec.provider = provider
         if provider == RemoteSparkProviders.iguazio:
             self.spec.env.append(
                 {"name": "MLRUN_SPARK_CLIENT_IGZ_SPARK", "value": "true"}
             )
-            self.apply(mount_v3io_extended())
+            self.apply(mount_v3io())
             self.apply(
                 mount_v3iod(
                     namespace=config.namespace,
                     v3io_config_configmap=spark_service + "-submit",
                 )
             )
 
@@ -174,52 +176,52 @@
     def deploy(
         self,
         watch=True,
         with_mlrun=None,
         skip_deployed=False,
         is_kfp=False,
         mlrun_version_specifier=None,
+        builder_env: dict = None,
         show_on_failure: bool = False,
     ):
         """deploy function, build container with dependencies
 
-        :param watch:      wait for the deploy to complete (and print build logs)
-        :param with_mlrun: add the current mlrun package to the container build
-        :param skip_deployed: skip the build if we already have an image for the function
-        :param mlrun_version_specifier:  which mlrun package version to include (if not current)
-        :param builder_env:   Kaniko builder pod env vars dict (for config/credentials)
-                              e.g. builder_env={"GIT_TOKEN": token}
-        :param show_on_failure:  show logs only in case of build failure
+        :param watch:                   wait for the deploy to complete (and print build logs)
+        :param with_mlrun:              add the current mlrun package to the container build
+        :param skip_deployed:           skip the build if we already have an image for the function
+        :param is_kfp:                  deploy as part of a kfp pipeline
+        :param mlrun_version_specifier: which mlrun package version to include (if not current)
+        :param builder_env:             Kaniko builder pod env vars dict (for config/credentials)
+                                        e.g. builder_env={"GIT_TOKEN": token}
+        :param show_on_failure:         show logs only in case of build failure
 
         :return True if the function is ready (deployed)
         """
         # connect will populate the config from the server config
         if not self.spec.build.base_image:
             self.spec.build.base_image = self._resolve_default_base_image
         return super().deploy(
             watch=watch,
             with_mlrun=with_mlrun,
             skip_deployed=skip_deployed,
             is_kfp=is_kfp,
             mlrun_version_specifier=mlrun_version_specifier,
+            builder_env=builder_env,
             show_on_failure=show_on_failure,
         )
 
 
 class RemoteSparkRuntimeHandler(KubeRuntimeHandler):
     kind = "remote-spark"
+    class_modes = {RuntimeClassMode.run: "remote-spark"}
 
     @staticmethod
     def _are_resources_coupled_to_run_object() -> bool:
         return True
 
     @staticmethod
     def _get_object_label_selector(object_id: str) -> str:
         return f"mlrun/uid={object_id}"
 
-    @staticmethod
-    def _get_possible_mlrun_class_label_values() -> typing.List[str]:
-        return ["remote-spark"]
-
 
 def igz_spark_pre_hook():
     run(["/bin/bash", "/etc/config/v3io/spark-job-init.sh"])
```

## mlrun/runtimes/serving.py

```diff
@@ -137,14 +137,17 @@
         default_handler=None,
         pythonpath=None,
         workdir=None,
         image_pull_secret=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        service_type=None,
+        add_templated_ingress_host_mode=None,
+        clone_target_dir=None,
     ):
 
         super().__init__(
             command=command,
             args=args,
             image=image,
             mode=mode,
@@ -174,14 +177,17 @@
             default_handler=default_handler,
             pythonpath=pythonpath,
             workdir=workdir,
             image_pull_secret=image_pull_secret,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            service_type=service_type,
+            add_templated_ingress_host_mode=add_templated_ingress_host_mode,
+            clone_target_dir=clone_target_dir,
         )
 
         self.models = models or {}
         self._graph = None
         self.graph: Union[RouterStep, RootFlowStep] = graph
         self.parameters = parameters or {}
         self.default_class = default_class
@@ -318,19 +324,25 @@
                                     tracking_policy = {'default_batch_intervals':"0 */3 * * *"}
                                     serving_fn.set_tracking(tracking_policy=tracking_policy)
 
         """
 
         # Applying model monitoring configurations
         self.spec.track_models = True
-        self.spec.tracking_policy = model_monitoring.TrackingPolicy()
+        self.spec.tracking_policy = None
         if tracking_policy:
-            self.spec.tracking_policy = self.spec.tracking_policy.from_dict(
-                tracking_policy
-            )
+            if isinstance(tracking_policy, dict):
+                # Convert tracking policy dictionary into `model_monitoring.TrackingPolicy` object
+                self.spec.tracking_policy = model_monitoring.TrackingPolicy.from_dict(
+                    tracking_policy
+                )
+            else:
+                # Tracking_policy is already a `model_monitoring.TrackingPolicy` object
+                self.spec.tracking_policy = tracking_policy
+
         if stream_path:
             self.spec.parameters["log_stream"] = stream_path
         if batch:
             self.spec.parameters["log_stream_batch"] = batch
         if sample:
             self.spec.parameters["log_stream_sample"] = sample
         if stream_args:
@@ -557,32 +569,32 @@
             self._secrets = SecretsStore.from_list(self.spec.secret_sources)
             if self._secrets.has_vault_source():
                 self._add_vault_params_to_spec(project=self.metadata.project)
             if self._secrets.has_azure_vault_source():
                 self._add_azure_vault_params_to_spec(
                     self._secrets.get_azure_vault_k8s_secret()
                 )
-            self._add_project_k8s_secrets_to_spec(
+            self._add_k8s_secrets_to_spec(
                 self._secrets.get_k8s_secrets(), project=self.metadata.project
             )
         else:
-            self._add_project_k8s_secrets_to_spec(None, project=self.metadata.project)
+            self._add_k8s_secrets_to_spec(None, project=self.metadata.project)
 
     def deploy(
         self,
         dashboard="",
         project="",
         tag="",
         verbose=False,
         auth_info: mlrun.api.schemas.AuthInfo = None,
         builder_env: dict = None,
     ):
         """deploy model serving function to a local/remote cluster
 
-        :param dashboard: remote nuclio dashboard url (blank for local or auto detection)
+        :param dashboard: DEPRECATED. Keep empty to allow auto-detection by MLRun API
         :param project:   optional, override function specified project name
         :param tag:       specify unique function tag (a different function service is created for every tag)
         :param verbose:   verbose logging
         :param auth_info: The auth info to use to communicate with the Nuclio dashboard, required only when providing
                           dashboard
         :param builder_env: env vars dict for source archive config/credentials e.g. builder_env={"GIT_TOKEN": token}
         """
@@ -634,15 +646,17 @@
             "parameters": self.spec.parameters,
             "graph": self.spec.graph.to_dict() if self.spec.graph else {},
             "load_mode": self.spec.load_mode,
             "functions": function_name_uri_map,
             "graph_initializer": self.spec.graph_initializer,
             "error_stream": self.spec.error_stream,
             "track_models": self.spec.track_models,
-            "tracking_policy": self.spec.tracking_policy,
+            "tracking_policy": self.spec.tracking_policy.to_dict()
+            if self.spec.tracking_policy
+            else None,
             "default_content_type": self.spec.default_content_type,
         }
 
         if self.spec.secret_sources:
             self._secrets = SecretsStore.from_list(self.spec.secret_sources)
             serving_spec["secret_sources"] = self._secrets.to_serial()
```

## mlrun/runtimes/utils.py

```diff
@@ -214,15 +214,21 @@
             Repo,
         )
     except ImportError:
         return None
 
     try:
         repo = Repo(path, search_parent_directories=True)
-        remotes = [remote.url for remote in repo.remotes]
+        remotes = [
+            remote.url
+            for remote in repo.remotes
+            # some stale remotes might be missing urls
+            # there is not a nicer way to check for this.
+            if repo.config_reader().has_option(f'remote "{remote}"', "url")
+        ]
         if len(remotes) > 0:
             return f"{remotes[0]}#{repo.head.commit.hexsha}"
     except (GitCommandNotFound, InvalidGitRepositoryError, NoSuchPathError, ValueError):
         pass
     return None
```

## mlrun/runtimes/mpijob/abstract.py

```diff
@@ -20,15 +20,15 @@
 
 from mlrun.config import config
 from mlrun.errors import err_to_str
 from mlrun.execution import MLClientCtx
 from mlrun.model import RunObject
 from mlrun.runtimes.kubejob import KubejobRuntime
 from mlrun.runtimes.pod import KubeResourceSpec
-from mlrun.runtimes.utils import AsyncLogWriter, RunError
+from mlrun.runtimes.utils import RunError
 from mlrun.utils import get_in, logger
 
 
 class MPIResourceSpec(KubeResourceSpec):
     _dict_fields = KubeResourceSpec._dict_fields + ["mpi_args"]
 
     def __init__(
@@ -56,14 +56,15 @@
         affinity=None,
         priority_class_name=None,
         disable_auto_mount=False,
         pythonpath=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        clone_target_dir=None,
     ):
         super().__init__(
             command=command,
             image=image,
             mode=mode,
             build=build,
             entry_points=entry_points,
@@ -84,14 +85,15 @@
             affinity=affinity,
             priority_class_name=priority_class_name,
             disable_auto_mount=disable_auto_mount,
             pythonpath=pythonpath,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            clone_target_dir=clone_target_dir,
         )
         self.mpi_args = mpi_args or [
             "-x",
             "NCCL_SOCKET_NTHREADS=2",
             "-x",
             "NCCL_NSOCKS_PERTHREAD=8",
             "-x",
@@ -170,38 +172,23 @@
         if resp:
             logger.info(f"MpiJob {meta.name} state={state or 'unknown'}")
             if state:
                 state = state.lower()
                 launcher, _ = self._get_launcher(meta.name, meta.namespace)
                 execution.set_hostname(launcher)
                 execution.set_state("running" if state == "active" else state)
-                if self.kfp:
-                    writer = AsyncLogWriter(self._db_conn, runobj)
-                    status = self._get_k8s().watch(
-                        launcher, meta.namespace, writer=writer
-                    )
-                    logger.info(f"MpiJob {meta.name} finished with state {status}")
-                    if status == "succeeded":
-                        execution.set_state("completed")
-                    else:
-                        execution.set_state(
-                            "error",
-                            f"MpiJob {meta.name} finished with state {status}",
-                        )
-                else:
-                    txt = f"MpiJob {meta.name} launcher pod {launcher} state {state}"
-                    logger.info(txt)
-                    runobj.status.status_text = txt
+                txt = f"MpiJob {meta.name} launcher pod {launcher} state {state}"
+                logger.info(txt)
+                runobj.status.status_text = txt
+
             else:
                 pods_phases = self.get_pods(meta.name, meta.namespace)
                 txt = f"MpiJob status unknown or failed, check pods: {pods_phases}"
                 logger.warning(txt)
                 runobj.status.status_text = txt
-                if self.kfp:
-                    execution.set_state("error", txt)
 
         return None
 
     def _submit_mpijob(self, job, namespace=None):
         mpi_group, mpi_version, mpi_plural = self._get_crd_info()
 
         k8s = self._get_k8s()
@@ -284,16 +271,14 @@
             return {p.metadata.name: p.status.phase for p in pods}
 
     def _get_launcher(self, name, namespace=None):
         pods = self.get_pods(name, namespace, launcher=True)
         if not pods:
             logger.error("no pod matches that job name")
             return
-        # TODO: Why was this here?
-        # k8s = self._get_k8s()
         return list(pods.items())[0]
 
     def with_tracing(
         self, log_file_path: str = None, enable_cycle_markers: bool = False
     ):
         """Add Horovod Timeline activity tracking to the job to analyse
         its performance.
```

## mlrun/runtimes/mpijob/v1.py

```diff
@@ -19,15 +19,15 @@
 from sqlalchemy.orm import Session
 
 import mlrun.runtimes.pod
 from mlrun.api.db.base import DBInterface
 from mlrun.config import config as mlconf
 from mlrun.execution import MLClientCtx
 from mlrun.model import RunObject
-from mlrun.runtimes.base import BaseRuntimeHandler, RunStates
+from mlrun.runtimes.base import BaseRuntimeHandler, RunStates, RuntimeClassMode
 from mlrun.runtimes.constants import MPIJobCRDVersions, MPIJobV1CleanPodPolicies
 from mlrun.runtimes.mpijob.abstract import AbstractMPIJobRuntime, MPIResourceSpec
 from mlrun.utils import get_in, update_in
 
 
 class MPIV1ResourceSpec(MPIResourceSpec):
     _dict_fields = MPIResourceSpec._dict_fields + ["clean_pod_policy"]
@@ -58,14 +58,15 @@
         affinity=None,
         priority_class_name=None,
         disable_auto_mount=False,
         pythonpath=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        clone_target_dir=None,
     ):
         super().__init__(
             command=command,
             image=image,
             mode=mode,
             build=build,
             entry_points=entry_points,
@@ -87,14 +88,15 @@
             affinity=affinity,
             priority_class_name=priority_class_name,
             disable_auto_mount=disable_auto_mount,
             pythonpath=pythonpath,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            clone_target_dir=clone_target_dir,
         )
         self.clean_pod_policy = clean_pod_policy or MPIJobV1CleanPodPolicies.default()
 
 
 class MpiRuntimeV1(AbstractMPIJobRuntime):
     _mpijob_pod_template = {
         "spec": {
@@ -190,15 +192,18 @@
             if self.spec.image:
                 self._update_container(
                     pod_template,
                     "image",
                     self.full_image_path(
                         client_version=runobj.metadata.labels.get(
                             "mlrun/client_version"
-                        )
+                        ),
+                        client_python_version=runobj.metadata.labels.get(
+                            "mlrun/client_python_version"
+                        ),
                     ),
                 )
             self._update_container(
                 pod_template, "volumeMounts", self.spec.volume_mounts
             )
             self._update_container(pod_template, "env", extra_env + self.spec.env)
             if self.spec.image_pull_policy:
@@ -313,14 +318,17 @@
             MpiRuntimeV1.crd_version,
             MpiRuntimeV1.crd_plural,
         )
 
 
 class MpiV1RuntimeHandler(BaseRuntimeHandler):
     kind = "mpijob"
+    class_modes = {
+        RuntimeClassMode.run: "mpijob",
+    }
 
     def _resolve_crd_object_status_info(
         self, db: DBInterface, db_session: Session, crd_object
     ) -> typing.Tuple[bool, typing.Optional[datetime], typing.Optional[str]]:
         """
         https://github.com/kubeflow/mpi-operator/blob/master/pkg/apis/kubeflow/v1/types.go#L29
         https://github.com/kubeflow/common/blob/master/pkg/apis/common/v1/types.go#L55
@@ -354,16 +362,30 @@
         return True
 
     @staticmethod
     def _get_object_label_selector(object_id: str) -> str:
         return f"mlrun/uid={object_id}"
 
     @staticmethod
-    def _get_possible_mlrun_class_label_values() -> typing.List[str]:
-        return ["mpijob"]
+    def _get_main_runtime_resource_label_selector() -> str:
+        """
+        There are some runtimes which might have multiple k8s resources attached to a one runtime, in this case
+        we don't want to pull logs from all but rather only for the "driver"/"launcher" etc
+        :return: the label selector
+        """
+        return "mpi-job-role=launcher"
+
+    @staticmethod
+    def _get_run_completion_updates(run: dict) -> dict:
+
+        # TODO: add a 'workers' section in run objects state, each worker will update its state while
+        #  the run state will be resolved by the server.
+        # update the run object state if empty so that it won't default to 'created' state
+        update_in(run, "status.state", "running", append=False, replace=False)
+        return {}
 
     @staticmethod
     def _get_crd_info() -> typing.Tuple[str, str, str]:
         return (
             MpiRuntimeV1.crd_group,
             MpiRuntimeV1.crd_version,
             MpiRuntimeV1.crd_plural,
```

## mlrun/runtimes/mpijob/v1alpha1.py

```diff
@@ -19,15 +19,15 @@
 from sqlalchemy.orm import Session
 
 import mlrun.runtimes.pod
 from mlrun.api.db.base import DBInterface
 from mlrun.config import config as mlconf
 from mlrun.execution import MLClientCtx
 from mlrun.model import RunObject
-from mlrun.runtimes.base import BaseRuntimeHandler, RunStates
+from mlrun.runtimes.base import BaseRuntimeHandler, RunStates, RuntimeClassMode
 from mlrun.runtimes.constants import MPIJobCRDVersions, MPIJobV1Alpha1States
 from mlrun.runtimes.mpijob.abstract import AbstractMPIJobRuntime
 from mlrun.utils import get_in, update_in
 
 
 class MpiRuntimeV1Alpha1(AbstractMPIJobRuntime):
     _mpijob_template = {
@@ -74,15 +74,18 @@
         update_in(job, "spec.template.metadata.labels", pod_labels)
         update_in(job, "spec.replicas", self.spec.replicas or 1)
         if self.spec.image:
             self._update_container(
                 job,
                 "image",
                 self.full_image_path(
-                    client_version=runobj.metadata.labels.get("mlrun/client_version")
+                    client_version=runobj.metadata.labels.get("mlrun/client_version"),
+                    client_python_version=runobj.metadata.labels.get(
+                        "mlrun/client_python_version"
+                    ),
                 ),
             )
         update_in(job, "spec.template.spec.volumes", self.spec.volumes)
         self._update_container(job, "volumeMounts", self.spec.volume_mounts)
         update_in(job, "spec.template.spec.nodeName", self.spec.node_name)
         update_in(job, "spec.template.spec.nodeSelector", self.spec.node_selector)
         update_in(
@@ -153,14 +156,17 @@
             MpiRuntimeV1Alpha1.crd_version,
             MpiRuntimeV1Alpha1.crd_plural,
         )
 
 
 class MpiV1Alpha1RuntimeHandler(BaseRuntimeHandler):
     kind = "mpijob"
+    class_modes = {
+        RuntimeClassMode.run: "mpijob",
+    }
 
     def _resolve_crd_object_status_info(
         self, db: DBInterface, db_session: Session, crd_object
     ) -> typing.Tuple[bool, typing.Optional[datetime], typing.Optional[str]]:
         """
         https://github.com/kubeflow/mpi-operator/blob/master/pkg/apis/kubeflow/v1alpha1/types.go#L115
         """
@@ -187,16 +193,30 @@
         return True
 
     @staticmethod
     def _get_object_label_selector(object_id: str) -> str:
         return f"mlrun/uid={object_id}"
 
     @staticmethod
-    def _get_possible_mlrun_class_label_values() -> typing.List[str]:
-        return ["mpijob"]
+    def _get_main_runtime_resource_label_selector() -> str:
+        """
+        There are some runtimes which might have multiple k8s resources attached to a one runtime, in this case
+        we don't want to pull logs from all but rather only for the "driver"/"launcher" etc
+        :return: the label selector
+        """
+        return "mpi_role_type=launcher"
+
+    @staticmethod
+    def _get_run_completion_updates(run: dict) -> dict:
+
+        # TODO: add a 'workers' section in run objects state, each worker will update its state while
+        #  the run state will be resolved by the server.
+        # update the run object state if empty so that it won't default to 'created' state
+        update_in(run, "status.state", "running", append=False, replace=False)
+        return {}
 
     @staticmethod
     def _get_crd_info() -> typing.Tuple[str, str, str]:
         return (
             MpiRuntimeV1Alpha1.crd_group,
             MpiRuntimeV1Alpha1.crd_version,
             MpiRuntimeV1Alpha1.crd_plural,
```

## mlrun/runtimes/sparkjob/abstract.py

```diff
@@ -7,15 +7,15 @@
 #   http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
+import os.path
 import typing
 from copy import deepcopy
 from datetime import datetime
 from typing import Dict, Optional, Tuple
 
 from kubernetes import client
 from kubernetes.client.rest import ApiException
@@ -29,24 +29,24 @@
 from mlrun.errors import err_to_str
 from mlrun.runtimes.base import BaseRuntimeHandler
 from mlrun.runtimes.constants import RunStates, SparkApplicationStates
 
 from ...execution import MLClientCtx
 from ...k8s_utils import get_k8s_helper
 from ...model import RunObject
-from ...platforms.iguazio import mount_v3io_extended, mount_v3iod
+from ...platforms.iguazio import mount_v3io, mount_v3iod
 from ...utils import (
     get_in,
     logger,
     update_in,
     verify_and_update_in,
     verify_field_regex,
     verify_list_and_update_in,
 )
-from ..base import RunError
+from ..base import RunError, RuntimeClassMode
 from ..kubejob import KubejobRuntime
 from ..pod import KubeResourceSpec
 from ..utils import get_item_name
 
 _service_account = "sparkapp"
 _sparkjob_template = {
     "apiVersion": "sparkoperator.k8s.io/v1beta2",
@@ -139,14 +139,15 @@
         disable_auto_mount=False,
         pythonpath=None,
         node_name=None,
         affinity=None,
         tolerations=None,
         preemption_mode=None,
         security_context=None,
+        clone_target_dir=None,
     ):
 
         super().__init__(
             command=command,
             args=args,
             image=image,
             mode=mode,
@@ -168,14 +169,15 @@
             disable_auto_mount=disable_auto_mount,
             pythonpath=pythonpath,
             node_name=node_name,
             affinity=affinity,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            clone_target_dir=clone_target_dir,
         )
 
         self._driver_resources = self.enrich_resources_with_default_pod_resources(
             "driver_resources", driver_resources
         )
         self._executor_resources = self.enrich_resources_with_default_pod_resources(
             "executor_resources", executor_resources
@@ -270,40 +272,41 @@
     def deploy(
         self,
         watch=True,
         with_mlrun=True,
         skip_deployed=False,
         is_kfp=False,
         mlrun_version_specifier=None,
+        builder_env: dict = None,
         show_on_failure: bool = False,
     ):
         """deploy function, build container with dependencies
 
-        :param watch:      wait for the deployment to complete (and print build logs)
-        :param with_mlrun: add the current mlrun package to the container build
-        :param skip_deployed: skip the build if we already have an image for the function
-        :param is_kfp:  whether running inside KFP step (no need to use,
-                        being enriched automatically if running inside one)
-        :param mlrun_version_specifier:  which mlrun package version to include (if not current)
-        :param builder_env:   Kaniko builder pod env vars dict (for config/credentials)
-                              e.g. builder_env={"GIT_TOKEN": token}
-        :param show_on_failure:  show logs only in case of build failure
+        :param watch:                   wait for the deploy to complete (and print build logs)
+        :param with_mlrun:              add the current mlrun package to the container build
+        :param skip_deployed:           skip the build if we already have an image for the function
+        :param is_kfp:                  deploy as part of a kfp pipeline
+        :param mlrun_version_specifier: which mlrun package version to include (if not current)
+        :param builder_env:             Kaniko builder pod env vars dict (for config/credentials)
+                                        e.g. builder_env={"GIT_TOKEN": token}
+        :param show_on_failure:         show logs only in case of build failure
 
         :return True if the function is ready (deployed)
         """
         # connect will populate the config from the server config
         get_run_db()
         if not self.spec.build.base_image:
             self.spec.build.base_image = self._default_image
         return super().deploy(
             watch=watch,
             with_mlrun=with_mlrun,
             skip_deployed=skip_deployed,
             is_kfp=is_kfp,
             mlrun_version_specifier=mlrun_version_specifier,
+            builder_env=builder_env,
             show_on_failure=show_on_failure,
         )
 
     @staticmethod
     def _get_gpu_type_and_quantity(resources):
         gpu_type = [
             resource_type
@@ -358,14 +361,23 @@
 
     def _get_spark_version(self):
         raise NotImplementedError()
 
     def _get_igz_deps(self):
         raise NotImplementedError()
 
+    def _pre_run(self, runobj: RunObject, execution: MLClientCtx):
+        if self.spec.build.source and self.spec.build.load_source_on_run:
+            raise mlrun.errors.MLRunPreconditionFailedError(
+                "Sparkjob does not support loading source code on run, "
+                "use func.with_source_archive(pull_at_runtime=False)"
+            )
+
+        super()._pre_run(runobj, execution)
+
     def _run(self, runobj: RunObject, execution: MLClientCtx):
         self._validate(runobj)
 
         if runobj.metadata.iteration:
             self.store_run(runobj)
         job = deepcopy(_sparkjob_template)
         meta = self._get_meta(runobj, True)
@@ -440,15 +452,18 @@
             elif self._default_image:
                 self.spec.image = self._default_image
 
         update_in(
             job,
             "spec.image",
             self.full_image_path(
-                client_version=runobj.metadata.labels.get("mlrun/client_version")
+                client_version=runobj.metadata.labels.get("mlrun/client_version"),
+                client_python_version=runobj.metadata.labels.get(
+                    "mlrun/client_python_version"
+                ),
             ),
         )
 
         update_in(job, "spec.volumes", self.spec.volumes)
 
         self._add_secrets_to_spec_before_running(runobj)
 
@@ -551,15 +566,19 @@
                         int,
                     )
 
         self._enrich_job(job)
 
         if self.spec.command:
             if "://" not in self.spec.command:
-                self.spec.command = "local://" + self.spec.command
+                workdir = self._resolve_workdir()
+                self.spec.command = "local://" + os.path.join(
+                    workdir or "",
+                    self.spec.command,
+                )
             update_in(job, "spec.mainApplicationFile", self.spec.command)
 
         verify_list_and_update_in(job, "spec.arguments", self.spec.args or [], str)
         self._submit_spark_job(job, meta, code)
 
         return None
 
@@ -641,15 +660,15 @@
         if "files" in deps:
             if "files" not in self.spec.deps:
                 self.spec.deps["files"] = []
             self.spec.deps["files"] += deps["files"]
 
     def with_igz_spark(self, mount_v3io_to_executor=True):
         self._update_igz_jars(deps=self._get_igz_deps())
-        self.apply(mount_v3io_extended(name="v3io"))
+        self.apply(mount_v3io(name="v3io"))
 
         # if we only want to mount v3io on the driver, move v3io
         # mounts from common volume mounts to driver volume mounts
         if not mount_v3io_to_executor:
             v3io_mounts = []
             non_v3io_mounts = []
             for mount in self.spec.volume_mounts:
@@ -677,25 +696,25 @@
         mem=None,
         cpu=None,
         gpus=None,
         gpu_type="nvidia.com/gpu",
         patch: bool = False,
     ):
         raise NotImplementedError(
-            "In spark runtimes, please use with_driver_limits & with_executor_limits"
+            "In spark runtimes, use 'with_driver_limits' & 'with_executor_limits'"
         )
 
     def with_requests(self, mem=None, cpu=None, patch: bool = False):
         raise NotImplementedError(
-            "In spark runtimes, please use with_driver_requests & with_executor_requests"
+            "In spark runtimes, use 'with_driver_requests' & 'with_executor_requests'"
         )
 
     def gpus(self, gpus, gpu_type="nvidia.com/gpu"):
         raise NotImplementedError(
-            "In spark runtimes, please use with_driver_requests & with_executor_requests"
+            "In spark runtimes, use 'with_driver_limits' & 'with_executor_limits'"
         )
 
     def with_node_selection(
         self,
         node_name: typing.Optional[str] = None,
         node_selector: typing.Optional[typing.Dict[str, str]] = None,
         affinity: typing.Optional[client.V1Affinity] = None,
@@ -781,14 +800,36 @@
         update_in(self.spec.restart_policy, "submission_retries", submission_retries)
         update_in(
             self.spec.restart_policy,
             "submission_retry_interval",
             submission_retry_interval,
         )
 
+    def with_source_archive(
+        self, source, workdir=None, handler=None, pull_at_runtime=True, target_dir=None
+    ):
+        """load the code from git/tar/zip archive at runtime or build
+
+        :param source:          valid path to git, zip, or tar file, e.g.
+                                git://github.com/mlrun/something.git
+                                http://some/url/file.zip
+        :param handler:         default function handler
+        :param workdir:         working dir relative to the archive root (e.g. './subdir') or absolute to the image root
+        :param pull_at_runtime: not supported for spark runtime, must be False
+        :param target_dir:      target dir on runtime pod for repo clone / archive extraction
+        """
+        if pull_at_runtime:
+            raise mlrun.errors.MLRunInvalidArgumentError(
+                "pull_at_runtime is not supported for spark runtime, use pull_at_runtime=False"
+            )
+
+        super().with_source_archive(
+            source, workdir, handler, pull_at_runtime, target_dir
+        )
+
     def get_pods(self, name=None, namespace=None, driver=False):
         k8s = self._get_k8s()
         namespace = k8s.resolve_namespace(namespace)
         selector = "mlrun/class=spark"
         if name:
             selector += f",sparkoperator.k8s.io/app-name={name}"
         if driver:
@@ -821,14 +862,17 @@
     @spec.setter
     def spec(self, spec):
         raise NotImplementedError()
 
 
 class SparkRuntimeHandler(BaseRuntimeHandler):
     kind = "spark"
+    class_modes = {
+        RuntimeClassMode.run: "spark",
+    }
 
     def _resolve_crd_object_status_info(
         self, db: DBInterface, db_session: Session, crd_object
     ) -> Tuple[bool, Optional[datetime], Optional[str]]:
         state = crd_object.get("status", {}).get("applicationState", {}).get("state")
         in_terminal_state = state in SparkApplicationStates.terminal_states()
         desired_run_state = SparkApplicationStates.spark_application_state_to_run_state(
@@ -886,26 +930,31 @@
         return True
 
     @staticmethod
     def _get_object_label_selector(object_id: str) -> str:
         return f"mlrun/uid={object_id}"
 
     @staticmethod
-    def _get_possible_mlrun_class_label_values() -> typing.List[str]:
-        return ["spark"]
+    def _get_main_runtime_resource_label_selector() -> str:
+        """
+        There are some runtimes which might have multiple k8s resources attached to a one runtime, in this case
+        we don't want to pull logs from all but rather only for the "driver"/"launcher" etc
+        :return: the label selector
+        """
+        return "spark-role=driver"
 
     @staticmethod
     def _get_crd_info() -> Tuple[str, str, str]:
         return (
             AbstractSparkRuntime.group,
             AbstractSparkRuntime.version,
             AbstractSparkRuntime.plural,
         )
 
-    def _delete_resources(
+    def _delete_extra_resources(
         self,
         db: DBInterface,
         db_session: Session,
         namespace: str,
         deleted_resources: typing.List[Dict],
         label_selector: str = None,
         force: bool = False,
```

## mlrun/runtimes/sparkjob/spark3job.py

```diff
@@ -96,14 +96,15 @@
         driver_volume_mounts=None,
         executor_volume_mounts=None,
         driver_java_options=None,
         executor_java_options=None,
         driver_cores=None,
         executor_cores=None,
         security_context=None,
+        clone_target_dir=None,
     ):
 
         super().__init__(
             command=command,
             args=args,
             image=image,
             mode=mode,
@@ -125,14 +126,15 @@
             disable_auto_mount=disable_auto_mount,
             pythonpath=pythonpath,
             node_name=node_name,
             affinity=affinity,
             tolerations=tolerations,
             preemption_mode=preemption_mode,
             security_context=security_context,
+            clone_target_dir=clone_target_dir,
         )
 
         self.driver_resources = driver_resources or {}
         self.executor_resources = executor_resources or {}
         self.spark_conf = spark_conf or {}
         self.hadoop_conf = hadoop_conf or {}
         self.job_type = job_type
```

## mlrun/serving/routers.py

```diff
@@ -20,26 +20,25 @@
 from io import BytesIO
 from typing import Dict, List, Union
 
 import numpy
 import numpy as np
 
 import mlrun
+import mlrun.model_monitoring
 import mlrun.utils.model_monitoring
 from mlrun.utils import logger, now_date, parse_versioned_object_uri
 
 from ..api.schemas import (
     ModelEndpoint,
     ModelEndpointMetadata,
     ModelEndpointSpec,
     ModelEndpointStatus,
-    ModelMonitoringMode,
 )
 from ..config import config
-from ..utils.model_monitoring import EndpointType
 from .server import GraphServer
 from .utils import RouterToDict, _extract_input_data, _update_result_body
 from .v2_serving import _ModelLogPusher
 
 # Used by `ParallelRun` in process mode, so it can be accessed from different processes.
 local_routes = {}
 
@@ -265,15 +264,15 @@
         context=None,
         name: str = None,
         routes=None,
         protocol: str = None,
         url_prefix: str = None,
         health_prefix: str = None,
         extend_event=None,
-        executor_type: ParallelRunnerModes = None,
+        executor_type: Union[ParallelRunnerModes, str] = ParallelRunnerModes.thread,
         **kwargs,
     ):
         """Process multiple steps (child routes) in parallel and merge the results
 
         By default the results dict from each step are merged (by key), when setting the `extend_event`
         the results will start from the event body dict (values can be overwritten)
 
@@ -300,14 +299,15 @@
         :param protocol:      serving API protocol (default "v2")
         :param url_prefix:    url prefix for the router (default /v2/models)
         :param health_prefix: health api url prefix (default /v2/health)
         :param executor_type: Parallelism mechanism,  Have 3 option :
                               * array - running one by one
                               * process - running in separated process
                               * thread - running in separated threads
+                              by default `threads`
         :param extend_event:  True will add the event body to the result
         :param kwargs:        extra arguments
         """
         super().__init__(
             context=context,
             name=name,
             routes=routes,
@@ -319,15 +319,15 @@
         self.name = name or "ParallelRun"
         self.extend_event = extend_event
         if isinstance(executor_type, ExecutorTypes):
             executor_type = str(executor_type)
             logger.warn(
                 "ExecutorTypes is deprecated and will be removed in 1.5.0, use ParallelRunnerModes instead",
                 # TODO: In 1.5.0 to remove ExecutorTypes
-                PendingDeprecationWarning,
+                FutureWarning,
             )
         self.executor_type = ParallelRunnerModes(executor_type)
         self._pool: Union[
             concurrent.futures.ProcessPoolExecutor,
             concurrent.futures.ThreadPoolExecutor,
         ] = None
 
@@ -501,15 +501,15 @@
         name: str = None,
         routes=None,
         protocol: str = None,
         url_prefix: str = None,
         health_prefix: str = None,
         vote_type: str = None,
         weights: Dict[str, float] = None,
-        executor_type: ParallelRunnerModes = ParallelRunnerModes.thread,
+        executor_type: Union[ParallelRunnerModes, str] = ParallelRunnerModes.thread,
         format_response_with_col_name_flag: bool = False,
         prediction_col_name: str = "prediction",
         **kwargs,
     ):
         """Voting Ensemble
 
         The `VotingEnsemble` class enables you to apply prediction logic on top of
@@ -1038,15 +1038,15 @@
     # Generating version model value based on the model name and model version
     if voting_ensemble.version:
         versioned_model_name = f"{voting_ensemble.name}:{voting_ensemble.version}"
     else:
         versioned_model_name = f"{voting_ensemble.name}:latest"
 
     # Generating model endpoint ID based on function uri and model version
-    endpoint_uid = mlrun.utils.model_monitoring.create_model_endpoint_id(
+    endpoint_uid = mlrun.model_monitoring.create_model_endpoint_uid(
         function_uri=graph_server.function_uri, versioned_model=versioned_model_name
     ).uid
 
     # If model endpoint object was found in DB, skip the creation process.
     try:
         mlrun.get_run_db().get_model_endpoint(project=project, endpoint_id=endpoint_uid)
 
@@ -1056,49 +1056,51 @@
         try:
             # Get the children model endpoints ids
             children_uids = []
             for _, c in voting_ensemble.routes.items():
                 if hasattr(c, "endpoint_uid"):
                     children_uids.append(c.endpoint_uid)
 
-                model_endpoint = ModelEndpoint(
-                    metadata=ModelEndpointMetadata(project=project, uid=endpoint_uid),
-                    spec=ModelEndpointSpec(
-                        function_uri=graph_server.function_uri,
-                        model=versioned_model_name,
-                        model_class=voting_ensemble.__class__.__name__,
-                        stream_path=config.model_endpoint_monitoring.store_prefixes.default.format(
-                            project=project, kind="stream"
-                        ),
-                        active=True,
-                        monitoring_mode=ModelMonitoringMode.enabled
-                        if voting_ensemble.context.server.track_models
-                        else ModelMonitoringMode.disabled,
+            model_endpoint = ModelEndpoint(
+                metadata=ModelEndpointMetadata(project=project, uid=endpoint_uid),
+                spec=ModelEndpointSpec(
+                    function_uri=graph_server.function_uri,
+                    model=versioned_model_name,
+                    model_class=voting_ensemble.__class__.__name__,
+                    stream_path=config.model_endpoint_monitoring.store_prefixes.default.format(
+                        project=project, kind="stream"
                     ),
-                    status=ModelEndpointStatus(
-                        children=list(voting_ensemble.routes.keys()),
-                        endpoint_type=EndpointType.ROUTER,
-                        children_uids=children_uids,
-                    ),
-                )
+                    active=True,
+                    monitoring_mode=mlrun.model_monitoring.ModelMonitoringMode.enabled
+                    if voting_ensemble.context.server.track_models
+                    else mlrun.model_monitoring.ModelMonitoringMode.disabled,
+                ),
+                status=ModelEndpointStatus(
+                    children=list(voting_ensemble.routes.keys()),
+                    endpoint_type=mlrun.model_monitoring.EndpointType.ROUTER,
+                    children_uids=children_uids,
+                ),
+            )
 
             db = mlrun.get_run_db()
 
             db.create_model_endpoint(
                 project=project,
                 endpoint_id=model_endpoint.metadata.uid,
-                model_endpoint=model_endpoint,
+                model_endpoint=model_endpoint.dict(),
             )
 
             # Update model endpoint children type
             for model_endpoint in children_uids:
                 current_endpoint = db.get_model_endpoint(
                     project=project, endpoint_id=model_endpoint
                 )
-                current_endpoint.status.endpoint_type = EndpointType.LEAF_EP
+                current_endpoint.status.endpoint_type = (
+                    mlrun.model_monitoring.EndpointType.LEAF_EP
+                )
                 db.create_model_endpoint(
                     project=project,
                     endpoint_id=model_endpoint,
                     model_endpoint=current_endpoint,
                 )
 
         except Exception as exc:
@@ -1200,16 +1202,16 @@
         context=None,
         name: str = None,
         routes=None,
         protocol=None,
         url_prefix: str = None,
         health_prefix: str = None,
         vote_type: str = None,
-        executor_type=None,
-        prediction_col_name=None,
+        executor_type: Union[ParallelRunnerModes, str] = ParallelRunnerModes.thread,
+        prediction_col_name: str = None,
         feature_vector_uri: str = "",
         impute_policy: dict = {},
         **kwargs,
     ):
         """Voting Ensemble with feature enrichment (from the feature store)
 
         The `EnrichmentVotingEnsemble` class enables to enrich the incoming event with real-time features
@@ -1297,23 +1299,23 @@
                               Example: If the model returns
                                        {id: <id>, model_name: <name>, outputs: {..., prediction: [<predictions>], ...}}
                                        the prediction_col_name should be `prediction`.
                               by default, `prediction`
         :param kwargs:        extra arguments
         """
         super().__init__(
-            context,
-            name,
-            routes,
-            protocol,
-            url_prefix,
-            health_prefix,
-            vote_type,
-            executor_type,
-            prediction_col_name,
+            context=context,
+            name=name,
+            routes=routes,
+            protocol=protocol,
+            url_prefix=url_prefix,
+            health_prefix=health_prefix,
+            vote_type=vote_type,
+            executor_type=executor_type,
+            prediction_col_name=prediction_col_name,
             **kwargs,
         )
 
         self.feature_vector_uri = feature_vector_uri
         self.impute_policy = impute_policy
 
         self._feature_service = None
```

## mlrun/serving/server.py

```diff
@@ -14,29 +14,28 @@
 
 __all__ = ["GraphServer", "create_graph_server", "GraphContext", "MockEvent"]
 
 import asyncio
 import json
 import os
 import socket
-import sys
 import traceback
 import uuid
 from typing import Optional, Union
 
 import mlrun
 from mlrun.config import config
 from mlrun.errors import err_to_str
 from mlrun.secrets import SecretsStore
 
 from ..datastore import get_stream_pusher
 from ..datastore.store_resources import ResourceCache
 from ..errors import MLRunInvalidArgumentError
 from ..model import ModelObj
-from ..utils import create_logger, get_caller_globals, parse_versioned_object_uri
+from ..utils import get_caller_globals, parse_versioned_object_uri
 from .states import RootFlowStep, RouterStep, get_function, graph_root_setter
 from .utils import event_id_key, event_path_key
 
 
 class _StreamContext:
     def __init__(self, enabled, parameters, function_uri):
         self.enabled = False
@@ -302,26 +301,35 @@
 def v2_serving_init(context, namespace=None):
     """hook for nuclio init_context()"""
 
     data = os.environ.get("SERVING_SPEC_ENV", "")
     if not data:
         raise MLRunInvalidArgumentError("failed to find spec env var")
     spec = json.loads(data)
+    context.logger.info("Initializing server from spec")
     server = GraphServer.from_dict(spec)
     if config.log_level.lower() == "debug":
         server.verbose = True
     if hasattr(context, "trigger"):
         server.http_trigger = getattr(context.trigger, "kind", "http") == "http"
+    context.logger.info_with(
+        "Setting current function",
+        current_functiton=os.environ.get("SERVING_CURRENT_FUNCTION", ""),
+    )
     server.set_current_function(os.environ.get("SERVING_CURRENT_FUNCTION", ""))
+    context.logger.info_with(
+        "Initializing states", namespace=namespace or get_caller_globals()
+    )
     server.init_states(context, namespace or get_caller_globals())
+    context.logger.info("Initializing graph steps")
     serving_handler = server.init_object(namespace or get_caller_globals())
     # set the handler hook to point to our handler
     setattr(context, "mlrun_handler", serving_handler)
     setattr(context, "_server", server)
-    context.logger.info(f"serving was initialized, verbose={server.verbose}")
+    context.logger.info_with("Serving was initialized", verbose=server.verbose)
     if server.verbose:
         context.logger.info(server.to_yaml())
 
 
 def v2_serving_handler(context, event, get_body=False):
     """hook for nuclio handler()"""
     if context._server.http_trigger:
@@ -432,15 +440,15 @@
         self.root = None
 
         if nuclio_context:
             self.logger = nuclio_context.logger
             self.Response = nuclio_context.Response
             self.worker_id = nuclio_context.worker_id
         elif not logger:
-            self.logger = create_logger(level, "human", "flow", sys.stdout)
+            self.logger = mlrun.utils.helpers.logger
 
         self._server = server
         self.current_function = None
         self.get_store_resource = None
         self.get_table = None
         self.is_mock = False
```

## mlrun/serving/states.py

```diff
@@ -29,14 +29,15 @@
 from ..platforms.iguazio import parse_path
 from ..utils import get_class, get_function
 from .utils import _extract_input_data, _update_result_body
 
 callable_prefix = "_"
 path_splitter = "/"
 previous_step = "$prev"
+queue_class_names = [">>", "$queue"]
 
 
 class GraphError(Exception):
     """error in graph topology or configuration"""
 
     pass
 
@@ -324,48 +325,26 @@
             else:
                 self._handler = get_function(self.handler, namespace)
             args = signature(self._handler).parameters
             if args and "context" in list(args.keys()):
                 self._inject_context = True
             return
 
-        if isinstance(self.class_name, type):
-            self._class_object = self.class_name
-            self.class_name = self.class_name.__name__
-
-        if not self._class_object:
-            if self.class_name == "$remote":
-
-                from mlrun.serving.remote import RemoteStep
-
-                self._class_object = RemoteStep
-            else:
-                self._class_object = get_class(
-                    self.class_name or self._default_class, namespace
-                )
-
+        self._class_object, self.class_name = self.get_step_class_object(
+            namespace=namespace
+        )
         if not self._object or reset:
             # init the step class + args
-            class_args = {}
-            for key, arg in self.class_args.items():
-                if key.startswith(callable_prefix):
-                    class_args[key[1:]] = get_function(arg, namespace)
-                else:
-                    class_args[key] = arg
-            class_args.update(extra_kwargs)
-
-            # add common args (name, context, ..) only if target class can accept them
-            argspec = getfullargspec(self._class_object)
-            for key in ["name", "context", "input_path", "result_path", "full_event"]:
-                if argspec.varkw or key in argspec.args:
-                    class_args[key] = getattr(self, key)
-            if argspec.varkw or "graph_step" in argspec.args:
-                class_args["graph_step"] = self
+            extracted_class_args = self.get_full_class_args(
+                namespace=namespace,
+                class_object=self._class_object,
+                **extra_kwargs,
+            )
             try:
-                self._object = self._class_object(**class_args)
+                self._object = self._class_object(**extracted_class_args)
             except TypeError as exc:
                 raise TypeError(
                     f"failed to init step {self.name}\n args={self.class_args}"
                 ) from exc
 
             # determine the right class handler to use
             handler = self.handler
@@ -383,14 +362,48 @@
             if handler:
                 self._handler = getattr(self._object, handler, None)
 
         self._set_error_handler()
         if mode != "skip":
             self._post_init(mode)
 
+    def get_full_class_args(self, namespace, class_object, **extra_kwargs):
+        class_args = {}
+        for key, arg in self.class_args.items():
+            if key.startswith(callable_prefix):
+                class_args[key[1:]] = get_function(arg, namespace)
+            else:
+                class_args[key] = arg
+        class_args.update(extra_kwargs)
+
+        # add common args (name, context, ..) only if target class can accept them
+        argspec = getfullargspec(class_object)
+        for key in ["name", "context", "input_path", "result_path", "full_event"]:
+            if argspec.varkw or key in argspec.args:
+                class_args[key] = getattr(self, key)
+        if argspec.varkw or "graph_step" in argspec.args:
+            class_args["graph_step"] = self
+        return class_args
+
+    def get_step_class_object(self, namespace):
+        class_name = self.class_name
+        class_object = self._class_object
+        if isinstance(class_name, type):
+            class_object = class_name
+            class_name = class_name.__name__
+        elif not class_object:
+            if class_name == "$remote":
+
+                from mlrun.serving.remote import RemoteStep
+
+                class_object = RemoteStep
+            else:
+                class_object = get_class(class_name or self._default_class, namespace)
+        return class_object, class_name
+
     def _is_local_function(self, context):
         # detect if the class is local (and should be initialized)
         current_function = get_current_function(context)
         if current_function == "*":
             return True
         if not self.function and not current_function:
             return True
@@ -1069,20 +1082,20 @@
             if hasattr(self._controller, "terminate"):
                 self._controller.terminate()
             return self._controller.await_termination()
 
     def plot(self, filename=None, format=None, source=None, targets=None, **kw):
         """plot/save graph using graphviz
 
-        :param filename:  target filepath for the image (None for the notebook)
-        :param format:    The output format used for rendering (``'pdf'``, ``'png'``, etc.)
-        :param source:    source step to add to the graph
-        :param targets:   list of target steps to add to the graph
-        :param kw:        kwargs passed to graphviz, e.g. rankdir="LR" (see: https://graphviz.org/doc/info/attrs.html)
-        :return: graphviz graph object
+        :param filename:  target filepath for the graph image (None for the notebook)
+        :param format:    the output format used for rendering (``'pdf'``, ``'png'``, etc.)
+        :param source:    source step to add to the graph image
+        :param targets:   list of target steps to add to the graph image
+        :param kw:        kwargs passed to graphviz, e.g. rankdir="LR" (see https://graphviz.org/doc/info/attrs.html)
+        :return:          graphviz graph object
         """
         return _generate_graphviz(
             self,
             _add_graphviz_flow,
             filename,
             format,
             source=source,
@@ -1249,15 +1262,15 @@
         cls = classes_map.get(kind, RootFlowStep)
         step = cls.from_dict(struct)
         step.function = function
         step.full_event = full_event or step.full_event
         step.input_path = input_path or step.input_path
         step.result_path = result_path or step.result_path
 
-    elif class_name and class_name in [">>", "$queue"]:
+    elif class_name and class_name in queue_class_names:
         if "path" not in class_args:
             raise MLRunInvalidArgumentError(
                 "path=<stream path or None> must be specified for queues"
             )
         if not name:
             raise MLRunInvalidArgumentError("queue name must be specified")
         # Pass full_event on only if it's explicitly defined
```

## mlrun/serving/v2_serving.py

```diff
@@ -13,25 +13,24 @@
 # limitations under the License.
 import threading
 import time
 import traceback
 from typing import Dict, Union
 
 import mlrun
+import mlrun.model_monitoring
 from mlrun.api.schemas import (
     ModelEndpoint,
     ModelEndpointMetadata,
     ModelEndpointSpec,
     ModelEndpointStatus,
-    ModelMonitoringMode,
 )
 from mlrun.artifacts import ModelArtifact  # noqa: F401
 from mlrun.config import config
 from mlrun.utils import logger, now_date, parse_versioned_object_uri
-from mlrun.utils.model_monitoring import EndpointType
 
 from .server import GraphServer
 from .utils import StepToDict, _extract_input_data, _update_result_body
 
 
 class V2ModelServer(StepToDict):
     """base model serving class (v2), using similar API to KFServing v2 and Triton"""
@@ -400,19 +399,20 @@
             "function_uri": self.function_uri,
         }
         if getattr(self.model, "labels", None):
             base_data["labels"] = self.model.labels
         return base_data
 
     def push(self, start, request, resp=None, op=None, error=None):
+        start_str = start.isoformat(sep=" ", timespec="microseconds")
         if error:
             data = self.base_data()
             data["request"] = request
             data["op"] = op
-            data["when"] = str(start)
+            data["when"] = start_str
             message = str(error)
             if self.verbose:
                 message = f"{message}\n{traceback.format_exc()}"
             data["error"] = message
             self.output_stream.push([data])
             return
 
@@ -441,15 +441,15 @@
                     data["values"] = self._batch
                     self.output_stream.push([data])
             else:
                 data = self.base_data()
                 data["request"] = request
                 data["op"] = op
                 data["resp"] = resp
-                data["when"] = str(start)
+                data["when"] = start_str
                 data["microsec"] = microsec
                 if getattr(self.model, "metrics", None):
                     data["metrics"] = self.model.metrics
                 self.output_stream.push([data])
 
 
 def _init_endpoint_record(
@@ -482,15 +482,15 @@
     # Generating version model value based on the model name and model version
     if model.version:
         versioned_model_name = f"{model.name}:{model.version}"
     else:
         versioned_model_name = f"{model.name}:latest"
 
     # Generating model endpoint ID based on function uri and model version
-    uid = mlrun.utils.model_monitoring.create_model_endpoint_id(
+    uid = mlrun.model_monitoring.create_model_endpoint_uid(
         function_uri=graph_server.function_uri, versioned_model=versioned_model_name
     ).uid
 
     # If model endpoint object was found in DB, skip the creation process.
     try:
         mlrun.get_run_db().get_model_endpoint(project=project, endpoint_id=uid)
 
@@ -507,26 +507,29 @@
                     model=versioned_model_name,
                     model_class=model.__class__.__name__,
                     model_uri=model.model_path,
                     stream_path=config.model_endpoint_monitoring.store_prefixes.default.format(
                         project=project, kind="stream"
                     ),
                     active=True,
-                    monitoring_mode=ModelMonitoringMode.enabled
+                    monitoring_mode=mlrun.model_monitoring.ModelMonitoringMode.enabled
                     if model.context.server.track_models
-                    else ModelMonitoringMode.disabled,
+                    else mlrun.model_monitoring.ModelMonitoringMode.disabled,
+                ),
+                status=ModelEndpointStatus(
+                    endpoint_type=mlrun.model_monitoring.EndpointType.NODE_EP
                 ),
-                status=ModelEndpointStatus(endpoint_type=EndpointType.NODE_EP),
             )
 
             db = mlrun.get_run_db()
+
             db.create_model_endpoint(
                 project=project,
-                endpoint_id=model_endpoint.metadata.uid,
-                model_endpoint=model_endpoint,
+                endpoint_id=uid,
+                model_endpoint=model_endpoint.dict(),
             )
 
         except Exception as e:
             logger.error("Failed to create endpoint record", exc=e)
 
     except Exception as e:
         logger.error("Failed to retrieve model endpoint object", exc=e)
```

## mlrun/utils/clones.py

```diff
@@ -47,15 +47,15 @@
     return temp_file
 
 
 def get_git_username_password_from_token(token):
     # Github's access tokens have a known prefix according to their type. See
     # https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/about-authentication-to-github#githubs-token-formats
     # We distinguish new fine-grained access tokens (begin with "github_pat_" from classic tokens.
-    if token.startswith("github_pat_"):
+    if token.startswith("github_pat_") or token.startswith("glpat"):
         username = "oauth2"
         password = token
     else:
         username = token
         password = "x-oauth-basic"
     return username, password
 
@@ -123,15 +123,15 @@
     username = url_obj.username or get_secret("GIT_USERNAME") or get_secret("git_user")
     password = (
         url_obj.password
         or get_secret("GIT_PASSWORD")
         or get_secret("git_password")
         or ""
     )
-    token = get_secret("GIT_TOKEN")
+    token = get_secret("GITHUB_TOKEN") or get_secret("GIT_TOKEN")
     if token:
         username, password = get_git_username_password_from_token(token)
 
     clone_path = f"https://{host}{url_obj.path}"
     enriched_clone_path = ""
     if username:
         enriched_clone_path = f"https://{username}:{password}@{host}{url_obj.path}"
```

## mlrun/utils/helpers.py

```diff
@@ -16,24 +16,28 @@
 import hashlib
 import inspect
 import json
 import re
 import sys
 import time
 import typing
+import warnings
 from datetime import datetime, timezone
 from importlib import import_module
 from os import path
 from types import ModuleType
 from typing import Any, List, Optional, Tuple
 
+import git
 import numpy as np
 import pandas
+import semver
 import yaml
 from dateutil import parser
+from deprecated import deprecated
 from pandas._libs.tslibs.timestamps import Timedelta, Timestamp
 from yaml.representer import RepresenterError
 
 import mlrun
 import mlrun.errors
 import mlrun.utils.version.version
 from mlrun.errors import err_to_str
@@ -123,28 +127,33 @@
     nest_asyncio.apply()
 
 
 class run_keys:
     input_path = "input_path"
     output_path = "output_path"
     inputs = "inputs"
+    returns = "returns"
     artifacts = "artifacts"
     outputs = "outputs"
     data_stores = "data_stores"
     secrets = "secret_sources"
 
 
 def verify_field_regex(
-    field_name, field_value, patterns, raise_on_failure: bool = True
+    field_name,
+    field_value,
+    patterns,
+    raise_on_failure: bool = True,
+    log_message: str = "Field is malformed. Does not match required pattern",
 ) -> bool:
     for pattern in patterns:
         if not re.match(pattern, str(field_value)):
             log_func = logger.warn if raise_on_failure else logger.debug
             log_func(
-                "Field is malformed. Does not match required pattern",
+                log_message,
                 field_name=field_name,
                 field_value=field_value,
                 pattern=pattern,
             )
             if raise_on_failure:
                 raise mlrun.errors.MLRunInvalidArgumentError(
                     f"Field '{field_name}' is malformed. Does not match required pattern: {pattern}"
@@ -163,14 +172,27 @@
     otherwise, it returns False
     """
     return mlrun.utils.helpers.verify_field_regex(
         field_name,
         tag_name,
         mlrun.utils.regex.tag_name,
         raise_on_failure=raise_on_failure,
+        log_message="Special characters are not permitted in tag names",
+    )
+
+
+def validate_artifact_key_name(
+    artifact_key: str, field_name: str, raise_on_failure: bool = True
+) -> bool:
+    return mlrun.utils.helpers.verify_field_regex(
+        field_name,
+        artifact_key,
+        mlrun.utils.regex.artifact_key,
+        raise_on_failure=raise_on_failure,
+        log_message="Slashes are not permitted in the artifact key (both \\ and /)",
     )
 
 
 def get_regex_list_as_string(regex_list: List) -> str:
     """
     This function is used to combine a list of regex strings into a single regex,
     with and condition between them.
@@ -252,19 +274,26 @@
 
 def to_date_str(d):
     if d:
         return d.isoformat()
     return ""
 
 
-def normalize_name(name):
+def normalize_name(name: str, verbose: bool = True):
     # TODO: Must match
     # [a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?
     name = re.sub(r"\s+", "-", name)
-    name = name.replace("_", "-")
+    if "_" in name:
+        if verbose:
+            warnings.warn(
+                "Names with underscore '_' are about to be deprecated, use dashes '-' instead. "
+                "Replacing underscores with dashes.",
+                FutureWarning,
+            )
+        name = name.replace("_", "-")
     return name.lower()
 
 
 class LogBatchWriter:
     def __init__(self, func, batch=16, maxtime=5):
         self.batch = batch
         self.maxtime = maxtime
@@ -310,16 +339,34 @@
 def verify_list_and_update_in(
     obj, key, value, expected_element_type: type, append=False, replace=True
 ):
     verify_field_list_of_type(key, value, expected_element_type)
     update_in(obj, key, value, append, replace)
 
 
+def _split_by_dots_with_escaping(key: str):
+    """
+    splits the key by dots, taking escaping into account so that an escaped key can contain dots
+    """
+    parts = []
+    current_key, escape = "", False
+    for char in key:
+        if char == "." and not escape:
+            parts.append(current_key)
+            current_key = ""
+        elif char == "\\":
+            escape = not escape
+        else:
+            current_key += char
+    parts.append(current_key)
+    return parts
+
+
 def update_in(obj, key, value, append=False, replace=True):
-    parts = key.split(".") if isinstance(key, str) else key
+    parts = _split_by_dots_with_escaping(key) if isinstance(key, str) else key
     for part in parts[:-1]:
         sub = obj.get(part, missing)
         if sub is missing:
             sub = obj[part] = {}
         obj = sub
 
     last_key = parts[-1]
@@ -603,50 +650,73 @@
 
     out = "<tr>" + gen_list(header, "th") + "</tr>\n"
     for r in rows:
         out += "<tr>" + gen_list(r, "td") + "</tr>\n"
     return style + '<table class="tg">\n' + out + "</table>\n\n"
 
 
-def new_pipe_meta(artifact_path=None, ttl=None, *args):
+def new_pipe_metadata(
+    artifact_path: str = None,
+    cleanup_ttl: int = None,
+    op_transformers: typing.List[typing.Callable] = None,
+):
     from kfp.dsl import PipelineConf
 
     def _set_artifact_path(task):
         from kubernetes import client as k8s_client
 
         task.add_env_variable(
             k8s_client.V1EnvVar(name="MLRUN_ARTIFACT_PATH", value=artifact_path)
         )
         return task
 
     conf = PipelineConf()
-    ttl = ttl or int(config.kfp_ttl)
-    if ttl:
-        conf.set_ttl_seconds_after_finished(ttl)
+    cleanup_ttl = cleanup_ttl or int(config.kfp_ttl)
+
+    if cleanup_ttl:
+        conf.set_ttl_seconds_after_finished(cleanup_ttl)
     if artifact_path:
         conf.add_op_transformer(_set_artifact_path)
-    for op in args:
-        if op:
-            conf.add_op_transformer(op)
+    if op_transformers:
+        for op_transformer in op_transformers:
+            conf.add_op_transformer(op_transformer)
     return conf
 
 
+# TODO: remove in 1.5.0
+@deprecated(
+    version="1.3.0",
+    reason="'new_pipe_meta' will be removed in 1.5.0",
+    category=FutureWarning,
+)
+def new_pipe_meta(artifact_path=None, ttl=None, *args):
+    return new_pipe_metadata(
+        artifact_path=artifact_path, cleanup_ttl=ttl, op_transformers=args
+    )
+
+
 def _convert_python_package_version_to_image_tag(version: typing.Optional[str]):
     return (
         version.replace("+", "-").replace("0.0.0-", "") if version is not None else None
     )
 
 
-def enrich_image_url(image_url: str, client_version: str = None) -> str:
+def enrich_image_url(
+    image_url: str, client_version: str = None, client_python_version: str = None
+) -> str:
     client_version = _convert_python_package_version_to_image_tag(client_version)
     server_version = _convert_python_package_version_to_image_tag(
         mlrun.utils.version.Version().get()["version"]
     )
     image_url = image_url.strip()
-    tag = config.images_tag or client_version or server_version
+    mlrun_version = config.images_tag or client_version or server_version
+    tag = mlrun_version
+    tag += resolve_image_tag_suffix(
+        mlrun_version=mlrun_version, python_version=client_python_version
+    )
     registry = config.images_registry
 
     # it's an mlrun image if the repository is mlrun
     is_mlrun_image = image_url.startswith("mlrun/") or "/mlrun/" in image_url
 
     if is_mlrun_image and tag and ":" not in image_url:
         image_url = f"{image_url}:{tag}"
@@ -663,14 +733,46 @@
     if registry and enrich_registry:
         registry = registry if registry.endswith("/") else f"{registry}/"
         image_url = f"{registry}{image_url}"
 
     return image_url
 
 
+def resolve_image_tag_suffix(
+    mlrun_version: str = None, python_version: str = None
+) -> str:
+    """
+    resolves what suffix should be appended to the image tag
+    :param mlrun_version: the mlrun version
+    :param python_version: the requested python version
+    :return: the suffix to append to the image tag
+    """
+    if not python_version or not mlrun_version:
+        return ""
+
+    # if the mlrun version is 0.0.0-<unstable>/<commit hash> then it's a dev version, therefore we can't check if the
+    # mlrun version is higher than 1.3.0, but we can check the python version and if python version was passed it
+    # means it 1.3.0-rc or higher, so we can add the suffix of the python version.
+    if mlrun_version.startswith("0.0.0-") or "unstable" in mlrun_version:
+        if python_version.startswith("3.7"):
+            return "-py37"
+        return ""
+
+    # For mlrun 1.3.0, we decided to support mlrun runtimes images with both python 3.7 and 3.9 images.
+    # While the python 3.9 images will continue to have no suffix, the python 3.7 images will have a '-py37' suffix.
+    # Python 3.8 images will not be supported for mlrun 1.3.0, meaning that if the user has client with python 3.8
+    # and mlrun 1.3.x then the image will be pulled without a suffix (which is the python 3.9 image).
+    # using semver (x.y.z-X) to include rc versions as well
+    if semver.VersionInfo.parse(mlrun_version) >= semver.VersionInfo.parse(
+        "1.3.0-X"
+    ) and python_version.startswith("3.7"):
+        return "-py37"
+    return ""
+
+
 def get_docker_repository_or_default(repository: str) -> str:
     if not repository:
         repository = "mlrun"
     return repository
 
 
 def get_parsed_docker_registry() -> Tuple[Optional[str], Optional[str]]:
@@ -700,15 +802,19 @@
     tag = tag or object_dict["metadata"].get("tag")
     status = object_dict.setdefault("status", {})
     object_dict["metadata"]["tag"] = ""
     object_dict["metadata"][uid_property_name] = ""
     object_dict["status"] = None
     object_dict["metadata"]["updated"] = None
     object_created_timestamp = object_dict["metadata"].pop("created", None)
-    data = json.dumps(object_dict, sort_keys=True).encode()
+    # Note the usage of default=str here, which means everything not JSON serializable (for example datetime) will be
+    # converted to string when dumping to JSON. This is not safe for de-serializing (since it won't know we
+    # originated from a datetime, for example), but since this is a one-way dump only for hash calculation,
+    # it's valid here.
+    data = json.dumps(object_dict, sort_keys=True, default=str).encode()
     h = hashlib.sha1()
     h.update(data)
     uid = h.hexdigest()
     object_dict["metadata"]["tag"] = tag
     object_dict["metadata"][uid_property_name] = uid
     object_dict["status"] = status
     if object_created_timestamp:
@@ -944,15 +1050,15 @@
     class_object = _search_in_namespaces(class_name, namespace)
     if class_object is not None:
         return class_object
 
     try:
         class_object = create_class(class_name)
     except (ImportError, ValueError) as exc:
-        raise ImportError(f"state init failed, class {class_name} not found") from exc
+        raise ImportError(f"Failed to import {class_name}") from exc
     return class_object
 
 
 def get_function(function, namespace):
     """return function callable object from function name string"""
     if callable(function):
         return function
@@ -1139,7 +1245,53 @@
     return not (path.startswith("/") or ":\\" in path or "://" in path)
 
 
 def as_number(field_name, field_value):
     if isinstance(field_value, str) and not field_value.isnumeric():
         raise ValueError(f"{field_name} must be numeric (str/int types)")
     return int(field_value)
+
+
+def filter_warnings(action, category):
+    def decorator(function):
+        def wrapper(*args, **kwargs):
+
+            # context manager that copies and, upon exit, restores the warnings filter and the showwarning() function.
+            with warnings.catch_warnings():
+                warnings.simplefilter(action, category)
+                return function(*args, **kwargs)
+
+        return wrapper
+
+    return decorator
+
+
+def resolve_git_reference_from_source(source):
+    # kaniko allow multiple "#" e.g. #refs/..#commit
+    split_source = source.split("#", 1)
+
+    # no reference was passed
+    if len(split_source) < 2:
+        return source, "", ""
+
+    reference = split_source[1]
+    if reference.startswith("refs/"):
+        return split_source[0], reference, ""
+
+    return split_source[0], "", reference
+
+
+def ensure_git_branch(url: str, repo: git.Repo) -> str:
+    """Ensures git url includes branch.
+    If no branch or refs are included in the git source then will enrich the git url with the current active branch
+     as defined in the repo object. Otherwise, will just return the url and won't apply any enrichments.
+
+    :param url:   Git source url
+    :param repo: `git.Repo` object that will be used for getting the active branch value (if required)
+
+    :return:     Git source url with full valid path to the relevant branch
+
+    """
+    source, reference, branch = resolve_git_reference_from_source(url)
+    if not branch and not reference:
+        url = f"{url}#refs/heads/{repo.active_branch}"
+    return url
```

## mlrun/utils/http.py

```diff
@@ -12,14 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import time
 
 import requests
 import requests.adapters
+import urllib3.exceptions
 import urllib3.util.retry
 
 from ..config import config
 from ..errors import err_to_str
 from . import logger
 
 
@@ -27,22 +28,37 @@
     """
     Extend requests.Session to add retry logic on both error statuses and certain exceptions.
     """
 
     # make sure to only add exceptions that are raised early in the request. For example, ConnectionError can be raised
     # during the handling of a request, and therefore should not be retried, as the request might not be idempotent.
 
+    # use strings because some requests exceptions are encapsulated in other exceptions, and we want to catch them all.
     HTTP_RETRYABLE_EXCEPTION_STRINGS = [
         # "Connection reset by peer" is raised when the server closes the connection prematurely during TCP handshake.
         "Connection reset by peer",
         # "Connection aborted" and "Connection refused" happen when the server doesn't respond at all.
         "Connection aborted",
         "Connection refused",
     ]
 
+    # most of the exceptions would not be encapsulated, we want to catch them all directly.
+    # this allows us more flexibility when deciding which *exactly* exception we want to retry on.
+    HTTP_RETRYABLE_EXCEPTIONS = [
+        # "Connection reset by peer" is raised when the server closes the connection prematurely during TCP handshake.
+        ConnectionResetError,
+        # "Connection aborted" and "Connection refused" happen when the server doesn't respond at all.
+        ConnectionRefusedError,
+        ConnectionAbortedError,
+        # often happens when the server is overloaded and can't handle the load.
+        requests.exceptions.ConnectTimeout,
+        requests.exceptions.ReadTimeout,
+        urllib3.exceptions.ReadTimeoutError,
+    ]
+
     def __init__(
         self,
         max_retries=config.http_retry_defaults.max_retries,
         retry_backoff_factor=config.http_retry_defaults.backoff_factor,
         retry_on_exception=True,
         retry_on_status=True,
         retry_on_post=False,
@@ -104,17 +120,20 @@
                         exc,
                         f"{method} {url} request failed, max retries reached,"
                         f" raising exception: {err_to_str(exc)}",
                         retry_count,
                     )
                     raise exc
 
-                # only retry on exceptions with the right message
+                # only retryable exceptions
                 exception_is_retryable = any(
                     msg in str(exc) for msg in self.HTTP_RETRYABLE_EXCEPTION_STRINGS
+                ) or any(
+                    isinstance(exc, retryable_exc)
+                    for retryable_exc in self.HTTP_RETRYABLE_EXCEPTIONS
                 )
 
                 if not exception_is_retryable:
                     self._log_exception(
                         "warning",
                         exc,
                         f"{method} {url} request failed on non-retryable exception,"
```

## mlrun/utils/logger.py

```diff
@@ -55,48 +55,58 @@
 
 class Logger(object):
     def __init__(self, level, name="mlrun", propagate=True):
         self._logger = logging.getLogger(name)
         self._logger.propagate = propagate
         self._logger.setLevel(level)
         self._bound_variables = {}
-        self._handlers = {}
+
+        for log_level_func in [
+            self.exception,
+            self.error,
+            self.warn,
+            self.warning,
+            self.info,
+            self.debug,
+        ]:
+            setattr(self, f"{log_level_func.__name__}_with", log_level_func)
 
     def set_handler(
         self, handler_name: str, file: IO[str], formatter: logging.Formatter
     ):
 
         # check if there's a handler by this name
-        if handler_name in self._handlers:
-            # log that we're removing it
-            self.info("Replacing logger output", handler_name=handler_name)
-
-            self._logger.removeHandler(self._handlers[handler_name])
+        for handler in self._logger.handlers:
+            if handler.name == handler_name:
+                self._logger.removeHandler(handler)
+                break
 
         # create a stream handler from the file
         stream_handler = logging.StreamHandler(file)
+        stream_handler.name = handler_name
 
         # set the formatter
         stream_handler.setFormatter(formatter)
 
         # add the handler to the logger
         self._logger.addHandler(stream_handler)
 
-        # save as the named output
-        self._handlers[handler_name] = stream_handler
-
     @property
     def level(self):
         return self._logger.level
 
     def set_logger_level(self, level: Union[str, int]):
         self._logger.setLevel(level)
 
     def replace_handler_stream(self, handler_name: str, file: IO[str]):
-        self._handlers[handler_name].stream = file
+        for handler in self._logger.handlers:
+            if handler.name == handler_name:
+                handler.stream = file
+                return
+        raise ValueError(f"Logger does not have a handler named '{handler_name}'")
 
     def debug(self, message, *args, **kw_args):
         self._update_bound_vars_and_log(logging.DEBUG, message, *args, **kw_args)
 
     def info(self, message, *args, **kw_args):
         self._update_bound_vars_and_log(logging.INFO, message, *args, **kw_args)
```

## mlrun/utils/model_monitoring.py

```diff
@@ -9,140 +9,50 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 
-import enum
-import hashlib
-from dataclasses import dataclass
-from typing import Optional, Union
+import json
+import warnings
+from typing import Union
 
 import mlrun
 import mlrun.model
 import mlrun.model_monitoring.constants as model_monitoring_constants
 import mlrun.platforms.iguazio
-import mlrun.utils
 from mlrun.api.schemas.schedule import ScheduleCronTrigger
-
-
-@dataclass
-class FunctionURI:
-    project: str
-    function: str
-    tag: Optional[str] = None
-    hash_key: Optional[str] = None
-
-    @classmethod
-    def from_string(cls, function_uri):
-        project, uri, tag, hash_key = mlrun.utils.parse_versioned_object_uri(
-            function_uri
-        )
-        return cls(
-            project=project,
-            function=uri,
-            tag=tag or None,
-            hash_key=hash_key or None,
-        )
-
-
-@dataclass
-class VersionedModel:
-    model: str
-    version: Optional[str]
-
-    @classmethod
-    def from_string(cls, model):
-        try:
-            model, version = model.split(":")
-        except ValueError:
-            model, version = model, None
-
-        return cls(model, version)
-
-
-@dataclass
-class EndpointUID:
-    project: str
-    function: str
-    function_tag: str
-    function_hash_key: str
-    model: str
-    model_version: str
-    uid: Optional[str] = None
-
-    def __post_init__(self):
-        function_ref = (
-            f"{self.function}_{self.function_tag or self.function_hash_key or 'N/A'}"
-        )
-        versioned_model = f"{self.model}_{self.model_version or 'N/A'}"
-        unique_string = f"{self.project}_{function_ref}_{versioned_model}"
-        self.uid = hashlib.sha1(unique_string.encode("utf-8")).hexdigest()
-
-    def __str__(self):
-        return self.uid
-
-
-def create_model_endpoint_id(function_uri: str, versioned_model: str):
-    function_uri = FunctionURI.from_string(function_uri)
-    versioned_model = VersionedModel.from_string(versioned_model)
-
-    if (
-        not function_uri.project
-        or not function_uri.function
-        or not versioned_model.model
-    ):
-        raise ValueError("Both function_uri and versioned_model have to be initialized")
-
-    uid = EndpointUID(
-        function_uri.project,
-        function_uri.function,
-        function_uri.tag,
-        function_uri.hash_key,
-        versioned_model.model,
-        versioned_model.version,
-    )
-
-    return uid
+from mlrun.config import is_running_as_api
 
 
 def parse_model_endpoint_project_prefix(path: str, project_name: str):
     return path.split(project_name, 1)[0] + project_name
 
 
 def parse_model_endpoint_store_prefix(store_prefix: str):
     endpoint, parsed_url = mlrun.platforms.iguazio.parse_path(store_prefix)
     container, path = parsed_url.split("/", 1)
     return endpoint, container, path
 
 
-def set_project_model_monitoring_credentials(
-    access_key: str, project: Optional[str] = None
-):
+def set_project_model_monitoring_credentials(access_key: str, project: str = None):
     """Set the credentials that will be used by the project's model monitoring
     infrastructure functions.
     The supplied credentials must have data access
-
     :param access_key: Model Monitoring access key for managing user permissions.
     :param project: The name of the model monitoring project.
     """
     mlrun.get_run_db().create_project_secrets(
         project=project or mlrun.mlconf.default_project,
         provider=mlrun.api.schemas.SecretProviderName.kubernetes,
-        secrets={"MODEL_MONITORING_ACCESS_KEY": access_key},
+        secrets={model_monitoring_constants.ProjectSecretKeys.ACCESS_KEY: access_key},
     )
 
 
-class EndpointType(enum.IntEnum):
-    NODE_EP = 1  # end point that is not a child of a router
-    ROUTER = 2  # endpoint that is router
-    LEAF_EP = 3  # end point that is a child of a router
-
-
 class TrackingPolicy(mlrun.model.ModelObj):
     """
     Modified model monitoring configurations. By using TrackingPolicy, the user can apply his model monitoring
     requirements, such as setting the scheduling policy of the model monitoring batch job or changing the image of the
     model monitoring stream.
     """
 
@@ -182,24 +92,99 @@
     @classmethod
     def from_dict(cls, struct=None, fields=None, deprecated_fields: dict = None):
         new_obj = super().from_dict(
             struct, fields=cls._dict_fields, deprecated_fields=deprecated_fields
         )
         # Convert default batch interval into ScheduleCronTrigger object
         if model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS in struct:
-            new_obj.default_batch_intervals = ScheduleCronTrigger.from_crontab(
+            if isinstance(
                 struct[
                     model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
-                ]
-            )
+                ],
+                str,
+            ):
+                new_obj.default_batch_intervals = ScheduleCronTrigger.from_crontab(
+                    struct[
+                        model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
+                    ]
+                )
+            else:
+                new_obj.default_batch_intervals = ScheduleCronTrigger.parse_obj(
+                    struct[
+                        model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
+                    ]
+                )
         return new_obj
 
     def to_dict(self, fields=None, exclude=None):
         struct = super().to_dict(
             fields,
             exclude=[model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS],
         )
         if self.default_batch_intervals:
             struct[
                 model_monitoring_constants.EventFieldType.DEFAULT_BATCH_INTERVALS
             ] = self.default_batch_intervals.dict()
         return struct
+
+
+def get_connection_string(project: str = None):
+    """Get endpoint store connection string from the project secret.
+    If wasn't set, take it from the system configurations"""
+    if is_running_as_api():
+        # Running on API server side
+        import mlrun.api.crud.secrets
+        import mlrun.api.schemas
+
+        return (
+            mlrun.api.crud.secrets.Secrets().get_project_secret(
+                project=project,
+                provider=mlrun.api.schemas.secret.SecretProviderName.kubernetes,
+                allow_secrets_from_k8s=True,
+                secret_key=model_monitoring_constants.ProjectSecretKeys.ENDPOINT_STORE_CONNECTION,
+            )
+            or mlrun.mlconf.model_endpoint_monitoring.endpoint_store_connection
+        )
+    else:
+        # Running on stream server side
+        import mlrun
+
+        return (
+            mlrun.get_secret_or_env(
+                model_monitoring_constants.ProjectSecretKeys.ENDPOINT_STORE_CONNECTION
+            )
+            or mlrun.mlconf.model_endpoint_monitoring.endpoint_store_connection
+        )
+
+
+def validate_errors_and_metrics(endpoint: dict):
+    """
+    Replace default null values for `error_count` and `metrics` for users that logged a model endpoint before 1.3.0
+
+    Leaving here for backwards compatibility which related to the model endpoint schema
+
+    :param endpoint: An endpoint flattened dictionary.
+    """
+    warnings.warn(
+        "This will be deprecated in 1.3.0, and will be removed in 1.5.0",
+        # TODO: In 1.3.0 do changes in examples & demos In 1.5.0 remove
+        FutureWarning,
+    )
+
+    # Validate default value for `error_count`
+    if endpoint[model_monitoring_constants.EventFieldType.ERROR_COUNT] == "null":
+        endpoint[model_monitoring_constants.EventFieldType.ERROR_COUNT] = "0"
+
+    # Validate default value for `metrics`
+    # For backwards compatibility reasons, we validate that the model endpoint includes the `metrics` key
+    if (
+        model_monitoring_constants.EventFieldType.METRICS in endpoint
+        and endpoint[model_monitoring_constants.EventFieldType.METRICS] == "null"
+    ):
+        endpoint[model_monitoring_constants.EventFieldType.METRICS] = json.dumps(
+            {
+                model_monitoring_constants.EventKeyMetrics.GENERIC: {
+                    model_monitoring_constants.EventLiveStats.LATENCY_AVG_1H: 0,
+                    model_monitoring_constants.EventLiveStats.PREDICTIONS_PER_SECOND: 0,
+                }
+            }
+        )
```

## mlrun/utils/regex.py

```diff
@@ -72,7 +72,9 @@
 project_name = dns_1123_label
 
 # Special characters are not permitted in tag names because they can be included in the url and cause problems.
 # We only accept letters, capital letters, numbers, dots, and hyphens, with a k8s character limit.
 tag_name = label_value
 
 secret_key = k8s_secret_and_config_map_key
+
+artifact_key = [r"[^\/\\]+$"]
```

## mlrun/utils/version/version.json

### Pretty-printed

 * *Similarity: 0.5%*

 * *Differences: {"'git_commit'": "'f4663a7f768b0bbcaa72120fd5796bcc0ce1c05f'", "'version'": "'1.3.1-rc1'"}*

```diff
@@ -1,4 +1,4 @@
 {
-    "git_commit": "5633cf684fa09d435bc0408d893f20e77c4f75b6",
-    "version": "1.3.0-rc9"
+    "git_commit": "f4663a7f768b0bbcaa72120fd5796bcc0ce1c05f",
+    "version": "1.3.1-rc1"
 }
```

## mlrun/utils/version/version.py

```diff
@@ -20,23 +20,41 @@
 
 if sys.version_info >= (3, 7):
     from importlib.resources import read_text
 else:
     from importlib_resources import read_text
 
 
+class _VersionInfo:
+    def __init__(self, major, minor, patch):
+        self.major = major
+        self.minor = minor
+        self.patch = patch
+
+    def __str__(self):
+        return f"{self.major}.{self.minor}.{self.patch}"
+
+
 class Version(metaclass=Singleton):
     def __init__(self):
         # When installing un-released version (e.g. by doing pip install git+https://github.com/mlrun/mlrun@development)
         # it won't have a version file, so adding some sane defaults
         self.version_info = {"git_commit": "unknown", "version": "0.0.0+unstable"}
+        self.python_version = self._resolve_python_version()
         try:
             self.version_info = json.loads(
                 read_text("mlrun.utils.version", "version.json")
             )
         except Exception:
             mlrun.utils.logger.warning(
                 "Failed resolving version info. Ignoring and using defaults"
             )
 
     def get(self):
         return self.version_info
+
+    def get_python_version(self) -> _VersionInfo:
+        return self.python_version
+
+    @staticmethod
+    def _resolve_python_version() -> sys.version_info:
+        return _VersionInfo(*sys.version_info[:3])
```

## Comparing `mlrun-1.3.0rc9.dist-info/LICENSE` & `mlrun-1.3.1rc1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mlrun-1.3.0rc9.dist-info/METADATA` & `mlrun-1.3.1rc1.dist-info/METADATA`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mlrun
-Version: 1.3.0rc9
+Version: 1.3.1rc1
 Summary: Tracking and config of machine learning runs
 Home-page: https://github.com/mlrun/mlrun
 Author: Yaron Haviv
 Author-email: yaronh@iguazio.com
 License: MIT
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
@@ -16,136 +16,148 @@
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Topic :: Software Development :: Libraries
 Description-Content-Type: text/markdown
+License-File: LICENSE
 Requires-Dist: urllib3 (<1.27,>=1.25.4)
 Requires-Dist: chardet (<4.0,>=3.0.2)
-Requires-Dist: GitPython (~=3.0)
+Requires-Dist: GitPython (>=3.1.30,~=3.1)
 Requires-Dist: aiohttp (~=3.8)
 Requires-Dist: aiohttp-retry (~=2.8)
 Requires-Dist: click (~=8.0.0)
 Requires-Dist: protobuf (<3.20,>=3.13)
 Requires-Dist: kfp (<1.8.14,~=1.8.0)
 Requires-Dist: nest-asyncio (~=1.0)
-Requires-Dist: ipython (~=7.0)
-Requires-Dist: nuclio-jupyter (~=0.9.6)
+Requires-Dist: ipython (<9.0,>=7.0)
+Requires-Dist: nuclio-jupyter (~=0.9.9)
 Requires-Dist: numpy (<1.23.0,>=1.16.5)
 Requires-Dist: pandas (<1.5.0,~=1.2)
-Requires-Dist: pyarrow (<7,>=3)
+Requires-Dist: pyarrow (<11,>=10)
 Requires-Dist: pyyaml (~=5.1)
 Requires-Dist: requests (~=2.22)
-Requires-Dist: sqlalchemy (~=1.3)
+Requires-Dist: sqlalchemy (~=1.4)
 Requires-Dist: tabulate (~=0.8.6)
 Requires-Dist: v3io (~=0.5.20)
 Requires-Dist: pydantic (~=1.5)
 Requires-Dist: orjson (~=3.3)
 Requires-Dist: alembic (~=1.9)
 Requires-Dist: mergedeep (~=1.3)
-Requires-Dist: v3io-frames (~=0.10.2)
+Requires-Dist: v3io-frames (~=0.10.4)
 Requires-Dist: semver (~=2.13)
 Requires-Dist: dask (~=2021.11.2)
 Requires-Dist: distributed (~=2021.11.2)
 Requires-Dist: kubernetes (~=12.0)
 Requires-Dist: humanfriendly (~=8.2)
-Requires-Dist: fastapi (~=0.88.0)
+Requires-Dist: fastapi (~=0.92.0)
 Requires-Dist: fsspec (~=2021.8.1)
 Requires-Dist: v3iofs (~=0.1.15)
-Requires-Dist: cryptography (<3.4,~=3.0)
-Requires-Dist: storey (~=1.3.6)
+Requires-Dist: storey (~=1.3.15)
 Requires-Dist: deepdiff (~=5.0)
 Requires-Dist: pymysql (~=1.0)
 Requires-Dist: inflection (~=0.5.0)
 Requires-Dist: python-dotenv (~=0.17.0)
+Requires-Dist: setuptools (~=65.5)
+Requires-Dist: deprecated (~=1.2)
 Provides-Extra: all
 Requires-Dist: adlfs (~=2021.8.1) ; extra == 'all'
 Requires-Dist: aiobotocore (~=1.4.0) ; extra == 'all'
 Requires-Dist: azure-core (~=1.24) ; extra == 'all'
 Requires-Dist: azure-identity (~=1.5) ; extra == 'all'
 Requires-Dist: azure-keyvault-secrets (~=4.2) ; extra == 'all'
 Requires-Dist: azure-storage-blob (~=12.13) ; extra == 'all'
 Requires-Dist: bokeh (>=2.4.2,~=2.4) ; extra == 'all'
 Requires-Dist: boto3 (<1.17.107,~=1.9) ; extra == 'all'
 Requires-Dist: botocore (<1.20.107,>=1.20.106) ; extra == 'all'
 Requires-Dist: gcsfs (~=2021.8.1) ; extra == 'all'
-Requires-Dist: google-cloud-bigquery[pandas] (~=3.2) ; extra == 'all'
+Requires-Dist: google-cloud-bigquery[bqstorage,pandas] (~=3.2) ; extra == 'all'
 Requires-Dist: google-cloud-storage (~=1.20) ; extra == 'all'
 Requires-Dist: google-cloud (~=0.34) ; extra == 'all'
+Requires-Dist: graphviz (~=0.20.0) ; extra == 'all'
 Requires-Dist: kafka-python (~=2.0) ; extra == 'all'
 Requires-Dist: msrest (~=0.6.21) ; extra == 'all'
-Requires-Dist: plotly (~=5.4) ; extra == 'all'
+Requires-Dist: plotly (<5.12.0,~=5.4) ; extra == 'all'
+Requires-Dist: pyopenssl (>=23) ; extra == 'all'
 Requires-Dist: redis (~=4.3) ; extra == 'all'
 Requires-Dist: s3fs (~=2021.8.1) ; extra == 'all'
 Provides-Extra: api
 Requires-Dist: uvicorn (~=0.20.0) ; extra == 'api'
 Requires-Dist: dask-kubernetes (~=0.11.0) ; extra == 'api'
 Requires-Dist: apscheduler (~=3.6) ; extra == 'api'
 Requires-Dist: sqlite3-to-mysql (~=1.4) ; extra == 'api'
 Requires-Dist: objgraph (~=3.5) ; extra == 'api'
 Provides-Extra: azure-blob-storage
 Requires-Dist: msrest (~=0.6.21) ; extra == 'azure-blob-storage'
 Requires-Dist: azure-core (~=1.24) ; extra == 'azure-blob-storage'
 Requires-Dist: azure-storage-blob (~=12.13) ; extra == 'azure-blob-storage'
 Requires-Dist: adlfs (~=2021.8.1) ; extra == 'azure-blob-storage'
+Requires-Dist: pyopenssl (>=23) ; extra == 'azure-blob-storage'
 Provides-Extra: azure-key-vault
 Requires-Dist: azure-identity (~=1.5) ; extra == 'azure-key-vault'
 Requires-Dist: azure-keyvault-secrets (~=4.2) ; extra == 'azure-key-vault'
+Requires-Dist: pyopenssl (>=23) ; extra == 'azure-key-vault'
 Provides-Extra: bokeh
 Requires-Dist: bokeh (>=2.4.2,~=2.4) ; extra == 'bokeh'
 Provides-Extra: complete
 Requires-Dist: adlfs (~=2021.8.1) ; extra == 'complete'
 Requires-Dist: aiobotocore (~=1.4.0) ; extra == 'complete'
 Requires-Dist: azure-core (~=1.24) ; extra == 'complete'
 Requires-Dist: azure-identity (~=1.5) ; extra == 'complete'
 Requires-Dist: azure-keyvault-secrets (~=4.2) ; extra == 'complete'
 Requires-Dist: azure-storage-blob (~=12.13) ; extra == 'complete'
 Requires-Dist: boto3 (<1.17.107,~=1.9) ; extra == 'complete'
 Requires-Dist: botocore (<1.20.107,>=1.20.106) ; extra == 'complete'
 Requires-Dist: gcsfs (~=2021.8.1) ; extra == 'complete'
-Requires-Dist: google-cloud-bigquery[pandas] (~=3.2) ; extra == 'complete'
+Requires-Dist: google-cloud-bigquery[bqstorage,pandas] (~=3.2) ; extra == 'complete'
+Requires-Dist: graphviz (~=0.20.0) ; extra == 'complete'
 Requires-Dist: kafka-python (~=2.0) ; extra == 'complete'
 Requires-Dist: msrest (~=0.6.21) ; extra == 'complete'
-Requires-Dist: plotly (~=5.4) ; extra == 'complete'
+Requires-Dist: plotly (<5.12.0,~=5.4) ; extra == 'complete'
+Requires-Dist: pyopenssl (>=23) ; extra == 'complete'
 Requires-Dist: redis (~=4.3) ; extra == 'complete'
 Requires-Dist: s3fs (~=2021.8.1) ; extra == 'complete'
 Provides-Extra: complete-api
 Requires-Dist: adlfs (~=2021.8.1) ; extra == 'complete-api'
 Requires-Dist: aiobotocore (~=1.4.0) ; extra == 'complete-api'
 Requires-Dist: apscheduler (~=3.6) ; extra == 'complete-api'
 Requires-Dist: azure-core (~=1.24) ; extra == 'complete-api'
 Requires-Dist: azure-identity (~=1.5) ; extra == 'complete-api'
 Requires-Dist: azure-keyvault-secrets (~=4.2) ; extra == 'complete-api'
 Requires-Dist: azure-storage-blob (~=12.13) ; extra == 'complete-api'
 Requires-Dist: boto3 (<1.17.107,~=1.9) ; extra == 'complete-api'
 Requires-Dist: botocore (<1.20.107,>=1.20.106) ; extra == 'complete-api'
 Requires-Dist: dask-kubernetes (~=0.11.0) ; extra == 'complete-api'
 Requires-Dist: gcsfs (~=2021.8.1) ; extra == 'complete-api'
-Requires-Dist: google-cloud-bigquery[pandas] (~=3.2) ; extra == 'complete-api'
+Requires-Dist: google-cloud-bigquery[bqstorage,pandas] (~=3.2) ; extra == 'complete-api'
+Requires-Dist: graphviz (~=0.20.0) ; extra == 'complete-api'
 Requires-Dist: kafka-python (~=2.0) ; extra == 'complete-api'
 Requires-Dist: msrest (~=0.6.21) ; extra == 'complete-api'
 Requires-Dist: objgraph (~=3.5) ; extra == 'complete-api'
-Requires-Dist: plotly (~=5.4) ; extra == 'complete-api'
+Requires-Dist: plotly (<5.12.0,~=5.4) ; extra == 'complete-api'
+Requires-Dist: pyopenssl (>=23) ; extra == 'complete-api'
 Requires-Dist: redis (~=4.3) ; extra == 'complete-api'
 Requires-Dist: s3fs (~=2021.8.1) ; extra == 'complete-api'
 Requires-Dist: sqlite3-to-mysql (~=1.4) ; extra == 'complete-api'
 Requires-Dist: uvicorn (~=0.20.0) ; extra == 'complete-api'
 Provides-Extra: google-cloud
 Requires-Dist: google-cloud-storage (~=1.20) ; extra == 'google-cloud'
-Requires-Dist: google-cloud-bigquery[pandas] (~=3.2) ; extra == 'google-cloud'
+Requires-Dist: google-cloud-bigquery[bqstorage,pandas] (~=3.2) ; extra == 'google-cloud'
 Requires-Dist: google-cloud (~=0.34) ; extra == 'google-cloud'
 Provides-Extra: google-cloud-bigquery
-Requires-Dist: google-cloud-bigquery[pandas] (~=3.2) ; extra == 'google-cloud-bigquery'
+Requires-Dist: google-cloud-bigquery[bqstorage,pandas] (~=3.2) ; extra == 'google-cloud-bigquery'
 Provides-Extra: google-cloud-storage
 Requires-Dist: gcsfs (~=2021.8.1) ; extra == 'google-cloud-storage'
+Provides-Extra: graphviz
+Requires-Dist: graphviz (~=0.20.0) ; extra == 'graphviz'
 Provides-Extra: kafka
 Requires-Dist: kafka-python (~=2.0) ; extra == 'kafka'
 Provides-Extra: plotly
-Requires-Dist: plotly (~=5.4) ; extra == 'plotly'
+Requires-Dist: plotly (<5.12.0,~=5.4) ; extra == 'plotly'
 Provides-Extra: redis
 Requires-Dist: redis (~=4.3) ; extra == 'redis'
 Provides-Extra: s3
 Requires-Dist: boto3 (<1.17.107,~=1.9) ; extra == 's3'
 Requires-Dist: botocore (<1.20.107,>=1.20.106) ; extra == 's3'
 Requires-Dist: aiobotocore (~=1.4.0) ; extra == 's3'
 Requires-Dist: s3fs (~=2021.8.1) ; extra == 's3'
```

## Comparing `mlrun-1.3.0rc9.dist-info/RECORD` & `mlrun-1.3.1rc1.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,219 +1,225 @@
-mlrun/__init__.py,sha256=rlEMuCWBJ8-4ZDL84hGr7HCB063QaEMByI6nAqrFk3E,8121
-mlrun/__main__.py,sha256=NVFr8f68Xg5jxRfJ5CunWqe6Py-pqz09wb_-h-hH-U8,45801
-mlrun/builder.py,sha256=3U-AaqJBDNioROgZGXLlaD4ZYG7bZ3zu1rb4Hdz7_8Q,22043
-mlrun/config.py,sha256=BCe0TWPi7cglV8n1ms92Dn1ebMnT4RW2_-NDaf29l2o,48683
-mlrun/errors.py,sha256=DYwaRy7am-hvkDNe1zjyQxhwYvSjtHqdwqJ9B1Gh2Vc,6505
-mlrun/execution.py,sha256=CYbmuS06iTYw7t2V5nhIt_ntM6SYaZXu3R34dxKNou4,35473
-mlrun/features.py,sha256=f-bNbYoTocQckeu4i-5EkBq69bL3zFFzNxK0qEAV_F4,14557
-mlrun/k8s_utils.py,sha256=vO7NS9WfSF6Z2XFCIYXNeQeG23NA59K3ugSnjuoVOQU,30935
-mlrun/kfpops.py,sha256=23Me7QErH34WZFlqjxcfecxhncF2QJCpuBCWL5LyL6U,27764
-mlrun/lists.py,sha256=QB0t_md73fhxsrerJvj4-SgxCtFoOpG5oP3aSXSRJGE,8301
-mlrun/model.py,sha256=LDH8dezs_6vDODc4CawWZiHoQutTcZKaPBSkBaixkI0,44013
+mlrun/__init__.py,sha256=cCTbgyTFsXvEdaq1Cvwz8s8FE75YGIJKX58um-fnfFs,8727
+mlrun/__main__.py,sha256=7rP5R0xv1YziN-yfFqy9IJM1Z16vehUNPVz_PUU0zqQ,47778
+mlrun/builder.py,sha256=SgkZdY0fj2xuzl8i4G2ZBXK1I8y9izw7skBi9fi8FuI,23554
+mlrun/config.py,sha256=gDDUKzogxN14i1USAXrEcxaH0UBz5wdEudTAAu4Dhf8,49829
+mlrun/errors.py,sha256=RABVls01sRBFPB_eRBnD49D5I_Fw_iZuVq9lcHd_QSk,6587
+mlrun/execution.py,sha256=jL7GuRPa4ZHxroW7kGLtBFeiOzDQoPv3bHZ2BGGSaUo,38928
+mlrun/features.py,sha256=4nQ6IokekQ7EYJU5BJxKivdyvsa6auXrePMpWozzHhk,15531
+mlrun/k8s_utils.py,sha256=5Ly-7Pgis6W1dHL1fOHSYkLcWEqZLdfGuDgDK-bsmIM,31384
+mlrun/kfpops.py,sha256=fCq9kqsIO5six8AmHkiRLngyDclRymd7V6U5YXnX_ek,29645
+mlrun/lists.py,sha256=yOKwpS71Fua08sV825Anth8aaR9H5bHZyV544YbnXj4,8360
+mlrun/model.py,sha256=hb7Zwbl9fXp6BAmYt-VBHZRMzhp3Ql8vKzHHqWgsShI,52194
 mlrun/render.py,sha256=983QAYawKTFlwXLpUwGC1gWEjUQUFxl1lo8bPQuXIA0,11828
-mlrun/run.py,sha256=2mNSY4S63A-eqsKkDu-nSpzbPXLDLXCg5pHO6HeXbD0,78718
-mlrun/secrets.py,sha256=ld-jwOv_jzq_Oibs5iAhf8lCqq9NqNypOnejNxRYjZY,7579
+mlrun/run.py,sha256=AoVyOqBTm1Hm3uIlSEkh_cqv0RuGsUFfBKpn085-w6I,64321
+mlrun/secrets.py,sha256=yboWaNO33RCXmopLL2bGCkDUbHuwJ7IgJaFv1lkoN_I,7731
 mlrun/api/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/alembic.ini,sha256=oeSJRHwBbF3c3-N_RJilcZD-diq3F-oPv21gDIkrZGs,2105
 mlrun/api/constants.py,sha256=fyTQXJe4sx4GK8vZxklivgJgaSyOftk_NezGKA1J-mo,685
 mlrun/api/initial_data.py,sha256=Zj9Oan9Qeg45AOv8Dfg3Gvsymuz5cFR7zgLskuxUTFs,23530
-mlrun/api/main.py,sha256=yWSCL0eTPEtxlX_khuwpZsetMmMY5kL-Zi5YvE619ls,13806
+mlrun/api/main.py,sha256=PKT5kdQTSZVKl8-miQwl--V0rc2HPCkuk_Zpn_EVqQM,24019
+mlrun/api/middlewares.py,sha256=VTW5VV7AGOigXf-ru2V3XSZzw_bMBr8j0uH2aMIGGfk,5235
 mlrun/api/api/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/api/api.py,sha256=suDQI8HL_zjtqaY7fBdm49SP73zJN2imdBiOh1hA4fQ,4267
-mlrun/api/api/deps.py,sha256=wA4zr0yvCuhVfwLa-6OSRvqzVqCE4L2gO06xxsV4VGc,3646
-mlrun/api/api/utils.py,sha256=Ywp4YVG-3yD_u43-5iavcai_Y9m5ulMDkUyNG_tNWcs,31272
+mlrun/api/api/deps.py,sha256=KTllUn0OHT-gGfnWPcz47QQwiHtxeHZBLEWMMbYWPBc,3143
+mlrun/api/api/utils.py,sha256=R2fVBlahNevk5IshtohBqibmS3Rnc4Ph3xViUoEKNfU,32788
 mlrun/api/api/endpoints/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/api/endpoints/artifacts.py,sha256=oGy-key8BmAUNWvCiOqAcatjV0pVd_0atcn8ZGftgjM,9458
 mlrun/api/api/endpoints/auth.py,sha256=8-vv61tPX_RFabJPPyXAWbSb8i3apcpbqJSs0GXINYM,1190
 mlrun/api/api/endpoints/background_tasks.py,sha256=qVLyyRLpW4TXLsDOGghLXFt1ugWvygcPhfcXMi1SRrg,3588
-mlrun/api/api/endpoints/client_spec.py,sha256=S3PFFFY_6OulsUEWz4Nfn1p-rFhNvwP7yXAz2p7Nz-M,859
+mlrun/api/api/endpoints/client_spec.py,sha256=0NzHkmV9O4izIu2bu-NhgaXi_UfJxkfsbOV7XZhzMUM,1202
 mlrun/api/api/endpoints/clusterization_spec.py,sha256=ImsNfHpCmXI83WZqDdBGfw2Qkra00-Q7PcWbSgEiQXA,1160
 mlrun/api/api/endpoints/feature_store.py,sha256=NCstDeosECMVE_JVjFJoL_XWY14ffDOCuZG6XQXwXTo,28813
 mlrun/api/api/endpoints/files.py,sha256=w412iL7Al7VHi_jJUvThyraO5hyWLrXG85iw10PVJx4,6065
-mlrun/api/api/endpoints/frontend_spec.py,sha256=tV8_7dFXTJLh6FrGv3fME74OSvo9dZmF0eqMsF0IXOE,5549
-mlrun/api/api/endpoints/functions.py,sha256=qJuBiao1cPSOjjNaa217HCdwHcwFX_8nuBbH5JkZQKU,29653
-mlrun/api/api/endpoints/grafana_proxy.py,sha256=qvrbLY70v-kpbag5AenUds8xzblSZzVf2WIh1ISL06E,17927
+mlrun/api/api/endpoints/frontend_spec.py,sha256=nr4EC25MbXCIDCWQaLD93saVB8cZg3R2UOUePx8xQ7U,5690
+mlrun/api/api/endpoints/functions.py,sha256=dOTy57CyTSqFI7mOB7utl8JUG7pR9idQn18h7P2NUkM,33894
+mlrun/api/api/endpoints/grafana_proxy.py,sha256=NFgIpoxIXAmI_3bKXTNvC0Z0wEu7WcqsBH3zqfhbyZo,5798
 mlrun/api/api/endpoints/healthz.py,sha256=WAZMBrEYHG-n1JkDcLkVMXl4dDEiqd_OpPj-DyqSlqc,979
-mlrun/api/api/endpoints/logs.py,sha256=mCl4xmglJYc6QTrnWnqDOdAIs3CnyJJ0TRtTBjkSwyA,2620
+mlrun/api/api/endpoints/logs.py,sha256=1a73ZwNNMDZaaYRqFbL3XZ6OrK3dKCpQI7HC-QJxI78,2429
 mlrun/api/api/endpoints/marketplace.py,sha256=PXc5OftoSoILyHCgSgNdNBEh4JjR8PmcvTQ6uB3nYfo,8283
-mlrun/api/api/endpoints/model_endpoints.py,sha256=5t8-TcDfydKc1SX7iX_k77JAVdsz_2k9TtmWI8Bep-Y,15513
+mlrun/api/api/endpoints/model_endpoints.py,sha256=vlKqhQUJZISBWujGT3BQLWQD0aVyihrMcl8Fb-W8PXo,15724
 mlrun/api/api/endpoints/operations.py,sha256=Fxtp2jY3dlgzYG-2vm1AqNnpxQ-7WaJuibyKX569stg,3700
-mlrun/api/api/endpoints/pipelines.py,sha256=rjn2UnjNhyeniEmoCUXSvjU7RGk32rPNACSkHHQXu8U,10347
-mlrun/api/api/endpoints/projects.py,sha256=qMm3GhxWQfT_7XEYrfvnR8NnhuZo7PeEkMf5RsMFtVg,11335
+mlrun/api/api/endpoints/pipelines.py,sha256=wV3ZvX7LPgb6bBsryXHXkwiiX_oxpK-Cwskj88W3KyE,9099
+mlrun/api/api/endpoints/projects.py,sha256=lFHvfDeeKdNIZ-DhmGKRSqQOuQuOWLu8a0uNay2tyDA,11392
 mlrun/api/api/endpoints/runs.py,sha256=2a_x6-IOLeQwhvLSH7dJOG3Xn-4aO2P4Vjt5T6J3cb8,8956
-mlrun/api/api/endpoints/runtime_resources.py,sha256=DxJweHUhqZdDErxIsqqeYpBz_4HVO3Txc3TfUhX7W8U,12375
+mlrun/api/api/endpoints/runtime_resources.py,sha256=Eer8nrP8Hh0y-pXkYr0dOXL7wjw4leE9Q-cxOMdIw08,8988
 mlrun/api/api/endpoints/schedules.py,sha256=Yw3tZNnjfZBgwS-Rsx-i8i8dzi-UNsbfNNvja8eN41I,10579
 mlrun/api/api/endpoints/secrets.py,sha256=l6IzLPMEJr_e7wrTNxLQIn-x8LGBlxeV7diYSAD55t4,6057
-mlrun/api/api/endpoints/submit.py,sha256=GldSIADRWV6MM1KLloNULOeW33xQvtED6Ot8EXt6AFQ,4857
+mlrun/api/api/endpoints/submit.py,sha256=mBizUlqKn0lc8YkrB0qVKAhLxF5Mg2Nz_0R_CGsehYA,5265
 mlrun/api/api/endpoints/tags.py,sha256=bnsWCKoOUnVHL42qqUzbXvs8gdmfT-8kcGwiT1svJcY,4843
 mlrun/api/api/endpoints/internal/__init__.py,sha256=Lq7QbwU5hFGCq6hzU28fA5t1soMesi7DVo99T21blU8,1203
 mlrun/api/api/endpoints/internal/config.py,sha256=kXnraXbXv029QZMMEjwvhsUWof69wTvFBLcRyB32JFc,1043
 mlrun/api/api/endpoints/internal/memory_reports.py,sha256=k9cA6NhvAPfA-CYRubpjSrhsHJ7Ig_wTFMIMTEZxS4E,1709
-mlrun/api/crud/__init__.py,sha256=fyhU83PDHvUP95pcwK8MQwEIHXzYA2UEMcvYr-tvWAk,1296
+mlrun/api/crud/__init__.py,sha256=WMo1AvY_XqJJQWd_9hgw0B35Rvnx50eN0uB4HRAms3E,1184
 mlrun/api/crud/artifacts.py,sha256=p-CJZKokYwy2ej0K2vEp5EEy5xM-FD7ytSWMHBd7J9Y,5433
-mlrun/api/crud/client_spec.py,sha256=-X28d4ExxiHgVNbhz24stwiXPDijoGE9DUFjTOwJWi8,5823
+mlrun/api/crud/client_spec.py,sha256=VapHAcFSKCmBq7AarJkpwoHns6fXLJ-VCEQcBuBczmU,7341
 mlrun/api/crud/clusterization_spec.py,sha256=wf9uiLb3DRwegDGlRu-dgfahoyp51bxtAuB8TEnklfc,1049
 mlrun/api/crud/feature_store.py,sha256=SAWhliY9UJAQbaJYKb7CmXTuVbovq3fDl-_5-RMxfxI,18449
-mlrun/api/crud/functions.py,sha256=BQ5OihXXXGdBTb7JRtcAcGX5nNssXGmkMGnKHPFRmsU,2612
-mlrun/api/crud/logs.py,sha256=7Q5UIsHwENIbqBCnjJIm5IMJM8btDnfPDJ7wDn4l9Dg,4429
+mlrun/api/crud/functions.py,sha256=pqCTL7rsHawfynV6DfqRrWKhnWxw1MNHJhLY_og6cJo,3550
+mlrun/api/crud/logs.py,sha256=r5JWMAtmxA9kIQ0RCi-DZG7njyh9GbmHL-2w_hu-r9M,9578
 mlrun/api/crud/marketplace.py,sha256=dDJG6puO_asotN8gRgkjwVXQwkLFR7MoTghAcb7TRY4,8180
-mlrun/api/crud/pipelines.py,sha256=kQJD8Qzq6N2pMnMJGv_vUb8LlaQVlXPJDNTjQ1qkE60,13968
-mlrun/api/crud/projects.py,sha256=g1hNC7iZ_VBWmE9pIBeOC7oyec8QRWHg5vm3Qmvz9yk,12098
-mlrun/api/crud/runs.py,sha256=bJHKtFdFIfEyFieaA0EERvxqQKJVJ56ZNU55lRXJ5pE,5787
+mlrun/api/crud/pipelines.py,sha256=aW0RDWAyzK0vnCzyuVLEHDsW-MY-Cy5RvvuqbUhh6ow,13982
+mlrun/api/crud/projects.py,sha256=uLLSMZD0Z8BLkm2naHdNyZK1XyF51IAGVqWN6ydI_9Y,13326
+mlrun/api/crud/runs.py,sha256=E_FP0tQcpBQbisVpDmGZ3Y-2Z0wzoQxkJ73V0ioNOZg,5931
 mlrun/api/crud/runtime_resources.py,sha256=XJRxzrh0NKKBqQq-wXAXFTxWkEMqAX_t3buJsVYOfT8,5539
 mlrun/api/crud/secrets.py,sha256=_aIjtNOBI3fNM_2Tz0_W6UMM3gbMfapDFsBaQU7P_WU,19885
 mlrun/api/crud/tags.py,sha256=TKi6u--McIdmcFEXNrbwgsX5wAaENil7FVwi8mnKqok,3265
-mlrun/api/crud/model_monitoring/__init__.py,sha256=aHqiURRM0rB2Y6slNQznRdJpNumS1DTOFANmQ2B98rk,701
-mlrun/api/crud/model_monitoring/model_endpoint_store.py,sha256=1SOgBfVnwsnTM1SgIbE6qHqsVubn6hKolUnQ2Y9PWb8,36036
-mlrun/api/crud/model_monitoring/model_endpoints.py,sha256=mEneSR6wlvIlsYbINwPjaqyehb0r4Z7ueOKCuSmr70s,32108
+mlrun/api/crud/model_monitoring/__init__.py,sha256=CAW_Xhm94IVid0yos0tLQUd_UdCRYz-_2s_rAloZEZw,722
+mlrun/api/crud/model_monitoring/grafana.py,sha256=uyZOa7KsqCkDWdfcWnV8xg2vlrzmPOQX_rbQq2X9bZ0,14943
+mlrun/api/crud/model_monitoring/model_endpoints.py,sha256=VOpm83yvmgycy-pKzin3CcixgDVOFpitqJHE80RLICQ,40998
 mlrun/api/db/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
-mlrun/api/db/base.py,sha256=kcwOmFp_hn7gQKcyJY7ST_d--Y2INXhh9AhNPvd2Dg4,12967
+mlrun/api/db/base.py,sha256=Kxj491ODRvO7X6sq5gl7oP1wPMPU38mbQPsgNYudTAQ,13684
 mlrun/api/db/init_db.py,sha256=5WSrojwOh79O3guN_7IEi9wjqzKj3H74DU2xbGtrElk,870
 mlrun/api/db/session.py,sha256=g2-5rlAE9PENCro6KBMrsvk5IZPrfHdKgEjjcwtDMro,1226
 mlrun/api/db/filedb/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
-mlrun/api/db/filedb/db.py,sha256=gv8WKn2Sxoi0oNc9nKGRXqFq0qm2R_TxgN8MGmFopVk,13831
+mlrun/api/db/filedb/db.py,sha256=iTehkcdD488diqx4oTng8AJcL2fsYKFJ61mdlMlhywg,14555
 mlrun/api/db/sqldb/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
-mlrun/api/db/sqldb/db.py,sha256=H46cN62dnXwXNpMDV_wJvJu2E0zuBKP418V_BuaXnN0,133098
+mlrun/api/db/sqldb/db.py,sha256=_i3NmUJcHm3p1NYqGzOavfrak8Vot69kI8A2nkR-IR4,136433
 mlrun/api/db/sqldb/helpers.py,sha256=j8VK-l_qZ5vLUjGkFK3D3fBgDgPmi-U8hU1MkMIAhC0,2340
-mlrun/api/db/sqldb/session.py,sha256=Di896Qr3fFGeZW3v8FBnEH7dPvQhfeRC2JobcpJ_Fgg,2245
+mlrun/api/db/sqldb/session.py,sha256=97QcZc7EOhypk3ZMl0F5k1ogsgK834S3SxCj3UNry-s,2542
 mlrun/api/db/sqldb/models/__init__.py,sha256=0cHZKMpzqkC6u3WGPEYE8zPcahY6KxBrK2pwkzTCCME,1063
-mlrun/api/db/sqldb/models/models_mysql.py,sha256=0vs1-rVxiUfpIB8SSZTA0DNLOum2M7mOljB0vzb5b_4,18680
-mlrun/api/db/sqldb/models/models_sqlite.py,sha256=rj9sxj9fMGgdN4jqZvY5kZAHjqqHeNwvhGHPRG_f4YM,17249
+mlrun/api/db/sqldb/models/models_mysql.py,sha256=WOyZDnQRvvXPrPWqJoJ5x-HULSXPssVy3GPru6JAgIM,18687
+mlrun/api/db/sqldb/models/models_sqlite.py,sha256=8tHiSP5ruRjenfZzoDvjnp7kLD7wfEi3XhZx1iXPHd8,16908
 mlrun/api/migrations_mysql/env.py,sha256=U5Fu1WLV5vggRYy4sa7d1ItJr1H3-T71BnkOw4ZjWIs,2906
 mlrun/api/migrations_mysql/versions/32bae1b0e29c_increase_timestamp_fields_precision.py,sha256=MF0DwcRcbyRXdWNeWieEWIu5zMpxZ5IQPmF__werbkU,4614
 mlrun/api/migrations_mysql/versions/4903aef6a91d_tag_foreign_key_and_cascades.py,sha256=BthqApYJLuzuHZEJfrOaERD8M-2FRGsZ3e5tRFvMk78,1936
 mlrun/api/migrations_mysql/versions/5f1351c88a19_adding_background_tasks_table.py,sha256=AuFHglUWD_ibU301xio--zcodAJ9yeGqbc8XFQ3zGGw,1909
+mlrun/api/migrations_mysql/versions/88e656800d6a_add_requested_logs_column_and_index_to_.py,sha256=jlQ40Yqcasyqu4qaetGxoY-DCn-GfWpU-K_Tb9zJVxo,1415
 mlrun/api/migrations_mysql/versions/9d16de5f03a7_adding_data_versions_table.py,sha256=1U5dpO6k_SLNZ0MAd5AukDddcxp8eCUTEx-2o3b_U9k,1504
 mlrun/api/migrations_mysql/versions/b86f5b53f3d7_adding_name_and_updated_to_runs_table.py,sha256=lppZKpOBbGoyzP855Q8Y5hWfcqCzCjOlz-FefAqenUQ,1649
 mlrun/api/migrations_mysql/versions/c4af40b0bf61_init.py,sha256=CGh1ihmMJ4GNpDXNoiB9ksSe1P7PyrV3NqWTiq6GTIg,24057
 mlrun/api/migrations_mysql/versions/ee041e8fdaa0_adding_next_run_time_column_to_schedule_.py,sha256=18_SGHfgvNE6TcjsP2_bmqAjL3YI70B0J5-NojmxRr4,1351
 mlrun/api/migrations_sqlite/env.py,sha256=U5Fu1WLV5vggRYy4sa7d1ItJr1H3-T71BnkOw4ZjWIs,2906
 mlrun/api/migrations_sqlite/versions/11f8dd2dc9fe_init.py,sha256=Kp1VTDMqS72UMODn1GboBo-IwUEZ8IWuflxrBTbATj0,11473
 mlrun/api/migrations_sqlite/versions/1c954f8cb32d_schedule_last_run_uri.py,sha256=w_l46X5Sl53fkku0t4lqmHtEkU_t9A8-lniMM9USknI,1348
 mlrun/api/migrations_sqlite/versions/2b6d23c715aa_adding_feature_sets.py,sha256=7PxARbyyFR1SlNHwTT5D41GpDGjd8b0zSSkYI4TtYmg,5180
 mlrun/api/migrations_sqlite/versions/6401142f2d7c_adding_next_run_time_column_to_schedule_.py,sha256=r0svJ5DsE633B2ss1yWwv50lPMjtSIMsKYOPvfCPBfo,1388
 mlrun/api/migrations_sqlite/versions/64d90a1a69bc_adding_background_tasks_table.py,sha256=pJqfbcEjG7I8yacspyFnbBZvVVpJ4mPLXc4VcJ8X1oQ,1767
+mlrun/api/migrations_sqlite/versions/803438ecd005_add_requested_logs_column_to_runs.py,sha256=3Q_PnbBjaD-04YfjH2MW4IUocOWVUfa-a1_Y-snzBHA,1360
 mlrun/api/migrations_sqlite/versions/863114f0c659_refactoring_feature_set.py,sha256=cNFtnxsL4tTnfZiEo3uhATcqmgU6aqh2jEf521G0jH8,1259
 mlrun/api/migrations_sqlite/versions/accf9fc83d38_adding_data_versions_table.py,sha256=Q7KfNsbnnPWhXUnLMmbGFZIaItOS_Hvr2bY_td-K3vw,1482
 mlrun/api/migrations_sqlite/versions/b68e8e897a28_schedule_labels.py,sha256=1indyv5TlsDK4haAC9xxNznRjXgqjNIjgfFOakgBpNo,1892
 mlrun/api/migrations_sqlite/versions/bcd0c1f9720c_adding_project_labels.py,sha256=JyUhI_H02D0fkBDZr3Hv4-KAiHEOL62z4-YE25ik5Rs,1882
 mlrun/api/migrations_sqlite/versions/cf21882f938e_schedule_id.py,sha256=A5aBWsOuCzs5cZrPiWO9ha26-N3JvzwsaI6wgOarHjY,1420
 mlrun/api/migrations_sqlite/versions/d781f58f607f_tag_object_name_string.py,sha256=icsKlQUC9lJkpdu0RbDpl3L1MMk3Bwb8pzCXZKO9xcw,2034
 mlrun/api/migrations_sqlite/versions/deac06871ace_adding_marketplace_sources_table.py,sha256=po2-IqIvS4pSY8Bw02q6ZEucjEnkXdH5UDudGVC-5S8,1828
 mlrun/api/migrations_sqlite/versions/e1dd5983c06b_schedule_concurrency_limit.py,sha256=9oGlxz4o7BlZbykO3zzedHqzOEoPnvPPeWMLxyRCBnY,1380
 mlrun/api/migrations_sqlite/versions/e5594ed3ab53_adding_name_and_updated_to_runs_table.py,sha256=lQ0lPq6xZD59iupkbAo0wCV-otE0G9lmjEpqIBZEguA,1831
 mlrun/api/migrations_sqlite/versions/f4249b4ba6fa_adding_feature_vectors.py,sha256=AWkrtG6jWOMJHyLqR8jrmbp95Fk9qB6qhjjYLb1mezo,3936
 mlrun/api/migrations_sqlite/versions/f7b5a1a03629_adding_feature_labels.py,sha256=KrIm5pHwHlJr5e3DdtMcBiEjgbopOniWzDi9T1XTSHQ,2588
-mlrun/api/schemas/__init__.py,sha256=TVHve6XLDgFuAYLi5VAcZnrH8wH2dnK6-AtL-HrbIkA,3976
+mlrun/api/schemas/__init__.py,sha256=9qJuHKGc6nLZzUNuKZImwqMRXQSTwfrT_gB6l-SAhNQ,3962
 mlrun/api/schemas/artifact.py,sha256=gpAdViV_3TQ-W2KPPNvdOArEfQZdd427YUW9bml9vE4,2070
 mlrun/api/schemas/auth.py,sha256=9MnT6Ckuy8_kAI7edsAqwN9-wp3noh5xZlL40utYXqA,5311
 mlrun/api/schemas/background_task.py,sha256=RayGDZ3_KYCYVx-n7CgMNDQJQp78ajrb5unQW6wFzhU,1563
-mlrun/api/schemas/client_spec.py,sha256=AkSVzTaJlsHpOsE-mlUtRA0h9n5cPEwQA8bZf4Defsg,2717
+mlrun/api/schemas/client_spec.py,sha256=bQhGYtkcJg27yo82y3FNiiNZbYuwWce8SQxcXtVKJpg,2751
 mlrun/api/schemas/clusterization_spec.py,sha256=QmQ95NFgRuKCZZYCQFCpQGa-rutxY7wAjJI7tVS8Oc4,898
-mlrun/api/schemas/constants.py,sha256=h7EldCa8MJ1hTmdc13z_zwCQGLX-zRFA_LXmouxizU8,5224
-mlrun/api/schemas/feature_store.py,sha256=IQKD5jvchO4S0dHVmixDCCM8ryeMccVIjSralNmu68M,3661
-mlrun/api/schemas/frontend_spec.py,sha256=N0xvG3oionOQZcWVB28L7sQj70O2RCa7ECaGBFg9HKw,2513
+mlrun/api/schemas/constants.py,sha256=JmIZGD2R1qjJIRk5fHNEFTVLw-6eh4cJ0FCP8i1r6xI,6278
+mlrun/api/schemas/feature_store.py,sha256=kX3Wd107ZfyGrDOcNmLEcgdVrFgtHTswzVhmH6VVWX4,3671
+mlrun/api/schemas/frontend_spec.py,sha256=-kYKekdyrUAx-dOhhyvhh54y-KWV3bGfFAxqJQ3jmiw,2571
 mlrun/api/schemas/function.py,sha256=5Iy0aZYwXw9_vLSPBUwhuD_YMuQn95_11oX7DSTFIeo,3991
 mlrun/api/schemas/http.py,sha256=q9l7LBK1pIWlax2gHK9rPQfeugHjBMUrLDWAxdGxUII,715
 mlrun/api/schemas/k8s.py,sha256=R6Ufggp8MqA0lQ68AMsh_qiRcbsovaWKJg1a40XzcZg,1405
-mlrun/api/schemas/marketplace.py,sha256=SSx7DScxnZmpbVLFZa11p7JhJHcDY3FtdPcCUtuFCXY,4255
+mlrun/api/schemas/marketplace.py,sha256=BD0Gb_VFxcvJS7_6gQqxb524TL2ZPn9xwbUhwvleoTo,4258
 mlrun/api/schemas/memory_reports.py,sha256=SlNJ-uya5RywEysm_IZMwF1t4j-zYsjOj8oPYwLRO08,920
-mlrun/api/schemas/model_endpoints.py,sha256=qpkPg7kEaqvpw5u4Dv2KuGqC74HmBh7fnj7rtAk3hSc,4872
-mlrun/api/schemas/object.py,sha256=fo7EdjT7IJwOlbmEEpmP_t7i4iBE7q7PO2o6PdXGzSU,1960
+mlrun/api/schemas/model_endpoints.py,sha256=j1U0bqYSv_ytjsQ7ZM0qEk4ebUdk-1Yks3h9dNEJijo,12343
+mlrun/api/schemas/object.py,sha256=bLMt30Kgch6_4Q_KML68NerU_HuTqW8K-4LUc8KfyVc,1965
 mlrun/api/schemas/pipeline.py,sha256=qT-4NW2vOXmLGxwbGhSPbmDRoeoOhCA2I-j52pop4dU,1194
-mlrun/api/schemas/project.py,sha256=AX5Zn5XUOrKHyhn7WWNeMlfMkVMyxEQaHkCbxT6Ejc4,3909
+mlrun/api/schemas/project.py,sha256=EhGRhSa_Pzzy8cxl_vtu93v2bydX9VHo12rM5rCSeOY,3935
 mlrun/api/schemas/runtime_resource.py,sha256=r4Inv2-ujfgpuYsp0e82A8MM-jdt0pJjD-oKWDNwlz0,1646
-mlrun/api/schemas/schedule.py,sha256=oTs7o-WNMaG0UGwS-oxiWNHAzhy0UJ5qEvBE43226Q0,3986
-mlrun/api/schemas/secret.py,sha256=ex9mrSbibeOLBMkC8nzBWh-ppsRiyVTc7d3RIQoF1I8,1484
+mlrun/api/schemas/schedule.py,sha256=RlHpjOaoiKn15DZkwCLZIBW9g8ArBKUhoTaCBlpx768,4192
+mlrun/api/schemas/secret.py,sha256=xdzAG8JCJVGy4f-qzcLH23uq4eNIuGePLdZPPFhunXs,1494
 mlrun/api/schemas/tag.py,sha256=x7l-nxJyjxqupu6-3CQLh_r6mD5-EST3KM-WyuTH-DM,919
 mlrun/api/utils/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/asyncio.py,sha256=E80efqnDt-rRLVqbdjlzHjfe5SNwB4Krn1Y9D0C0JMg,1092
 mlrun/api/utils/background_tasks.py,sha256=esLg3Abfozpbc1wBa4RY5_jSLLD6TLvhIMixTixsNRQ,7302
 mlrun/api/utils/helpers.py,sha256=MHtJ6HICTIsTX6jH5D5FCz3P-uYBQ-nmCNft6gbT73s,2413
 mlrun/api/utils/memory_reports.py,sha256=Diraa4EbJJ28NGrfSuOuGroVsE2sNeRkjUp7Dl4qDlI,3728
 mlrun/api/utils/periodic.py,sha256=Vc8jz2WIsItkb7rcmdtxUfD4-Pohlg_XVbLEUw0S394,2599
-mlrun/api/utils/scheduler.py,sha256=HwJ0_KGLzlix3WHeRhFcAagBFwvvDoPS7r4Yb3pGo2s,38870
+mlrun/api/utils/scheduler.py,sha256=gSPQqOECd2XSpyiDCu2ru4Vy6zxcKUOagVvqlFcEfi4,38822
 mlrun/api/utils/auth/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/auth/verifier.py,sha256=lq2BC0enehWv4mOgNP9nQMjnIw8HAvlgKFogE88O4Hg,12249
 mlrun/api/utils/auth/providers/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/auth/providers/base.py,sha256=lTbV35QVryy7nwY9iMvJk0ubS_jDwJ7mptNjqWnbdiU,1363
 mlrun/api/utils/auth/providers/nop.py,sha256=5hZ880PMHagbUHVAQcC6FSQUCQyxk8UimKYlBHuj8eI,1470
-mlrun/api/utils/auth/providers/opa.py,sha256=-3O4antemW0syUUL57Orh1JEJ3EScAESnqCGpRGzksQ,10471
+mlrun/api/utils/auth/providers/opa.py,sha256=Tg9MWaka2iBhh26S313LFr5v-46_kG9D3F2-DVXXumU,10835
 mlrun/api/utils/clients/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
-mlrun/api/utils/clients/chief.py,sha256=eDW3e3-raMzzRsSl2slYSOflE7tWSjvxLtR7M2ixufw,13014
-mlrun/api/utils/clients/iguazio.py,sha256=4v6l5aj31mi_hMndHyHQsElkSHl_Rlg5nY08TLKdknY,30137
+mlrun/api/utils/clients/chief.py,sha256=DVYvWEWm-GmMZBscrcY6ZbjpWwaO-ZYu3X2BTrfZ4DM,13232
+mlrun/api/utils/clients/iguazio.py,sha256=64m0AUqykYHtwMoWQ2t7VmyuVWM2IQBC1lRIcNbBhSQ,30488
+mlrun/api/utils/clients/log_collector.py,sha256=LTDpmk4MQuTNyMIcOXQ4tZLX2TvXXbTuU4tUN1qDW_s,10775
 mlrun/api/utils/clients/nuclio.py,sha256=D-yzYXX6rOHiZ0jO96EuQCGs_Z7fadThLavVYKJaM2Y,9841
+mlrun/api/utils/clients/protocols/__init__.py,sha256=xY3wHC4TEJgez7qtnn1pQvHosi8-5UJOCtyGBS7FcGE,571
+mlrun/api/utils/clients/protocols/grpc.py,sha256=WLwnKSEf2X9_PzaaWBuqGKHlD7H39vf8Cch5UerXEoQ,2564
 mlrun/api/utils/db/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/db/alembic.py,sha256=sUVnWHXRzA_Yhn2GWiSqeQ8dcfpC4IPQpTFBjTta_iU,3305
-mlrun/api/utils/db/backup.py,sha256=uzO01-B8-hxG5RydFQVYZ4cQRIC3oxlkPj4oQNN6bz0,8100
-mlrun/api/utils/db/mysql.py,sha256=3dVJuuzDGfZWg-squV9t5qmUbXoC-RGn2Jk0j2kPD9Y,3793
+mlrun/api/utils/db/backup.py,sha256=LL4qL3YaLAbehS-KHn-Ieys333ZReEnmFIOoYV7BKzc,8214
+mlrun/api/utils/db/mysql.py,sha256=KWvD37V2_1hztu_g4-Jpe4aLmcc5Gl6x7-HzYWqkBOM,3795
 mlrun/api/utils/db/sql_collation.py,sha256=t1pYJNPDwSP0PZwtlTqMAUgYhGZLRv0awbnEYy3Geis,992
 mlrun/api/utils/db/sqlite_migration.py,sha256=oPv2Knboe4vQGn9MDUfqbFrcIhvSuDoFji1Emj59MIA,3855
 mlrun/api/utils/projects/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/projects/follower.py,sha256=DW7nRVNZZa6Bry4wybGssp32TxXBgsROJsz2wGmXaFI,17315
 mlrun/api/utils/projects/leader.py,sha256=d9ugV_tLhHlzJdqArWiuByG6bKrvW5wHAqJ4Pr8uxko,19424
-mlrun/api/utils/projects/member.py,sha256=rkP1UqMfCedO9Bzi1lcDIvWArBr4k3-_K0JzZMwRQOk,4936
+mlrun/api/utils/projects/member.py,sha256=bOQq5wNRGYR8uI0BwQJjdvtb3CbepEuiQZ00dDWgD8s,7040
 mlrun/api/utils/projects/remotes/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/projects/remotes/follower.py,sha256=UrtXlvliQ6Uyi7qn_y1HZTm1WuXNl_1mJhYqHrFT4Vc,2614
 mlrun/api/utils/projects/remotes/leader.py,sha256=D0V41b5rcr-w4AgEOCp0THG7ve2v4BePQG41ms1HJKs,2064
 mlrun/api/utils/projects/remotes/nop_follower.py,sha256=lMnq7uZcNbNc4A3ghhTdYzJjSo6V3sYnyqnFTbzpbP0,4601
 mlrun/api/utils/projects/remotes/nop_leader.py,sha256=0sLDBZcGtacQwygS1p7GD--EGFLFWohOGFyXmIiy5x0,3801
 mlrun/api/utils/singletons/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/singletons/db.py,sha256=4jzYXBZYHGjEARXCbHFwIcvlqW-05efUZVvrsnXiLf8,1439
 mlrun/api/utils/singletons/k8s.py,sha256=fxQuohr-iIGKQEAR6V5iZ3dka0438Tfm0xq_j2D5OGo,694
 mlrun/api/utils/singletons/logs_dir.py,sha256=zCALZ1N8IylkfvATfsbWfBtEPvWKl2AEQ2-QF-J0VWs,840
 mlrun/api/utils/singletons/project_member.py,sha256=1xlvJjbY-HvQuUV5rsQg9rMt-Y9MKU77Az5f98v-D28,1279
 mlrun/api/utils/singletons/scheduler.py,sha256=LmauJTsB69P_gkx4xTMzQrW1kaaN050txZzrrl08i_k,1063
 mlrun/artifacts/__init__.py,sha256=b86JkwaOMjN9gPzeL-RlkAtiITaVmGS9viNlvGG1lrs,1091
-mlrun/artifacts/base.py,sha256=VYrLVKcI2eUVqZaBTbc2-e1PKc1RWGjeLfWfXXRJ550,46443
-mlrun/artifacts/dataset.py,sha256=NkL5l73XdEJtNs4FoXaXrMIfnXNU8gQv_50axb4eGPE,24722
-mlrun/artifacts/manager.py,sha256=Zm8CBhwfiv8GHYiBsnqR-KaVbKV9v-w4zJo6bd-4GOw,12001
-mlrun/artifacts/model.py,sha256=dSbnzu5F0DRQZnO9xTW4HHfxhRGHN3nk7hEqUQg2M0k,32043
-mlrun/artifacts/plots.py,sha256=e3mqLHkSjqkQyrrG-V3VVSI7_r7UnMvmU264mE8xKwY,14636
-mlrun/data_types/__init__.py,sha256=S8erhsRy_Kd1L_G59UYn3f4ASq2mQkl-DixVqHMBfBE,1039
-mlrun/data_types/data_types.py,sha256=PhYwciI5koHC1d4EmNeYwc9gG0SKLOftGhp0H3hLxps,4541
-mlrun/data_types/infer.py,sha256=RnKNgavRHd9LXQHtPphR202ehu28elgR5upBmp-59g8,5499
-mlrun/data_types/spark.py,sha256=rSxfbcccL18WiWKCa866wwKnspC2uA8JhWCIEmj2jMM,8786
+mlrun/artifacts/base.py,sha256=l-dRIaK89NOIiBqiSbo1vbPks8CeRv83wSKndybJt0U,30849
+mlrun/artifacts/dataset.py,sha256=30N8bYHiX6vW-w6yKAcTGHqxDQ8yGDvxYSVrR2g2VNM,20366
+mlrun/artifacts/manager.py,sha256=O3V_T7Tw6Q425N6SwbWs5M4pAngRa6wc2DQdrdpZfDM,12110
+mlrun/artifacts/model.py,sha256=SmzieOo7d78CPhVyyHMmI6WltkCSVn-d72jAxhHKd7E,23673
+mlrun/artifacts/plots.py,sha256=0Jq5OgDB1srtUlcISF696E_q3S_D-mqeMe6Wyn1S6ZQ,15383
+mlrun/data_types/__init__.py,sha256=hBd2-QsTqesw3HUDoIUaUtCR1mWEcRc4V7Z1V8lNP0s,1087
+mlrun/data_types/data_types.py,sha256=xjsnUw144Lbkg4JqYLYym8qQpucYQUjphxay_BIc7VA,4647
+mlrun/data_types/infer.py,sha256=ErGpXigp8bG6hkPJfbJt8cJZxsZvj-bK0dLSiTlUYzk,5813
+mlrun/data_types/spark.py,sha256=f7ila08Hnckxs-RjhzubRbg2_ZzyNpvCV_Vrgak7yUM,9118
 mlrun/datastore/__init__.py,sha256=lEcQKc3_Q2dfK6CTg2hwlTH3IoKQg-xE0WeMOanmxfo,3300
 mlrun/datastore/azure_blob.py,sha256=XFBpXZfwMKvv0rrYVP2J6RDqziNPHW6KqCbsY-VLzto,6946
-mlrun/datastore/base.py,sha256=4JgaXw5i_DOY0IJQiMXLGdskUia6TUgEOpwyZRGWSuA,16142
-mlrun/datastore/datastore.py,sha256=OeaCrQuzxe11GCB7UX9T6Ddk_msqy5bVTosZMApduAo,7961
+mlrun/datastore/base.py,sha256=5njgvevYPBEAAKJ0AFAh-fzebietmifi4sNuFYWAxa0,17304
+mlrun/datastore/datastore.py,sha256=l6CfmIYn7rdPQyRZ8kZu45cfyDZcDXDH5CwLKvsFlI8,7995
 mlrun/datastore/filestore.py,sha256=v9-BTJMgamGN_neoXNkIbNNr56UpgOewMEX70P8MTbc,3791
 mlrun/datastore/google_cloud_storage.py,sha256=9dtZt7Opytrra45urj6ObYa1fxf7UIOHXSoog4G9l7I,5114
 mlrun/datastore/inmem.py,sha256=o6Svv12k5PxJNT24nMgV9FBYEPCzD3OQzuuvU6OeCYY,2627
-mlrun/datastore/redis.py,sha256=izoPCwdDCWJT00XJsmENf-NxW-wTxZCCxEfk_0rGZXM,4758
+mlrun/datastore/redis.py,sha256=pywWgjGJ51pmvKuwX1MI3ILWqh6WtgDs9igOQAhmIhc,4873
 mlrun/datastore/s3.py,sha256=fn1Yg5Rs33ugHlwTKvBfu_jMKqkSZWgHNw0ocQ5nO7A,7035
-mlrun/datastore/sources.py,sha256=gNEHY6PanyoWxPNDqiJsbmpaz0bOI6z7w9MVfPtXbLY,29687
+mlrun/datastore/sources.py,sha256=89ckC7p5wmLdKCtZjSdWog6On97k8-JfhsUPKnRsucE,34025
 mlrun/datastore/store_resources.py,sha256=N4pNnvs8xvDt7eg7czP59BFfjgVxfiQLBlhl0ehTkzo,6864
-mlrun/datastore/targets.py,sha256=LF8ewEo5utxiitPfV2rzK4hZSuN-dn8NKLwcVAJJ8hk,52773
-mlrun/datastore/utils.py,sha256=rkAGw5ujz9IaqsKCFVXI50NHe7ighjhFT3rCHgTsiVI,1512
+mlrun/datastore/targets.py,sha256=CRWCpIv8ps062ykyXR_YZl7egi4BwI7WXYWBxfiYLKs,61928
+mlrun/datastore/utils.py,sha256=WNKBhgG2w9xAviyieGCB6hTnESEYzCwzgjcjz6uaWC4,1660
 mlrun/datastore/v3io.py,sha256=ArEYq78irv5bwlRwcLeVfFJvcwtXEamGsZ2I0sVt7Qg,8097
 mlrun/datastore/wasbfs/__init__.py,sha256=4CK7vZeJmC4Ak9cJjG07cGnk7jlkBlpCxw-ANfbBmzk,1343
 mlrun/datastore/wasbfs/fs.py,sha256=DEZgwrmQSPeR93MNlC9OCwuU9wvTSmIM534p5ccQzAE,6152
-mlrun/db/__init__.py,sha256=aNX7CINSVZCe4GuBD4umsri-RRaDUjU0PwCQhLibhlE,2806
-mlrun/db/base.py,sha256=i8OYTyB0S1qKTTSlri_CyfToWChqIQ-b76s1PrR0EE8,14722
-mlrun/db/filedb.py,sha256=PHfiGS-QL81jApmJBLye6mngpj122mTrUFQYxWfbxHA,28101
-mlrun/db/httpdb.py,sha256=aAHRb025dAbuVgKGqTUDNwzgDWt1Zdqzc_E1MPk_oHA,127412
-mlrun/db/sqldb.py,sha256=xbeFp5pR_Meu9s2cnAgGN05tL7RX5HDHQjYj5CnSmp4,23676
+mlrun/db/__init__.py,sha256=4_UTWWoVZU5B2D70NLTjYlMM7GVmLofnPRo5nGzT7XY,2810
+mlrun/db/base.py,sha256=FR1LnEP0Y4UlarcxM6wki4HeYnL0raccPkt_2tkEngU,14796
+mlrun/db/filedb.py,sha256=Q2KlBGolTSjROt4-iSa7gWVlZVIF5uYOoW4Mf1MULzI,28129
+mlrun/db/httpdb.py,sha256=7pa5nwfwsptKakNBOFCWI7TQ-J_VoU3wv97KHzkC7b0,128262
+mlrun/db/sqldb.py,sha256=CdiF5D2t3oQLtphKNUzBY4DJSY-ThGSxS5ks108uxIQ,24292
 mlrun/feature_store/__init__.py,sha256=guoak0hQTMoE4YsWwyoyso0CYE9NSPoP0eUal4crfVA,1501
-mlrun/feature_store/api.py,sha256=Wir-bKbpyj5VmKsRnOGZqM6KPGnBZqrrQb5hXHcaEzA,41126
-mlrun/feature_store/common.py,sha256=151wpdKEGiDsSmQgdDVNAlNE3oCLhw9dWjX3pgZg8Pc,12754
-mlrun/feature_store/feature_set.py,sha256=PtdynyOvTo03D_rqjRfAfQ7hjqh-VOz1nWaQkSQ8Tpc,41889
-mlrun/feature_store/feature_vector.py,sha256=3U8bX51V1EuClVEO2xBeOdazIcAN6N38UYQio9fPZdo,21658
-mlrun/feature_store/ingestion.py,sha256=nunGFNqBikRsTwKnScCxa-csk2i4K5OgapAhTZp2WaI,11461
-mlrun/feature_store/steps.py,sha256=pc5B3LFboJMHxD7QjgJc6m6Eio8PMzh-j3qchkqjU6o,23658
-mlrun/feature_store/retrieval/__init__.py,sha256=_Yz73tj0-zV4EWaOwz5fhojj5ieeA5Bb6qYdlUizW6I,1012
-mlrun/feature_store/retrieval/base.py,sha256=K93KGAkxPuKiy0IdLKypbvq8CanO0U0H80DZrTWzrhI,7588
-mlrun/feature_store/retrieval/dask_merger.py,sha256=kas7D0tkOb9FeDsAPXtZ2UW_-TnighpMR0LubMdyefk,4738
-mlrun/feature_store/retrieval/job.py,sha256=JNNJVYIjxLBRzd_DW-sD-QbjaGKKMYPDBRBmIC954Vk,5437
-mlrun/feature_store/retrieval/local_merger.py,sha256=oTSFBid6KPGxk57wQwxW82rqdaK8fT33D6jYqfYC8Pg,4941
+mlrun/feature_store/api.py,sha256=Nc2whgnymqvFa32PE4agdebhhf6ApUMKOr0Wlie1GB8,42928
+mlrun/feature_store/common.py,sha256=bFpPyFgGFuh-SwTl5AMUGD1mJr3GhVsFcDu-yIP5HAc,12807
+mlrun/feature_store/feature_set.py,sha256=5bigExu8KSIm2kD12eWvf1uZWIk7VNqzWye_uAah9XU,46903
+mlrun/feature_store/feature_vector.py,sha256=hLOyejUK-itqZRzbqOQEQcijJHsJlypuHD7ZWQ6B5aE,21937
+mlrun/feature_store/ingestion.py,sha256=7qcBfNkDZsD4IXRdRN4OCSPIlpQDVo3WaO8pnAAYY6Q,11813
+mlrun/feature_store/steps.py,sha256=sqwY_IsUUA0ATNQryExjjzRwqgRKN4Ez66OktXVSoFY,23868
+mlrun/feature_store/retrieval/__init__.py,sha256=2b2WoPmH4TqcSSJ2OQYSjsDIcUe1KA5DnG7-wkrIayM,1232
+mlrun/feature_store/retrieval/base.py,sha256=38n5qY60V-wvn5vAVSd4qQlfkMMTMchX0c2TdZ8XqqE,25911
+mlrun/feature_store/retrieval/dask_merger.py,sha256=-xRgRPWUblu3KtVhEoL0YXEAcgkZrSUykDe31xnEzRI,4261
+mlrun/feature_store/retrieval/job.py,sha256=NwVrTKlR_w4KpMgQwTkreddYUbWI-6pYuksXowZQY9c,7106
+mlrun/feature_store/retrieval/local_merger.py,sha256=h6FE11EZxxqVe2EhVnQtwl5cxOBsOCXQCbTLOJk3op8,4765
 mlrun/feature_store/retrieval/online.py,sha256=tnpHqcbaA16lKTuvlU6WoXwnb_SLmbWBLzyJSvhss28,3352
-mlrun/feature_store/retrieval/spark_merger.py,sha256=D_a1Hd79ilBDhUY2Sa2L2kNnQAy9HIAOXuRnb3q-cMs,9726
+mlrun/feature_store/retrieval/spark_merger.py,sha256=R-xHI2ubdx8y_bvgnxYfLtOTOWCy5q6Bjd2AZD1fh1w,9661
 mlrun/frameworks/__init__.py,sha256=H1bU7R7Ua6e52HLpP-MivDJh-L47564uJNTsmgJ0LH4,743
-mlrun/frameworks/parallel_coordinates.py,sha256=YT_omrLPQ8buGXoBW-6dD3bH1nVbphEgCstqAc6v3Yg,11404
+mlrun/frameworks/parallel_coordinates.py,sha256=83AvqW9z666XDWd29WopLeOdEFAA2HpRZS6d08z1Nbs,11466
 mlrun/frameworks/_common/__init__.py,sha256=5C5C4nQkaGHnv4WuCLjcjtb9nfhRK-7g7O6bbuJVkSY,962
 mlrun/frameworks/_common/artifacts_library.py,sha256=RVh-uIinpH1do5UE6C6iIT44S5VaRvvZONLOp7jCPyA,8515
 mlrun/frameworks/_common/mlrun_interface.py,sha256=WD-CmVirLUx62pzcNLK8OYZpfrfP561rkU9g4o5d1ko,21018
 mlrun/frameworks/_common/model_handler.py,sha256=n89sZZXdUyeYVzPjmWGuRCO8EVX9PI9pjK44CTl8mbk,55376
 mlrun/frameworks/_common/plan.py,sha256=NgO7TEWBCLj1SPZL01zgRmVD-KYdwcZNCDiDi_ucuqE,3469
 mlrun/frameworks/_common/producer.py,sha256=if5LJarHi0PtBoJquEtEpWDdZ1uezgeyI6lmjEDS-us,5757
 mlrun/frameworks/_common/utils.py,sha256=AP54RnKfTZEJtMeiYkl8OWHIc-LAwA9Js-nrSlFvxXA,9209
@@ -223,15 +229,15 @@
 mlrun/frameworks/_dl_common/loggers/__init__.py,sha256=DZ4HwyoeHy_Y1mPsRyOcra3yCXhcR8lloYHEhXToxCk,787
 mlrun/frameworks/_dl_common/loggers/logger.py,sha256=AdlofLPJLVMZbVqUmeZvSyExxaCLwQroonW_WeaXAQk,11531
 mlrun/frameworks/_dl_common/loggers/mlrun_logger.py,sha256=T7FoOVxKc6ontfJBJpfnfc7ecxRiJm0JlBLunx1FtUM,14777
 mlrun/frameworks/_dl_common/loggers/tensorboard_logger.py,sha256=RY-hSYHWb81l6ftm3GEggUnbad9jvcGy92dqB9AOGeA,28414
 mlrun/frameworks/_ml_common/__init__.py,sha256=kO3SZHMaHcqZMU8l3Wz-Pcuys6gBNuKDj4nqUNkLtOs,956
 mlrun/frameworks/_ml_common/artifacts_library.py,sha256=Q0mD-8IDFh0hqVjaCUxj3TINSne36l4feCkzCnm1hFU,3169
 mlrun/frameworks/_ml_common/model_handler.py,sha256=z5s5_uLOM37kvGf4NklmHrhIdu3GKU_vSgHJdooC6mU,16957
-mlrun/frameworks/_ml_common/pkl_model_server.py,sha256=Gf8OSRcxRDygfmbxfnf8tbzxnEzDYMF-PVxUetUPyao,1702
+mlrun/frameworks/_ml_common/pkl_model_server.py,sha256=1mw-vbDtESlQ6NPxjLHfQqjOKP48vJjcJAOPsPh5pyw,2368
 mlrun/frameworks/_ml_common/plan.py,sha256=U9a3O9SIgoYtqOnquK87nbOeiLyC95nQ8UJ7KqhArAg,4881
 mlrun/frameworks/_ml_common/producer.py,sha256=E0b8oJRR5Vh9SXsn1UYatXwGOp0rB6Qq8ah-y8lamBU,4061
 mlrun/frameworks/_ml_common/utils.py,sha256=9Zq28eI9HSdfpyxT7aPmoim56riaX2DUFu_4KeFvFGk,10490
 mlrun/frameworks/_ml_common/loggers/__init__.py,sha256=KVgp9xsbVEiMV562iPkmr7eYn_rWwNGq4_9jc8ZC0JU,737
 mlrun/frameworks/_ml_common/loggers/logger.py,sha256=gpC-g2cBbfjA8qLnAfUZD9y2if2mMHyOeFFRLlH5DY0,5684
 mlrun/frameworks/_ml_common/loggers/mlrun_logger.py,sha256=mRfIALjGq7ZlQODOzLvqijYL7UZzQq8nJknuhaNG_wo,6453
 mlrun/frameworks/_ml_common/plans/__init__.py,sha256=h9yzfzK0NxDfb4TcyrgC38BWjSvucifD28i2GMa5Wgw,922
@@ -255,28 +261,28 @@
 mlrun/frameworks/lgbm/mlrun_interfaces/__init__.py,sha256=L1lSIsqk3ZZ3d9h7hHv-hMcmqbbCGUopOMs6e_sCpzY,842
 mlrun/frameworks/lgbm/mlrun_interfaces/booster_mlrun_interface.py,sha256=KR3DKwKeXYHDSarlqpxPdUflQZKEXHjrgYOdm4Tk3ko,1624
 mlrun/frameworks/lgbm/mlrun_interfaces/mlrun_interface.py,sha256=-jqcM3-53y_Rmk-UWMfw5ac77HXPVAFnZbKq3kjYqJA,14256
 mlrun/frameworks/lgbm/mlrun_interfaces/model_mlrun_interface.py,sha256=LrPLVduyTagD-QB81ktpJYxhZ1sOiMecgmVBmvB2nuI,1333
 mlrun/frameworks/onnx/__init__.py,sha256=APwk3ZpJxY1EjBPV35_-LBzb1xEV8F-3bQrG8x6bANE,791
 mlrun/frameworks/onnx/dataset.py,sha256=xkgdDHKOQZ2qe7A5a5Q0_E9RYCDnqVl7Ogpj98Izcuc,6098
 mlrun/frameworks/onnx/mlrun_interface.py,sha256=5mNIFjTCpRBQglyDyScL7GTt1907FhI2zIZsyD9aTOs,2405
-mlrun/frameworks/onnx/model_handler.py,sha256=DA6oHJPmpNpKWwyFboCvOWTd6HuQSNwcEDH6J3vj1H0,6120
+mlrun/frameworks/onnx/model_handler.py,sha256=x6bVC7bcb37p1VeauYTG_BOQg-FX3V47GSFAxdDNhiI,6203
 mlrun/frameworks/onnx/model_server.py,sha256=uVV5JE5HMRHsOjYJBu4FKRRkCU7A78rjNtvB2I-QVY0,7061
 mlrun/frameworks/pytorch/__init__.py,sha256=-u1MUIPxdQu1qJA7EBfaWI_x3KeGHgIM76dCACRWLvs,22056
 mlrun/frameworks/pytorch/callbacks_handler.py,sha256=4XcfCCvxdfppRgfXsLxtbGSxcWT3uHUZHTBnN1TjHig,27904
 mlrun/frameworks/pytorch/mlrun_interface.py,sha256=ZxZKXFsM9VLxfhs2sMrl8p4Bc8Nam4xM4nmPxoB08Lg,44639
 mlrun/frameworks/pytorch/model_handler.py,sha256=rNv8X0YC1b7aQL3IFtSGB_rgoyIXbincP_Ebx-slF7w,22465
 mlrun/frameworks/pytorch/model_server.py,sha256=bp79k7tOK6CiH8i82a_oP71vG_8z-Jpyr1kIsa9OJOo,10136
 mlrun/frameworks/pytorch/utils.py,sha256=Oq66xJpXcm-f3PztIm7TfGZTNY18aXG4Ikw_s9OD5x8,4515
 mlrun/frameworks/pytorch/callbacks/__init__.py,sha256=13WM9gPhfVTWzGG3nlmJYxNFUhpUBc5-fpjIFRDxBGM,896
 mlrun/frameworks/pytorch/callbacks/callback.py,sha256=sgCK8wqmQvaxc65sWutaUZgrIoQN3w3V2_x3li2VPhw,11524
 mlrun/frameworks/pytorch/callbacks/logging_callback.py,sha256=m5X-BpRdfq-Om_yR9R38u9PtZhqtw1C7PuOpajgGOf4,23166
 mlrun/frameworks/pytorch/callbacks/mlrun_logging_callback.py,sha256=ipiqVQsIwbTNxSB_OoccXY6Ju29zFms-adVq-Vhe32c,9310
 mlrun/frameworks/pytorch/callbacks/tensorboard_logging_callback.py,sha256=sr_XzE9xjstoJ4UwXPbN9hLMWsgCbUVkCwUuITqWgu8,26661
-mlrun/frameworks/sklearn/__init__.py,sha256=38LLKcrIOSDIbiVfAk6_BZZpU6Ak3L6dDNk4s2ol-3I,10940
+mlrun/frameworks/sklearn/__init__.py,sha256=AqOSAPp1OGIHr2qZ4gGOX2PEqbpmQGo6cIpC3yB70zk,10892
 mlrun/frameworks/sklearn/estimator.py,sha256=wz-bQVQA3ZDCJrVhbKeAlq20Gur87hezS-ZUIMdwGMs,5852
 mlrun/frameworks/sklearn/metric.py,sha256=P6fwzFd0JfCBXpdUoqZdiUWggEG2aIy9RtOiDDEiNm0,7117
 mlrun/frameworks/sklearn/metrics_library.py,sha256=acnHwpW-rBTHxKXl2iL4Xa-M_b-AMHrvT7DaYiIVoDQ,12215
 mlrun/frameworks/sklearn/mlrun_interface.py,sha256=97UyVfcsgbDwU0IhTb_xTrfNOcMhKI4CPX6VZ057QYs,14126
 mlrun/frameworks/sklearn/model_handler.py,sha256=EXgFajawu9qHtz4rIR7GsGWcFoIAC9eOsMCOS7tM28I,4745
 mlrun/frameworks/sklearn/utils.py,sha256=yYsUq-rZZkil9O2nj5FSndz6ZZcwsaKFG0MKxBZs7-4,1209
 mlrun/frameworks/tf_keras/__init__.py,sha256=qDT6pdAloTVAbMF-h04IKGNW9h1cO3L-erTsiHLVsv4,10455
@@ -289,84 +295,98 @@
 mlrun/frameworks/tf_keras/callbacks/mlrun_logging_callback.py,sha256=N1_lNXSig6FwSUt1P8ZNKf1Hie-9pMo2feFjV7AoJzg,8791
 mlrun/frameworks/tf_keras/callbacks/tensorboard_logging_callback.py,sha256=YM7gNuryhioDrvVPBhpIUo9lH-bhE5JdE-xSo-kriP4,28728
 mlrun/frameworks/xgboost/__init__.py,sha256=2-q_HGIgwzZUoBpxMC5OBYpn29qh84HHwZpHRcOke_I,10287
 mlrun/frameworks/xgboost/mlrun_interface.py,sha256=JwbFkYz97gmkjLN1V_zu8nTG9zSey1RtUmUO6XfaZ54,878
 mlrun/frameworks/xgboost/model_handler.py,sha256=3KSLoL_uBBhRPkGEgRxJz1MPxQbcbvuIxJawQConfrQ,11617
 mlrun/frameworks/xgboost/utils.py,sha256=Yz7vIfnFMqa2A0k2GweXL912-tt7JnQdYsNX-pFs45I,1069
 mlrun/mlutils/__init__.py,sha256=enRhuXMjuev4xr-0l1zLxtoDp79FHc-HXbUoagYomvk,760
-mlrun/mlutils/data.py,sha256=bfq9Ul4pyS9L54y_OGxVFOStze5CRNxsm0tXoPMU-Gk,4808
-mlrun/mlutils/models.py,sha256=M9NRV727iNil3d_L9R4E460wN_bIeBureO-6gHA3rYo,2230
-mlrun/mlutils/plots.py,sha256=y4_YBwApyt1Szv-WQ6RVhA1fn1qYvP3SpGcDqqUDRGk,28253
-mlrun/model_monitoring/constants.py,sha256=PBXozTi4W0erE0V2s-25sV-ETQea1ikAnOwf1aHQFEY,2142
+mlrun/mlutils/data.py,sha256=uQ45eaKYx3Jy93l2TqosFW68Kj_ZtVI06ilxGxydaUY,5325
+mlrun/mlutils/models.py,sha256=_CijiNJkLnWdz0HU3DAU6P8TbobY7R2QVpuCOHTJD-4,2598
+mlrun/mlutils/plots.py,sha256=0-Rih6th9WkgzZRPIPZwz08lv4bVSX7YbyGNgA02xdA,30120
+mlrun/model_monitoring/__init__.py,sha256=5TTKiOBEZcUCDqPYqmPhCf_qukmha10vbLo6H2mC4jw,1307
+mlrun/model_monitoring/common.py,sha256=jPh_HQlFHTZipEUlU4BGXgBGf3bxRu0JHkV5MdmoiKI,2962
+mlrun/model_monitoring/constants.py,sha256=dGdQMDFudz4ZB-YYp2V5T2K0KbwIeq1ZjrOeqWOfohA,3117
 mlrun/model_monitoring/features_drift_table.py,sha256=DlMkc-GwRhIALXB0OdCQkvOZQUVNI69RpJ1PAwLqK9Y,23948
-mlrun/model_monitoring/helpers.py,sha256=MNcBGzEe3qiAbHBappx2TEaryV_q0J8uJe18Nqz-F84,5939
-mlrun/model_monitoring/model_monitoring_batch.py,sha256=EG1sAW4AKDCS91nve8PGIwM1flEcYPGlu0x3M-3oBxA,35538
-mlrun/model_monitoring/stream_processing_fs.py,sha256=DQAj593BfCsg-0kfFVlPAUJ9YYm8XJaqihnsTojAttY,44033
+mlrun/model_monitoring/helpers.py,sha256=KSQhT5orKZH6EN-Aow1OCeEZVtRatRuDWz7Xh-MFW8g,5935
+mlrun/model_monitoring/model_endpoint.py,sha256=Km7slqz_2O4mv9TZkBF9-gwrr7LYIAEKnmGd0OB9IA0,5176
+mlrun/model_monitoring/model_monitoring_batch.py,sha256=3EUb1KBA0b3SyP6aWa-Lxd0OWqbbMDrA8e_-ouGnjUY,36191
+mlrun/model_monitoring/stream_processing_fs.py,sha256=JDFigL-_UJ-s-JUPp3FMZWKMMtC7edN8poPM3Yo3lm0,43025
+mlrun/model_monitoring/stores/__init__.py,sha256=0FlHSjq2etDBnlzzj930LEF0p6bO7G5i_INTUtT-lLE,4240
+mlrun/model_monitoring/stores/kv_model_endpoint_store.py,sha256=krVYkYN8_G3TeXSAGS5ZXJQTM5LhymibK4vrP9ISvy8,16926
+mlrun/model_monitoring/stores/model_endpoint_store.py,sha256=-Brbv-jMx47rIFUPP0Ykb92o1KPyic9FgGBy4TA3ejs,5695
+mlrun/model_monitoring/stores/sql_model_endpoint_store.py,sha256=UEU2iOCchjXbdvcRpwqrQx0ES43gcMYIWU1jS-K8wdk,15700
+mlrun/model_monitoring/stores/models/__init__.py,sha256=ea5Sca62LlYpjsTDMlaxRyIjRCpwOPxRwFJ5sABur-k,884
+mlrun/model_monitoring/stores/models/base.py,sha256=Az7Q2JZKCTqZJ2hqYaOLr2owVMagClFp2KwuriKMx24,655
+mlrun/model_monitoring/stores/models/mysql.py,sha256=o8vaYdE1Cu2Rsd7AM6-xMHIr-qFEQ_LOvqoZlgFbnFM,3744
+mlrun/model_monitoring/stores/models/sqlite.py,sha256=kkQvEVzJcSZcf2PkA9-3tLpkJU5KZ-J-aht4uA2qU2c,3661
 mlrun/platforms/__init__.py,sha256=NNh9MSxgjdi7QftO3DHp4axQnBeO5IjxD8oR13_jp3A,2400
-mlrun/platforms/iguazio.py,sha256=ca77Lu7_WwmwmkOgxhyJtJ_z8UfMdd28mhPpebfcjbo,24642
+mlrun/platforms/iguazio.py,sha256=_a9IMZCn_YEN6hmTss0cLh1Hg44VVw5pJb9iUQxScVQ,22976
 mlrun/platforms/other.py,sha256=DwqbdbMNlkC2nEl1yJ0jF9WZJzjVu2IVPTC3bQ_W9Y0,11852
 mlrun/projects/__init__.py,sha256=dsXSDyqBhLi8OOfpdjLJpYOwC2fy_Q_Ki95Bk6gVSwc,1153
-mlrun/projects/operations.py,sha256=C-xqZ7tzLwaFtNN2Eujkn80X4l3kCQxAPnPRYpE-h6I,15873
-mlrun/projects/pipelines.py,sha256=5E6ZX8bVeP6RbqSfpDekREbUp5NwdvfiwrnqT2YHqyg,37274
-mlrun/projects/project.py,sha256=Fjlmtx6MEw-LkhPJLaSa80FLOv8yJJDk4-xbB5yVTpE,117036
-mlrun/runtimes/__init__.py,sha256=qWr7Ux9QzbDQtECuCVPHs3O5po0y2sOHdGWmx8ug5p4,6595
-mlrun/runtimes/base.py,sha256=EsxQKD7_jmCrFXLxgetlmUtHDLvtJWiW1dOGniirNFU,96046
+mlrun/projects/operations.py,sha256=RZAyhsi3VuqvJjA3gwknuSpWhM1BfOFsZ-lGX9fIXCQ,17302
+mlrun/projects/pipelines.py,sha256=6iYVViKMUaEfqGIrVgQdl4UjtbDHe0nzlNXkLKte8fo,37882
+mlrun/projects/project.py,sha256=SYzn0b8m2QuHofSVWgZ5sntjdBKobb4UlaHJjJpPJnI,103212
+mlrun/runtimes/__init__.py,sha256=1rNfzU3G76BxDkqvTVVrxlQkhLDSmlzv838_56OID7E,8973
+mlrun/runtimes/base.py,sha256=M5bJyOLqhEfSlkOD49SCpd_wH1bd4dMZle_03otYiG4,107571
 mlrun/runtimes/constants.py,sha256=Os_6YpWE8WMhigm1h3RKvn9Uo4LXNaEbA2xNSEDDEao,6689
-mlrun/runtimes/daskjob.py,sha256=Ff2LZYYTJm6wgmHf7ygYeIhZmla4b3O6r58nxzLIhr8,29821
+mlrun/runtimes/daskjob.py,sha256=Hol5_kzTfJBP4WN6orPlGSlSRDPec1HcBD8id_jSdPA,30403
 mlrun/runtimes/funcdoc.py,sha256=U5Hrkeo7i7CUnZFQ5g7-CyWMvXiQXPGrfsNdgsDAraQ,9190
-mlrun/runtimes/function.py,sha256=n2K_64AkI-XnNll1nZKGM8jkjM0n5Pj-bL92GPrs8Mw,60304
+mlrun/runtimes/function.py,sha256=vKTRqXtHAm__vVvaUJVozzFWqCdLFzulYr0Yy8_ZiKM,69047
 mlrun/runtimes/function_reference.py,sha256=ikxeXeFPAn7PpfYR1DPBRFc9MSXXFM34uH5z6iRTz9M,4911
 mlrun/runtimes/generators.py,sha256=WvXzsfZZWqxLV1ncZ-lzFHZH2ITK6ICROgDv2vfQUs4,6530
-mlrun/runtimes/kubejob.py,sha256=fvzqwbN0Qo8rNpZplCul2IIK-m-U9Z6AzecLemxBu-A,15672
-mlrun/runtimes/local.py,sha256=gGaBxKlLhWZkrqWDu-_xZf6OqKTj_LznlarMFc-2BEg,17083
+mlrun/runtimes/kubejob.py,sha256=nNxXZWKgLLgDdOSPaetZUngnSIp-yK9YUmBtCMUUQPU,17034
+mlrun/runtimes/local.py,sha256=cxT1RNSz0R1JQ2_SFLuQQhK7_nbsEc8_jdKHEUi8iFw,17858
 mlrun/runtimes/nuclio.py,sha256=ih2iwrJieeEom3iW0yU99QG4_u_Bdv7VWgs1CK4Q1P8,2885
-mlrun/runtimes/pod.py,sha256=ojx0DXsbJHn7Qr5MT69BtqSgDkfn2sHNriQnm4Rej4c,59226
-mlrun/runtimes/remotesparkjob.py,sha256=AfDQ2RimsWZ2ossI8ijZALUQ_V5zf3Jz6RHl-_dNk1s,7472
-mlrun/runtimes/serving.py,sha256=6Gw44AIxvQAdaysPWHGUk6CvMwWbIWR2HaL26gehPRI,29227
-mlrun/runtimes/utils.py,sha256=N90LT0m4Va5RD1nsPlsB8Ziy2bRapX3fXFALmjdo6PA,21026
+mlrun/runtimes/pod.py,sha256=sWtw5wkme43VrQVEYDiU67uSC4zBbSyzqXZFYwWYewM,60648
+mlrun/runtimes/remotesparkjob.py,sha256=Lp2EN32GQ1rY_34MEepdUzRTg-AP-OKyUM7xcy0Npb8,7695
+mlrun/runtimes/serving.py,sha256=ylR-qQJe-EvMrHc3C9g7oYRi3WVDSnTAvFXezus3dtE,29852
+mlrun/runtimes/utils.py,sha256=r1FGNRETsZykdsy_DNpbyvqxsVcTetYRdHg-aelFt1k,21249
 mlrun/runtimes/mpijob/__init__.py,sha256=E0oiOsSYsRBBR0HV6e_EGaL_j2_dYEJwAcICnF8mOYU,790
-mlrun/runtimes/mpijob/abstract.py,sha256=W78x9nOeZf0TsQAOtSE2syC0PwXYueOOtyzmZJtIIPY,15538
-mlrun/runtimes/mpijob/v1.py,sha256=QhKDdlai5gsdQJDN0LVoOixjOP1GVwCW9EqaIvFcB8g,12833
-mlrun/runtimes/mpijob/v1alpha1.py,sha256=Dq9JI_jpSBevPSQa1ooJhewqX9iuMi3kiKO8RTi3b98,7537
+mlrun/runtimes/mpijob/abstract.py,sha256=_6CCDl4FXNpDzg1qTiEQGaqXyblx4gXYquAdKIG0fk0,14782
+mlrun/runtimes/mpijob/v1.py,sha256=o-ZDw3O0HOzTMZ3lI3gMjGG0NYY0Ux3RqL0Kz9K3eV4,13845
+mlrun/runtimes/mpijob/v1alpha1.py,sha256=4rMpJk1C_gL6QtOmEFcgcmaCkHcor9mdKvIL46fEKFw,8460
+mlrun/runtimes/package/__init__.py,sha256=EHFvxDWnRkXqjmdv9Mj3O-nCYAFLbRsNgX5zR0ElwAk,673
+mlrun/runtimes/package/context_handler.py,sha256=5br30fRHHhWQJgSWF2zqf0M8XOxVr27ZkOFWVDgf4f0,27044
 mlrun/runtimes/sparkjob/__init__.py,sha256=cDzK8jEJvNsSSujDmEt03h1Mnlj7MUvdCEUXDNAb1wc,788
-mlrun/runtimes/sparkjob/abstract.py,sha256=C-_4vTrNOTsKR2z2n3GM9YF9mIRb4KOpoCI6ZMOjX0E,33761
+mlrun/runtimes/sparkjob/abstract.py,sha256=o5ykIx4GkwLU2QoQNQS9oNm5qebB17sOVblbh0ZDjG8,35976
 mlrun/runtimes/sparkjob/spark2job.py,sha256=StWv5hk99pHslkIpOzz5T-szCYN2kkC20ixEdlD3yIA,2033
-mlrun/runtimes/sparkjob/spark3job.py,sha256=RktxE6Vk9NqnwJdqzdvZmpTMvsBACMZOTg78qRekCYw,28644
+mlrun/runtimes/sparkjob/spark3job.py,sha256=JzwinNIiPXBapSC-gAsbhf81oouxhx41U5oQwoNeYhM,28722
 mlrun/serving/__init__.py,sha256=NP9VMS7aaFBGCspi-8dPqMzEXpDOIUJXcyjr-CCTaEY,1050
 mlrun/serving/merger.py,sha256=oRX6gJ3LUVeCJcTpJ1nwh4d1tk5FrSZshkXcH-y-dd4,6116
 mlrun/serving/remote.py,sha256=HJS9bz5_mUuaKGsNbqRKpo-eVHKbc1fIEOEsECPmnko,18038
-mlrun/serving/routers.py,sha256=ADfVvW1U4K9QkRqMmkJTyWGTDQmo3xZ5DdbvvFMnHwA,54988
-mlrun/serving/server.py,sha256=FGfecMTEfUKuilyQHm-XJtG4nZbllnR0vqMSVI6pHXY,18686
+mlrun/serving/routers.py,sha256=1F1TGz4W82tX_DZShG9tSc5eIOD8PmzexZ4kCTwiLk0,55244
+mlrun/serving/server.py,sha256=ePfYiefH3HkNag5qHDzDyoowaNNMbjJ9YKpPS9wX9Xw,19005
 mlrun/serving/serving_wrapper.py,sha256=ivoSlFNuC92plPHRfMzHr-hdN-jGqxneGiufJdgoxVc,836
-mlrun/serving/states.py,sha256=VNJFOCkP2wRmkSMdBjIJ-qDXqAO08byYHCR6brSdK9c,47891
+mlrun/serving/states.py,sha256=mhV1kS038iTGz6P-mvlmRFCrAG8THr9681LmO9aoreQ,48391
 mlrun/serving/utils.py,sha256=1fLfn07R4-RlUcdUgYYwUTFF47NozQmV9BnZVbu4-lU,3468
 mlrun/serving/v1_serving.py,sha256=UF6Ydgyo-DuHZ4DkrEdNMQl5oopVaZqm4EfBMBSvhDY,11814
-mlrun/serving/v2_serving.py,sha256=3Ozd_WeqfKG62xO3qo5ReBZ8fEZUB1qA8IWSCHOxDIw,21336
+mlrun/serving/v2_serving.py,sha256=uIKQnTITJozqk6WrmJhO0hKfjCl8FLYc_IpCEYt5elA,21441
 mlrun/utils/__init__.py,sha256=jT8jJCOKKOA8PnL4KC5eVd7yKmYJuN9_qrzGmvHcGns,855
 mlrun/utils/async_http.py,sha256=AvI4a9D0frI6XxHvqnQ4AzEXopezo90zZHvsOAJJt6g,10397
 mlrun/utils/azure_vault.py,sha256=atz9fIu1vfgWAND1g6flRQDhrX-xBxZ_6MOWm34Onh0,3456
-mlrun/utils/clones.py,sha256=dPySydbVA6FLK1y7otJUD8DoIVp01pT3cQJ5abHNTc4,6186
-mlrun/utils/helpers.py,sha256=qhKQKR6y8UKDgYCn2f5e6Qo2hN5thSbPcYRlqZH_JH4,35912
-mlrun/utils/http.py,sha256=aoIL-QEjBjtO9zf5C6ggRtMIcnXA9ou0UYPZgbMuuvM,6061
-mlrun/utils/logger.py,sha256=Vq27m07TlE18KQtrYPLtVytbhKA-LtCOBQ_mp-Ll-J0,5324
-mlrun/utils/model_monitoring.py,sha256=xOS_E2lYY5oiHQqlD3aZhcCT_dd8OLH5Y_iLua0praw,7097
-mlrun/utils/regex.py,sha256=GY8Kpg50vcZ6YGtMxU1abdwN0CKGeooceYbGiHQleHc,3923
+mlrun/utils/clones.py,sha256=lKgQeibQ3xQ9LH5bZTZCoYCXoOx_2mYNGD5A-OOxwAQ,6245
+mlrun/utils/db.py,sha256=SqDrvIpGX_qHs0MNx_PWQNRcUhHaKLngoHFKLW3m5j0,1662
+mlrun/utils/helpers.py,sha256=V7mWXFogvtNGPIrx_D7AdT7wNixCpU1XVniAHHQXZkA,41426
+mlrun/utils/http.py,sha256=FVgdYV8Np3TKbqszEtXrlgwqNyjScTMLAjJhlsWLifo,7093
+mlrun/utils/logger.py,sha256=O4pH45kdz0cO-e4eKeRxbZUIRLGn2X0BJcjSY9cWB04,5637
+mlrun/utils/model_monitoring.py,sha256=wS6T9KgG-XCB21MNc6edNODEqFBBqzi5bUgSvPpKt-c,7875
+mlrun/utils/regex.py,sha256=3hSOVEU5128xio_3BLBEmvvRGLipmGP2Sh7XgVAYs8w,3954
 mlrun/utils/singleton.py,sha256=kV9HhbzdmXo8gGKBPdbHWspRDutlkKX1ZEn96xs_LRs,883
 mlrun/utils/v3io_clients.py,sha256=ekxhjfcUnjV8cejQYTQUHnhYOKHA4KekIdSaywydTdM,1319
 mlrun/utils/vault.py,sha256=1zr_3gkXoerYID_4Z5vYkBO9FeCKd43Qm-XlmGBk_Ok,9957
 mlrun/utils/notifications/__init__.py,sha256=CgWLxslSqhTH-tExi_UR4AT-ipjkGUF4gwf9mKcNua8,990
 mlrun/utils/notifications/notification_pusher.py,sha256=C5PZYwHPHmwnbES1zTVGKz4_wbX7cR3pDl1PDqjM4hA,7093
 mlrun/utils/notifications/notification/__init__.py,sha256=s7owPm6jGxuN_JBU0nFac6iD6BuLhEbnhq-NMF1TLf8,1833
 mlrun/utils/notifications/notification/base.py,sha256=dkUmwB1-o1qpFs9MCIOkYAZYsODelkU2xm1iRM3wJlU,2067
 mlrun/utils/notifications/notification/console.py,sha256=QCdulv9i8nCCYAA8ftmf22vvZwBp3SRBCKiB0v1WBQY,1901
 mlrun/utils/notifications/notification/git.py,sha256=qI5Kd4U0PX8vfIVT_yjBIrToiJYzCS-XvY96Xck2Nkc,4510
 mlrun/utils/notifications/notification/ipython.py,sha256=jsM_tTV3ZzXv5NoQN2anfZJDTYsk95NDYVQnWFc9Zow,1951
 mlrun/utils/notifications/notification/slack.py,sha256=wt6RlqJu9QC99Ki-3HNYmizYTyAnIVimFQ7bf-fYX2E,3650
 mlrun/utils/version/__init__.py,sha256=hwfJgGWYGWFpepVGI1GbuCPqqEFGRbgguJg5sC0v4TU,614
-mlrun/utils/version/version.json,sha256=qc33ymN89BDu7wYZ6ZJRm9eHVO2W0kmv40OKuMR3bYg,88
-mlrun/utils/version/version.py,sha256=zGuJajSRu6-nr0TIY8QkG23pw8fBS-BrAIhtvbi9S88,1469
-mlrun-1.3.0rc9.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-mlrun-1.3.0rc9.dist-info/METADATA,sha256=vhZknG7PqFAbHBjSvMSEXiOUlHQqB1KrGROa04LF24I,16288
-mlrun-1.3.0rc9.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-mlrun-1.3.0rc9.dist-info/entry_points.txt,sha256=ZbXmb36B9JmK7EaleP8MIAbZSOQXQV0iwKR6si0HUWk,47
-mlrun-1.3.0rc9.dist-info/top_level.txt,sha256=NObLzw3maSF9wVrgSeYBv-fgnHkAJ1kEkh12DLdd5KM,6
-mlrun-1.3.0rc9.dist-info/RECORD,,
+mlrun/utils/version/version.json,sha256=5cmcFaHZ0ibGXvIK-sKSAldeT3hnOUtlM7IIVbgCejw,88
+mlrun/utils/version/version.py,sha256=O4Q4kwtKlI73oK7oBPuz4SVkUI8BC11E9DJIKHT91kU,1970
+mlrun-1.3.1rc1.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+mlrun-1.3.1rc1.dist-info/METADATA,sha256=JSX6dsizs2aK3tG6ckCdj7CuSv5FHO6-xZ0d9KCbiuU,16975
+mlrun-1.3.1rc1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+mlrun-1.3.1rc1.dist-info/entry_points.txt,sha256=ZbXmb36B9JmK7EaleP8MIAbZSOQXQV0iwKR6si0HUWk,47
+mlrun-1.3.1rc1.dist-info/top_level.txt,sha256=NObLzw3maSF9wVrgSeYBv-fgnHkAJ1kEkh12DLdd5KM,6
+mlrun-1.3.1rc1.dist-info/RECORD,,
```

